{"meta":{"title":"K A I","subtitle":"","description":"","author":"Kaillliu","url":"http://kaillliu.github.io","root":"/"},"pages":[{"title":"","date":"2022-03-28T10:54:00.479Z","updated":"2022-03-28T10:54:00.479Z","comments":true,"path":"manifest.json","permalink":"http://kaillliu.github.io/manifest.json","excerpt":"","text":"{\"name\":\"string\",\"short_name\":\"Junzhou\",\"theme_color\":\"#49b1f5\",\"background_color\":\"#49b1f5\",\"display\":\"standalone\",\"scope\":\"/\",\"start_url\":\"/\",\"icons\":[{\"src\":\"images/pwaicons/36.png\",\"sizes\":\"36x36\",\"type\":\"image/png\"},{\"src\":\"images/pwaicons/48.png\",\"sizes\":\"48x48\",\"type\":\"image/png\"},{\"src\":\"images/pwaicons/72.png\",\"sizes\":\"72x72\",\"type\":\"image/png\"},{\"src\":\"images/pwaicons/96.png\",\"sizes\":\"96x96\",\"type\":\"image/png\"},{\"src\":\"images/pwaicons/144.png\",\"sizes\":\"144x144\",\"type\":\"image/png\"},{\"src\":\"images/pwaicons/192.png\",\"sizes\":\"192x192\",\"type\":\"image/png\"},{\"src\":\"images/pwaicons/512.png\",\"sizes\":\"512x512\",\"type\":\"image/png\"}],\"splash_pages\":null}"},{"title":"about","date":"2022-03-27T10:02:17.000Z","updated":"2022-03-29T05:26:19.360Z","comments":true,"path":"about/index.html","permalink":"http://kaillliu.github.io/about/index.html","excerpt":"","text":"不知道这一页该放些啥，就放个邮箱吧，有啥事可以发邮件联系我😄 邮箱：kaillliu@163.com"},{"title":"分类","date":"2022-03-27T09:43:43.000Z","updated":"2022-03-28T06:10:42.758Z","comments":true,"path":"categories/index.html","permalink":"http://kaillliu.github.io/categories/index.html","excerpt":"","text":""},{"title":"404","date":"2022-03-27T10:04:11.081Z","updated":"2022-03-27T10:04:11.081Z","comments":true,"path":"404/index.html","permalink":"http://kaillliu.github.io/404/index.html","excerpt":"","text":""},{"title":"站外链接","date":"2022-03-28T06:11:16.000Z","updated":"2022-03-28T06:14:09.815Z","comments":true,"path":"link/index.html","permalink":"http://kaillliu.github.io/link/index.html","excerpt":"","text":""},{"title":"contact","date":"2022-03-27T10:13:42.000Z","updated":"2022-03-27T10:13:54.674Z","comments":true,"path":"contact/index.html","permalink":"http://kaillliu.github.io/contact/index.html","excerpt":"","text":""},{"title":"标签","date":"2022-03-27T09:44:50.000Z","updated":"2022-03-28T06:10:24.448Z","comments":true,"path":"tags/index.html","permalink":"http://kaillliu.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"计算机网络 面试题 总结回顾（2）","slug":"计算机网络基础题库","date":"2023-08-18T07:00:00.000Z","updated":"2023-09-08T04:38:10.523Z","comments":true,"path":"2023/08/18/计算机网络基础题库/","link":"","permalink":"http://kaillliu.github.io/2023/08/18/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E9%A2%98%E5%BA%93/","excerpt":"","text":"场景篇 介绍一下OSI七层协议,各层都是做什么的?各自都有什么协议? OSI七层协议的全称是开放互联系统协议,这个系统一共有七层,从上到下依次是: 应用层:这一层主要通过定义各种各样的应用层协议的头部,来完成用户所需要的目标功能,比如说HTTP协议通过定义cache-control这样的头部字段来完成浏览器的缓存控制,还有例如FTP协议、SMTP协议,也都是通过定义协议的相关字段来实现相关的功能的 表示层:这一层主要通过双方协商的相关字段来确定双方数据传输的时候的编码格式,比如说有ASCII格式等,意思是说将上层交付下来的报文基于这个ASCII这个格式来编码和解码 会话层:会话层主要用来控制底层传输层协议中TCP协议、UDP协议相关的会话建立，主要通过定义一些协议,来控制不同机器上用户之间建立以及会话的管理,比如说有RPC协议,SSL协议,TLS协议等 传输层:传输层主要是将上层的数据包交付到下一层的网络的,同时在下层网络层发生了异常的时候,在上层的传输层协议要提供必要的控制来保证数据到达对等端,最为典型的就是TCP协议了 网络层:网络层中的核心是路由器,可以说路由器的功能就代表了网络层的功能,主要是要完成网络中分组的分组转发,路由选择,同时在协议的支持下,对错综复杂的、异构的网络进行规划和编址,典型的协议就有IP协议,还有BGP协议等 数据链路层:网络层解决了异构网络数据网络之间的机器如何通信的问题,那么数据链路层就解决了局域网内的机器是如何通信的问题了,它将上层交付下来的数据转换为MAC帧,然后基于MAC地址(机器的物理地址)进行寻址,将具体的比特流发生到具体的机器上,常见的协议就有CSMA/CD协议,这个协议的全称是带载波监听的多路访问技术,完成的是局域网内的数据传输 物理层:物理层解决了从计算机或者物理设备发出的数字信号如何转换为光电信号的问题。 IP协议和TCP协议属于哪一层? IP协议属于网络层,TCP协议属于传输层 输入一个URL发生了什么? 举一个例子,假设输入了www.baidu.com到浏览器中,这时候发生了什么? 第一步,浏览器会解析你输入的URL得到必要的信息,然后封装成HTTP请求,比如说访问百度的这个URL,具体来说就是封装一个GET的HTTP请求,封装对象分别是 请求行:HTTP协议的版本,选用的请求方式(Get or Post) 请求头:协议的头部字段,比如说有keep-alive、connection、cache-control这些字段 请求行:用来分割请求的首部和请求体的一个空行 请求体:存放具体的数据,像这个GET请求就不会有数据 一般来说,执行完这个HTTP请求的封装的时候,就会交付到操作系统的协议栈中,但是这时候还少点信息,因为这时候给的URL是一个域名,在IP层是无法直接通过域名来找到对方的主机的,因此在这样的情况下,还需要通过DNS协议来找到对方的主机IP地址 第二步,基于DNS协议完成域名=&gt;IP地址的解析,这个解析一般来说需要经过以下的步骤: 客户端(浏览器)会发送一个DNS查询请求,会向本地域名服务器查询:这个url的ip地址是什么?如果本地域名查询到了,那么就直接返回到客户端,如果查询不到,它就会给根域名服务器的地址给本地域名服务器,也就是给.这个域名服务器的地址给它 本地域名服务器再拿着这个根域名服务器的地址,然后去问这个根域名服务器,这个url的ip地址是什么? 由于根域名服务器并不直接存储域名的IP地址映射,它存储的是各个顶级域名服务器的地址,因此这时候就会给.com的地址给它 本地域名服务器查询顶级域名服务器,如果顶级域名服务器也不知道,就会给它发权威域名服务器的地址,也就是负责www.baidu.com这个域名的地址,这时候权威域名服务器如果发现它的缓存中有数据,那么就可以直接返回了,如果发现缓存中没有数据,就会直接报错 第三步,解析出来了IP地址后,就会交给底层的网络协议栈,通过系统调用Socket库中的相关功能,完成网络的传输 第四步,交由TCP协议进行打包和连接的建立,简单来说就是将上层的HTTP请求数据包包装成TCP报文,然后和对等端三次握手之后,将数据包发送出去。 第五步,TCP包在将数据报交付出去的时候,会经过IP层,这一层的主要作用是根据IP地址来决定要如何转换,在操作系统中,有一个叫做路由表的东西,在linux系统中可以通过route -a这样的指令来查看,在执行转发的时候,会将IP地址和这张表中的路由条目进行与运算,如果得到匹配的结果之后,这个数据包从哪个接口出去,用哪张网卡的IP地址作为IP数据包的包头的字段,就都知道了 第六步,当数据包来到了目标网段之后,这时候就会将IP包包装为MAC帧,具体的过程是这样的,首先就是先读取本机的MAC帧,它是通过读取本机的ROM来获取的,然后要获取对方的MAC地址,它是通过ARP协议来实现的,过程是本机向外广播说:”谁的IP地址是xxx,收到请回复”,然后收到这个广播的机器就会比对自己的IP地址,如果匹配上了,那么就会发送一个回包,说的是:”我的IP地址xxx,我的MAC地址是xxx”,然后本机收到之后,就会将这个映射IP=&gt;地址写入到ARP缓存中,下次还得发数据的时候就用缓存中的内容就可以了 第七步,封装好MAC帧,到达了网卡,网卡将数据发送出去的时候,一开始是数字信号,然后通过网络适配器中的调频器之类的适配,将其转换为光电信号在电路上传输,最终就到达了目标机器 目标机器在收到这个包之后,就执行拆包等操作,拆出来HTTP请求的原包,然后解析请求,后台服务器返回一个html页面的数据,原路返回,原机器收到后,也是一顿拆包,然后最终浏览器得到了响应体中的数据,将这个数据渲染到了页面上了 DNS是如何解析的?属于哪一层的协议? DNS的解析分为两种,分别是递归查询和迭代查询,其中迭代查询的方式大致如下: 客户端(浏览器)会发送一个DNS查询请求,会向本地域名服务器查询:这个url的ip地址是什么?如果本地域名查询到了,那么就直接返回到客户端,如果查询不到,它就会给根域名服务器的地址给本地域名服务器,也就是给.这个域名服务器的地址给它 本地域名服务器再拿着这个根域名服务器的地址,然后去问这个根域名服务器,这个url的ip地址是什么? 由于根域名服务器并不直接存储域名的IP地址映射,它存储的是各个顶级域名服务器的地址,因此这时候就会给.com的地址给它 本地域名服务器查询顶级域名服务器,如果顶级域名服务器也不知道,就会给它发权威域名服务器的地址,也就是负责www.baidu.com这个域名的地址,这时候权威域名服务器如果发现它的缓存中有数据,那么就可以直接返回了,如果发现缓存中没有数据,就会直接报错 迭代查询中的请求者都是本地域名服务器,也就是说这种模式中,根域名服务器这一类的服务器是只指路不带路 而递归查询则是带路,后续的查询工作需要根域名服务器这些服务器来完成 输入一个域名,是怎么知道端口号的? 首先,通过域名是只能够知道IP地址的,是无法知道端口的,但是对于HTTP请求或者是HTTPS请求来说,有一个默认的端口号是80和443,它会先去尝试这个端口号能否完成通信,如果无法完成通信就报错 但是对于一些完成有特殊需求的,比如说像Java开发的Tomcat服务器,端口通常是8080,这个端口必须指明,否则无法访问 如果浏览器没有显示页面有哪些原因? 这个问题从输入URL之后发生了什么为切入点进行思考 (1)输入的URL有问题,url的组成是&lt;协议类型:ip:端口/域名/文件路径&gt;,可能是文件路径输错了,在服务器上找不到这个文件,就空白了 (2)url中,ip/端口不对 (3)TCP连接出现问题,网络超时,导致页面没有及时传输过来 (4)IP层出现问题,比如说路由器挂掉了,无法完成分组转发 (5)数据链路层中,底层的ARP缓存中数据不正确,就是说ARP缓存的是旧数据,所对应的机器的MAC地址已经失效,需要重新发广播请求 客户端TCP连接一个不存在的IP地址的服务端会发生什么? 这个问题就是在Linux中执行ping xxx.时候,如果输错了IP地址会发生什么? 这个问题我需要从两种情况进行回答: 首先第一种情况,当目的的IP地址和本机的IP地址处在同一个局域网的时候,由于机器在转发的时候,它有一个机制,就是拿到一个数据包,它会先去判断这个IP是否和主机本机地址处于一个局域网中,如果处于一个局域网中的话就不会走路由表,否则的话就会去走路由表的相关判断 因此在这样的情况下,它会直接将上层的TCP交付到IP层,然后IP层包装好目的IP地址和本地的IP地址的之后,就会将这个包交给数据链路层,数据链路层首先是基于ARP协议,在局域网内广播:谁的IP地址是xxx,这时候因为你的IP地址就是不存在的,所以在这样的情况下,那么就肯定收不到回复了,于是无法组成MAC帧在局域网内传播。 第二种情况,当目的的IP地址和本机的IP地址不是处在同一个局域网的时候,本机会查询路由表,一般来说会匹配到默认路由,就是本局域网的默认网关,然后就会将这个TCP报文发向这个默认网关,默认网关收到后,也会查路由表,不过因为这个IP地址不存在,因此会在网络中不断转发,直到TTL耗尽,此时客户端不会收到响应,因此会不断超时重传,超时重传达到一定的次数之后,就会直接断开连接了 第三种情况,就是这个IP地址所属的局域网网段在网络中是存在的,但是在网络中不存在,在这样的情况下,被发送到目的网段之后,就会回到第一种情况,无法组装成MAC帧,最终就无法响应了 客户端 tcp 连接一个ip地址存在但是端口不存在的服务端会发生什么？ 首先,IP地址是存在的,那么这就意味着你的SYN报文可以正常达到对方的机器,然后对方机器收到你这个包之后,通过网络协议栈的处理,发现在系统中并没有任何一个进程在监听这个端口,这时候TCP协议会认为这是个错误,于是内核就会发送一个RST的复位报文,重置连接 客户端UDP发送一个IP地址存在但是端口不存在的报文会发送什么? 首先,IP地址是存在的,这就意味着UDP报文可以正常到达对方的机器,然后对方的机器收到这个包之后,发现本机上并没有任何一个进程在监听这个端口,于是这时候UDP包会被简单地丢弃。 但是要注意,此时ICMP协议会帮我们打小报告,也就是说当收到UDP包之后,会返回差错报文信息,这个差错报文信息的类型是端口不可达,这时候的含义是:你的UDP报文正确达到了对方的机器,但是端口是无效的 HTTP篇 HTTP的报文格式是怎么样的?是如何分割的? HTTP的报文可以分成是HTTP请求报文和HTTP响应报文,这两种报文的格式分别是: 12345678HTTP请求报文:&lt;请求行(包含有HTTP协议的版本,所用的请求方法)请求头(包含有HTTP协议中规定的协议头部字段,比如说有cache-control,content-type)空行(CR+LF),用来分割请求头和请求体&gt;请求体(Post请求一般会携带相关参数,Get请求一般将参数放在URL上)HTTP响应报文:&lt;响应行(包含有HTTP协议的版本,响应码,关于这个响应码的简要说明)响应头(包含有HTTP协议中规定的协议头部字段,比如说有Content-Type,用来告诉客户端本次返回的数据格式)&gt;空行(CR+LF),用来分割请求头和请求体响应体(返回本次服务端响应的内容) HTTP有哪些方法? HTTP请求的方法有:Get、Post、Put、DELETE、Head等 Get请求和Post请求有什么区别?Get请求一定具有幂等性吗? 关于他们的区别,可以从以下这几个方面进行讲述,首先从RFC的语义来看 Get请求是从服务端上获取资源,它是可以被缓存的,意味着对服务端的操作是只读的,它是安全而且幂等的 Post请求是向服务端上推送资源,本质上是根据这个Post的请求报文来对服务器上的资源进行修改,它会更新服务器上的资源,同时由于报文中携带数据,可能有一定的安全隐患,同时由于对服务端上的资源做了修改,因此它不是幂等的 从报文的格式来说: Get请求一般不在请求体中携带参数,而是在URL上携带参数,这也就意味着有一定的限制,因为URL只支持ASCII码,同时长度具有一定的限制,不适合携带大量的二进制数据 Post请求一般是在请求体中携带参数,它支持传输二进制的数据,同时参数不会暴露在URL上。 问题:Get请求一定具有幂等性吗? 不是,从RFC的语义来讲,Get请求就是只读的,无法你触发多少次,最终的结果都是一样的,因为只读文件而不会修改文件,但是在实际开发中,这取决于开发者,如果开发者在返回资源的时候,对服务器上的资源做了修改,那么这时候就肯定不是幂等的了 关于安全的说法:安全是指传输的报文会不会被篡改,会不会被窃取,如果使用HTTP的话就肯定不是安全的,因为HTTP是明文传输的,要实现安全,可以使用引入了TLS/SSL协议的HTTPS协议 HTTP有什么状态码? HTTP的状态码比较多,但是可以根据百位数来确定这些状态码的大致含义是什么 1xx:这种状态码比较少见,我见过的只有在网站协议从简单的HTTP协议升级成WebSocket协议的时候看到过,在服务器返回支持协议升级的时候,这时候就会返回一个101的状态码,告诉客户端,目前正在的进行通信协议需要更换了. 2xx:对方正常响应,也就是说报文被收到了而且正常处理,一般来说有: 200 OK:表示服务器处理成功,一般来说会给一个content 204 Not Conent:和200的含义是一致的,但是返回的响应体中没有数据 206 Partial Content:常见于断点续传和分块下载,表示当前分片处理成功了,是全部数据的一部分处理成功了 3xx:表示资源路径的变更情况,主要来说有: 301 Moved Permanently表示永久重定向了,这时候会返回一个Location字段,其中的值就是要重定向的地址,永久重定向的表现为:你浏览器的地址栏的url变成了这个location的地址 302 Found表示临时重定向,表示资源还存在,但是暂时需要用其他的url进行访问 304 Not Modified:这个状态码通常出现在HTTP协议中的缓存处理中,通过这个状态码就知道当前的缓存没有过期,可以接着使用 4xx:一般来说是前端的错误,主要来说有: 400 Bad Request表示你的请求报文有问题,服务端无法解析,但是是一个非常笼统的错误反馈 403 Forbidden前端发送的报文是没有问题的,但是服务端拒绝让你访问这个资源 404 Not Found前端给的路径有问题,服务端上找不到这个资源 5xx:一般来说是服务端有问题,主要来说有: 500 Intetnal Server Error:服务器的内部错误,表示服务器处理产生了异常 501 Not Implemented:暂时没有实现,请以后再来 502 Bad GateWay:代理服务器可以正常工作,但是实际工作的服务器产生了异常 503 Service Unavilable:当前服务器很忙,暂时无法响应客户端 重定向是哪一类状态码?临时重定向和永久重定向有什么区别? 重定向是3xx的状态码,关于临时重定向的区别和永久重定向的区别有: 临时重定向是302状态码,这时候你浏览器的URL并不会变成Location中的url 永久重定向是301状态码,这时候浏览器的URL会变成Location中的url HTTP1.1 和HTTP2.0的区别? 在具体HTTP1.1之前,可以先讲讲HTTP1.0的特性,然后过度到HTTP1.1 HTTP1.0的特性 HTTP1.0是短连接的连接维持方式,也就是说在底层的TCP完成三次握手之后,就发送一次数据之后就会发送四次挥手然后结束通信,因此开销是比较大的 第二个特性是它存在一个HTTP层面的请求队头阻塞的问题,这个问题是这样说的,HTTP1.0仅支持串行的发送HTTP请求,也就是说只有当上一个请求发送出去了,后面的请求才能继续发送,这个问题的本质原因是因为它仅支持短连接,根本无法在同一条TCP连接上同时发送HTTP报文 第三个特性是HTTP1.0是明文传输的,头部没有做压缩,传送数据是用的纯文本的格式,这意味着机器在收到这个报文之后,还需要将文本格式的数据转化为二进制格式的数据之后才能读取 HTTP1.1的改进与特性 HTTP1.1改进了短连接,实现了底层的TCP连接的连接复用,通过底层TCP连接的连接复用,可以减少因为三握四挥造成的额外开销。 第二个特性是它解决了HTTP1.0中请求队头阻塞的问题,通过一种叫做管道(可以同时发送多个HTTP请求而不必等到响应回来)技术来实现的,提高了HTTP报文的发送效率,但是这个特性带来的问题是响应队头阻塞的问题,这个问题具体来说就是,在接收响应的时候,只能够按照请求的顺序来接收响应并且处理,后面发送请求但是先到来的响应,尽管数据已经被接收了,但是依然无法提交到用户缓冲区中供其使用,造成一定的浪费 HTTP1.1还没有解决的问题和性能瓶颈 请求的头部没有经过压缩,每次都需要发送大量冗余的头部,比如说Content-Type这样的字段,通常来说在HTTP请求中不会经常变化,但是每次请求都会带上这个请求头,造成一定的浪费 报文明文传输,不安全 报文是以文本格式定义的,这意味着如果它要被计算机处理,那么首先要经过二进制的转换,所以在这样的情况下,会增加一定的开销 好好的全双工的TCP被HTTP协议完成了单工协议,这样的话无法完全利用底层的TCP协议 HTTP2.0的改进以及它与HTTP1.1的区别有哪些? HTTP2.0解决了头部开销的相关问题,由于每次都会携带大量冗余相同的头部字段,那么它采用了一种叫做HPACK的算法,这个算法的工作流程是将HTTP头部中的这些字段存储到机器上的一本字典中,举个例子Content-Type = application/json,这个键值对会被记录到一本字段中,并且会获得一个索引号,比如说3,这样的话就将大量的字符压缩成了一个整形,HTTP解析头部的过程,只需要到字典中去查询这个索引号所对应的数据就可以了 第二个改进的地方,HTTP2.0变得安全了,它的底层是基于HTTPS这样的协议来保证数据不会明文传输,保证不会被篡改等 第三个改进的地方,HTTP2.0将报文的编码格式换成了二进制编码格式,虽然这样对人不友好,但是对计算机是友好的,计算机只需要读取这个报文,而不需要对报文做编码转换,提高了解析的效率 第三个改进的地方是就解决了HTTP层面的响应队头阻塞,HTTP2.0中提出了一种叫做Stream的技术,这种技术主要实现了并发传输,实现原理是:首先在一个TCP连接中,可以同时传输多个请求/响应,这些请求和响应被包装成Message,然后一个Stream会运输若干个这种Message,当这些Stream到达对等端之后,这时候就会根据Stream头部中的StreamId字段,拼装成完整的HTTP报文,这也就意味着,不同的HTTP请求可以同时发送,同时对等端也能够有能力并发处理这些响应,意思是说不必按照请求的发送顺序来处理响应了,而是谁的响应先到,谁先被组装成完整的HTTP报文的话就可以先处理了,这就很好的解决了队头响应阻塞的问题 第四个改进的地方就是实现了服务器资源推送的功能,客户端和服务端都可以新建Stream,通过客户端发送的StreamId都是奇数,服务器发送的StreamId都是偶数的方式来区分Stream,通过这样的区分,就可以实现双向数据的传输而不至于混淆双方的数据,充分利用了TCP协议全双工的特点。 HTTP2.0有什么缺点? 缺点主要有: 存在一个TCP层面的队头阻塞,TCP层面的队头阻塞是讲,当TCP的滑动窗口不够大的时候,这时间会将后续的报文给丢弃掉,举个例子,TCP的滑动窗口值能够容纳Stream1和Stream2的内容,但是现在在TCP线路上并发了Stream1、2、3,这时候因为Stream2和Stream1丢失了,因此滑动窗口停留在初始状态,但是Stream3的内容到达了,但是由于TCP的滑动窗口中没有这个范围的数据,因此Stream3的数据尽管了到达了也会被丢失,白白发送了,这就是TCP队头阻塞的问题 HTTP2.0和HTTP3.0的区别？ 由于HTTP2.0存在有一个TCP层面的队头阻塞的问题,所以在这样的情况下,HTTP3.0索性将底层的TCP协议替换成了UDP协议 问题:HTTP3.0的底层换用了UDP协议,那么如何来保证传输的可靠性呢? 其实这个问题就是如何基于UDP协议来实现一个可靠的传输协议,可以借鉴一下。 答案是QUIC协议,这个协议有这样的特点: 没有队头阻塞:为什么没有?首先QUIC协议中也有类似于Stream的概念,每一个Stream中包含有若干个message,如果其中一个message丢失了,不会阻塞其他的stream的传输,只会影响本stream,这是因为它底层是UDP实现的,是面向数据报而不是面向字节流的,因此只要对应的包达到了就可以了,而不像TCP协议这样必须保证每个字节都必须按照顺序到达,那么如果丢包了,就会触发当前stream的当前包的重传而已 更快的连接建立:HTTPS的底层如果是TCP连接的话,首先要完成TCP的三次握手,然后再完成SSL/TLS协议的三次握手,但在QUIC协议下,这个握手过程只需要一个RTT,QUIC协议包含了TLS协议,它会在自己的帧中携带TLS中的记录,就相当于在完成QUIC握手的同时,完成了TLS的三次握手,这个过程主要是完成TLS认证的同时也去完成了QUIC的连接ID的确立 连接迁移:上面提到了一个概念叫做连接ID,连接ID是用来标识一对设备的,在TCP中,我们用四元组&lt;本机IP,本机端口,目的IP,目的端口&gt;,只要这四元组中有一个不同,就需要重新建立连接,于是在这样的情况下,如果是TCP连接,比如说本来用WIFI连接的,现在换成流量了,那么就要重新连接,是具备一定连接成本的,但是QUIC不一样,只要本机记住了连接ID,就可以一直用这个连接ID来标识自己,这样的情况下,就不需要重新执行QUIC的三次握手了 HTTP用户后续的操作，服务端如何知道属于同一个用户？ 首先先说问题所在,HTTP是无状态的协议,服务器不会去记忆HTTP的状态,每次请求到来,它都认为是一个新的请求,这样的话就无法起到记忆的效果了。那么要实现记忆的通常是基于Cookie-Session来实现的。 具体的流程是这样的,客户端向服务器请求登录,验证通过之后,这时候就会在响应的头部打上一个标签,通常是什么JSessionId这样的字样,这其实就是在服务器的底层中,它创建了一个map,然后设置了一个键值对&lt;JSessionId,Object&gt;,这个Object就是Session 然后下次客户端来访问服务器的时候,这时候就会将JSessionId带上发送到服务端,然后服务端就会拿着这个JSessionId就去查底层的map,拿到这个session之后就知道来的人是谁了 如果服务端是一个集群机器？ 服务端是一个集群机器,我们上面知道了,存放实体数据的实际上是存放在服务器内存中的session,集群服务器之间内存是不共享的,办法主要有: 引入中间件,比如说redis,设计一个分布式session,这样的话每一个机器就都能够访问redis,也就都能共享你这个session了 cookie 和 session有什么区别? 先说结论,cookie是存放在客户端的,通常存放在浏览器的缓存(临时)/磁盘(可永久持久化,也可以设置过期时间),它是用来标识服务端上存储的session的,而session是放在服务端中的,通常是存放在服务器的运行内存中,如果服务器重启了,那么就可能导致Session丢失了,需要重新获取 什么是JWT?讲讲原理和校验机制 JWT本身就是无状态的,它包含了身份验证所需要的全部信息,因此服务器就不需要保存session了,这样的话无论你的服务器是否重启,或者中间件服务器是否发生数据丢失,只要客户端存有这个token,就可以完成身份的验证 JWT有三个部分组成,分别是: Header 1234&#123; &quot;alg&quot;:&quot;HS256&quot;, &quot;typ&quot;:&quot;JWT&quot;&#125; alg:签名的算法,typ:令牌的类型 Payload 123&#123; &quot;userName&quot;:&quot;123456&quot;&#125; 主要包含了一些注册声明和公有声明,私有声明,这个部分默认是不加密的,因此不要将隐私信息存储到这个payload中 Signature数字签名,主要是防止对前两部分进行篡改,主要的算法就是将Header和Payload拼在一起,然后用只有服务器知道的密钥,基于签名算法计算出一个签名,如果对方不知道密钥,那么篡改之后得到的签名和用服务端密钥签名所得到的结果肯定是不一样的 JWT实现身份校验的原理是什么? (1)用户向服务器发送用户名,密码以及验证码用来登录系统 (2)如果用户名和密码正确的话,那么服务端就会签发一个token,也就是JWT (3)用户以后每次向后端发送请求的时候,都会在Header中带上个JWT (4)服务端得到这个JWT之后,获取用户端的相关信息 什么是CSRF攻击? 跨站请求伪造,简单来说就是用你的身份去做一些不好的事情,尤其是当你的JWT是存储在你的Cookie中的话,假设你到Cookie中存储了一个银行的JWT,然后在一个非法网站中藏了一个请求,这个请求截取了你的JWT,然后用你的这个JWT去完成转账操作,这样你的钱就被骗走了 JWT这种技术适合在客户端中使用,因为不需要cookie 如何动态刷新JWT? (1)定期检测更新JWT 服务端给的 JWT 有效期设置为 30 分钟，服务端每次进行校验时，如果发现 JWT 的有效期马上快过期了，服务端就重新生成 JWT 给客户端。客户端每次请求都检查新旧 JWT，如果不一致，则更新本地的 JWT。这种做法的问题是仅仅在快过期的时候请求才会更新 JWT ,对客户端不是很友好。 (2)每次请求都返回新 JWT 这种方案的的思路很简单，但是，开销会比较大，尤其是在服务端要存储维护 JWT 的情况下。 (3)JWT 有效期设置到半夜 这种方案是一种折衷的方案，保证了大部分用户白天可以正常登录，适用于对安全性要求不高的系统。 (4)用户登录返回两个 JWT 第一个是 accessJWT ，它的过期时间就是JWT本身的过期时间比如半个小时 另外一个是 refreshJWT 它的过期时间更长一点比如为 1 天。 客户端登录后，将 accessJWT 和 refreshJWT 保存在本地，每次访问将 accessJWT 传给服务端。服务端校验 accessJWT 的有效性，如果过期的话，就将 refreshJWT 传给服务端。如果有效，服务端就生成新的 accessJWT 给客户端。否则，客户端就重新登录即可。 什么是跨域?什么情况下会发生跨域请求? 跨域:浏览器不能够执行其他网站的脚本,它是因为浏览器的同源策略导致的,跨域限制访问,实际上是浏览器的限制 在以下的情况将会发生跨域请求 协议不同,比如说服务端支持的是HTTP请求,而你发送了HTTPS请求 域名不同 端口不同 Restful是什么?Restful请求的URl有什么特点 Restful中提供的请求方法中有Get、Post、Put、Delete这四种操作 Rest风格倡导URL地址使用统一的风格设计,从前到后各个单词使用斜杆分开,不使用问号键值对的方式携带参数,而是将要发送给服务器的数据作为数据作为URL地址一部分,以保证整体风格的一致性。 具体的特点可以结合平时开发过程中定义的url进行说明 比如说做一个教务系统,编写一个获取学生的接口,在使用Restful之前的url通常是这样写的 1/getStudentById?id=1 而在使用了Restful之后,就将其改成了 1/student/1 可以看到特点是参数不用问号键值对的方式携带参数了,而是将要发送给服务器的数据作为URL地址的一部分 特别说明:Get是用来获取数据的(只读)、Put是用来更新数据的(update)、Delete是用来删除数据的,Post通常是用来新增数据的 HTTPS篇 HTTP和HTTPS有什么区别? HTTP和HTTPS的区别主要是在于HTTP是不安全的,而HTTPS是安全的,具体的区别如下: HTTP协议无法保证传输的数据是安全的,因为它是明文传输的,只要不法分子具有抓包手段,那么它就能够知道报文中的数据内容,HTTPS因为引入了共享密钥对称加密传输这样的方式,使得只有通信双方才能加密和解密数据 HTTP协议无法保证传输的数据是没有被篡改过的,而HTTPS通过摘要技术就可以实现数据的校验 HTTP协议无法传输数据的对等端就是目标方,而HTTPS通过CA证书这种方式就可以验证对方的身份 HTTP协议的默认端口是80端口,HTTPS的默认协议是443 HTTP协议的底层是基于TCP连接的,因此在完成三次握手后就可以传输数据,HTTPS协议的底层是基于TCP+SSL/TLS协议的,因此HTTPS在TCP完成了三次握手之后,还需要完成TLS/SSL握手 了解过哪些加密算法? (1)对称加密算法(AES加密算法、DES加密算法),这个算法的基本流程是,服务端通过专用信道将共享密钥发送到客户端,在之后的传输中,服务端用这个共享密钥对数据进行加密,然后客户端用这个共享密钥对数据进行解密 (2)非对称加密算法(RSA加密算法),这个算法的基本流程是,服务端通过自己的一套算法计算出一对公钥和私钥,然后将公钥注册到网络上,要注意一点是公钥加密后的数据,只有私钥可以解密,于是在这样的情况下,客户端和服务端就各自有一套公钥和私钥,具体的流程如下: 当服务端要向客户端发送数据的时候,这时候会客户端的公钥对数据进行加密,客户端接收了之后,这时候就会用客户端的私钥进行解密,除非客户端的私钥泄露,否则数据无法被截取解密 当客户端要向服务端发送的数据的时候,这时候会用服务端的公钥对数据进行加密,服务端接收了之后,这时候就会用服务端的私钥进行解密。 对称加密和非对称加密的区别 区别在于使用的密钥方式,对称加密中双方使用的密钥都必须是保密的,而且是相同的,从他们的实现来看,对称加密的运算速度很快 非对称加密中,双方的私钥是必须保密的,公钥是可以公开的,从他们的实现来看,非对称加密的运算速度很慢 HTTPS的建立过程是怎么样的? 关于HTTPS的连接建立过程,主要可以分成两个阶段。 第一个阶段主要是要完成底层的TCP连接,也就是三次握手,完成了三次握手之后,就要完成TLS/SSL握手,具体来说是这样的: (1)ClientHello,首先客户端请求和服务端连接,这时候就会先跟服务端协商HTTPS通信的一些基本事项,比如说有 支持的TLS/SSL协议版本 支持的密码套件 客户端生产的一个随机数 (2)ServerHello,这是服务端对客户端给出的基本事项的一个回应,来表明客户端本次通信要选用哪些套件 支持的TLS/SSL协议版本号,如果服务端不支持客户端的协议版本号的话就直接终止会话 本次通信选用的密码套件,比如说RSA 服务端生产的一个随机数 含有服务端公钥,基本信息的CA证书 (3)ClientReply,这是客户端认证了服务端的身份后给出的回应 验证CA证书,验证完成后,取出公钥 一个pre-master-key,这个是客户端产生的一个随机数,这个随机数会用服务端给出的公钥进行加密传输 通信方式改变通知,表示以后都将用一个对称密钥的方式进行通信 握手结束通知,表示客户端的SSL/TLS握手到此结束,同时会将客户端收到的所有信息做一个摘要,发送给服务端作一个校验 (4)ServerReply,这是服务端计算出来对称密钥之后的一个回应 通过三个随机数,ClientRandom、ServerRandom、经过解密之后的pre-master-key,计算出对称密钥 通信方式改变通知,表示今后都将用一个对称密钥进行通信 握手结束通知,表示客户端的SSL/TLS握手到此结束了,同时会将服务端收到的所有信息做一个摘要,发送给服务端作一个校验 SSL握手流程为什么要用非对称密钥 证明为什么,最好的办法就是反证法,假设SSL握手流程使用的对称密钥,那么会发生什么? 首先在正常的网络传输中,都是使用公开的信道,这就意味着你在网络上传输的数据随时可能被抓包 那么如果使用对称密钥的话,那么前提就是双方都具有这个密钥,那么就要通过网络信道将密钥从对等端传输到对等端了,这就意味着,我们这就将密钥暴露在网络信道上了,这就无法起到保密的作用了 并且,我们使用非对称密钥的方式,就是为了加密对称密钥,现在SSL握手就用加密对称密钥,这不是矛盾了么? 为什么HTTPS不用非对称加密算法加密HTTP报文? 先说结论,这是因为使用非对称加密算法的话,HTTPS的通信就会十分缓慢,因为非对称加密算法的效率是很低的 对于HTTPS这种需要在网络中执行大数据量传输的协议来说,不适合,并且会导致用户的体验很差 其次,对称加密算法的效率是要远高于非对称加密算法的效率的,因此HTTPS的加密策略是: 利用非对称加密算法加密对称密钥,保证对称密钥的安全性,由于对称密钥信息量通常比较小,这时候效率的牺牲是可以接受的,而在之后采用高效的对称加密算法,这时候是很好的 HTTPS会对URL进行加密吗? 要理解这个问题,首先于要知道URL是存在哪里的,URL通常是存储在HTTP Header中的,因此是属于HTTP报文的一部分,因此HTTPS会对URL进行加密 CA证书绿色是什么意思?什么时候是红色的?什么时候是绿色的? CA证书是绿色的:它的含义是你的证书通过了验证,那么就会是绿色的 那么它是怎么来验证的呢?首先先来谈谈CA证书的组成,关于CA证书的组成,CA证书的组成有两部分 包含有服务器的基本信息,服务器的公钥等等的一个公开信息表 CA的数字签名,当客户端拿到这个签名后就需要验证这个签名了 首先要知道CA机构是如何生成这个签名的,首先它会服务器的基本信息以及公钥这些打成一个包,然后基于一个哈希算法,将这个计算出来的哈希值通过CA的私钥进行加密,就形成了一个数字签名了 只有CA签发的证书才能够被CA公钥所解密 当客户端拿到这个CA证书后,它首先也是会去通过这个服务器的基本信息以及公钥打成一个包,哈希运算后得到一个哈希值,然后同时,用CA的公钥对数字签名进行解密,同样得到一个哈希值,然后对比两个哈希值,如果相同的话,就证明你的这个CA证书是可信的,这时候就是绿色的,否则就是红色的。 自己随便编一个证书可以吗？需要去什么地方注册 不可以,CA证书必须是由CA机构亲自用它的私钥进行加密后产生数字签名后才是有效的,而CA机构的私钥是绝对保密的 TCP篇 说说TCP三次握手的流程 TCP三次握手的流程如下:在初始的时候,服务端和客户端都处于一个关闭的状态,客户端打开,然后服务端被动打开,监听来自客户端的报文,也就是进入一个LISTENING的状态 接着客户端发送一个SYN+c_isn,含义是将发送第一个握手报文,主要是初始化序列号,同时告诉服务端客户端试图和服务端建立连接,这时候客户端进入到了一个SYN_SEND的状态 然后服务端会发送一个SYN+ACK+s_isn,含义是响应客户端的请求,同时将服务端的初始化序列号告诉客户端,这时候服务端进入到了一个SYN_RCVD的状态 当客户端收到这个SYN+ACK之后,此时就进入到了ESTABLISHED的状态,表明可以开始传输数据了,然后客户端就会可以发送数据了,也就是发送ACK,至于带不带数据根据客户端的情况而异 当服务端收到这个ACK之后,就进入到了ESTABLISHED的状态 如果第二次握手丢包会发生什么? 第二次握手的包是SYN+ACK,它的目的主要有 对第一次握手进行确认,是对第一次握手的确认报文 第二次握手中的SYN,是服务端发起建立TCP连接的报文 所以在这样的情况下,会引发两个事件,第一个事件,首先客户端一直没有收到ACK,于是它会认为自己的包丢失,于是会重传第一次的握手报文,第二个事件,由于含有SYN的报文,需要接收一个ACK来确认自己的报文,所以它自己也会重传 当某一个报文的重传达到最大次数限制之后,这时候就会断开连接 如果第三次握手丢包会发生什么? 首先先来分析第三次握手是什么性质的包,第三次握手的包是一个ACK包,因此它是不会主动重传的,所以在这样的情况下,它引发的事件是第二次握手的报文的重传,当重传的次数超过了一定限制之后,这时候就会断开连接 为什么需要三次握手?两次不行吗? 首先从全双工的角度来讲,三次握手可以保证双方都具备了收发能力,分析如下: 第一次握手,什么都不能够确认,客户端不能确保自己发出去的数据能否被接收到,不知道自己是否有发送能力,没有收到数据,不能确定是否有接收能力,服务端没有回传数据,不确定对方是否有接收能力和发送能力 第二次握手,服务端发送出了SYN+ACK,可以确认客户端具有发送能力(可以被服务端收到),同时客户端可以收到服务端的数据,所以客户端具有接收能力,因此进入了ESTABLISHED的状态,而服务端可以确认自己具有接收能力,但无法确认是否具有发送能力,需要客户端发送回包并且被自己收到才能确认 第三次握手,客户端发送ACK能够被服务端收到,那么说明服务端也具有发送能力,具备全双工的条件,进入ESTABLISHED 从解决历史连接的角度来讲,三次握手可以杜绝历史连接分析如下: 这是因为三次握手的条件,产生了一个中间状态,使得服务端可以对那些历史连接做一个重置 假设这样一个场景,就是网络非常阻塞,那么客户端发送了很多次SYN报文,如果只有两次握手的话,那么服务端在收到第二次握手的时候就直接进入了ESTABLISHED的状态,这时候服务端就能够直接发送数据了,但是如果是历史连接的话,那么就白白浪费了网络流量了,这是因为两次握手没有提供一个中间状态来给服务端来断绝这些历史连接 TCP四次挥手的过程 四次挥手的流程如下: 我们假设客户端试图关闭连接 (1)客户端发送FIN报文,这时候客户端从ESTABLISHED变成了FIN_WAIT_1,主要是用来告诉服务端,客户端这边的数据传输完成了,关闭发送通道了 (2)服务端接收了FIN报文,这时候服务端从ESTABLISHED变成了CLOSE_WAIT,这是一个缓冲的时间段,这个时间段说的是,服务端那边程序编程中要调用close()函数来处理收尾一些工作,因此是等待服务端程序主动调用close(),在没有调用这个函数之前,都是处于一个CLOSE_WAIT的状态 (3)然后服务端发送收尾数据 (4)发送完毕后,服务端告知客户端,服务端这边的数据发送完毕了,于是发送了FIN报文,这时候服务端就从CLOSE_WAIT状态变成了LAST_ACK,表示等待客户端最后的ACK,确保关闭 (5)客户端收到这个FIN之后,表示知道了对方要关闭连接了,为了防止自己的ACK丢包,对方没有收到这个ACK之前就提前关闭了连接导致了不优雅的关闭,这时候客户端就进入了一个TIME_WAIT状态,表明确实等待对等关闭后自己才关闭 (6)服务端收到这个ACK之后,就关闭了,客户端等待TIME_WAIT结束后,就进入了CLOSE的状态,TCP连接结束 为什么TCP需要三次挥手?三次不行吗? 首先先来分析哪一次挥手能够被省略掉,假设服务端在收到客户端的FIN之后,它本身也没有数据要发送,这时候是可以将FIN+ACK一起发送的,这时候就可以换成三次挥手了,但是一般来说服务端都还要发送收尾数据,于是在这样的情况下,就需要预留一个缓冲时间,因此最终还是设计了三次挥手 TIME_WAIT是如何产生的 TIME_WAIT是在主动要求关闭连接的那一段产生的,它主要是为了等待对等端正常退出 为什么需要TIME_WAIT的状态 TIME_WAIT设计出来的用意,主要是为了优雅地关闭TCP连接,尽管处于TIME_WAIT那一端的内核可以提前关闭连接,在后续服务端发送FIN的时候,内核也能够根据报文的上下文来发送RST复位报文,也能够关闭连接,但是这是一种暴力的方式,是不优雅的。 其次,是为了防止历史连接中的数据,被后面相同的四元组的连接错误接收,为了防止错误的序列号被错误接收,假设这样一个场景: 网络拥堵,网络中发送了很多个seq = 301的报文,阻塞在网络中,如果没有TIME_WAIT的状态,然后TCP在后续又开启了同样的连接,如果这时候seq = 301恰好在TCP连接中设定的滑动窗口中,那么这个报文就会被接收,尽管这种现象可以通过时间戳的选项来杜绝,但是在一开始的TCP版本是没有这个时间戳这个选项的,那么设定TIME_WAIT就可以杜绝这个现象,这是TIME_WAIT设定的是2MSL,在这个时间段内,可以保证残留在网络中的本次所有的TCP包都失效被丢弃 服务端产生大量close_wait状态的原因是什么? close_wait产生的原因主要有: (1)服务端这边没有主动调用系统调用close()函数执行收尾函数，这就可能导致大量的连接处于close_wait (2)没有将socket注册到epoll上,这样的话就无法通过事件驱动机制来获取连接的socket,那么就自然无法调用close()了，出现这种现象的原因可能是在将socket注册到epoll之前,抛出了异常 (3)在新连接到来的时候,没有调用accept()。 服务端产生大量的TIME_WAIT状态的原因是什么? TIME_WAIT这个状态是主动关闭连接方才会出现的状态,如果服务器出现大量的TIME_WAIT状态的TCP连接,就是说明服务器主动断开了很多的TCP连接那么一般来说有什么原因呢? HTTP请求没有采用长连接:只要客户端和服务端一方中,这个header中带有Connection:close的话,就会导致短连接 服务端关闭了长连接,那么是谁来主动提出关闭? 假设是客户端主动提出关闭,那么服务端在写完最后一个reponse之后,需要将这个socket放入到readable队列,然后调用select/poll去等待事件,然后调用一次read()才能知道连接被关闭了,这是两次的系统调用 而如果是服务端主动关闭连接,那么服务端在写完最后一个reponse之后,可以直接调用close()就可以释放连接了,剩下的工作交给TCP协议栈即可 客户端关闭了长连接,那么是谁来主动提出关闭? 客户端关闭了长连接,那么意味着客户端在收到请求后,就希望关闭连接,但是客户端并不知道服务端什么时候发送完,所以在这样的情况下,只能将关闭的权利交给服务端 HTTP请求超时:当大量的连接超时之后,这时候就会大量的连接主动断开,这时候也会导致大量的TIME_WAIT HTTP请求数量超过了限制 TCP的keepalive了解吗?和HTTP的keepalive有什么区别? TCP的keepalive说的是保活机制,如果两端一直没有数据交互,就达到了触发TCP保活机制的条件,那么内核中的TCP协议栈就会发送探测报文,如果对等程序是正常工作的,那么TCP的保活探测报文就会被发送到对等端,这样TCP的保活时间就会被重置,需要等待下一个TCP保活时间到来 如果对等端的主机宕机了,那么这个探测报文就会石沉大海,达到保活探测次数之后,TCP就会报告这个TCP连接已经关闭了 HTTP的keepalive说的是连接保持机制,当HTTP的Connection设置为Keep-alive的时候,这时候它的底层TCP连接就开启了长连接模式,也就是说一个TCP连接对应多个HTTP连接","categories":[{"name":"题库","slug":"题库","permalink":"http://kaillliu.github.io/categories/%E9%A2%98%E5%BA%93/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://kaillliu.github.io/tags/Java/"},{"name":"面试题","slug":"面试题","permalink":"http://kaillliu.github.io/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"name":"题库","slug":"题库","permalink":"http://kaillliu.github.io/tags/%E9%A2%98%E5%BA%93/"},{"name":"计算机网络","slug":"计算机网络","permalink":"http://kaillliu.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]},{"title":"计算机网络 面试题 总结回顾（1）","slug":"计算机网络滚动复习","date":"2023-08-17T07:00:00.000Z","updated":"2023-09-08T04:36:17.750Z","comments":true,"path":"2023/08/17/计算机网络滚动复习/","link":"","permalink":"http://kaillliu.github.io/2023/08/17/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%BB%9A%E5%8A%A8%E5%A4%8D%E4%B9%A0/","excerpt":"","text":"为什么需要有TCP/IP网络模型? 对于同一台设备上的进程间通信,可以使用: 管道:其实就是通过fork()指令来创建父子进程,通过父子进程的共享数据的方式来实现进程间数据的共享,通常就是通过共享底层文件系统的fd来实现的。 消息队列:消息队列就是一个消息结构体,通过封装一个队列,将消息结构体push()到这个队列中,基于先进先出的原则,实现进程间的缓存区通信的功能 共享内存:就是对于进程独有的内存空间做一个共享,比如说两个进程中的页表地址是一致的,这样的话就可以实现内存之间的相同映射,基于这个相同的映射,就可以实现两个进程同时操作同一个内存 信号量:信号量机制在底层有两个字段,第一个是一个count计数,假设这个值是n吧,那么当n &gt; 0的时候,那么这时候count就代表可用的资源个数,当n &lt; 0的时候,这时候就代表当前有多少个线程正在被阻塞,这时候会与第二个字段BlockQueue阻塞队列关联,通过这个队列就可以知道哪些线程被阻塞了 既然进程间有这样的IPC通信协议,他们建立起来的基础是这些进程处于同一个操作系统中,通过底层所实现的这些数据结构,就可以实现进程间的通信,但是网络间的通信,这意味着这些主机的操作系统、中间传输设备(如路由器)通常是异构的,所以为了要兼容多种多样的设备,于是就协商出来了一套通用的网络协议。 为什么网络要进行分层? 关于这个问题,可以这样进行回答: 首先,网络通信这件事情是十分复杂的,如果要拆解,一次成功的网络通信,要求: 底层的物理设备不出差错,能够以正确的方式解析电磁波 数据包在两个主机之间有一条路径,可寻址 如果数据包在网络上丢失了,这时候要做处理/维护数据包的语义完整性 网络通信要完成用户指定的功能 假设将这些功能全部在一起完成,那么就会导致网络设计的耦合度太强了,比如说我底层使用的物理设备需要更换的时候,这时候就要修改整一套系统,假设你建立了一条TCP连接,理论上来讲,这条TCP连接是在底层的物理设备的支持下完成连接的,如果物理设备更换了,那么就会导致TCP连接直接被重置,甚至需要对TCP相关的代码需要重新编码,这是一件十分不合适的事情,这就无法实现热插拔等相关功能了 TCP/IP的应用层是干什么的? 应用层协议是直接面向用户的,因此它负责完成两个进程之间的通信,一般来说,它就是专门用来完成用户提出的请求的,比如说用户需要完成HTTP传输,那么就需要使用HTTP协议,并且在头部字段定义相关的字段,比如说用来传输普通的文本等,这个协议并不关心底层是如何传输的,它只关心如何将用户的请求翻译成协议的字段 应用层是工作在操作系统的用户态的,传输层以及以下是工作在内核态中的 TCP/IP的传输层是干什么的? 关于传输层的作用,可以这样说,传输层负责接收来自于上层的应用层的数据包,然后将这些数据包做一些相关的封装,下发到网络层,然后让网络层完成主机间的传递 网络层是负责的是主机间的传输 传输层负责的是主机间进程的传输 也就说网络层负责将一个主机上的数据包发送到另一台主机设备的网络适配器缓冲区上,然后由操作系统的TCP/IP协议栈,负责处理这个数据包,然后将这个数据包头部含有的信息进行解析,也就是一般来说就是通过端口来进行检查,用端口+协议来标识某一个特定的应用 在传输层中,有两个协议,一个是叫做TCP协议,一个是叫做UDP协议,这两个协议的存在是为了适应不同的网络环境下的不同应用的需求,比如说有: UDP协议:UDP协议的特点是面向数据报的,面向无连接的,尽最大努力传输的协议,它只负责对上层的应用数据包进行封装,它非常简单,头部的字段只有目的端口、源端口、校验和、包长度,因此在这样的基础上,就可以实现简单的转发功能,适用场景比如说直播,视频通话等这些要求时效性强的场景 TCP协议:TCP协议的特点是面向字节流的,面向连接的,可靠的传输协议,它的特点主要就是可靠,可以用来做一个网络文件的传输,可以保障数据的完整性,UDP其中的一个特点是面向数据报的,这个特点决定了UDP在收取上层应用数据包的时候,这时候不会将数据进行分片,而是将分片的工作交给了网络层的IP协议 如果TCP采用这样的原则的话,那么就可能导致一个现象,就是一个大的TCP报文段在经过IP协议的分片后,如果其中一个小报文段丢失了,那么最终就可能导致整个TCP报文段的重新传输,这是十分不划算的。 因此TCP有自己的一套分片规则,它会根据TCP连接建立的时候协商好的MSS最大报文段,根据这个最大报文段来进行分片,即使中途有一个MSS大小的报文段丢失了,只需要重传这一个报文段即可,不然的话就还需要重传一个TCP报文段。 TCP/IP的网络层是干什么的? 传输层的功能主要是为了处理两个进程之间的通信问题,它的设计理念是只需要负责好上层应用之间的数据传递就可以了,但是它没有完成两个进程之间的数据包,在错综复杂的网络中是如何传输的问题,因此在这样的情况下,还设计了一个网络层,网络层的作用主要可以概括为: 路由选择、分组转发,这也就是路由器的功能,而这其中最关键的一个协议就是IP协议,IP协议的主要作用就是提供了一套规范,通过这个规范来确定IP包的首部字段的功能,功能其实是比较复杂的,首部字段比较重要的有IP源地址,IP目的地址,以及一些例如校验和之类的字段,通过&lt;目的地址,源地址&gt;的这个字段对,就可以实现基本的网络路由寻址。 寻址的过程大致是这样的:一个数据包被发送到一个路由器的缓存队列中,然后路由器中的处理程序取出这个数据包,然后根据内部的iptables来确定这个数据包要发送到哪一个端口,然后沿着端口的这条路径不断传送,直到到达指定的路径即可。 为什么有了MAC地址还要有IP地址? MAC地址对于每一个物理设备来讲都是独一无二的,通过MAC地址,在数据链路层就可以实现局域网寻址,局域网可以假设是非常小规模的,因此通信的时候可以使用带载波监听的多路访问技术CSMA/CD,可以通过这个技术来广播一个物理帧,然后这个物理帧上就会带着目标设备的MAC地址,然后对应的设备就会检查这个帧头部的MAC地址是否和本物理设备上的MAC地址是否相同,如果相同,那么就接收 MAC地址是物理地址,它的构成是这样的&lt;厂商标识码,厂商自行安排的尾数&gt;,那么如果只有MAC地址的话,那么就意味着这些设备的标识地址都没有规律,在这样的情况下,为了找到网络上的每一台设备,我们需要一个巨大的中央服务器,这个中央服务器要存储所有设备的MAC地址,在当前的网络规模下,是无法想象这样的设计的 因此在这样的情况下,基于MAC地址还开发出来了IP地址,IP地址通过&lt;网络号，主机号&gt;的方式来对网络设备进行划分,这样的话就可以实现这样一种方案,就是知道了对方的IP地址,我就知道要往哪里转发,因为一个设备归属于一个局域网,那么我只需要知道这个局域网的入口路由器是哪个,就可以知道我要将这个数据包转发到哪里了,这个情况下,只需要每个路由器维护自己的一张表,而不需要安排一个巨大的服务器来进行存储。 为什么有了IP协议还要有UDP协议? 首先要搞清楚,IP协议是在网络层上工作的,而网络层上的工作是为了实现从主机到主机的寻址,我们说的计算机网络通信通常指的是一个进程到另外一个进程的通信,因此在这样的情况下,我们需要在传输层设计一个尽最大努力传输的协议,来和TCP协议的使用场景进行区分 TCP/IP的网络接口层是干什么的? 我们说网络层负责的是跨网段的传输,也就是说从一个网段中传输数据包到另外一个网段,那么网络接口层就是负责局域网内的传输,也就是说,当一个数据包完成了跨网段的识别 从一个网络中的路由器发送到另外一个网络上的路由器的时候,这时候就是网络层完成的事情 那么在同一个网络中,路由器和具体设备的通信的时候,实际上是依赖一个叫做数据链路层的层级来完成操作的,也就是说,从这个数据链路层中,它完成的是局域网通信,主要完成网络适配器的识别和数据包的匹配 负责完成底层数字信号的调频调幅调相的相关功能 什么是局域网? 一种私有网络,将分布在小范围内的网络设备串联在一起的一种小型网络,通常不经过路由器,而是通过交换机、网桥等设备进行连接 输入一个URL,问你这期间发生了什么? 这个问题 比较复杂,需要从几个方面进行回答 从B/S应用架构来进行回答 首先浏览器发起了一个HTTP请求,然后这个请求就会被转发到后台服务器上,后台服务器就会解析这个请求的含义,通常来说,HTTP请求的格式是请求行(包括有HTTP版本号,URL,请求方法GetOrPost)|请求头(包含了HTTP协议中规定的应用字段)|空行(其实就是一个cr lf回车,用来分割控制信息的头部)|请求体(具体携带的负荷) 然后后端服务器就会解析这个HTTP请求,然后从Web服务器上取出需要相应的资源,然后将资源封装起来原路返回 这个资源被浏览器接收到了之后,然后就会浏览器就会将这个HTTP响应解析出来,然后将数据渲染到浏览器上 HTTP响应的格式是响应行(包括有版本号,状态码,短语(也就是当前状态码所代表的含义是什么))|响应头(包括本次返回响应的数据长度是多少?)|空行(用来分割响应头和响应体)|响应体 从计算机网络协议栈的角度来进行回答 以上是从B/S架构交互流程来进行说明的,如果要从网络协议栈来说明的话,可以基于TCP/IP四层协议来进行说明,比如说我输入了一个www.baidu.com,那么大致将经过: 首先,第一步,用户输入了这个URL,于是浏览器就需要负责将这个URL的相关信息封装成一个HTTP请求,比如说www.baidu.com,浏览器内置选用了HTTP/1.1的版本的协议,然后使用了Get请求,然后请求体是空的,然后准备交付到下一层,此时就经历一个委托的过程,我们知道TCP/IP四层的通信,主机之间的通信是基于IP协议进行通信的,因此在交付到下层的时候,这时候还缺少一个IP地址,因此在交付之前,还需要查询一下IP地址 于是第二步,就需要执行一个DNS查询,DNS查询是基于一个UDP协议来完成的,具体的流程是: 客户端会先向本地域名服务器查询,问它知不知道www.baidu.com的IP地址,如果它知道就直接返回 如果本地域名无法查询到,于是就获取顶级域名服务器的地址,也就是.的地址,这个地址是所有服务器都知道的,这时候本地域名服务器就会向根域名服务器查询www.baidu.com的地址 注意,根域名服务器并不起到一个直接解析的作用,而是起到一个指路的作用,这时候它会告诉顶级域名服务器的地址,也就是.com的地址 然后本地域名服务器就会向.com的域名服务器进行查询,如果.com的域名服务器也没有,它就会告诉他掌管www.baidu.com的权威域名服务器的地址 然后本地域名服务器最终就会向这个域名服务器请求IP地址,这时候就能够查询成功了 查询成功之后,这时候就能够将IP地址投入委托使用了 第三步,获取了通信的必要信息,比如说IP地址,端口号等,这时候应用程序就会调用封装好的Socket中的接口,调用这些接口实际上就发起了系统调用,操作系统根据通信需要用到的协议,将消息发送到具体的通信模块中,比如说发送到TCP处理模块中,然后进行一系列的网络传输操作 第五步,建立TCP连接,TCP连接是一个非常复杂的协议,首部字段主要有: 源端口号、目的端口号 报文段的序号:用来保证传输过程中不乱序传输,可靠传输的必要条件,传输过程中如果出现了乱序,会根据滑动窗口中的序号限定来确定哪些报文段可以被接收,哪些需要丢弃 确认号:接收方表示从ack-1之前的所有字节都被接收到了 状态位,我们说TCP连接的变化,其实就是一个状态机不断变化的过程,状态转移需要依赖于双方交换的报文段中的状态位,比如说有FIN、ACK、RST、SYN等通过这些状态位来确定当前TCP连接状态 窗口大小,它是TCP的精髓所在,在实现拥塞控制(控制数据包注入网络中的速度),流量控制(控制发送的速率)的时候有很大作用 然后执行TCP的三次握手,这时候会经历: 一开始,服务端和客户端都是处在一个CLOSE的状态,然后这时候服务端被动打开连接,客户端主动建立连接,也就: 客户端发送一个SYN+clinet_seq的报文段,请求服务端的连接,进入SYN_SENT的状态 服务端接收到这个报文后,进入SYN_RCVD,返回一个SYN+ACK=1+ack=client_seq+1+server_seq的报文段 客户端接收到这个报文之后,就会发送一个ACK,进入了ESTABLISHED的状态,服务端在接收到这个ACK之后,也就会进入到一个ESTABLISHED 然后就可以基于这个TCP进行数据的发送了,注意这个过程,建立TCP报文的时候,实际上也是需要底层的IP支持的,因此在第一个报文发出的时候,会经历这样的过程: 第六步,底层的IP协议接收到来自上层的TCP报文段之后,这时候就会将上层的TCP报文段包装成一个IP包,IP 包的最重要的字段就是源IP地址和目的IP地址 主要的过程是这样的,首先主机拿到这个IP报文,然后它会比对操作系统内核中提供的一个叫做路由表的数据结构,将当前的目标IP地址和每一项的子网掩码进行与运算,如果与运算后的结果和条目表中的IP地址是相同的,那么就选择这个条目中规定的网卡进行数据的发送,这就确定了源IP地址 当匹配到最后一项的时候,这代表着当前主机并不直接和这个网络下的网络设备连接,而是要通过本网络的网关进行转发,具体的格式是0.0.0.0 GateWay ,然后主机就将数据转发到网关了 当转发到网关的时候,这时候网关就查询路由表,具体的就是&lt;目标IP地址,子网掩码,转发端口号&gt;,也就是将IP地址和子网掩码进行与运算,如果和目标IP地址吻合,那么就直接通过这个端口转发出去,否则还需要经过默认网关 第七步,经过了大量的路由转发,这时候到了目标主机所在的子网内,这时候就通过ARP协议来进行IP地址和MAC地址的转换,具体来说是这样的: (1)当ARP缓存中IP地址=&gt;MAC地址的映射的话,这时候就直接取出MAC地址,然后封装MAC帧发送即可 (2)当没有的时候,这时候就需要执行一个广播,也就是说,在局域网内广播谁的IP是&#123;IP&#125;?,请发送你的MAC地址过来,然后这时候收到验证的设备就会回播一个MAC地址,收到这个MAC地址之后,就会在ARP缓存中存下来 在局域网内,就通过CSMA/CD协议发送数据包,然后在发送出去之前,还需要FCS的计算等操作,然后通过调频调幅调相的过程,将数字信号转换为频带信息,这时候就进行真正的网络传输了 当这个数据包到达对方主机后,就会通过数据链路层=&gt;网络层=&gt;传输层=&gt;应用层这样的顺序,不断拆解头部,然后就可以得到实际的数据了 TCP的基本认识 TCP的头部字段 TCP的头部字段通常有:序列号(在建立连接的时候,由计算机产生的随机数作为初始值,通过SYN包传给接收端的主机,每次发送一个数据,就累加一次该数据字节数的大小,用来解决网络包乱序的问题)、确认应答号(指下一次期望收到的序列号),控制位,主要是用来沟通两台主机的状态变化 ACK:当这个位为1的时候,表示是一个确认上一次应答的包,此时ack的值是生效的 RST:当这个位为1的时候,表示检测到当前的TCP环境产生了异常,必须强制断开连接 SYN:表示希望建立连接,并且在seq字段中进行初始化 FIN:表示希望关闭这一方的数据传送通道 为什么需要TCP协议? TCP协议工作在IP协议之上,那么就要谈到IP协议设计的功能了: 路由选择、分组转发,假设没有TCP协议,那么假设传输过程中路由器故障,那么就会导致数据全部丢失,而对于传输双方来说是无法感知的,因此在这样的情况下,就必须要有一个工作在IP层之上的协议,来控制这个IP协议的传输了,IP协议它无法保证网络包的可靠交付,不保证网络包的按序交付,也不保证网络包的数据完整性 因此在这样的情况下,TCP的出现可以使得网络数据包的可靠传输,按序交付,数据报的完整性 TCP是什么? TCP叫做传输控制协议,它的特点是: 面向连接的、可靠的、基于字节流的传输协议 所谓面向连接,就是要建立起一条逻辑连接信道之后,才能进行后续的传输,它一定是一对一的通信传输连接,一对多是无法做到的 所谓可靠的,就是无论底层的网络出现了怎么样的变化,它在允许的情况下(超时重传次数允许的情况下,一定能够完成数据报的可靠交付) 所谓面向字节流的这个概念,要和面向数据报的概念进行联合讲解,所谓面向数据报,说的是上层应用交付怎么样的数据报,传输层就传输怎么样的数据回去,因此对等端传输地数据总是按照用户的意愿的 但是面向字节流可能会将上层应用交付的一个应用数据包拆分成多个报文段,然后分别发送,如果消息报文段没有规定确切的边界,那么是无法读取出有效的信息的 如何来描述一个TCP连接 一个TCP连接是用于保证可靠性和流量控制的某些状态信息,这些信息的组合,包括有Socket、序列号、窗口大小用来描述一个连接 Socket:ip和端口号 序列号:用来解决乱序问题的 窗口大小:做流量控制的 如何唯一确定一个TCP连接? TCP的四元组=&gt;&#123;目的IP地址,目的端口号,源IP地址,源端口号&#125; 有一个IP的服务端监听了一个端口,它的TCP的最大连接数是多少? IP数最多有2^32,端口数最多有2^16,因此最多可以维持2^48个连接 连接还会受到系统的其他资源的限制 文件描述限制:每个TCP连接都是一个文件,如果文件描述符被占满了,那么就会发生TooManyOpenFile的异常 内存限制:每个TCP连接都要占用一定的内存,操作系统的内存是有限的,如果内存被打满了,那么就会发生OOM TCP和UDP有什么区别? 关于TCP和UDP的区别,可以从以下几个方面进行区分: (1)连接 TCP是面向连接的传输协议,传输数据之前先要建立连接 UDP是面向无连接的传输协议,传输数据之前不需要创建连接 (2)数据载体 TCP是面向字节流的,消息没有边界,但是可以保障有序性和可靠性 UDP是面向数据报的,可能导致丢包和乱序 (3)可靠性 TCP基于滑动窗口+序列号+响应机制实现了可靠性 UDP不保证可靠性 (4)首部的开销 TCP的首部一定要占20个字节,当采用了例如SACK之类的机制的时候,这时候还会占用最多20个字节,因此最多40个字节 UDP首部只有8个字节,四个字段,分别是&#123;目的端口,源端口,校验和,包长度&#125; (5)服务对象 TCP的服务对象是一对一的 UDP的服务对象可以是多个 (6)拥塞控制和流量控制 TCP基于响应应答机制+滑动窗口可以实现拥塞控制 UDP无论网络情况如何,都是直接发送数据的 (7)分片不同 TCP会在传输层实现分片 UDP不会分片,它会将分片的任务交给IP层 简述一下TCP三次握手的流程 (1)初始化的情况下,Client和Server都处于一个CLOSED的状态,然后此时Server被动打开连接,进入到一个LISTEN的状态,然后客户端请求建立连接,也就是进入一个SYN_SEND的状态 这个报文包含有的信息主要有client初始化之后的序列号,以及带有SYN标记的数据包,表示希望和Server建立连接 (2)服务端在收到第一个握手包之后,进入到一个SYN_RCVD的状态,然后此时就要发送回去一个响应,这时候同时会初始化自己的序列号 这个报文包含有的信息主要有server初始化之后的序列号,以及带有SYN标记的数据包,同时会将ACK=1,ack =client_isn+1,表示正在和client建立连接,正确收到了上一次连接请求包 (3)客户端在收到服务端的ACK+SYN之后,这时候就进入了一个ESTABLISHED的状态,这也就代表着可以发送数据了,这时候会对上一次的SYN做一次ACK,也就是: 这个报文包含的信息主要有ACK=1,ack = server_isn+1,表示已经正确收到server的同步连接请求包,注意,由于此时是ESTABLISHED的状态,因此这时候可以携带数据,也可以不携带数据 (4)服务端接收到客户端的ACK = 1,ack = server_isn+1的包之后,这时候就会进入到ESTABLISHED的状态了 如何查看TCP连接的状态? 1netstat -napt 为什么TCP的握手需要三次? 从建立全双工连接的角度上来说 从全双工的角度上来看,三次握手可以实现双方的收发正常,非常好理解 (1)第一次握手报文,什么都确定不了,客户端无法确定自己的报文是否到达服务端,也就是无法确认自己是否有发送能力,同时也无法确认接收方是否有接收能力和发送能力 (2)第二次握手报文,此时客户端可以确定自己的报文到达了服务端,也就是可以确认自己具有发送能力,同时具备接收能力,于是它就进入了ESTABLISHED的状态,但是服务端只可以确认自己具有接收能力,但是不确定具有发送能力,于是只是保持SYN_RCVD的状态,于是客户端此时发送ACK (3)第三次握手报文,此时服务端收到后,进一步确定了发送能力,于是进入了ESTABLISHED 从确定一条TCP连接的角度上来说 从这个角度上来看,三次握手的首要原因是为了要排除历史连接的错误 (1)排除历史连接的错误,首先,假设这样一个场景,也就是说,当TCP建立的时候,这时候网络阻塞了,于是TCPSYN报文一直发送不到服务端,然后客户端重置连接,在网络通畅的时候,这时候就会重新发送SYN,这时候就出现了一种情况了:网络中同时存在新的连接报文和旧的连接报文,而且这两个报文什么时候到达服务端是不确定的,因此下面就来讨论一下:假设新的连接报文序号是90,假设旧的连接报文序号是100 如果新的连接报文比旧的连接报文要先到达 这时候新的连接报文到达服务端之后,服务端会返回SYN+ACK+ack = 91,客户端收到这个ACK之后,然后发送ACK,此时TCP连接就建立好了,如果此时旧的连接报文到达的时候,这时候就会触发一个ChallengeACK,这个ACK的作用主要是为了检查当前的SYN是否有效,也就是回复一个SYN+ACK+ack=91的包回去,给客户端检查,如果客户端检查发现和上下文环境不符合,那么就发送RST报文。 如果旧的连接报文比新的连接报文要先到达 如果旧的连接报文比新的连接要先到达的时候,服务端也会返回SYN+ACK+ack = 100,客户端收到这个ACK,检查上下文环境是91,因此会发送RST报文,此时就会重置连接了,在后续新的报文到达的时候,就可以正常接收连接了 之所以要三次握手,可以假设只有两次握手会发生什么 如果只有两次握手,那么就意味着服务端返回了SYN+ACK+ack的话,就直接进入了ESTABLISHED,这实际上是非常草率的过程,也就是说服务端并不能够确认自己具有发送能力的同时,同时无法避免历史报文的影响,如果收到的是历史报文,那么就会建立一个历史连接,然后服务端就会发送数据,这会导致网络资源的浪费 (2)基于三次握手可以实现双方序列号的同步 序列号是实现TCP的关键数据结构,通过这个字段,可以实现: 数据包的有序传输,可以将那些乱序的数据包丢弃 数据包的可靠传输,便于超时重传 可以知道哪些报文是已经被接收的了 通过三次握手,第一次握手,告知服务端,客户端的初始化序列号,不确定服务端收到没有 第二次握手,告诉客户端关于服务端的初始化序列号,不确定客户端收到没有,但是可以确定服务端收到了客户端的初始化序列号 第三次握手,告诉服务端,服务端的初始化序列号接收到了 (3)避免资源的浪费 假设只有两次的握手,资源的浪费主要体现在,历史连接导致的无效的数据传输、一个SYN报文就对应一个连接,如果是重传的SYN报文,那么就可能导致大量的无效连接,同时可能导致被不法分子利用,基于泛洪SYN来对服务器进行攻击 总结 两次握手:无法防止历史连接的建立,会造成双方资源的浪费,也无法可靠的同步双方的序列号 四次握手:理论上三次握手就可以实现可靠的连接建立了,不需要更多的握手次数 初始化的序列号相同该怎么办?会有什么问题? 首先假设初始化的序列号相同会发生什么,假设每一次的TCP连接都是从0开始的 假设Server和Client建立了连接,然后从0开始发送数据,然后发送到序号为50的时候,此时发送了大量的超时重传,然后超过了次数限制之后,就发送了RST报文,重置了这个连接,但是注意,序号为50的报文此时还是残留在网络中的,因此在这样的情况下 然后重新建立连接,从0开始发送数据,然后发送到序列号为50的时候,此时发送的数据包和超时数据包混合在一起,这时候就产生了数据异常了 为了解决这个问题,TCP设计的序列号初始化是随机的,尽量来避免历史连接的序列号来影响本次连接,但是要注意,序列号是有回绕现象的,也就是说当序列号到达了2^32-1之后,又会变成0,因此在这样的情况下,就要使用时间戳来实现了,简单来说就是看你这个数据包的时间戳是否是递增的,如果是递增的话那么就接收,否则就关闭 IP层会分片,为什么还需要MSS呢? MTU:一个网络包的最大长度,以太网中一般是1500个字节 MSS:除去TCP和IP头部之后,一个网络包所能容纳的最大数据长度 假设只有IP的分层的话,那么在这样的情况下,首先对于一个IP报文而言,这个报文的数据部分是由TCP头部和TCP数据段组成的,如果IP包的大小超过了MTU的情况下,那么需要IP就进行分片了,那么在这样的情况下,假设一个IP分片丢失了,那么就会导致整个TCP报文段的重传,为了避免这样的现象影响效率,于是使用了MSS 这个MSS是这样起作用的,简单来说,就是当TCP组装报文段的时候,如果这时候报文段的长度超过了MSS,那么就会在传输层进行分片,如果一个TCP分片丢失了,那么就只需要重传这一个分片就可以了 如果第一次握手报文丢失了,会发生什么? 注意,这种状态的特殊报文段一般的逻辑是这样的: 1没有收到数据报=&gt;触发超时重传=&gt;重传次数到达上限=&gt;断开连接=&gt;客户端单方面断开连接 详细:当第一次握手报文,也就是SYN的报文传出去之后,然后这时候SYN+ACK没有被收到,由于发送的是SYN包,因此在这样的情况下,就会触发重传,第一次超时重传是1s之后,之后就会在*2,也就是1+2+4+8+16+32,当达到了这个上限之后,这时候就不会再重传了,而是操作系统内核将这条连接进行释放 如果第二次握手报文丢失了,会发生什么? 首先明确这时候双方发送数据包的性质: 客户端发送的是SYN数据包,不是纯ACK包,因此当发生了超时的时候需要进行重传 服务端发送的是SYN+ACK数据包,不是纯ACK包,因此当发生了超时的时候需要进行重传 那么在这样的情况下,当第二次握手报文丢失的时候 从客户端的角度上来看,就是没有收到ACK,因此会重传SYN数据包 从服务端的角度上来看,就是没有收到客户端的第三次握手报文,于是会重传SYN+ACK数据包 然后从状态转移来看,如果客户端重传的SYN报文到达了服务端,那么这时候服务端就会重传SYN+ACK,因为是重传,那么无论是ChallangeACK亦或者是正常的ACK,都是原来的序列号 当客户端收到这个SYN+ACK之后就会进入到ESTABLISHED,然后继续后续的传输了 如果后续重传到达了一定的次数的时候,任意一端都会关闭连接 如果第三次握手报文丢失了,会发生什么? 首先先来分析上下文的性质,首先: 第二次握手的报文属于是SYN+ACK,具有重传的义务 第三次握手的报文属于ACK报文,可以携带数据,因此需要分情况讨论 当第三次握手的报文没有携带数据的话,那么客户端就不会重传,这时候服务端就会不断重传SYN+ACK,达到超时的次数之后,就会通知操作系统内核释放这个连接 当第三次握手的报文有携带数据的时候,那么客户端就会重传,这时候断开连接的权利掌握在双方 什么是SYN攻击?如何避免SYN攻击? 要理解这个问题,你首先要理解一次连接在操作系统内核是如何发生的 以Linux系统为例,它是这样管理的,首先是一个主机的SYN报文发送过来,如何这时候操作系统内核就会将相关的信息封装成一个结构体,然后将这个结构体放入到一个内核中一个叫做SYN连接队列的数据结构 然后这时候内核会扫描这个队列,然后发送SYN+ACK给对等端,如果对等端发送一个ACK的时候,这时候就会从SYN连接队列中pop()出来一个数据结构,然后将这个数据结构push()到一个accept队列中,然后操作系统内核就会提供一个系统调用accept(),如果调用accept()就会从这个队列中pop()出来,然后提供操作系统的系统调用来对这个socket进行读写。 至于如何防范SYN攻击,就需要从半连接队列如何被打满的这个角度来进行分析了 方法一:设置Linux系统内核中的半连接队列的大小,具体来说有三个参数 方法二分析:当发生了半连接队列被打满的时候,这时候最严重的后果就是后续的报文被丢弃,于是我们可以将保存多余数据包的调大,这时候就可以降低半连接队列被打满的副作用 方法三分析:半连接队列被打满的时候,会导致连接无法建立,那么在这样的情况下,我们可以绕过SYN半连接队列的方法来解决这个问题,具体的流程是这样的: 当SYN队列满了之后,后续队列收到新的SYN包的时候,这时候不会创建数据结构并且push()到半连接队列中,这时候它会通过一定的算法,生成一个cookie,这个cookie后续可以通过一定的算法来验证这个Cookie的合法性,如果合法,那么就说明是之前本机生成的cookie 如果合法,那么就会将对象放入到accept队列中 方法四分析,如果可以尽快确认这个SYN报文是无效的,并且将这个连接从内核中删除,那么一定程度上就可以解决这个问题,我们可以通过减少SYN+ACK的重传次数以及重传的间隔时间,就可以让这些SYN来得快,去得也快,最终就可以实现SYN队列的空余 简述TCP四次挥手过程 关于TCP四次挥手的流程,可以这样讲述: 第一步,客户端完成了本机的数据传输,因此这时候就会发送一个控制位为FIN = 1的数据包到服务端,这时候客户端进入到一个FIN_WAIT_1的状态,这时候根据全双工的流程,客户端关闭了发送的通道,但是保留了接收的通道 第二步,服务端收到FIN = 1的数据包,这时候服务端因为是被动关闭,有可能还有数据没有发送完毕,因此这时候进入了CLOSE_WAIT,表示等待本机从剩余数据发送完,然后就会发送一个ACK,让对方知道之前FIN = 1的数据包已经收到了 第三步,服务端发送剩余数据 第四步,服务端数据发送完毕,这时候服务端就会发送一个FIN = 1的数据包,表示服务端也关闭发送的通道了,这是会需要等待客户端的最后ACK，因此进入了LAST_ACK的状态 第五步,客户端收到FIN = 1,表示客户端收到了服务端通知关闭发送通道的通知,然后发送ACK,表示确认,然后进入到TIME_WAIT 第六步,服务端收到了ACK,于是进入到了CLOSED状态 第七步,客户端TIME_WAIT结束,进入到CLOSED状态 注意:主动关闭连接的才会有TIME_WAIT的状态 为什么挥手是四次? 首先分析一下,如果只有三次挥手会怎么样? 如果只有三次挥手,客户端发送一个FIN，表示此时关闭发送通道,然后服务端发送一个FIN+ACK,表示服务端关闭发送通道和接收通道,然后客户端收到这个ACK之后,还要回包ACK,表示知道了对方要关闭了 三次挥手在服务端没有多余的数据的时候,是可以变成三次挥手的,但是通常来说FIN+ACK是会分开发送的 第一次挥手丢失了会发生什么? 第一次挥手是主动关闭者发送FIN报文,如果第一次挥手无法得到对方的ACK,那么就会触发超时重传,因此这时候的逻辑是这样的,会在一段时间内不断重传FIN报文,如果超过了重传的次数,那么就会直接进入到CLOSED的状态,后续的报文处理会基于操作系统内核对这个报文的定义,通常来说会基于RST报文来对这些进行限制 第二次挥手丢失了会发生什么? 首先明确,第二次挥手是一个ACK报文,因此在这样的情况下,ACK报文不会重传,只会认为是对等端发送失败了,因此在这样的情况下,就会引发对等端不断重传FIN = 1的报文,当超过了次数之后,这时候客户端就会直接关闭掉了 那么这时候就会问了,那么服务端呢?服务端一旦进入了CLOSE_WAIT的状态之后,这时候关闭的权限不是交给操作系统内核的,而是交给了用户程序,只有在用户程序调用了CLOSE()之后,才会发送第三次的FIN报文,因此这里可能会有死等的风险,这个解决办法需要通过编码来避免,也就是一定要调用close() 第三次挥手丢失了会发生什么? 上面提到了,如果服务端进入到了CLOSE_WAIT,除了用户程序调用close(),否则一直就卡在这个状态,在数据发送完毕后,这时候就会将FIN报文发送出去,如果发送的时候不断超时,不断重传,无法收到对方的ACK,那么这时候在超过了重传次数之后,就会直接关闭连接 第四次挥手丢失了会发生什么?(重要) 第四次挥手错误是TCP处理中最为核心最为复杂的一个过程 当客户端收到了服务端的FIN之后,这时候就会发送第四次挥手,也就是回复一个ACK给上次的FIN,那么如果这个ACK一直没有被收到的话,那么服务端就会不断重传FIN,客户端一直处于一个TIME_WAIT的状态,于是在这样的情况下,会出现的情况是 服务端不断重传FIN直到达到超时的次数,然后断开连接 客户端无感知,它认为是ACK报文到达了,因此在2MSL之后,就会自动关闭连接 为什么TIME_WAIT是2MSL? 首先你要理解什么是MSL,所谓的MSL就是报文最大生存时间,与之相对的有IP协议中的TTL,它表示IP数据报经过的跳数,在Linux设置中,通常是设置TTL是64,MSL是30s,那么在这个时间段内,TCP报文都是有效的,超过这个时间,那么就被认为是无效报文,会被路由转发设备给丢弃,这意味着,一个报文在传输过程中,如果超过了MSL,那么这个报文就会被丢弃。 比如，如果被动关闭方没有收到断开连接的最后的 ACK 报文，就会触发超时重发 FIN 报文，另一方接收到 FIN 后，会重发 ACK 给被动关闭方， 一来一去最多2个MSL。 如果在2MSL内,都没有再收到这个FIN,那么就认为对方已经收到了这个ACK 为什么不是4MSL或者8MSL呢? 这个问题我认为和超时重传的时间设置有关,一般来说,超时重传的时间会被设置为小于MSL,因此在这样的情况下,2MSL完全够用,这里说的够用,说的意思是能够确保服务端收到了这个ACK并且重传FIN能够被客户端感知到 如果大于了MSL,那么这时候就可能需要4MSL或者8MSL了,但是实际上不会这样来设置超时时间 亦或者是触发了超时重传,但是FIN报文阻塞在路由器中无法发出,这时候也会导致超过2MSL,但是这都是小概率事件,忽略这些事件比用复杂的逻辑去处理他们更加有性价比 深入剖析TIME_WAIT的状态 之所以需要TIME_WAIT的状态,主要有两个原因: 防止历史连接中的数据,被后面相同的四元组接收 假设这样一种场景,如果没有TIME_WAIT的话,那么这就意味着直接关闭,网络上可能残留有上一次连接的数据报文,因此在这样的情况下,就可能导致下一次相同连接的四元组,恰好序列号又是也一样的,这样的话就会导致数据被错误接收,因此为了避免这样的情况,因此就可以使得上一次报文全部消失之后再建立下一次连接 保证被动关闭连接的一方,能被正确关闭 被动关闭的一方是我们的服务端,假设没有TIME_WAIT的状态,如果你客户端的ACK直接丢失了,那么服务端发来了FIN之后,虽然也能够被重置的RST报文进行重置,但是这不是一种正常关闭的状态,是不优雅的,因此设置了这个状态来进行过度 TIME_WAIT过多有什么危害? 占用系统资源,比如说文件描述符,内存资源,CPU资源,线程资源 占用端口资源 如果客户端的TIME_WAIT状态过多,占满了所有的端口资源,那么就无法对&lt;目的IP,目的端口&gt;发起连接了,但是使用的端口,还是可以继续对另外一个服务端发起连接,这是因为内核在识别数据要转发到哪个进程的时候,会根据定义socket的四元组来进行确定,只要有一个字段不同,就算一条不同的连接,就是一个不同的socket 如果服务端的TIME_WAIT过多,不会导致端口资源受限,因为服务端只监听一个端口,它操作的是连接对象,但是当TIME_WAIT过多的时候,这时候会导致系统资源被浪费 TIME_WAIT如何排查? 出现大量TIME_WAIT有什么原因? TIME_WAIT只有在主动发起断开连接请求的一方才有,因此要从这个角度来入手 HTTP没有使用长连接 1Connection: keep-alive 客户端禁用了长连接,而服务端开启了长连接,谁来关闭连接? 服务端来关闭,这是因为客户端关闭了长连接,这意味者客户端仅发起一次请求就下线了,关闭连接的这件事情要交给服务端来确认,我们将关闭连接这件事情交给本次请求的末端是合理的 客户端开启了长连接,而服务端关闭了长连接,谁来关闭连接? 服务端来关闭,这个又是需要基于操作系统的开销来考量了 如果是客户端关闭这个长连接,那么意味着服务端需要将这个连接放入到操作系统内核的等待队列中,然后不断监听连接事件,当发生了连接关闭事件之后,这时候就还需要发起系统调用,这时候socket会有不必要的等待时间+；两次系统调用 如果是服务端来关闭这个长连接,那么意味着服务端只需要调用一次close(),然后剩下的交给TCP协议栈处理就可以了 HTTP长连接超时 当超时的时候,这时候服务端就会自动调用close()来关闭连接 HTTP长连接请求到达了上限 比如 nginx 的 keepalive_requests 这个参数，这个参数是指一个 HTTP 长连接建立之后，nginx 就会为这个连接设置一个计数器，记录这个HTTP 长连接上已经接收并处理的客户端请求的数量。如果达到这个参数设置的最大值时，则 nginx 会主动关闭这个长连接，那么此时服务端上就会出现 TIME_WAIT 状态的连接。 keepalive_requests 参数的默认值是 100 ，意味着每个 HTTP 长连接最多只能跑 100 次请求，这个参数往往被大多数人忽略，因为当 QPS (每秒请求数) 不是很高时，默认值 100 凑合够用。 但是，对于一些 QPS 比较高的场景，比如超过 10000 QPS，甚至达到 30000 , 50000 甚至更高，如果 keepalive_requests 参数值是 100，这时候就 nginx 就会很频繁地关闭连接，那么此时服务端上就会出大量的 TIME_WAIT 状态。 解决方案? 方法一:开启TCP连接复用,也就是说,在处于TIME_WAIT状态的TCP连接中抽取连接,然后重置它的状态,使之成为一个新的连接对象,并且为之所用,这样的话就可以减少TIME_WAIT的数量 方法二:强制重置,也就是说当TIME_WAIT超过了一定的阈值之后,这时候会将之后的连接给直接重置 方法三:通过编程,在close()添加一个SO_LINER来绕过TIME_WAIT,直接重置连接即可 什么是CLOSE_WAIT?大量出现了CLOSE_WAIT怎么办? 首先这个状态出现服务端收到FIN = 1的报文之后,这个状态的终止需要用户进程调用close()才能解决 一个普通的TCP服务端的流程: 将服务端socket,bind绑定端口,listen监听端口 将服务端socket注册到epoll中 epoll_wait等待连接到来的时候,调用accept()获取连接 epoll_wait等待事件发生 调用close() 第一个原因,没有使用accept(),因此积压了大量的CLOSE_WAIT 第二个原因,大量的客户端主动断开了连接,也就是说那种发送了第一个SYN之后,然后就失联的 第三个原因,没有监听socket,没机会调用close 第四个原因,没用close 客户端突然出现了故障怎么办? 为了解决这个问题,提出了一个保活机制,也就是在一个连接上没有任何的数据传送的时候,这时候就基于保活机制,每隔一个时间间断,就会发送一个探测报文,如果连续好几个报文都没有响应回包,那么这时候就认为这个TCP连接就已经死亡了,系统内核就会将错误信息上报 一般来说,有三种情况: 第一种情况,TCP对等端存活,保活计时器重置 第二种情况,TCP对等端进程重启了,此时对等端会返回一个RST报文,然后重置连接 第三种情况,TCP对等端宕机,探测报文石沉大海,此时直接释放服务器的连接 如果已经建立了连接，但是服务端的进程崩溃会发生什么？ TCP 的连接信息是由内核维护的，所以当服务端的进程崩溃后，内核需要回收该进程的所有 TCP 连接资源，于是内核会发送第一次挥手 FIN 报文，后续的挥手过程也都是在内核完成，并不需要进程的参与，所以即使服务端的进程退出了，还是能与客户端完成 TCP 四次挥手的过程。 我自己做了个实验，使用 kill -9 来模拟进程崩溃的情况，发现在 kill 掉进程后，服务端会发送 FIN 报文与客户端进行四次挥手。 什么是HTTP协议? HTTP协议翻译过来就是超文本传输协议,关键字是如下三个: 超文本:它是HTTP协议传输数据的数据的格式,具体来说,超文本就是一个超越文本的文本,它是视频、图片、视频等链接的载体,能够从一个超文本跳转到另外一个超文本,这是超文本最重要的特性 传输:所谓传输,就是提供一个协议,这个协议可以实现一个进程和其他进程的通信,它是一个双向的协议,通过这个协议可以实现两个进程之间的数据传输的约定和规范 协议:它是HTTP的本质,在相同操作系统之中,可以基于IPC(进程间通信,包括有管道,消息队列,socket,信号量,共享内存)来实现进程间的通信,那么在网络上,由于不同进程之间,他们所在的操作系统可能是异构的,因此为了解决这个问题,提出了协议,所谓的协议,就是将要将网络上传输的这些数据的解析方式做一个限定,因为二进制数据是操作系统之间都可以识别的,通过协议,就可以将这些二进制数据进行正确的解析,然后就可以通过这些数据进行通信了 总而言之,HTTP协议是用来实现网络上两个进程之间的超文本传输的一个网络通信协议 HTTP常见的状态码有哪些? 1xx:这一类信息属于一个提示信息,是协议处理中的一个中间状态,实际中用到的比较少,比如说在升级WebSocket协议的时候,就会出现这个状态码,表示将要升级成WebSocket协议 2xx:这个状态码表示服务器成功处理了客户端的请求 200 OK:是最常见的状态码,表示一切正常,如果是非HEAD请求,服务器返回的响应头部会有body的数据 204 No Content:是成功的状态码,和200OK是基本相同的,但是响应头中没有body数据 206 Partial Content:是应用于HTTP分块下载或者断点续传,表示响应返回的body数据不是资源的全部,而是其中的一部分而已,它也表示服务器的处理是成功的 3xx:状态码表示客户端请求的资源发生了变动,需要使用新的URL重新发送请求获取资源,也就是重定向 301 Moved Permanently:表示永久重定向,说明请求的资源已经不存在了,需要使用新的URL再次访问 302 Found:表示临时重定向,说明请求的资源还在,但是暂时需要使用另外的一个URL来进行访问 301和302都会在响应的头部使用字段Location,来指明后续将要跳转的URL,浏览器将会自动重定向到新的URL 304 Not Modified:表示资源没有修改,重定向到已经存在的资源文件,也称为是缓存重定向,也就是告诉客户端可以继续使用缓存,用于做一个缓存的控制 4xx:表示发送的报文有错误,服务器无法处理,一般来说是前端发送的请求有错误 404 Bad Request:表示客户端请求的报文是有错误的,但这是个笼统的错误 403 Forbidden:表服务器禁止访问这个资源,不是你的请求有错误 404 Not Found:表示资源在服务器上找不到,因此无法提供给用户 5xx:表示客户端的请求报文是正常的,但是在服务器处理内部的时候发生了错误,属于这个服务器端的错误码 500 Internal Server Error:和400是类似的,它是一个笼统的错误码,表示服务器发生了错误,但是具体是啥错误不知道,非常笼统 501 Not Implemented:表示客户端请求的功能还不支持,类似于即将开业,敬请期待的意思 502 Bad GateWay:通常是服务器作为网关或者代理的时候返回的错误,表示服务器自身的工作是正常的,但是真实的后端服务器访问出错 503 Service Unavailable:表示服务器当前很忙,暂时无法响应客户端,请稍后再试 HTTP的头部字段有哪些? Host:假设这样一个场景,在一个IP主机上,部署了三个网站(容器),那么这个请求过去,要被哪个服务器来解析呢?这时候就可以基于Host字段来实现了,可以通过这个字段,将请求发送到同一个服务器上的不同网站 Content-Length字段:服务器在返回数据的时候,会有Content-Length字段,表明本次回应的数据长度,HTTP协议是基于一个TCP协议进行通信的,如果使用了TCP传输协议,就会存在一个粘包的问题,HTTP协议通过在头部设置一个换行符作为头部的边界,通过Content-Length作为单个HTTP Body的边界,这两个方式都是为了解决粘包的问题 Connection字段:常用于客户端要求服务器使用HTTP长连接机制,长连接就是讲只要任意一端没有明确提出断开连接的请求,就保持TCP的连接 1Connection: Keep-Alive Content-Type:用于服务器回应的时候,来告诉本次报文是什么格式,通常来说,这个字段和客户端的Accept:来联合使用的,通过这个字段,客户端就知道以什么样的编解码方式来获取本次的数据 Content-Encoding字段,说明数据的压缩方法,表示服务器返回的数据使用了什么样的压缩格式 1Content-Encoding: gzip Get请求和Post请求有什么区别 根据RFC规范,GET请求是从服务器中获取资源而不是推送资源,这个语义是只读的,这个资源是静态的文本、页面、图片视频等,GET请求的参数位置一般写在URL中,URL规定只能够支持ASCII,因此GET请求的参数只允许ASCII字符,并且对URL的长度是有限制的 根据RFC规范,POST请求向服务器推送资源,它不是安全的,也不是幂等的,POST请求数据通常写在body中,body中的数据格式是任意的,而且浏览器不会对body大小做限制 GET的语义是获取指定的资源,Get方法是安全和幂等的,可以被缓存的 Post的语义是根据请求负荷body中的字段对指定的资源做出处理,具体的处理方式根据资源类型的不同而不同,Post是不安全的,不幂等的,大部分实现是不可以缓存的 Get请求可以带body吗? 理论上可以的,因为从本质上来说,Get请求和Post请求都是一个HTTP报文,HTTP报文的格式是首部+报文的主体,同时POST请求中的URL也是可以带有一个参数的 HTTP缓存的实现方式? 对于一些具有重复性的HTTP请求,比如说每次请求得到的数据都是一样的,就可以将这一对请求=&gt;响应的数据都缓存在本地,那么下一次就直接读取本地的数据,而不必在网络获取服务器的响应了,这样的话HTTP/1.1的性能就肯定有提升了,一般来说有强制缓存和协商缓存 什么是强制缓存? 所谓强制缓存,就是只要浏览器判断缓存没有过期,那么就直接使用浏览器的本地缓存,决定是否使用缓存的主动性在于浏览器,通常来说会通过一个状态码200(from disk cache)这个字段来确定,你当前获取的资源是通过缓存来获取的,那么具体来说是怎么实现的呢?它和Redis中的缓存过期时间比较相似 Cache-Control:它是一个相对时间 Expires:是一个绝对的时间 Cache-Control:选项更多一些,设置得更加精细,具体的实现如下: 当浏览器第一次请求访问服务器资源的时候,服务器会返回这个资源的同时,在请求头的首部加上一个Cache-Control,这个字段中设置了过期时间的大小 浏览器去请求资源的时候,会先访问本地缓存,如果本地缓存的请求=&gt;响应键值对中体现的Cache-Control过期了,那么就向服务器发送HTTP请求(不论资源是否变化,这时候服务器都会返回一份最新的数据),否则的话就走from disk cache 服务器再次收到请求之后,会更新本地缓存中的Cache-Control 什么是协商缓存? 首先先来理解强制缓存有什么弊端,强制缓存的弊端主要在于: 无论服务器上的资源和本地缓存中的资源是否相同,服务器在收到这个请求之后,都会发送一份最新的数据回来 因此在这样的情况下,可能导致无效的IO,于是就提出了协商缓存,所谓协商缓存,就是在本地缓存过期了之后,这时候会向服务器验证本地缓存和远程服务器资源的一致性,如果是相同的,那么就不会再发送最新的数据,而是发回一个信号,说资源没有改动过,本次不发送最新的数据,请你使用本地的资源就可以了 那么是怎么来实现的呢?一般来说有两种策略 根据资源上一次被改动的时间,这个策略就是if-modified-since =&gt; modified-since来实现的 具体来说是这样的,就是当浏览器客户端发现本地资源过期了,然后它发现这个资源的响应头中有modifed-since字段,它就会将这个字段的值给赋值到if-modified-since中,然后在请求头上带上这个字段 然后在服务器的一端,收到这个请求之后,就会比较这个if-modified-since和对应资源的修改时间,如果资源的修改时间更大,那么返回最新的数据,这时候返回的状态码是200 OK 如果是相同的话,那么就说明资源没有被改动过,于是在这样的情况下,返回状态码304 Not Modified,通知客户端走缓存 根据资源本身的内容做一个摘要,通过这个摘要来确定资源是否被改动过了 具体来说,它的实现是这样的,就是当浏览器客户端发现本地资源过期了,然后它发现这个资源响应头中带有etag的字段,它就会将这个字段的值给赋值到if-none-match中,然后在请求头上带上这个字段 然后在服务器的一段,收到这个请求之后,就会比较这个if-none-match和对应资源的etag,如果资源的etag和对应的if-none-match中的值是不相等的话,那么就返回最新的资源,走200 OK,否则的话走304 Not Modified,如果 为什么要使用eTAG? 对应缓存更新频率高的,如果一秒内更新了多次,那么就会造成协商缓存的失效 有时候没有修改文件,只是打开了文件,也可能导致文件修改时间的变化 文件修改时间与操作系统有关,无法很好地做到操作系统异构化下的同质操作 39. HTTP和HTTPS有什么区别? 具体的区别主要就是安全和不安全的问题,首先从连接建立的过程来说: HTTP协议传输是不安全的,其中数据是明文传输的,而HTTPS通过在HTTP协议和TCP协议的中间引入了SSL/TLS协议,通过这样的方式来实现了数据的加密传输,即使HTTP数据包在网络中被截获了,对方也不知道其中的内容是什么 HTTP协议是基于TCP连接实现的,因此在TCP连接建立完毕后,就可以实现HTTP传输了,而HTTPS因为需要完成TLS/SSL的握手,因此连接建立的速度会更慢一些 HTTPS需要CA证书,来保证服务器的身份是可信的 HTTP的默认端口是80端口,HTTPS的默认端口是443端口 HTTPS解决了什么问题? HTTP是明文传输协议,这意味着在公开信道上传输的时候,可能会导致数据包被截获,可能会有三个风险 第一个风险,就是数据明文传输,如果里面存储了敏感信息,那么容易被窃取 第二个风险,数据明文传输,如果被中间人截获并且添加了额外信息,那么信息容易被篡改 第三个风险,数据明文传输,如果没有加以验证对方的身份,对方不断伪造数据包,这样就可能导致用户一直访问的是一个冒牌服务器 而HTTPS通过: 第一个手段,通过加密密钥,通过这个密钥来对数据进行加密,实现了除了传输的双方,其他人都无法获取相关的数据 第二个手段,通过摘要算法+数字签名,基于摘要和数据内容的对比,实现了数据无法被篡改 第三个手段,通过CA证书,来保证服务器是可信的 详细说说三个手段的实现过程 混合加密实现了信息的机密性,即使数据包被截获,没有通信密钥,也无法对数据的查询 摘要算法实现了完整性,它能够为数据生成独一无二的指纹,指纹用来对数据的完整性做一个校验,解决了篡改的风险 将服务器公钥放入到数字证书中,通过权威机构的认证来确定服务器是可信的 混合加密:所谓的混合加密,就是非对称加密传输通信密钥,对称加密传输通信报文 在建立之前,会在客户端和服务端生成一对公钥和私钥,所谓的公钥和私钥是这样的,首先服务器上有个公钥,这个公钥是大家都知道的,客户端上有一个私钥,这个私钥是由它自己管理的,那么在这样的情况下 服务端对通信密钥用公钥加密后,只有存储在客户端本地的私钥是可以解密的,因此可以保证通信密钥的传输安全 在完成了通信密钥的传输之后,之后所有的数据传输都使用这个通信密钥进行传输了 摘要算法+数字签名:为了保证传输的内容不被篡改,我们需要对内容计算出一个指纹,然后同内容一起传输给对方 通过这个指纹,对方就可以将数据和摘要进行对比(指的是将数据通过公开的摘要算法计算出来的摘要和对方传过来的摘要进行对比),如果是一致的,那么就认为数据没有被篡改 但是要注意了,你的这个摘要包是完全有可能被伪造的,这是因为中间人可以通过自己构造出一个包,然后通过构造这个包的摘要,这样的话对等端进行验证之后,它依然发现是合法的 那么怎么来解决这个问题呢?可以通过数字签名的方式来实现 之前提到了有一个叫做公钥和私钥的东西,这两个东西对原始报文的加密顺序不同,达到的效果也是不一样的 如果先用公钥加密,再用私钥解密,可以保证内容传输的安全,因为被公钥加密的内容,其他人是无法解密的,只有持有私钥的人,才能解密出实际的内容 如果先用私钥加密,再用公钥解密,可以保证数据是对等端传过来的,因为私钥只有对等端才持有 一般来说,在使用这个方法的时候不会对数据内容进行直接签名,因为这样签名的效率实在太低,因此通常是对定长短小的摘要进行签名,这样的话可以提升效率 一般来说是这样做的,服务端内部保管了一个私钥,然后服务端对报文摘要进行私钥加密,然后客户端用这个公钥对摘要进行解密,在这样的情况下就可以实现签名认证了 数字证书技术(重要) 通过哈希算法可以保证信息不会被篡改、数字签名可以保证信息是持有私钥的人发送的 但是这其中的关键是,必须要保证你获取到的公钥是正确的,否则的话就无从谈起 那么如果在公开信道上传输公钥的时候,这个公钥被替换了,怎么办呢? 将会出现这样的情况,出现一个中间人,这个中间人截获了所有公钥包,然后替换为自己的公钥,于是在后面,所有人获取到的公钥都是这个中间人的公钥,那么这时候,其他真正的对等端反而无法接收真实的数据,而是只能够接收中间人的数据,这样也会造成冒充的风险 因此,在这样的情况下,为了验证公钥的合法性,引入了第三方权威机构,在使用公钥之前,使用权威机构的手段来对公钥进行验证,验证合法后才能继续使用 数字证书有什么用? 数字证书是为了验证你的这个公钥,确实是对等端的公钥,而不是中间人的公钥 因此数字证书中会有公钥信息,同时还会含有服务器的信息,通过验证服务器的信息,就可以知道你这个公钥是合法的了,具体验证流程是这样的: 首先服务器向CA机构提交服务器信息,包括有服务器的个人信息+公钥打包成一个数据包,你可以理解成将这些信息封装成一个字符串,然后通过摘要算法,将这些信息弄成一个定长的hash,然后用CA的私钥进行加密,然后呢,将数据包的信息和经过加密后的hash打包成一个数字证书,就可以使用了 那么客户端会怎么处理这个数字证书呢? 会将服务器的个人信息+公钥执行摘要算法,得到一个hash1,然后将证书中的CA数字签名用CA公钥进行解密,得到hash2,然后比较hash1 == hash2?如果相等,那么证明这个证书就是可信的,可以使用公钥,否则的话就是不可信的 HTTPS是如何建立的? SSL/TLS握手的基本流程: 第一步,客户端向服务端请求公钥并且验证公钥的合法性 第二步,双方协商生产会话密钥 第三步,双方采用会话密钥进行加密通信 首先要清楚,TLS建立之前,要先执行TCP的三次握手,然后此后基于这条TCP连接执行TLS/SSL的四次握手 握手的流程: 第一次握手,ClientHello,这个过程是客户端首先发起的,客户端请求与服务器建立一个HTTPS连接,于是告诉对方(1)自己支持的TLS/SSL协议的版本号(2)自己的支持密码套件有哪些(3)客户端这边自己产生的第一个随机数 第二次握手,ServerHello,这个过程是服务端给客户端的一个回应,一般来说会回应说(1)确认版本号(2)确认密钥套件,便于后续双方协商自己的密钥是如何生成的(3)服务器的CA证书(4)服务端自己产生的第二个随机数 第三次,ClientReply,首先,在收到你这个ServerHello的时候,这时候会验证你的证书的合法性,验证的流程是这样的:(1)拿到数字证书的服务器信息+公钥,做一个摘要算法,然后将数字证书中的CA签发的数字签名,进行CA公钥的解密,然后两个相同,验证通过(2)在客户端产生一个pre-master key,用公钥加密后传输出去(3)加密通信算法改变通知,表示之后都将使用对称会话密钥进行通信(4)客户端进入SSL/TLS的ESTABLISHED,将之前通信的内容做一个摘要提供给服务端进行检验 第四次,ServerReply,服务端收到了三个随机数,经过协商的加密算法,计算出本次的通信密钥,然后向客户端发送最后的消息: (1)加密通信算法改变通知,表示随后的消息都将采用会话密钥进行通信 (2)服务器握手结束通知,表示服务器的握手阶段已经结束了,同时会将之前所有的内容做一个摘要,给客户端一个验证的机会 (3)TLS的握手阶段全部结束,之后都将使用普通的HTTP协议通信,只不过使用通话密钥来对数据报文进行加密## HTTPS一定安全可靠的吗？ 不一定,当用户信任了不可信的证书的时候,这时候就会导致HTTPS失守了,但是HTTPS本身是安全可靠的,出现这样的问题还是因为用户的操作不规范导致的 下面来讲讲中间人攻击是如何发生的 首先客户端向服务器正常发起一次HTTPS请求,首先也是要完成TLS的四次握手,但是这时候HTTPS请求就会被转发到一个假基站上,也就是说你的报文被人截获了 客户端发起一个Client Hello,携带了相关的密码套件信息,随机数,请求数字证书,TLS/SSL协议版本号,但是它不是直接发给Server的,而是经过了一个中间人服务器,这个中间人服务器截获了第一个随机数 中间人服务器截获后,伪装成客户端,向真正的服务器发送请求 然后接着,服务器发起一个Server Hello,携带了相关的密码套件确认,随机数,数字证书,TLS/SSL协议版本号,然后转发到中间人服务器,截获了第二个随机数 然后这时候中间人服务器将自己的证书转发到客户端上 接着,客户端收到Server Hello的时候,会进行CA证书,然后这时候就会发现不对劲了,就是你的这个CA证书是不合法的,然后就会弹窗:服务器证书不可信,然后客户端点击继续浏览,那么就会继续握手流程,它会用中间人的公钥对当前产生的密钥进行加密,然后发送给中间人服务器 中间人服务器收到ClientReply之后,就会计算和客户端的通信密钥A,同时会继续和真正的服务器进行握手操作,也就是会给服务器一个ClentReply,就会计算和客户端的通信密钥B 接下来的流程,就是中间人服务器用通信密钥A解密客户端的数据,用通信密钥B解密服务段的数据,这样的话数据就被偷看了 如何解决中间人攻击问题? 不要信任不合法的证书 采取双方验证,上面说的情况是:只有客户端验证对方的身份,如果服务端是正规服务器,那么它也会验证客户端的身份,具体的实现是这样的: 双向验证就是:客户端和服务端都有一个数字证书,这也就意味着双方都有一对公钥和私钥","categories":[{"name":"题库","slug":"题库","permalink":"http://kaillliu.github.io/categories/%E9%A2%98%E5%BA%93/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://kaillliu.github.io/tags/Java/"},{"name":"面试题","slug":"面试题","permalink":"http://kaillliu.github.io/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"name":"题库","slug":"题库","permalink":"http://kaillliu.github.io/tags/%E9%A2%98%E5%BA%93/"},{"name":"计算机网络","slug":"计算机网络","permalink":"http://kaillliu.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]},{"title":"操作系统 面试题总结回顾","slug":"操作系统题库","date":"2023-08-16T07:00:00.000Z","updated":"2023-09-08T04:33:03.442Z","comments":true,"path":"2023/08/16/操作系统题库/","link":"","permalink":"http://kaillliu.github.io/2023/08/16/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%A2%98%E5%BA%93/","excerpt":"","text":"进程与线程 什么是进程? 什么是程序?什么是进程? 1程序`:程序是程序员编写的源代码,一般来说在计算机中以文本的方式存在,在编译之后,就会生成一个二进制的可执行文件,当运行这个文件的时候,它就会被`装载`到内存中,然后CPU就会执行其中的每一条指令,这个运行中的程序就是`进程 什么是进程中断? 首先讲讲为什么需要进程中断,进程的中断通常来讲是这样的,在一个多级批处理系统中,同一个时刻有多个进程被创建,并且通过PCB以及进程状态队列管理这些进程,但是CPU只有一个,这也就意味着,只一个进程获得了CPU之后,其他进程就无法获得CPU了,假设这样一个场景,就是进程在执行过程中发起了IO请求,那么进程在只有获得了IO完成之后的响应之后才能够继续运行,如果这时候还让这个进程独占CPU,其他进程需要CPU又用不到了 基于这个情况,提出了中断的概念,这个概念是说,当一个进程因为阻塞或者其他原因退出CPU的时候,在之后需要重新调度这个进程的时候,就会向CPU发起一个中断,在发起这个中断之后,就会重新调度相应的进程执行 这样做的优点主要是在进程陷入阻塞之后,可以让其他进程运行,而在阻塞解除之后,CPU有能力继续这个进程的执行。 什么是并发?什么是并行? 并发:并发指的是同一个时间段内有,有多个进程/线程交错运行 并行:并行指的是同一时刻有,多个进程/线程同时运行 进程的状态模型 对于进程的状态,实际上有最简单的三状态模型,还有完整的五状态模型 什么是三状态模型? 三状态模型描述了进程的部分最重要的生命周期,他们分别是: 运行状态(Running):它表示着进程获得了CPU,并且在CPU的调配下运行代码 就绪状态(Ready):进程获得了除了CPU之外的所有资源,比如说完成了进程内存空间的分配等 阻塞状态(Blocking):进程可能因为发起了IO请求等,需要等待内核缓冲区数据准备完毕而暂停运行的状态,这时候它需要等待这个事件发生了回调之后才能继续执行 什么是五状态模型 关于五状态模型,这个模型描述了进程完整的生命周期 新建状态(New):它表示的是这个进程的PCB已经被创建好了,但是还没有分配具体的内存空间,还不能被调度上CPU 终止状态(Terminated):它表示的是进程正在从操作系统中取消注册,这个过程中执行例如回收内存空间的相关操作,但是PCB这个数据结构没有完全从操作系统中删除 简述状态轮换 状态轮换,在操作系统的实现中,一般是通过一个队列来实现的,在操作系统中,分别有: 就绪队列:就绪队列指的是进程在新建完毕后,就会被送入这个队列中,然后在CPU调度的时候,就会从这个队列中选中进程送入CPU 阻塞队列:阻塞队列指的是进程在运行过程中,发起阻塞请求之后就会送入这个队列,然后在收到中断的时候,就会从这个队列中取出相应的进程执行,注意这个队列会分类的,比如说IO请求吧,可能会分成打印机设备的IO请求的队列,网络设备的IO请求的队列,或者是某某事件请求的队列 进程的生命周期: 首先操作系统从后备作业井中取出一个作业,这个作业不是进程,而是一个进程的模板,也就是说要基于这个作业的描述,来创建你的进程 第一个过程,基于作业的描述创建进程,这时候进入进程从NULL-&gt;新建状态,这一步的工作其实就是创建了一个PCB,并且交给了操作系统管辖,但是此时还没有被进程分配空间,比如说分配虚拟内存的页表空间,以及相关的寄存器等 第二个过程,基于进程所需要的空间,为进程分配空间以及一系列的进程初始化工作,在完成之后,这个进程就会被插入到就绪队列中,这时候进入进程从新建状态-&gt;就绪状态 第三个过程,基于CPU的调度策略,从就绪队列中挑选出一个进程,上CPU执行,这时候进程就进入到了运行态 第四个过程,基于CPU的调度策略,当运行态的进程运行到中途发起了IO请求陷入阻塞的时候,这时候就会退出CPU,然后将其插入到IO请求对应的阻塞等待中,进入一个运行状态-&gt;阻塞状态 第五个过程,基于内存的管理策略,当操作系统发现内存不足的时候,这时候会将阻塞态的进程所分配的空间换入到磁盘中,进入到一个阻塞状态-&gt;阻塞挂起态 第六个过程,基于内存的管理策略,当操作系统发现需要调度挂起态的进程的时候,这时候会将阻塞挂起态的进程换入到内存中,然后进入到一个阻塞态 第七个过程,基于CPU的调度策略,当阻塞态的进程需要调度上CPU的时候,这时候就进入到一个运行态 第八个过程,基于内存的管理策略,当操作系统发现内存不足的时候,这时候会将就绪态的进程所分配的空间换入到磁盘中,进入到一个就绪状态-&gt;就绪挂起态 第九个过程,基于内存的管理策略,当操作系统发现需要调度挂起态的进程的时候,这时候会将就绪挂起态的进程换入到内存中,然后进入到一个就绪态,然后重新参加进程调度 第十个过程,当运行结束之后,这时候就会执行相关的进程收尾工作,这时候PCB还没有从操作系统中删除,这时候是一个终止态 进程在操作系统中的存在形式 为什么需要有阻塞队列和就绪队列? 这是因为在执行CPU调度的时候,是要从特定的状态的进程集中进行检索的,如果没有这个队列,那么就意味着要遍历所有注册在PCB上的进程,在这样的情况下,将会极大降低CPU调度的效率,基于这个情况,设定了阻塞队列和就绪队列 在Linux源代码中,进程的描述是通过结构体PCB的形式进行说明的,主要包含了有什么信息呢?这个问题可以这样来说明 进程在操作系统中工作,关联到的有: 进程调度子系统,因此存储有进程的一些基本信息,比如说有进程的唯一标识符,用来在PCB表中标识这个进程,有进程的归属用户,表示这个用户是谁创建出来的。还有进程控制的一些相关信息,比如说进程分配的优先级,它在调度的时候占的权重是多少,进程当前的状态 进程在工作时,是基于进程中分配的空间和操作系统分配的资源进行工作的,因此它内部有一张资源分配清单,比如说这个进程打开了什么文件,正在使用什么IO设备,分配的内存空间地址在什么地方 进程的运行和CPU脱不开关系,因此CPU中寄存器中的值,当进程被切换的时候,CPU状态的相关信息都会被保存到PCB中,这个东西就叫做现场,在进程被换下到的时候,这时候就会将寄存器中的值全部记录到PCB中,这样的话就进程恢复运行的时候,就能够将之前的运行状态恢复下来了 PCB是如何组织的 通过进程队列的方式,比如说有等待队列,就绪队列,运行队列(实际上是运行指针,通常来说一个CPU只能运行一个进程,因此它是一个指针,指向一个进程实例),那么新建队列呢? 新建队列可以理解就是等待队列,因为新建的过程就是要等待操作系统为止分配资源,在分配完毕之后,就将这个进程从队列中弹出,然后插入到就绪队列中 进程的控制原理 进程的控制原理主要可以从每个状态的转移都发生了什么来讲述 进程新建的时候,都发生了什么?:进程新建的时候,首先操作系统会为其创建一个PCB,然后在这个PCB上填入相关信息,然后等待操作系统为其分配资源,这个期间都处于一个新建态,这时候其实是处于一个等待队列中的,然后在创建完毕之后,就会从等待队列中弹出,然后插入到就绪队列中,供CPU挑选调度 进程被调度上CPU的时候,都发生了什么?:进程被调度的时候,一般来说需要更改PCB头部信息,将原本在CPU上的进程插入到指定的队列中,然后操作系统中的运行指针指向被调度的进程。 进程被阻塞的时候,都发生了什么?:进程被阻塞的时候,这时候进程就会退出CPU,这时候就会将当前CPU的运行环境,比如说有程序计数器,寄存器(比如说有栈顶寄存器%rbp,%rsp)等这些寄存器中的值,全部保存到PCB中,然后将这个PCB插入到一个等待队列中,然后就会运行指针就会指向新调度的进程了 进程被唤醒的时候,都发生了什么?:进程被唤醒的时候,这时候进程会从原来的队列中被弹出,然后运行指针指向这个进程,接着将PCB中的CPU相关信息恢复到CPU的寄存器上,然后CPU开始执行相关的指令 进程被终止的时候,都发生了什么?:进程可以有三种终止方式,分别是: 正常的终止,当子进程终止的时候,它在父进程继承的资源就会被回收,如果是父进程被终止了,那么子进程就会变成一个孤儿进程,操作系统会将这个进程托管给1号进程,父进程的资源就会被回收,然后将这个对应的进程的PCB中队列中删除 异常终止 外界干预(kill) 进程的上下文切换发生了什么? 首先要搞清楚为什么需要进程上下文切换,进程上下文切换发生的时机有: 按照CPU的调度策略,在一定时间片结束之后,会换用新的进程执行 当前执行中的进程陷入了一个阻塞的状态 CPU的上下文切换 CPU在执行的时候,必须知道当前进程的执行环境,比如说进程执行中的函数调用地址,函数返回地址,函数执行过程中的中间操作数栈,为了解决这个问题,而每个进程的执行过程又都是不一样的,如果没有一个数据结构来存储当前的执行情况,那么在发生了进程切换之后,就无法找回原来的执行状态了,为了解决这个问题,设计了CPU上下文切换这种机制 简单来说就是将CPU的相关寄存器信息,以及当前页表地址等环境信息存储到PCB中,这个叫做保护现场 将CPU的相关寄存器信息,恢复到CPU上,这个叫做恢复现场,恢复现场的过程就是说将相关的信息恢复到CPU上,好让CPU知道那些执行信息从哪里加载,从哪里执行 CPU的上下文切换有哪几种? 进程间上下文切换 线程间上下文切换 中断上下文切换 其实中断上下文切换可以看作是进程间上下文切换的一种,因为从本质上讲,中断实际上是调用了内核程序的函数,你可以理解成内核程序和用户程序之间发生了一次上下文切换 因此系统调用的时候,会引起一定的额外开销 什么是线程? 为什么需要线程?只有进程不行吗? 证明一个设计不行的办法,就是假设没有这个设计会发生什么?假设我们要设计一个视频播放程序,这个程序要完成三件事情,分别是: 从网络或者本地磁盘中读取文件信息(IO事件,引发阻塞)到用户缓冲区中 用户缓冲区中的信息被解码为可播放的文件信息(CPU运算) 播放这些东西(I/O) 如果只有进程,那么我们可以启动三个进程,这三个进程分别执行这三个任务,但是问题是:如何来共享数据?效率会不会太低了? 我们这样分析,首先共享数据,意味着我们需要通过fork()或者共享内存的方式来读取缓冲区中的数据,要对共享内存区域施加保护 其次,效率问题,进程间的切换是重量级的,尤其是在内存占用大的进程中,切换页表是十分重量级的操作,引起效率降低 可以看出,首先就是效率低下的问题,如果我们可以创建一个结构,这个结构可以在不引发进程切换的情况下,同时安排多种任务的执行,尤其是可以同时执行IO任务和CPU运算任务的这种模型,而且这些任务都是共用一块内存空间的就好了 因此提出了线程 线程之间可以并发执行,并且共享相同的内存空间,线程是进程间执行的一条流程,线程的切换代价很小,只需要维持线程执行过程中的寄存器相关数据就可以了,线程之间可以并发执行,只要保证并发安全,就可以实现对同一个进程空间内的数据访问,他们可以共享代码段,但是每个线程都各自有一套独立的寄存器和栈,这样就可以确保控制流是相对独立的 线程对比进程,有什么优缺点? 首先线程它是轻量级的,在上下文切换调度的时候,维持的现场是少量的 各个线程之间可以并发执行,一个进程中可以划分多个子任务,提高效率 线程之间可以共享文件资源,不需要通过消息队列等需要经过内核的方式来执行 缺点:进程中的一个线程崩溃的时候,其他线程就都会崩溃,这是因语言而异的,具体来说,就是用户级线程和内核级线程的区别 线程和进程有什么区别? 区别主要体现在创建的开销,执行时的开销,销毁时的开销 (1)创建的开销,进程的创建涉及到一个内存的分配和相关资源平台的创建,比如说有文件管理相关结构的创建,内存相关结构的创建,而线程的创建只需要创建TCB即可,资源管理机构是共享的,因此创建线程要比创建进程快得多,同时也可以看出,进程是资源调度的基本单位,而线程是是CPU调度执行程序流的基本单位 (2)执行时的开销,在执行的时候,进程执行上下文切换可能会导致页表这样重量级数据结构的切换,而线程的上下文切换只需要保存少量信息,比如说寄存器,栈等相关信息就可以完成切换了,同时线程间的通信或者数据共享,因为是处在同一个地址空间的,因此不需要内核的干预就可以共享数据,而进程间的通信,比如说IPC中的消息队列/信号量这样的机制,都是基于内核实现的,在这样的情况下,引起了更大的开销 (3)销毁时的开销,进程在销毁的时候,需要完成相关资源的释放,比如说有文件的关闭,内存的回收(具体表现为空闲列表/内存分区整理)等工作,这些都需要一定的开销,而线程的创建,只是删除TCB的相关信息而已,一般来说就是释放掉几个变量值,非常块 线程在操作系统中是如何实现的? 用户级线程:在用户空间实现的线程,不是由内核管理的线程,是由用户态的线程库来实现线程的管理 内核线程:在内核中实现的线程,是由内核管理的线程 轻量级线程:在内核中用来支持用户线程的 这个知识点比较晦涩,我们以实例来了解,区分用户级线程和内核级线程,可以从这些线程在什么地方调度进行区分,也就是说,用户级线程的调度发生在用户态下,而内核态线程的调度发生在内核态下,还是很难懂,下面举个例子 以Go语言中的协程为例,它就是一个用户级线程,假设我们在一个执行线程中开辟了5个协程,那么这5个协程就是在这个线程执行的过程中执行程序流的,你可以理解成,有五条不同的程序流,在一个线程间来回切换,在操作系统内核程序看来,尽管有五条不同的程序流,但是始终只有一个线程(或者是一个进程)在执行,这种模型称为是用户线程:内核线程= N:1的模型 以Java语言中的线程为例,底层是使用C/C++中的pthread来实现的,每创建一个线程,操作系统都能感知到,因此在执行调度的时候,每个线程都对于一个内核级线程,这种模型称为是用户线程:内核线程 = 1:1的模型 总结:如何来理解用户级线程 用户级线程:它是由语言本身的函数库来实现的,线程的调度发生在用户态,可能在程序方面创建了N个线程,但是在操作系统内核感知中,就只是一个进程被创建了或者是一个线程被创建了,当发生了内核级的线程调度的时候,这N个用户级线程全部都会被挂起 用户级线程有什么优缺点? 优点:多个用户级线程对应一个内核级线程,因此在这些用户级线程不停调度的时候,这时候不会触发系统调用,就好像只是发生了函数执行到一半然后切换一样,在实现上就是在会在进程内部维护一张TCB表,通过这个TCB表来完成进程内部的用户级线程的调度 缺点:由于操作系统不参与用户级线程的调度,如果一个用户级线程发生了阻塞,那么这就意味着共用同一个内核线程的这些用户级线程就会被全部阻塞,当一个线程开始运行之后,除非它主动交出CPU的使用权,否则它所在的进程当中的其他线程无法运行。同时运行会比较慢,因为这多个用户级线程共用的一个内核级线程的时间片 内核级线程有什么优缺点? 内核级线程只有在支持线程技术的操作系统中有,那么这张TCB表就是操作系统亲自维护的,于是在这样的情况下,就是Java中的线程实现模型,具体来讲,就是Java中new Thread().start()之后,在操作系统中就真的会创建一个新的线程然后执行 优点:(1)在一个进程当中,如果某个内核线程被阻塞了,不会引发其他线程的阻塞(2)分配给线程,多线程的进程获得更多的CPU运行时间 缺点:(1)需要维护TCB表,当TCB表中的元素过多的时候,可能导致性能下降(2)线程的切换都是基于内核来完成的,上下文切换开销巨大 什么是轻量级进程 轻量级进程是操作系统内核支持的用户线程,首先要理解上面讲的这个内核级线程和用户级线程都是在同一个进程间调度的,那么在不同进程间的线程间调度,无论是哪种调度,都会调度进程的切换,所以在这样的情况下,提出了轻量级进程 轻量级进程的概念,就是进程的概念模糊了,就好像CPU调度上轻量级LWP的时候,就好像在调度同一个进程中的线程一样,这样的话就减少了上下文的开销 进程/线程调度算法有哪些? 从总体上来看,进程的调度算法有抢占式的调度算法、非抢占式的调度算法 抢占式的调度算法:根据一定的算法,计算出这个进程所需要执行的时间片,在运行完这个时间片之后,强制让其退出CPU 非抢占式的调度算法:挑选一个进程运行,直到这个进程运行完毕后/阻塞,才让它退出CPU 下面简述一下相关算法: (1)先来先服务算法:简单来说,就是根据插入就绪队列的先后顺序,来决定谁先上CPU,这种算法最好要搭配时间片来使用,就是说在一个进程运行一定时间片之后,将其加入到队列的尾部,它对长作业是有利的,不适合IO密集型的系统,因为假想一下,一个线程需要大量IO,但是IO时间非常短,一IO就会插到尾部去了,这样的话获得CPU的机会很少 (2)最短作业优先算法:最短作业优先算法理论上可以,但是实际上因为无法估算一个作业运行时间而无法执行这种算法,这种算法的初衷就是提供系统的吞吐量,因为单位时间完成的任务数量越多,那么吞吐量就越高,那么将CPU有限分配给那些运行时间短的任务,就能尽可能短的时间内完成尽可能多的任务,但是可能导致长任务饥饿 (3)最高响应比优先调度算法:它是根据一个响应比这个指标来动态调整谁先上CPU的,它通过(等待时间+要求服务的时间)/(要求服务的时间)这个比例来判断,谁相对来说等的最久,这样的话就能够避免饥饿的问题,因为等待时间越长,要求服务的时间越短,这个比例就会越大,因此照这样来看,就能够避免等待时间太长的问题发生 (4)时间片轮转算法:每个进程都被分配一个时间片,在时间片运行完毕后自动退出,重点是如何设计CPU的时间片,如果时间片太长,那么就可能导致进程饥饿,如果太长,那么就会导致频繁的上下文切换调度 (5)最高优先级算法:根据进程的优先级,优先挑选那些优先级高的进程上CPU,静态的优先级,提前设定好的优先级,动态的优先级,比如说最高响应比优先,其实就是一种动态优先级的思路 (6)多级反馈队列优先算法:我理解它就是先来先服务算法+最高优先级算法结合,它设置了多个队列,每个队列的运行时间片都是不一样的,假设一个进程刚来,那么它就会进入一级队列,然后它会执行一级队列中规定的时长,如果执行完了这个时长还没执行完,就会推到第二集队列,不断推,直到执行完毕为止,反馈意思是讲,当一个进程到了更高级的队列的时候,这时间就执行更高级队列中的进程 判断调度算法好坏的指标有哪些? CPU的利用率:调度算法能不能保证CPU始终是匆忙的状态 系统的吞吐量:吞吐量表示的是单位时间内CPU完成进程的数量,长作业的进程会占用较多的CPU资源,因此会降低吞吐量 周转时间:进程运行+阻塞+等待的总和,越短越好 等待时间:这个等待时间不是阻塞等待的时间,而是进程处于就绪队列中的时间 响应时间:用户提交请求到系统第一次产生响应所花费的时间，在交互式系统中，响应时间是衡量调度算法好坏的主要标准,尤其是客户端相关的开发,要重视这个指标 进程间的通信方式(IPC) 进程间的通信方式大致有如下的方式 基于管道的通信方式 1list | grep inst 这个|就是一个管道,它的作用就是将上一个进程的输出作为参数输入到下一个进程中,这个过程就是一个进程间通信的过程,它的底层是基于fork()和文件描述符共享这样的方式来实现的 如果要彻底理解管道通信方式,那么就先要理解什么是fd 什么是fd? 关于什么是fd的问题,可以用这张图来表示: 可以看到fd表中存储了大量的fd索引值,通过这个索引指向文件表,然后文件表中存储了真正的文件地址,最终对这个文件进行读写 那么管道它在linux源码的底层中,就是在File table中注册了&lt;操作方式,文件地址&gt;这样的键值对,通过这个fd,就可以基于这个fd对文件进行相应的读写操作了 那么接下来看管道相关的操作,它底层源代码是通过void pipe(int[2] fd)这个系统调用来实现的,通过这个系统调用,在File table上注册上read&amp;write的fd,指向的是同一个inode,那么管道的话就可以通过那个read的fd来从文件中读取数据,可以通过write的fd来从文件中写入数据,那么这仅仅只是进程中对这个文件的管理而已 然后在使用了管道之后,它其实还做了fork(),简单来说就是创建一个子进程,让这个子进程也拥有这个fd的信息,这样的话,父进程就可以基于这个fd来向文件中写入数据,然后子进程就可以基于这个fd来向文件中读取数据了 如果需要双向通信怎么办? 双向通信的话,首先我们要了解,单向通信的时候,这时候父进程会关闭读取的fd,子进程会关闭写入的fd,如果是双向通信的话,那么就需要创建两条管道,然后父进程关闭写入的fd,子进程关闭读取的fd,这样的话就可以实现两条管道通信,互不干扰了 关于管道通信的弊端 基于fork()实现的,如果父进程具有的数据非常多,那么就可能导致进程缓慢,而且一次fork(),我们真正想要的数据就是两个索引值,开销和收益不成正比. 基于消息队列的通信方式 消息队列:管道通信的弊端在于,每一次通信都需要执行fork(),效率低下,如果需要频繁地交换数据的话,那么这就意味着需要不断地fork(),频繁地执行这个系统调用,然后复制数据,每一次消息通信都这样的话,那未免效率太低下了 所以的话,一种思路就是设置一个缓冲区,通过这个缓冲区,双方进程从这个缓冲区中读取数据就可以了,这其实就相当于一个生产者/消费者模型,生产者进程往这个缓冲区中丢数据,消费者进程从这个缓冲区中读取数据,Linux的实现方式是在内核中设置一条链表,然后生产者执行push_back(),消费者执行pop_back(),但是由于是内核缓冲区中的数据,因此每次取数据都需要执行上下文的切换(执行系统调用),所以在这样的情况下,也会造成一定的开销,但是相比起fork()的方式,已经是非常轻量级的了 消息队列的弊端? 通信不及时,首先,生产者的投递需要将数据从用户缓冲区拷贝到内核缓冲区,这存在一定的时延 没有持久化,消息存在的是内核缓冲区中,如果操作系统挂掉了,那么消息就丢失了 不适合大数据量的传输,首先就是时延很高,操作系统还对消息做了一个限制,不能发送消息长度大于length()的消息 基于共享内存的通信方式 上面讲到了消息队列这样的方式,它的弊端在于每次读取数据都需要陷入一次系统调用,而且对于大数据量的数据处理的时候,有明显的瓶颈,所以在这样的情况下,提出了共享内存的方式 共享内存的原理,首先要搞清楚共享内存的支撑是什么,共享内存的支撑首先是虚拟内存技术,虚拟内存技术使得每一个进程都有自己的一个虚拟内存空间,然后每个进程都可以基于自己的虚拟内存空间执行内存的操作,它底层是基于一个逻辑地址=&gt;物理地址的映射来实现的,具体来说,就是在程序中划定的地址,每个进程可能是一样的,比如说进程A可能有一个变量地址是0x01,进程B也可能有一个变量地址是0x01,但是在具体的物理内存中,这两个变量的物理地址是不一样的。 那么共享内存就是抓住了这一点,它将映射的物理内存地址设置为了同一块,这样的话另一个进程对这块内存的操作,另一个进程就能马上看到了,这样做的好处是: 提高了通信效率,避免了数据来回拷贝 缺点是: 可能产生并发安全的问题,需要通过信号量/加锁的方式来实现线程安全 基于信号量的通信方式 上面讲到了共享内存来实现进程间的通信,那么在这样的情况下,需要保证并发安全,就可以基于信号量来实现,信号量在操作系统底层中是这样定义的 1234struct seamphore&#123; int value; queue blockQueue;&#125; 当需要对共享内存执行互斥保护的时候,这个value就会被初始化为1,当有一个进程需要获取资源的时候,就需要执行acquire()操作,然后就会这个value--,如果value == 1,那么代表获取成功 如果value &lt;=0,那么就代表获取失败,就会将当前这个进程加入到这个blockQueue中 当对资源操作完毕后,就需要执行release()的操作,这时候会检查,如果value == 0,那么就代表只有自己获取到这把锁,于是直接value++,如果value &lt; 0,那么就证明有人因为获取到这把锁被阻塞了,就需要唤醒blockQueue中的进程,然后value++ 当需要对共享内存执行一个同步保护的时候,这个value就会被初始化为0,比如说生产者消费者模型吧,A是生产者,A在生产区满的时候会将这个semaphore执行一个release()的操作,然后消费者B才能去消费 如果消费者B提前去消费了,那么在value == 0的情况下就会被阻塞,只有A生产完毕后,B才会被唤醒,这样就可以实现同步的效果了 基于信号的通信方式 信号:在Linux操作系统中就是kill指令,它可以在任何时刻给任何进程发送一个信号,如果进程设置了信号回调函数的话,那么就会执行这个信号回调函数,对信号的处理主要有: 执行默认操作,比如说终止进程 捕捉信号,其实就是在程序中注册一个信号回调函数,当收到这个信号的时候执行某某操作 忽略信号,SIGKILL和SEGSTOP无法忽略。 有没有无法杀死进程的情况? 要了解这个问题,首先要明白什么是僵尸进程?什么是孤儿进程? 这两种进程是特殊状态下的进程,当在执行fork()的时候,会出现父子进程这一说,但是实际上,父子进程之间退出顺序是不确定的,因为fork()其实就是复制出来了两个进程 第一种情况,父进程早于子进程结束,这时候子进程就变成了孤儿进程,这时候操作系统会将这个子进程托管到init这个一号进程上,然后init进程会定期执行wait()/waitPid()来执行子进程的资源回收,主要是删除PCB,然后还原PCB表中可用的PID 第二种情况,父进程晚于子进程结束,这时候子进程就变成了僵尸进程,它说的是子进程虽然释放了自己全部资源,但是子进程的PCB信息还没有被回收,比如说还占用着PID,如果出现了大量的僵尸进程,那么就会导致无法再创建新的进程了,这种危害是比较大的,解决办法是这样的: 将这种出现大量僵尸子进程的父进程干掉,然后全部转移给init进程,这样的话就会回收掉这些PCB 或者就是加强编码意识,在父进程相关代码中添加定时wait()/waitPid()的方式来回收掉这些进程 或者是注册信号函数,通过注册SIGCHILD信号处理程序,当进程结束的时候向这个父进程发送信号,父进程随即调用wait()/waitPid()回收资源 fork()两次,意思是讲,有一个P进程,然后通过fork(),产生C1进程,然后在C1进程再执行fork(),产生C2进程,然后C1进程马上退出,C2就会被init进程托管了 回到问题,无法杀死进程其实就是杀死子进程的情况,子进程虽然资源被释放了,但是由于PID还注册在进程表中,看起来就好像没有杀死一样,方法如上。 基于Socket的通信方式 网络通信,从最本质上来讲,其实也就是分布在不同网络上的主机上的进程进行通信,如果需要跨主机通信的时候就需要用这个Socket进行通信了,下面来讲讲socket的创建原理 1int socket(int domain,int type,int protocol) 在C/C++中使用Socket通信的时候,分别有三个参数,主要有: domain:指定协议族,比如说有AF_INET表示IPV4、AF_INET6表IPV6、AF_LOCAL/AF_UNIX用于本机通信 type:用来指定通信的特性,比如说有SOCK_STREAM表示字节流,对应的TCP这样的连接方式,还有的有SOCK_DGRAM表示的是数据报,对应的是UDP、SOCK_RAW表示的是原始套接字 protocol参数表示的是用来指定通信协议的,但是目前基本废弃了 那么实现不同的协议的通信参数配合有 实现TCP字节流通信:AF_INET、SOCK_STREAM 实现UDP字节流通信:AF_INET、SOCK_DGRAM 实现本地字节流,只需要将协议换成是AF_LOCAL/AF_UNIX就可以了 说说使用TCP字节流的底层实现 第一步,服务端和客户端初始化一个socket,这时候会在底层中创建文件,然后返回读写相关的fd 第二步,服务端调用bind,设置socket的IP和端口 第三步,服务端调用listen,进行监听 第四步,服务端调用accept,这一步其实就是不断轮询是否有socket完成了连接初始化,然后它就会取出这个socket对应的fd,监听其中的数据变化 第五步,客户端调用connect(),执行经典的三次握手 第六步,服务端accept(),然后告诉客户端,我本地有一个文件索引是fd,专门用来给你写数据的,你下次发数据包的时候,就在这个数据包上标明要写入服务端上哪个文件fd,然后协议栈就会根据这个信息,将相关字节写入这个文件中 第七步,客户端write、服务端read 第八步,户端断开连接时，会调用 close，那么服务端 read 读取数据的时候，就会读取到了 EOF，待处理完数据后，服务端调用 close，表示连接关闭。 说说使用UDP数据报的底层实现 网络通信部分是这样实现的 第一步,客户端和服务端都执行new socket(),然后执行bind(),监听端口上是否有数据到来 第二步,客户端执行sendTo(),然后等待数据的返回,也就是执行recvfrom() 第三步,服务端执行recvFrom(),然后执行sendTo() 本地 socket 被用于在同一台主机上进程间通信的场景： 本地 socket 的编程接口和 IPv4 、IPv6 套接字编程接口是一致的，可以支持「字节流」和「数据报」两种协议； 本地 socket 的实现效率大大高于 IPv4 和 IPv6 的字节流、数据报 socket 实现； 对于本地字节流 socket，其 socket 类型是 AF_LOCAL 和 SOCK_STREAM。 对于本地数据报 socket，其 socket 类型是 AF_LOCAL 和 SOCK_DGRAM。 本地字节流 socket 和 本地数据报 socket 在 bind 的时候，不像 TCP 和 UDP 要绑定 IP 地址和端口，而是绑定一个本地文件，这也就是它们之间的最大区别。 死锁篇 什么是死锁? 死锁从现象上来说,就是在做并发安全控制的时候,因为控制不当而导致的,假设这样一个场景,有线程A和线程B同时需要资源1和资源2 然后线程A申请资源1成功了,占用了资源1,然后申请资源2的时候发生了时间片超时 然后线程B申请资源2成功了,然后申请资源1的时候,因为不够,陷入了阻塞 然后线程A恢复,继续申请,发现被线程B占用,于是这就出现了线程A等待线程B,线程B等待线程A的情况 从发生的因果关系上来看,要满足下面的四个条件,分别是: 对临界资源的控制是互斥的 占有而且等待,线程在获取了资源之后,在申请新的资源的时候如果不足的时候就会被阻塞,同时不会释放手上的资源 不可剥夺,线程在被获取的之后,除非自动释放,不然不会被剥夺 形成循环等待 死锁的解决办法 死锁的解决办法通常有预防、避免、检测和解除 死锁预防 预防:是采用某种策略,限制对并发资源的请求,重点是使得死锁条件在系统执行的时间点上,都不同时成立 首先互斥条件是无法破坏的,因为破坏了互斥条件的话,就无法做到资源的保护了 其次,不可剥夺这个条件也可以使用,但是剥夺式的算法可能导致系统处理效率下降,举个例子,一个进程在获取了打印机资源之后,如果这时候有其他进程强行剥夺了这个资源的话,就有可能导致出现异常现象,因此这个不可剥夺并不适用于全部的资源 因此可以从占有且等待和形成循环等待链的这两个条件入手 有两种策略: 静态资源分配策略:这种策略说的是在进程执行的时候,提前就将资源一次性全部分配给它,然后才开始执行,这样的话就可以避免占有而且等待的情况,静态资源分配策略避免了一个进程占有了资源而无法启动的情况发生 层次分配策略:它破坏了形成循环等待链的情况发生,这种策略是将资源进行分级,只有申请了低级的资源才能申请高级的资源,需要理解的是,为什么这种策略能够解决形成循环等待链的问题?这是因为循环等待的情况是这样的,线程A获取了高级的资源,反而去申请低级的资源,线程B获取了低级的资源,去申请高级的资源,症结在于线程A的这种情况,如果是按照层次进行分配的话,那么就出现拥有低级的资源去申请高级的资源的情况,这样就可以避免了交叉申请,最终避免了循环等待的情况发生 死锁避免 死锁的预防可以有效解决相关的问题,它有点像悲观锁,它料定系统中一定会产生死锁,于是以最悲观的方式来限定资源的申请,这样做就会导致系统的运行效率降低,那么死锁避免就是讲 假设系统中不经常发生死锁,系统只有在分配资源时,检测到可能发生死锁的时候,出手干预 有一种经典的策略可以实现死锁避免,也就是银行家算法,银行家算法的核心概念有: 安全状态:分配之后,能否在当前的剩余进程中找到一个执行顺序,使得全部进程运行完毕,如果存在这样的方式,那么就将资源分配给它 不安全状态:剩余资源无法满足就绪队列中的任意一个进程,也就是无法产生任意一个安全队列 核心思路是这样的:先试探性地将资源分配给该进程,然后执行检测算法,如果安全的话,那么就执行分配,否则的话就取消分配 死锁检测 死锁的检测算法是基于图算法来实现的,具体地来说,就是会将进程和资源抽象成图,然后根据成环的情况来检测死锁,算法的流程如下: 如果进程-资源图中没有环路,这时候就没有发生死锁 如果有环的话,那么就要执行这个算法,简单来说就是这样的,首先我们先将那些既没有阻塞等待也不是孤立的节点找出来,然后把它的分配边和请求边消去,如果一直这样消下去,最终图上所有进程都是孤立的,那么就证明没有死锁 原理是什么? 首先,为什么要消去那些没有阻塞等待的节点?这是因为它不阻塞等待,证明它可以运行完,运行完了之后自然就会释放资源,然后就可以把分配边和申请边给去掉,然后看看还有哪些进程能继续运行的,如果最终没有边了,证明大家都能运行完,因此这个算法是可以成立的 死锁解除 死锁解除一般来说就要配合死锁检测算法来使用的,当操作系统检测到有死锁发生的实时,就会启动死锁解除的流程: 立即结束所有进程的执行,重启操作系统 撤销所有涉及到死锁的进程,解除死锁后继续执行 逐个撤销涉及到死锁的进程,回收资源直到解除 抢占资源,从相关进程中剥夺资源给这些进程使用,从而解除死锁 实际编程中如何解决死锁的问题? 死锁一般现象是程序的执行时间过长,这时候就要到服务器上查看了 第一步,查看相关进程,使用top -n1 | grep xxx这样的关键字查看PID 第二步,使用jstack PID查看是否发生死锁 内存管理篇 什么是虚拟内存? 什么是虚拟内存地址?什么是物理内存地址? 首先先来讲讲为什么需要有这两种地址的划分,这是操作系统中运行了多个进程,如果这多个进程同时操作物理内存地址的话,就会难以管理: 如果只有物理内存地址,那么在编写程序的时候,就需要在程序中将物理内存地址写死,但是这是一件不可能的事情,你开发一个程序,是给很多人用的,每个人的机器上用的内存地址都是不同的,不能行 进程的挂起和恢复的时候,需要重写程序中大量的地址,效率太低 因此引入了虚拟内存地址,虚拟内存地址对于程序执行来说,是透明的,它就好像在操作一块只属于自己的内存地址一样,比如说进程A定义了一个变量a,进程B定义了一个变量b,他们的虚拟内存地址都是0x1,但是他们对这个变量的操作互相都是不可见的,那么实际上是在操作什么呢?实际上是在操作经过MMU翻译之后的物理内存地址,通过MMU这个桥梁,完成虚拟内存地址对物理内存地址映射,从这个角度上来说,实现了进程间操作内存的一个隔离 操作系统是如何来管理虚拟内存地址和物理内存地址之间的关系的? 这个问题简单来说,就是如何基于虚拟内存地址得到物理内存地址,并且能够保证各个进程之间所持有的物理内存地址的操作不会引发冲突? 什么是内存分段? 内存分段,简单来说就是将进程中各个数据段,按照它的含义执行分段,比如说有代码段、数据分段、栈段、堆段,不同的段是有不同的属性的,所以就有分段的形式将这些段分离出来管理 内存分段的情况下,是如何完成翻译的? 内存分段的关机数据结构是虚拟内存地址和段表,通过这两个数据结构来实现段地址的翻译,具体来说就是: 首先拿到一个虚拟内存地址,然后通过高x位得到这个地址在段表中的下标,比如说是1 然后它就会拿着这个下标1,去查询段表,得到这个段在物理内存中的实际地址,然后再用剩余的低x位,通过实际物理地址+这个段内偏移量,就得到了一个实际物理内存地址 如何完成内存保护的? 段表中实际上是一个二元组,里面存储的是&lt;段表的下标&gt;:&lt;段的基地址,段的界限&gt;,通过下标寻址,就可以知道这个段的界限,如果翻译所得的地址大于了这个界限,就会抛出段错误的异常 分段有什么缺点? 分段的缺点主要有: 换入换出的效率比较低,因为要执行换入和换出的时候,是一整段换入换出的,而一段可能会很长,所以涉及到的数据拷贝可能效率会比较低 存在内存碎片,比如说段在内存中随机分配,产生了[512,128,256,128]这样的布局,然后一个进程退出两个128的段被释放了,于是在这样的情况下,如果来了一个256MB的段需要分配,这样就会导致段无法被分配下来,而内存中明明就有256MB的空余,这样的话就导致内存利用率低了,办法也是有的,就是执行内存整理,但是需要一定的内存开销 什么是内存分页? 什么是页框:页框是一个分页概念,它将内存中划分成了一个个大小相同的单元,然后装有数据的页就会装入这个页框中,页框是内存划分的逻辑概念 什么是页:实际装数据的内存单元,页是实际存储数据的物理概念 分页技术的情况下,是如何完成翻译的? 同理,每个进程都有一张页表,&lt;虚拟页号&gt;:&lt;实际页号,页内偏移量&gt;,首先拿到一个虚拟地址,从高位切分出一个虚拟页号,然后拿着这个虚拟页号到页表中查询,拿到这个二元组之后,就到实际内存中查询实际的页号,然后根据页内偏移量,就能够找到实际的地址了 如何完成内存保护的? 内存保护:主要也是通过页表界限寄存器来判断的,如果虚拟页号大于其中存储的值的话,那么就证明越界,如果偏移量大于页大小的时候,那么也证明越界了 分页技术有什么优缺点? 先说优点: 内存的换入和换出的效率提高了,由于分页是固定大小的,因此在这种情况下,只需要换入和换出小部分的进程就可以了 解决了内存外碎片的问题,因为分页技术的存在,使得内存的分配是以页为单位的,因此离散化的分配方式可以使得内存页干掉了内存外碎片 缺点: 会产生内存内碎片的问题,尽管数据不足4KB,最后也是会分配完整的一个4KB的页给这个进程的 页表内存占用高,假设一个内存为32位的机器,它所代表的虚拟空间是4GB,那么就需要2^20个页来存储页表,大约就需要4MB的内存来存储页表,这样的开销是很巨大的。 什么是多级页表技术? 多级页表相当于说给页表再建一个页表,比如说本来一个页表要要存储2^20个页表项,那么在多级页表中,它对这些页表项进行再次划分,比如说我将0~1023虚拟页号的这个页表记录一个起始地址,然后当我的虚拟页号落在这个区间的时候,我就去查找二级页表,然后发现0~1023页表的起始地址为0x00,然后将这个起始地址拿出来,然后起始地址+偏移量,就可以找到具体的页表项了,这是地址翻译的原理 二级页表的开销不是更大的吗? 确实是,但是根据程序的局部性原理,一级页表中的数据只有少部分会被加载到内存中,而只有二级页表是常驻在内存中的,而二级页表的存储开销是非常小的,这样就起到了使用更小的空间,可以存储更大搜索区间的效果 什么是TLB? 多级页表解决了页表空间占用太大的问题,但是多级页表的翻译技术使得翻译这个过程更加耗时了,于是带来了一定时间上的开,为了解决这个问题,引入了硬件机构TLB快表,快表相当于是一个缓存,它的工作原理是这样的: 由于TLB的占用很小,而且引入了并行匹配技术,因此在其中查询某一个页表项的时候是很快的,是纳秒级的查询,在CPU寻址的时候,会先查询TLB中有没有想要的页表项,如果TLB没有命中,才会查询到在内存中的页表 TLB的高效的原因是程序的局部性原理,被存入到TLB中的页表项在最近一段时间内被多次访问。 什么是段页式内存管理? 段页式内存管理:所谓段页式的内存管理,是集成了段式和页式的管理优点的一种管理方式,主要的工作原理如下: 页式管理的缺点主要是它将本来具有一定含义的进程数据段拆分了无意义的页,这样的话就丢失了一部分信息 因此在这种情况下,段页式的内存管理将进程划分成了很多个具有一定逻辑意义的数据段,这些数据段具有一定的信息,比如说代码段,数据段等等,然后再把这些段分成一页一页,通过这样的设计,就可以将内存的管理单位变成了页,同时还能将进程的段记录下来,这样的话可以保留最大的信息,那么段页式内存管理的翻译流程是怎么样的呢? 首先会将一个地址划分成三个部分: 第一部分,段选择因子,其实就是这个地址在段表中的索引,它的存储格式是&lt;段选择因子&gt;:&lt;页表起始地址&gt; 第二部分,页选择因子,当得到了页表起始地址后,就基于页选择因子,得到具体的页表项在页表中的哪一个位置 第三部分,页偏移量,当得到了页偏移量之后,就可以定位这个虚拟地址的实际物理地址了 虚拟内存的作用是什么? 首先,虚拟内存技术可以使得进程的占用总内存远远超过物理设备的内存,因为程序的运行符合局部性原理,CPU的访问呈现出一个28原则,也就是只有百分之20的内存是这个时间段内才会被频繁访问的,而其他那些80%的内存就可以被放到磁盘上,节省内存 第二,通过页表分配技术,使得每个进程操作的内存不会相互冲突 第三,页表里的页表项中除了物理地址之外，还有一些标记属性的比特，比如控制一个页的读写权限，标记该页是否存在等。在内存访问方面，操作系统提供了更好的安全性。 系统内核篇 谈谈什么是内核？ 计算机是由软件和硬件组成的,但是实际上运行的还是底层的硬件,硬件会提供一些接口为我们提供服务,但是如果每一个开发的软件都需要操作这些硬件提供的接口,首先第一个问题就是引起很多冗余的代码,第二个问题就是在操作这些硬件的时候,可能会导致不同的开发者对这些硬件不熟悉,或者程序写死对一些硬件的操作,在更换一个设备之后,这个软件就跑不起来了,为了解决这个问题,就提出了内核程序 实际上,内核程序就是操作系统的核心,通过内核程序,用户软件不必直接与硬件交互,而是通过操作系统提供的接口,通过这些接口来操作实际的硬件,从而发挥计算机的功能,内核的功能有:管理进程、管理内存、管理硬件设备、提供系统调用 谈谈什么是用户态和内核态? 在CPU的所有指令中,有一些指令设计到非常重要的功能,比如有直接操作物理内存,重置时钟等,如果直接让用户执行这些指令,就非常有可能导致系统崩溃,因此为了避免这样的情况,就将指令划分成了特权指令和非特权指令 特权指令:特权指令就是一些危险的指令,只有内核程序才能执行 非特权指令:用户态的程序就能够执行 基于安全的考虑,就将这些指令进行了分支,分成了4个ring 操作系统根据特权分级,将进程分成了内核空间和用户空间,内核空间对应的是Ring0,用户空间对应的是Ring3 Ring3只能访问受限的资源,不能够直接访问内存等设备,必须通过系统调用才能够陷入到内核态,然后让内核态的程序去执行相关特权指令 什么时候会从用户态陷入到内核态? 系统调用 异常:当发生了异常(例如缺页异常)的时候,这时候就会触发由当前运行进程切换到处理此异常程序的程序中,也就转换到了内核态 外围设备的中断:当外围设备完成了用户的操作请求之后,这时候就会向CPU发出相应的中断信号,这时候CPU就会停下正在做的事情,然后执行一个中断处理程序,比如说正在执行一个用户态的程序,当外围设备发出了读写IO事件完毕了之后,这时候CPU就会停下来了,然后执行一个中断处理程序(这个程序是内核程序执行的) 当触发了一个系统调用,这时候会发生什么？ 当发生了系统调用,这时候如果本来是用户态的,会发生以下的过程: 从用户态跳转到内核态:当应用程序执行系统调用的时候,会先将系统调用的名称翻译成系统调用号,然后将系统调用号和请求参数放入到寄存器中,然后执行中断指令(int $0x80指令),产生一个中断,CPU陷入到了内核态中 执行内核态的逻辑:CPU跳转到中断处理程序,这时候会先执行一个现场的保存,简单来说就是将当前CPU的上下文保存到内核栈中,比如说栈顶寄存器的值,中间计算寄存器的值等等。然后这时候就会将刚才的系统调用号(其实就是中断向量号),从中断向量表中取出来一个函数入口地址,然后将函数入参带过去执行 返回到用户态:执行完系统调用之后,就会执行一个中断返回指令(iret指令),将原来用户态的线程恢复回来,其实就是将原本在内核栈中的现场值都恢复到CPU上,恢复执行 可以看出,一次系统调用将会导致两次CPU的上下文切换 用户态和内核态是如何切换的? 在程序执行的过程中,栈是不可缺少的,因为栈是进程执行过程中的活动记录,缺少了栈,就无法执行函数返回等操作了 在Linux中,函数栈可以分为是用户栈和内核栈,通过用户栈和内核栈来实现用户进程的执行和内核程序的执行 用户栈切换到内核栈:执行中断指令(int $0x80指令),当中断发生了之后,CPU会到Linux中的一个特定机构(TSS)中获取这个内核栈的内存地址,也就是获取一个段选择子(内核程序的段表中,用来标志栈段的那个索引)、栈顶指针,有了这两个值就能定位内核栈了,然后送入到ss寄存器和rsp寄存器,这时候CPU就指向了内核栈的栈顶位置了,这就完成了用户态到内核态的一次切换,其中执行栈的切换就是标志 跳入中断处理函数开始执行:简单来说就是将当前用户态执行程序中的相关寄存器的值全部压入到内核栈中 内核态跳转到用户栈:当中断结束的实时,就会将寄存器中的值全部弹出,然后恢复到CPU上下文中,执行一个iret的指令,最重要的是将ss寄存器和rsp寄存器恢复到用户态执行的情况 切换上下文会使得TLB中的缓存全部失效 什么是中断?中断有哪些分类? 中断是系统从来响应硬件请求的一种机制,操作系统收到了硬件的请求中断的时候,会打断当前正常执行的进程,然后调用当前内核中的处理程序来响应设备的请求 中断:由硬件设备触发,这时候外部设备会给内核发送去一个中断向量号,属于一个异步的事件 异常:CPU在执行指令的时候检测到的反常条件,比如说有除法异常等 INT指令:INT指令后面接一个数字,就相当于直接用指令的形式,告诉CPU一个中断号,比如INT 80,这样就去执行一个系统调用 根据实现的方式不同,将中断分成了硬中断和软中断 硬中断是在硬件CPU执行指令的时候去检测中断,具体来说就是在执行每一条这个CPU指令的最后,都会去检查是否有中断发生,如果有中断发生了,那么就会把中断号取出来,然后执行中断处理程序,然后跳过去执行中断处理程序 软中断就是一个单独的守护进程,不断轮询一组标志位,如果哪个标志位有值了,那么就去执行哪一个中断处理函数 都是定期检查中断,为什么还需要有软中断呢? 这是因为硬中断通常来说都是非常重要的操作,通常有可能会临时关闭中断,如果长时间占用硬中断函数不返回(当前中断处理程序没有执行完毕之前,都不能处理别的中断请求),那么就有可能导致其他硬中断请求被搁置太长时间,甚至产生丢失,在这样的情况下,我们希望硬中断的持续时间越快越好,Linux为了解决这个问题,将中断过程分成了两个阶段 第一个阶段:快速响应中断,主要负责处理那些和硬件紧密相关或者时间敏感的事件 第二个阶段:延迟处理上半部分没有完成的工作,一般是由内核守护进程来执行的,相当于说将中断处理程序比较复杂的部分都拆分出来了,通过异步的方式来处理这些任务 举个例子,执行一个TCP连接,然后网卡接收到一个数据报,通过DMA技术发送到内核缓冲区中,接收完毕后,网卡就会触发一个硬中断,CPU在收到这个中断之后,就会马上执行中断处理程序,第一个阶段,它会将软中断标记数组中的某一个位置标记一下,然后就完成了本次硬中断 第二个阶段,内核中的守护进程会去轮询这个标记数组,看哪个位置被标记为1了,然后执行相应的中断处理函数,以网络包的这个例子为例,这个中断就是将内核缓冲区中的数据包交付内核协议栈,内核协议栈拆包,然后读取数据,然后根据端口号等信息交付到对应的用户进程的用户缓冲区 软中断的作用就是承接中断处理函数中比较复杂而且耗时的操作,让硬中断的中断处理函数尽可能地简单,从而提高系统的响应速度 补充知识点 什么是mmap?有什么应用? mmap是一种内存映射技术方法,将一个文件或者其他对象映射到进程的地址空间,实现文件磁盘地址和进程虚拟地址空间中一段虚拟地址的一一对映射关系,mmap的实现是这样的,mmap系统调用会在内核中创建一个虚拟内存的结构,这个结构会指向内存中的某个内存区,然后应用程序访问这个虚拟内存地址的时候,就会产生缺页异常,然后触发一个缺页异常的处理函数,然后读取文件数据到物理内存中,将这一块物理内存与刚才mmap创建的虚拟内存进行映射。 实现这样的映射关系之后,进程不仅可以像访问内存一样读写文件,多个进程映射同一个文件,还能保证虚拟地址空间映射到同一块内存中,达到一个共享内存的作用 共享内存实际上是把不同进程的虚拟地址空间映射当中,不同的进程直接通过修改各自的虚拟地址空间中的内容就可以实现通信了 共享内存几乎不需要进行内存数据的拷贝就能够实现,也就是说数据从进程A的虚拟内存中写入数据,立即就能够被B所感知到,其他进程间通信的机制,需要通过Linux内核程序的多次拷贝才可以执行,因此使用共享内存比较高效 传统传输文件的补足:如果原本要实现一个文件的传输,那么要完成以下的操作,比如说要把本地主机上的文件基于socket技术传输到远程,那么需要完成什么事情呢? 首先第一步,在设备支持的前提下,基于DMA技术将磁盘中文件拷贝到内核缓冲区中,这首先是一次数据的拷贝 第二步,用户程序无法直接使用内核缓冲区的数据,于是需要CPU的干预,将数据从内核缓冲区中搬运到用户缓冲区中,这时候就是陷入一个内核态,内核程序将数据从内核缓冲区中拷贝到用户空间中 第三步,用户程序可以使用用户缓冲区中的数据了,然后在CPU的干预下,发起内核态的切换,然后就是将用户数据拷贝到socket缓冲区中 第四步,通过DMA技术,将socket缓冲区的数据拷贝到网卡设备的缓冲区中 可以看出,明明只是发送一份数据,却在Linux中拷贝了四次 mmap+write这种技术可以直接将内核缓冲区中的数据映射到用户空间,这样的话,操作系统内核和用户程序之间的数据交互就不需要拷贝来拷贝去了,应用程序调用了mmap()之后,DMA会把磁盘缓冲区中的数据拷贝到内核缓冲区中,然后应用程序跟操作系统内核共享这个缓冲区,应用程序再调用write(),将内核缓冲区中的数据直接拷贝到socket缓冲区中,这一切都发生在内核态,由CPU来搬运数据 最后把内核的socket缓冲区中的数据拷贝到网卡的缓冲区中,这个过程是由DMA搬运的 什么是零拷贝? 零拷贝技术并不说不进行拷贝,而是说没有发生不同数据空间之间的拷贝,比如说: 在上面的例子中,内核缓冲区=&gt;Socket缓冲区的时候有发生数据的拷贝操作,但是他们都是在内核中的,因此在这样的情况下,没有发生上下文的切换调度,这其实就是一个零拷贝的技术 top指令会采集什么信息? free命令会有什么信息? Mem 内存的使用信息 Swap 交换空间的使用信息 第一行 total 系统总的可用物理内存大小 used 已被使用的物理内存大小 free 还有多少物理内存可用 shared 被共享使用的物理内存大小 buff/cache 被 buffer 和 cache 使用的物理内存大小 available 还可以被 应用程序 使用的物理内存大小 free 与 available 的区别 free 是真正尚未被使用的物理内存数量。 available 是应用程序认为可用内存数量，available = free + buffer + cache (注：只是大概的计算方法) Linux 为了提升读写性能，会消耗一部分内存资源缓存磁盘数据，对于内核来说，buffer 和 cache 其实都属于已经被使用的内存。但当应用程序申请内存时，如果 free 内存不够，内核就会回收 buffer 和 cache 的内存来满足应用程序的请求。","categories":[{"name":"题库","slug":"题库","permalink":"http://kaillliu.github.io/categories/%E9%A2%98%E5%BA%93/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://kaillliu.github.io/tags/Java/"},{"name":"面试题","slug":"面试题","permalink":"http://kaillliu.github.io/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"name":"题库","slug":"题库","permalink":"http://kaillliu.github.io/tags/%E9%A2%98%E5%BA%93/"},{"name":"操作系统","slug":"操作系统","permalink":"http://kaillliu.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}]},{"title":"WebSocket 面试题总结回顾","slug":"websocket理论","date":"2023-08-15T07:00:00.000Z","updated":"2023-09-08T04:30:40.690Z","comments":true,"path":"2023/08/15/websocket理论/","link":"","permalink":"http://kaillliu.github.io/2023/08/15/websocket%E7%90%86%E8%AE%BA/","excerpt":"","text":"使用前端不断轮询后端这种策略的弊端 为了维护用户的体验,需要在1~2s的周期内不断地对后端进行轮询,这种策略带来的带宽额外开销是非常巨大的 同时不断的HTTP请求交互,还会给下游服务器造成非常大的负担,因为压根服务端里面就没有数据,那还轮询个啥? 长轮询 在HTTP请求发出后,一般会给服务预留一定的时间作为响应,比如3s,如果在规定的时间内没有返回,那么就认为是超时了,如果我们将HTTP的请求超时时间设置得很大,那么只要在这30s内收到了请求,那么就立即将数据返回到客户端,如果超时,那么就立即发送下一次请求 这样的话就减少了HTTP请求的个数,并且在大部分的情况下,用户都会在30s的区间内做扫码操作,所以响应是非常及时的 像这种发起一个请求，在较长时间内等待服务器响应的机制，就是所谓的长训轮机制。我们常用的消息队列 RocketMQ 中，消费者去取数据时，也用到了这种方式。 像这种,在用户毫无感知的情况下服务器将数据推送到服务端的技术就是服务器推送技术 一般来说的实现有短轮询(短时间内发起多次请求)、长轮询(较长的时间内维护同一次请求) WebSocket 假设现在的项目需求是 需要在一个时间周期内不断地向客户端推送信息,那么这时候就需要用到WebSocket技术了 TCP的特性是全双工的,它在同一时间内,双方都能够主动地向对方发送数据,这就是所谓的全双工技术 而现在使用最广泛的HTTP/1.1，也是基于TCP协议的，同一时间里，客户端和服务器只能有一方主动发数据，这就是所谓的半双工。 所以,为了更好地支持这种场景,我们需要设计一个新的TCP协议,于是新的应用层协议WebSocket就出现了 WebSocket连接是怎么连接的? 首先,普通的网页端与服务端的请求正常情况下还是走HTTP请求的,但是当客户端想要升级为WebSocket的时候,那么就需要基于HTTP协议完成WebSocket协议的连接握手了,具体的过程是这样的: 首先在HTTP的头部添加一些特殊的header头 123Connection: UpgradeUpgrade: WebSocketSec-WebSocket-Key: T2a6wZlAwhgQNqruZ2YUyg==\\r\\n 解析: Connection:浏览器想要升级协议 Upgrade:升级成啥呢?升级成WebSocket协议 Sec-WebSocket-Key:随机生成的 base64 码（Sec-WebSocket-Key） 如果此时服务端是支持WebSocket协议的,那么就会走WebSocket的握手流程,同时根据客户端生成的base-64码,用某个公开的算法变成另一段字符串放在 HTTP 响应的 Sec-WebSocket-Accept 头里，同时带上101状态码，发回给浏览器。HTTP 的响应如下： 1234HTTP/1.1 101 Switching Protocols\\r\\nSec-WebSocket-Accept: iBJKv/ALIW2DobfoA4dmr3JHBCY=\\r\\nUpgrade: WebSocket\\r\\nConnection: Upgrade\\r\\n 101指的是协议切换的状态码,当建立了websocket连接之后,在服务端返回可客户端的握手报文中就携带有此字段 之后，浏览器也用同样的公开算法将base64码转成另一段字符串，如果这段字符串跟服务器传回来的字符串一致，那验证通过。 简述webSocket的握手流程 首先,协议升级请求由客户端发出,然后在头部中携带如下字段 123Connection: UpgradeUpgrade: WebSocketSec-WebSocket-Key: xxx 然后发送到服务端,服务端如果支持这个协议的话,那么就会返回一个响应信息 1234HTTP/1.1 101 Switching Protocols\\r\\nSec-WebSocket-Accept: iBJKv/ALIW2DobfoA4dmr3JHBCY=\\r\\nUpgrade: WebSocket\\r\\nConnection: Upgrade\\r\\n 客户端在拿到这个信息之后,将这个Sec-WebSocket-Accept与自己之前发送的那个密文进行加密,然后对比,如果相同,那么就验证通过,连接成功建立 可以看出,WebSocket在握手阶段是借助了HTTP请求协议的,但是在连接建立之后就没有关系了。 WebSocket的消息格式 上面提到在完成协议升级之后，两端就会用webscoket的数据格式进行通信。 数据包在WebSocket中被叫做帧，我们来看下它的数据格式长什么样子。 opcode字段：这个是用来标志这是个什么类型的数据帧。比如。 等于 1 ，是指text类型（string）的数据包 等于 2 ，是二进制数据类型（[]byte）的数据包 等于 8 ，是关闭连接的信号 payload字段：存放的是我们真正想要传输的数据的长度，单位是字节。比如你要发送的数据是字符串&quot;111&quot;，那它的长度就是3。 WebSocket会用最开始的7bit做标志位。不管接下来的数据有多大，都先读最先的7个bit，根据它的取值决定还要不要再读个 16bit 或 64bit。 如果最开始的7bit的值是 0~125，那么它就表示了 payload 全部长度，只读最开始的7个bit就完事了。 如果是126（0x7E）。那它表示payload的长度范围在 126~65535 之间，接下来还需要再读16bit。这16bit会包含payload的真实长度。 如果是127（0x7F）。那它表示payload的长度范围&gt;=65536，接下来还需要再读64bit。这64bit会包含payload的长度。这能放2的64次方byte的数据，换算一下好多个TB，肯定够用了。 payload data字段：这里存放的就是真正要传输的数据，在知道了上面的payload长度后，就可以根据这个值去截取对应的数据。 大家有没有发现一个小细节，WebSocket的数据格式也是数据头（内含payload长度） + payload data 的形式。 这是因为 TCP 协议本身就是全双工，但直接使用纯裸TCP去传输数据，会有粘包的”问题”。为了解决这个问题，上层协议一般会用消息头+消息体的格式去重新包装要发的数据。 而消息头里一般含有消息体的长度，通过这个长度可以去截取真正的消息体。","categories":[{"name":"题库","slug":"题库","permalink":"http://kaillliu.github.io/categories/%E9%A2%98%E5%BA%93/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://kaillliu.github.io/tags/Java/"},{"name":"面试题","slug":"面试题","permalink":"http://kaillliu.github.io/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"name":"题库","slug":"题库","permalink":"http://kaillliu.github.io/tags/%E9%A2%98%E5%BA%93/"},{"name":"websocket","slug":"websocket","permalink":"http://kaillliu.github.io/tags/websocket/"}]},{"title":"Redis 面试题总结回顾","slug":"Redis基础回顾","date":"2023-08-14T07:00:00.000Z","updated":"2023-09-08T04:29:06.537Z","comments":true,"path":"2023/08/14/Redis基础回顾/","link":"","permalink":"http://kaillliu.github.io/2023/08/14/Redis%E5%9F%BA%E7%A1%80%E5%9B%9E%E9%A1%BE/","excerpt":"","text":"Redis Redis和Memcache有什么区别? Memcache本身也是基于内存的数据库,那么为什么不选它作为缓存呢?这个的话就要搞清楚它的区别: 首先他们都是基于内存的数据库,因此他们一般都用来做缓存 他们都有过期策略 两者的性能都非常高 Redis和Memached的区别: Redis支持的数据类型更加丰富(String、Hash、List、Set、Zset),而Memcached只支持最简单的&#123;key=&gt;value&#125;的数据类型 Redis支持将存储在内存中的数据进行持久化,可以将内存中的数据全部保持在磁盘中,重启的时候可以再次加载进内存进行使用,而Memcached没有持久化功能,数据全部存在内存之中,Mecached重启或者挂掉之后,数据就没有了 Redis原生就支持集群,可以很好的支持高可用,而Memecached没有原生的集群模式,需要依赖客户端来实现往集群中分片写入数据 Redis支持发布订阅模型,Lua脚本,事务等功能,而Meecached不支持 为什么使用Redis作为MySQL的缓存? 主要是因为Redis具备高性能和高并发两种特性 Redis具备高性能,首先这个问题特性可以从Redis的特性出发,它本身由于就是基于内存实现的,因此与CPU的交互速度快,同时由于网络通信部分Redis采用了高性能的IO多路复用模型,同时底层首先了多种非常高效的数据结构,在节省内存的同时还控制了查询的时间复杂度,对比于可能需要频繁IO的MySQL来说,Redis的性能是非常高的 Redis具备高并发,单台设备的RedisQPS是MySQL的10倍,Redis的单机QPS通过轻突破10w,而MySQL很难突破1w Redis的数据类型以及使用场景分别是什么? Redis提供了丰富的数据类型,比如说有String、Hash、Zset、List、Set这些数据类型 String这个结果存储的值是字符串、整数或者浮点数,它可以对字符串或者字符串的一部分进行操作,对整数或者浮点数进行自增或者自减的操作 List本质上是一个链表,链表上的每个节点都包含一个字符串,它支持的操作是对链表的两端进行push和pop,读取单个值或者多个值,还可以根据值查询或者删除元素 Set本质上是一个无序集合,字符串的集合,包含基础的方法有看是否存在、添加、删除、还包含有计算交集差集等 Hash包含有键值对的无序散列,包含的方法有添加,删除等元素 Zset有序集合,和散列一样,存储的是键值对,但是其底层数据结构决定其天然有序,字符串成员和浮点数分数之间的有序映射,元素的排列顺序由分数的大小来决定 使用场景有哪些? String类型的应用场景有缓存对象(json),常规计数(令牌桶)等,分布式锁,共享session等 List类型的应用场景有消息队列(生产者需要自行实现全局唯一性ID),不能够以消费组形式消费数据,因为数据阅后即焚 Hash类型,缓存对象,购物车等 Set类型,聚合计算(交集、并集、差集)等场景,比如说点赞，共同关注，抽奖活动等 Zset类型,排序类型,比如说排行榜,电话和姓名等 BitMap:二值状态统计的场景,比如说签到,判断用户登录状态,连续签到用户总数等 HyperLogLog:海量数据基数统计的场景,比如说百万级UV计数 GEO:滴滴打车 Stream:Redis实现的消息队列,相比于List实现的消息队列,它可以自动生成全局唯一性ID,支持以消费者组形式消费数据 五种常见的数据类型是怎么实现的? 1String类型的内部实现 String类型的底层的数据的实现主要是基于SDS实现的,它的中文名字叫做简单的动态字符串,Redis的源代码是用C语言写的,但是C语言本身自带的字符串非常不方便,首先: C语言的字符串的长度是通过遍历来找到的,也就是说通过遍历找到\\0来实现的 因此C语言的字符串的长度获取是一个O(n)的级别的时间复杂度 而C语言的字符串由于需要\\0来截断,因此在这种情况下,如果字符串中需要存储二进制的话,那么就会导致存储不了,因此,C语言字符串不支持二进制存储 同时C语言的字符串在拼接之前并没有做缓冲区检查,也就是说当字符串做拼接的时候,这时候就可能会导致缓冲区溢出,而Redis的SDS相关API在操作之前都做了一个缓冲区的检查,因此不会造成缓冲区的溢出 内部实现,String类型的底层的数据结构实现主要是int和SDS,字符串对象的内部编码encoding有3种int、raw和embstr int:首先会检查传入的这个整数值是否是一个数字类型，如果是的话,那么就判断这个数字类型是否能够用long类型的数据类型来描述,如果能够用long类型来描述,那么就直接让RedisObject结构中的ptr的属性的值设置为这个long值就可以了 RedisObject是什么 RedisObject是Redis设计用来封装数据用的,通常来说在头部会标明你这个对象存储了什么样的数据结构,也就是type,然后在encoding中表明了存储这种数据结构用的存储格式,然后在ptr中存储具体的值 12345struct redisObject&#123; int type; int encoding; void* ptr;&#125;; 如果字符串对象保存的是一个字符串,那么就会先判断这个字符串的长度了,如果字符串的长度小于指定的长度的话,那么就会将SDS的头部放在redisObject相连的一片区域中,然后这个头部的buf指针再指向一个指定的字符串区间 如果字符串对象保存的是一个字符串,那么就会先判断这个字符串的长度,如果字符串的长度大于指定的长度,那么就会重新申请空间,在这个空间中存放SDS的头部,然后在SDS的buf指针再指向一个指定的字符串空间 为什么要这样做? 当字符串的长度太长的时候,就需要将ptr指向一个SDS的头部,这个过程涉及到一次内存分配,然后SDS头部的buf指针又需要指向一个字符串的首部,这个过程涉及到一次内存分配 当发生了内存回收的时候,这时候就需要0两次内存回收了 因此为了解决这个问题,embstr的编码会使用SDS来保存值,但是不同之处在于embstr会通过一次内存分配函数来分配一个连续空间,这个连续的空间可以存储下一个完整的SDS头部,而raw编码则是会通过分配出一个空间,然后存储SDS的头部,然后这个头部中buf指针再申请一块自己使用的空间 有什么好处? embstr的使用可以使得内存分配次数降低,然后减少了指针寻址的次数 释放embstr编码的字符串同样可以调用一次内存释放的函数 因为embstr字符串保存在一个连续的空间中,因此可以更好的使用CPUCache 那么有什么缺点? 如果字符串的长度增加需要重新分配的时候,整个redisObject和sds需要重新分配空间,这和Java中的字符串不可变类似,redis没有为embstr编码的字符串编写任何相应的更改,当我们对embstr编码的字符串执行任何修改命令,程序会先将对象的编码从embstr转换成raw,然后在执行修改命令 List底层是如何实现的? List类型的底层数据结构是基于双向链表或者是压缩列表实现的: 如果列表中的元素小于512个的时候,列表中的每个元素的值都小于64个字节,Redis会使用压缩列表(zipList)作为底层的数据结构 如果列表的元素不满足上述的条件,那么就会基于双向链表来实现的 链表结构的设计是怎么样的? 在Redis的双向链表的设计中,list结构为链表设定了头结点和尾结点,然后在节点之间可以通过prev和next来进行访问,时间复杂度分析: listNode链表节点的结构中带有prev和next指针,因此从一个节点出发,访问上一个节点和下一个节点所需要的时间复杂度为O(1) list结构头部因为封装了头尾指针的信息,因此访问头部和尾部都只是需要O(1)的时间复杂度 list结构因为提供了链表节点数量len,因此获取链表中的节点数量是O(1)的时间复杂度 listNode链表用void指针保存节点值,并且可以通过list结构的dup,free,match函数指针为节点设置该节点类型特定的函数,因此链表节点可以保存各种不同类型的值 关于链表的缺陷 链表之间的每个节点都不是连续的,那么这就意味着无法很好地利用CPU缓存,能够很好地利用CPU缓存的结构就是数组,因为数组的内存是不连续的,这样的话就可以充分利用CPU缓存来加速访问 原理:因为链表是分散在内存中的,因此在一次加载的时候,会导致只能加载一个链表节点到Cache中,但是如果是数组,可以加载这个数组的一部分到内存中 Redis3.0的List对象在数据量比较少的情况下,会采用压缩列表作为底层数据的实现,它的优势是节省内存空间,并且是内存紧凑型的数据结构,不过压缩列表存在连锁更新的问题,因此在后来改用了quicklist/listpack来进行实现 压缩列表是什么? 压缩列表是Redis为了节约内存而设计的,在我看来,压缩列表就是一个集中了数组和链表的特点的数据结构,主要体现在:(1)压缩列表的内存是连续分配的,这个符合数组的特点(2)压缩列表的元素查询是类似于链表寻址的方式,这个符合链表的特点(3)压缩列表中可以存储不等长的数据,这个符合数组的特点 压缩列表和其他数据结构类似,有一个数据头和数据体,其中数据头描述的是这个压缩列表中的基本元信息,而数据体描述的是具体存储的信息 首先,压缩列表可以用O(1)的时间复杂度来查询它占用的总字节数,因此记录了zlbytes 第二,压缩列表可以用O(1)的时间复杂度来获取尾部的节点,因此记录了zltail 第三,压缩列表可以用O(1)的时间复杂度来查询列表中有几个元素,因此记录了zlen 第四,当在遍历元素的时候,要确定什么时候停止,因此记录了zlend,通过这个字段来描述这个列表的固定值 然后就是数据体的部分,数据体它要完成三个功能 可以存储数据,因此最基本的,有一个数据域data 可以向前遍历,因此存放了一个prevlen,通过当前指针-prevlen就可以访问到上一个节点 可以向后遍历,因此存放了encoding,通过当前指针+encoding中存储的字段长度,就可以遍历到下一个节点 重点说一下encoding和prevlen字段,这个字段是压缩列表实现内存压缩的关键 压缩列表中每个节点的prevlen属性都记录了前一个节点的长度,而且prevlen属性的空间大小和前一个节点的长度值是有关的,比如说: 如果前一个节点的长度是小于254个字节的,那么要表示254还没有超过8个bit,因此prevlen就可以使用1byte来实现 如果前一个节点的长度是大于254个字节的,那么prevlen为了避免频繁扩容,因此在超过之后,就会直接使用5个字节的空间来保存这个长度,但是要注意,这个5个字节并不是完全用来表示长度的,而是在第一个byte标记为255,来表示当前prevlen的长度大于了254,然后在后4个byte来标记具体的长度 同时,对于不同的数据类型,它也有不同的保存策略 首先,如果当前节点的数据类型是整数,那么会在encoding中对整数类型进行标记,encoding长度为1字节,通过encoding确认了整数类型,就可以确认整数数据的实际大小了,比如如果encoding编码确定了数据是int16整数,那么data的长度就是int16的大小 如果当前节点的数据类型是字符串,那么根据字符串的长度大小,encoding会使用1byte/2byte/5byte的空间进行编码,encoding编码的前两个bit来表示数据的类型,后续的其他bit表示字符串数据的实际长度,也就是data的长度 解释一下连锁更新问题 压缩列表除了查找复杂度高的问题,还存在有一个连锁更新的问题,场景是这样的: 压缩列表新增某个元素或者修改某个元素的时候,如果空间不够,压缩列表占用的空间内存就需要重新分配,假设有这样的情况,压缩列表中的每一个元素存储的prevlen都是253个字节,因此这时候prevlen的字段都是占了1个字节,然后突然第一个元素的长度变成了254个字节,那么这时候第二个节点的长度的prevlen就变成了257个字节,从这之后的所有元素都需要将头部的prevlen字段修改成5个字节的长度,造成了连锁更新 连锁更新通常意味着元素的挪动,如果元素很多的话,那么就意味着元素在所申请的内存空间中大量重复地移动,这还不是最严重的情况,最严重的情况是当压缩列表的空间不足的时候,就需要频繁触发内存的申请和回收,可能造成长时间的阻塞 压缩列表的缺陷 压缩列表因为存在有连锁更新的问题,因此通常来说就只能够应对小部分的数据的情况,如果在大数据量的情况下,就会导致严重的阻塞问题 Hash底层是如何实现的? Hash类型的底层数据结构是基于哈希表或者是压缩列表实现的 关键值:列表中的元素要小于512个,列表中的每个元素要小于64个字节 当数据量小,而且元素小于64个时候,这时候就用压缩列表实现的 而哈希表示实现Hash的重点 12345678910typedef struct dictht&#123; //哈希表数组 dictEntry **table; //哈希表的大小 unsigned long size; //哈希表大小掩码,可以用来计算索引值 unsigned long sizemask; //该哈希表中已经有的节点数量 unsigned long used;&#125;dictht; 哈希表是一个数组,数组的每一格元素都是一个指向哈希表节点的指针,然后在这一个节点连接下一个具有相同索引的节点,这是为了解决哈希冲突的问题。 哈希冲突它指的是不同的key,但是通过hash()计算出来的index是一样的 hash是如何执行扩容的? hash的扩容就是rehash的过程,如果rehash的过程十分耗时,那么可能会造成阻塞 于是hash的扩容过程就是执行一个渐进式rehash()的过程,一般来说有三个过程: 给哈希表2分配一个空间,一般是比哈希表1大一倍 将哈希表1中的数据迁移到哈希表2 迁移完成后,哈希表1的空间会被释放,并且将哈希表2设置为哈希表1,然后在哈希表2新创建一个空白的哈希表,为下一次rehash做准备 渐进式rehash的目的主要是为了避免阻塞 那么是如何执行渐进式的rehash的呢?首先它不会阻塞主线程 先给哈希表2分配空间,在rehash的期间,每次哈希表元素进行新增、删除、修改的时候,Redis除了会执行对应的操作之外,还会顺序将哈希表1中索引位置上的所有&#123;key=&gt;value&#125;迁移到哈希表2 随着处理客户端发起的哈希表操作请求数量越多,最终某个时间点会把哈希表1的所有&#123;key=&gt;value&#125;迁移到哈希表2中 具体的过程是这样的:多次渐进式rehash,核心思想是将大工作量通过拆分成 注:每次使用哈希表只会使用下标为0的哈希表,因此在每次rehash结束后,就会将迁移完毕的哈希表设置为ht[0],然后重置ht[1]的空间为空 第一步,设置一个变量叫做rehashIndex = 0,标记开始rehash,注意这个变量就是rehashIndex=-1的时候,此时标志着rehash结束了或者是还没有开始 第二步,每次执行新增、查询、修改、删除等操作的时候,都会检查一下dict.rehashIdx是否大于-1,如果是的话,那么就将这个dict.ht[0].table[rehashIndex]的entry链表rehash到dict.ht[1],然后将rehashIndex++ 比如说数组有&#123;0,1,2,3,4&#125;,然后就会将0的位置迁移到新表上的0,然后index++,继续迁移1…直到迁移到4 迁移过程如何保障新表和旧表的数据一致性? 在做rehash的时候是将旧的数据迁移到新表上,这个数据要么在新表上,要么在旧表上,在rehash的过程中 新增操作,直接写入到新表中,为什么要这样做呢?这是因为本来扩容的目的就是想要将数据全部迁移到新表上,然后后面只查询新表,那么如果插入到旧表上,后面也不会去查询,是无用功 查询操作,会先到旧表中查询,如果旧表中没有,那么就会查询新表,这样的话就能够查询到最新的数据,旧的数据也不会因此丢失 删除操作,会先删除旧表中的数据,然后删除新表的数据,保持了一致性 什么时候会导致扩容? 初始扩容,如果哈希表为空,那么初始化哈希表的默认大小为4 当负载因子(used/size)达到1以上的时候,并且当前没有持久bgrewrite等子进程操作的时候 当负载因子(used/size)达到5以上的时候,此时的哈希冲突已经非常严重了 扩容为多少? 扩容为used+1,底层会对扩容的大小做一个判断,实际上找的是第一个大于等于used+1的2^n 什么时候会导致收缩? 当size&gt;4(哈希表的初始大小)并且负载因子低于0.1的时候就会触发收缩 收缩成多少? 首先它也是要保障当前的所有元素都能够存进去,然后就是要重置大小为used+1以上的第一个2^n Set底层是如何实现的? Set类型的底层数据结构是基于哈希表或者整数集合实现的,如果集合中的元素小于512个,所有值小于64个字节(默认值)的话,Redis会使用整数集合作为Set的底层数据结构 如果集合中的元素不满足上面的条件,那么Redis使用哈希表作为Set的底层数据结构 什么是整数集合? 首先要搞清楚为什么需要整数集合 整数的存储是redis的一个topic之一,一个int是32个bit,大约能够表示21亿的数据,但是在实际开发中,通常用的数字是比较小的,16个bit通常就能够满足需求了,但是如果用户非要存储大数据,该怎么办呢? 因此redis提出了一种折中的方案,就是整数集合,整数集合本质上就是一个元素长度可变的数组,它通过头部中的encoding字段来确定每一个元素的长度,encoding字段表示当前数组中存储的最长整数的长度 比如说最小的是int16还有int32、int64等,然后通过这个encoding字段,来实现数组寻址 如何实现的呢?它是通过数组的首地址+encoding*下标来实现的,读取其中的数据也是通过encoding中规定的位数来实现的 整数集合存在什么问题? 整数集合在不需要大数据的情况下能够节省很多内存空间,但是当需要升级的时候,这时候可能会引发一定的性能问题,当整数集合需要升级的时候,它是这样操作的,它会从新分配的空间的尾部开始,然后一个个的从后向前的复制元素到尾部 为什么要从后往前? 这是为了防止覆盖,因为如果从前往后的,由于升级过程中新的元素长度肯定是大于原来的长度的,因此在这样的情况下,会导致数据的覆盖 什么是跳表? 首先来理解一下为什么需要链表,这是因为链表的查询时间复杂度为O(n),而红黑树以及AVL在执行范围查询的时候通常需要通过中序遍历等复杂的操作进行遍历,这样设计无疑会增加操作的复杂度 跳表的特性 跳表只能够用于元素有序的情况,所以跳表对标的是平衡树和二分查询,是一种插入/删除/搜索都是O(logn)的数据结构,它的最大优势就是原理简单,跳表以有序的方式在层次化的链表中保存元素,效率和平衡树媲美 跳表优化原始链表的方式是通过添加多级索引,通过多级索引来实现的,原始的链表的下一个节点指针导致它的步长只能是1,而添加了高级索引,就能够实现更长的步长 跳表查询原理 以上图为例,假设将要查询8这个节点 第一步,从最高级索引出发,比较当前指向的节点的下一个节点和8的关系,当前指向的节点的下一个节点是7 7比8要小,因此没有找到合理的范围,最高级指针在索引的这个层级上执行next 第二步,在7这个节点上,观察到下一个节点是null,说明没有更大的元素了,因此执行一个指针下沉的操作 第三步,下沉后,继续比较下一个元素是和8的关系,发现下一个元素比8要大,说明找到了我们想要查询的元素 第四步,继续比较下一个元素和8个元素,发现就是8,查询结束 跳表的时间复杂度是怎么算的? 假设链表上有n个节点,每一层的节点数量都比上一层要少1/2,假设最后一层有k个节点,那么我们可以用等比数列的公式,假设首项是k,公比为2,最后一项为n,问你共有多少项?这个多少项就是这个指针要向下沉多少次 也就是n=k*2^(x-1),也就是x = log2(n/k)+1,k可能很小,因此x = log2n,是一个log2n的时间复杂度 跳表的缺点是什么? 在使用跳表的情况下,由于这个元素的增加和删除而导致它的索引也会发生变化,有些数并不是十分工整的,最后经过多次改动之后,最后维护的索引有些地方会跨几步,有些地方会只跨几步,这是因为里面的一些元素被增加和删除,而且它的维护成本还是比较高的,也就是说当添加一个元素的时候,需要将索引更新一遍,在这种过程中它如果需要增加和删除的话,它的时间复杂度就可能变成O(logn),而不是O(1)的时间复杂度了 跳表的组成是怎么样的? 从图中可以看出,跳表主要由以下部分组成: 表头(head):负责维护跳表的节点指针 跳跃表节点:保存着元素值,以及多个层 层:保存着指向指向本层中其他元素的指针,高层的指针越过的元素数量大于等于低层的指针,为了提高查找的效率,程序总是从高层开始访问,然后随着元素值范围的缩小,慢慢降低层次 表尾:全部由NULL组成,表示跳跃表的末尾 Redis是如何实现跳跃表的? header:指向跳跃表的表头节点 tail:指向跳跃表的表尾节点 level:记录目前跳跃表内,层数最大的那个节点的层数,表头节点的层数不计算在内 length:记录跳跃表的长度,跳跃表目前包含的节点的数量 跳跃表的节点包含了什么? 层:节点用L1、L2、L3等字样标记节点的各个层，每个层带有两个属性,前进指针和跨度,前进指针用于访问位于表尾方向的其他节点,而跨度则是记录了前进指针所指向节点和当前节点的距离 后退指针:它指向位于当前节点的前一个节点,后退指针在程序从表尾向表头遍历使用的 分值:各个节点中的1.0、2.0、3.0是节点所保存的分支,在跳跃表中,节点按照各自保存的分支从小到大排列 成员对象:各个节点中的o1、o2、o3是节点保存的成员对象 如果要查询元素abcd,权重为4,那么首先从跨度最大的那一层节点开始搜索 第一步,他在标注为L2的那个节点开始看后面的节点是什么,发信是abc,权重为3,于是通过forward指针,步进到abc,权重为3的节点 然后指针向下遍历,然后看下一个节点是abcde,权重为4,这时候就会发现此时下一个节点的权重值是大于等于4的,此时指针向下沉 到达level0之后,然后看下一个节点是abcd,权重为4,查询结束 跳表节点层数的设置 跳表相邻两层的节点数量最理想的比例是2:1,查询复杂度可以降低到O(logn),计算的时间复杂度如上面的等比公式 那么怎么样才能维持相邻两层的节点数量的比例为2:1呢? 如果采用的是新增节点或者删除节点的时候,来调整跳表的节点的时候来维持比例的话,那么就会带来额外的开销 Redis给的一种巧妙的方法是:跳表在创建节点的时候,随机生成每个节点的层数,没有严格维持相邻两层节点的比例,具体的做法是这样的:跳表在创建节点的时候,会生成一个范围为[0-1]的随机数,如果这个随机数小于0.25(相当于概率为25%),那么层数就增加1层,继续生成一个随机数,直到随机数的结果大于0.25结束,最终确定该节点的层数 这样的做法,相当于每增加一层的概率不超过25%,层数越高,概率就越低,层高的最大限制是64 为什么用跳表而不用平衡树? 从内存占用上来比较,跳表比平衡树要更灵活一些,平衡树每个节点包含2个指针,分别指向左右子树,而跳表中的每个节点包含的指针数目平均为1/(1-p),具体取决于参数p的大小,如果像Redis里的实现一样,取p=1/4,那么平均每个节点都包含有1.33个指针 在做范围查询的时候,跳表的查询是基于遍历实现的,但是平衡树的对于范围查询的操作是基于中序遍历实现的 从算法实现的角度上来看,跳表的实现更加简单 在并发环境下skiplist有另外一个优势，红黑树在插入和删除的时候可能需要做一些rebalance的操作，这样的操作可能会涉及到整个树的其他部分，而skiplist的操作显然更加局部性一些，锁需要盯住的节点更少，因此在这样的情况下性能好一些。 Redis是单线程的吗? 单线程指的是Redis中处理命令是单线程的,也就是说从服务器接收客户端请求=&gt;解析请求=&gt;进行数据库的读写操作=&gt;发送数据到客户端这个过程是由一个线程来完成的,这也就是常说Redis是单线程的原因 但是实际上Redis是多线程的,Redis在启动的时候,是有后台线程,注意到Redis完成一个完整指令的过程是有存在一个网络IO的过程的,涉及到IO,那么就有可能导致线程阻塞的风险,因此为了避免阻塞的问题,Redis通过后台线程的方式来解耦处理指令、接收指令、发送结果集的过程,通过将那些可能造成阻塞的问题加入到不同的任务队列中,将处理好的任务结果存储在内存中,然后交给主线程来进行读取,这样的话就可以避免线程阻塞了 Redis中主要存在的耗时任务有:关闭文件、AOF刷盘、释放内存,这些任务创建单独的线程来处理,如果把这些任务都交给主线程来做,那么可能导致主线程阻塞,后台线程相当于一个消费者,生产者把耗时任务丢到任务队列中,消费者不断轮询这个队列,拿出这个任务就去执行对应的方法就可以了 BIO_CLOSE_FILE:关闭文件任务队列,当队列有任务之后,后台线程会调用close(fd),将文件关闭 BIO_AOF_FSYNC:AOF刷盘任务队列,当AOF日志配置成everysec选项后,主线程会将AOF写日志操作封装成一个任务,也放到队列中,当发现队列有任务的时候,后台线程就会调用fsync(fd),将AOF文件刷盘 BIO_LAZY_FREE:lazy free任务队列,当队列中有任务的时候,后台线程就会free(obj)释放对象/free(dict)删除数据库所有对象/free(skiplist)释放跳表对象 Redis单线程模式是怎么执行的? 首先要了解什么叫IO多路复用,程序注册一组socket文件描述给操作系统,表示说程序想要操作内核帮忙监视这一批fd是否产生了IO事件,有了就告诉程序去处理 这样这样理解,一个socket就对应一个fd,假设在网络环境中,但需要传送数据的时候,就可以将数据写入到这个fd中,然后网络适配器通过读取这个fd中的内容,组装TCP/UDP报文发送出去 然后当接收方的网卡接收到数据的时候,就将这些数据写入到fd中,当写入完毕的时候,就会发出一个IO就绪的事件 1epoll`相比于`select/poll`,节省了fd集合复制到内核的时间`(只需要epoll_create)`在内核中创建红黑树,后续通过`epoll_ctl`在红黑树上注册fd,轮询监听就需要`epoll_wait`,节省了遍历所有fd的时间,`内核中callback机制将已经就绪的fd写入到一个链表中再copy到用户空间 所谓IO多路复用,首先理解IO,IO是说发生了网络IO事件,远程的主机试图与本机建立IO通道,多路,就是有多个不同的连接都尝试和本机建立IO通道,复用就是指同一个线程负责将这些连接对象注册到本机上的监听集合上 Redis初始化的过程 首先调用epoll_create创建一个epoll对象,这个对象其实就是一棵红黑树,这棵红黑树上存储了一系列的fd,当需要查询fd的时候,就可以以O(logn)的时间复杂度查询fd 然后调用bind()绑定端口和调用listen()监听该socket,当发生了IO就绪时间的时候产生回调 然后,将调用epoll_ctl()将listen_socket加入到epoll()中,同时注册连接事件处理函数,当有连接发生的时候就触发这个函数 初始化完毕后,主线程就进入到一个事件循环函数 先调用处理发送队列函数,看一下发送队列中是否有任务,如果有发送任务,那么就通过write函数将客户端发送缓存区内的数据发送出去,如果这一轮数据没有发送完毕,就会注册写事件处理函数,等待epoll_wait()发现可写后再处理 然后调用epoll_wait()函数等待连接事件的到来 如果是连接事件到来了,那么就会调用连接事件的处理函数,首先它会调用accept()获取已经连接的socket,调用epoll_ctl将已经连接的socket加入到epoll,然后注册读时间处理函数 如果是读事件到来了,那么就会调用读事件处理函数,这个函数会做这些事情,调用read获取客户端发送的数据=&gt;解析命令=&gt;处理命令=&gt;将客户端对象添加到发送队列=&gt;将执行结果写到发送缓冲区等待发送 如果是写事件到来了,那么就会调用写事件处理函数,该函数会做这些事情,通过write函数将客户端发送缓存区中的数据发送出去,如果这一轮的数据没有发送完毕,那么就会继续注册写事件处理函数,等待epoll_wait发现可写后再处理 Redis为什么使用单线程还这么快? 原因主要有: 基于内存的操作:Redis的操作都是基于内存实现的,内存的读写速度非常快,并且设计了非常高效的数据结构,因此它的命令处理速度非常快,而我们说Redis的单线程是模型说的是处理指令是单线程的,因此单线程的操作不会是Redis的瓶颈所在,既然CPU不是瓶颈,那么自然就采用单线程的解决方案了 避免了多线程的竞争操作:在单线程指令处理的速度已经很快的情况下,就没有必要去用多线程了,因为多线程的创建,本身就意味着创建线程,切换线程的这些开销 Redis基于IO多路复用模型解决了Redis的瓶颈:这是因为Redis的瓶颈不在它的指令处理速度,而是在它的网络IO中的相关情况,如果将主线程用于处理网络IO事件,那么就可能导致主线程阻塞而无法处理命令,为此Redis使用了IO多路复用模型来处理网络IO事件,通过这个方式来解决主线程阻塞的问题 IO多路复用模型是什么? 简单来说,就是一个线程负责分发请求,当有一个连接建立的时候,这个线程将连接对象注册到内核中的一个红黑树上,然后由内核来实现对这些连接的监控,当有连接发生了网络IO事件的时候，这时候就会将这个事件请求交给Redis线程处理,这就实现了Redis线程处理多个IO流的效果 这样做能够尽最大程度地减少线程创建和线程调度产生的开销 Redis6.0之前为什么使用单线程? 制约Redis性能表现瓶颈并不是CPU,我们采用多线程的最大目的就是为了提高CPU的利用率 在单线程+内存操作的基础上,就已经能够发挥出CPU的最大利用率,当引入多线程 由于本身创建线程维护线程就需要一定的成本,当发生线程上下文切换调度的时候,带来的成本是更加沉重的,同时为了维护共享内存的线程安全问题,还要考虑加锁,以及内存可见性的问题,如此一套下来,就可能导致CPU的利用率提高不多,甚至出现无效工作量导致CPU忙等的情况,但是内核的工作量提升很多的情况 而Redis的性能表现瓶颈更多情况下是受到内存大小和网络IO的限制,所以Redis核心线程模型使用单线程并没有什么问题,如果想要使用服务的多核CPU, 可以在一台服务器上启动多个节点或者采用分片集群的方式 Redis6.0之后为什么引入了多线程 这是因为Redis在远程服务器上的访问通常需要承受10w的TPS,这意味着大量的网络IO请求,如果只有一个线程负责请求的接收,假设请求的参数很多,那么可能导致一个线程阻塞,如果只有一个线程来处理请求,那么可能导致后续的请求都被积压了,引入多线程的话,有以下的好处: 随着网络硬件的性能提升,网络设备的接收速度很快,因此可能出现这样的一种情况,就是说网络设备接收数据包的速度很快,但是线程处理的速度还不如网络设备的处理速度,当多开几个线程的时候,就可以充分利用多核CPU的优势,同时从网络设备缓冲区中取数据,这样的话就能够尽最大程度地去执行相关指令 Redis6.0版本支持的IO多线程的特性,默认情况下IO多线程只针对发送响应数据,并不会以多线程的方式处理读请求,要想开启多线程处理客户端读请求,就需要将Redis.conf配置文件中的io-threads-do-reads的配置项设置为yes 因此在6.0之后，Redis会默认创建以下的线程: Redis主线程,这个线程主要负责执行解析好的指令 关闭文件后台线程,AOF刷盘任务线程,释放内存任务线程 三个IO线程 Redis如何实现数据不丢失? 这个是实现Redis持久化的相关功能,那么先来说说为什么Redis需要持久化? Redis之所以快,这是因为它的实时数据都是存储在内存中,因此内存一旦掉电,那么就会导致数据全部丢失,为了防止这种情况,必须要有一种手段:使得内存中的数据持久化到磁盘中 一般来说有三种方式: 第一种方式:AOF日志,可以将这个日志看作是MySQL中的ROW格式的binlog,它的主要作用就是将执行的每一条写操作指令,将该命令以追加的方式写入到一个文件中,然后在Redis重启的时候,重放这些日志就可以了 第二种方式:RDB方式,RDB的英文全称为Redis Data Base,它的核心思想是将Redis当前的内存数据以二进制的方式记录到磁盘中,然后在Redis重启的时候,将这个二进制文件载入到内存中就可以了 第三种方式:混合持久化,它的特点是混合了AOF和RDB的方式。 AOF日志是如何实现的? 实现的具体流程:Redis在执行完一条写操作命令后,就会将该命令以追加写的方式写入到AOF文件中,在Redis重启的时候,会读取该文件记录的命令,然后逐一执行该指令 为什么是先执行命令,再把命令写入日志呢? 避免额外的开销:如果是先写入日志再执行命令,那么可能导致一个情况,如果写操作指令是不合法的,那么之前写入日志的指令就是不合法的,就需要做一个撤销的操作 不会阻塞当前指令的执行:无论怎么说,写入日志文件的操作的速度总归是不如内存处理的速度的,因此从用户的体验来看或者是从系统的吞吐量来看,先写日志再写指令,可能导致后续指令的阻塞 有什么风险? 数据可能丢失:这是因为是先执行命令再写日志的,如果恰好在执行完命令,而还没有写日志就宕机了,那么数据就就丢失了 可能阻塞后续的其他操作:这是因为后续的操作都是要通过当前的主线程来完成的,如果当前主线程因为写日志而阻塞了,那么就可能导致后续的操作无法执行 AOF的写回策略有哪几种? 写回策略基本都是有套路的,一般来说数据有三个存放的区域,aof_buf缓冲区(最不安全,最容易丢失)、AOF文件的缓冲区(page_cache,一般安全,只要机器不掉电,数据就不会丢失)、磁盘(最安全,只要磁盘不损毁就不会丢失数据),那么AOF的写回策略就针对这三个区域,设计了三种策略 首先先来看看AOF日志写回的一个具体流程,执行写操作命令,然后这个命令会追加到Redis进程的server.aof_buf缓冲区中,然后通过系统调用write(),将缓冲区中的数据拷贝到page_cache中,然后由内核发起fsync(),将数据刷回磁盘,完成整个生命周期 Always:总是,意思是说当执行完一条指令的时候,就将写入到缓冲区中的立即写入page_cache中,然后立即调用fsync() Everysec:每一秒,意思是说当执行完一条指令的时候,就将写入到缓冲区中,然后拷贝到page_cache,每隔1s,就将这些数据立即写入到page_cache中,然后立即调用fsync() No:不同步,意思是数欧当执行完一条指令后,写入到缓冲区中,然后调用write()拷贝到page_cache中,然后由操作系统来确定什么时候调用fsync() 如果一直这样追加写,那么AOF文件不是会爆满吗? 是的,如果一直追加写而不加以限制,那么首先在删除这个文件的时候,就可能导致系统的阻塞,同时在Redis启动的时候,要读取一个非常大的指令文件,然后依次执行,这样的情况下,就可能导致启动速度会非常慢,同时还有一个比较严重的问题就是效率低下,因为指令是追加写,那么可能存在无效指令的问题 比如说用户执行了set name 123 set name 456 set name 789...执行了若干次,然后最后删除了name这个key,那么前面这若干次操作就都是无效的,这是一个非常严重的问题 因此为了应对这个问题,提出了AOF重写机制,所谓AOF重写机制,就是当AOF文件的大小超过了所设定的阈值后,Redis就会启用AOF重写机制,来尽可能地压缩AOF文件的信息量以及减少无效的操作 重写AOF日志的过程是怎么样的? Redis的重写AOF过程是由后台子进程完成的,通常可以通过bgrewriteaof(backGroundReWriteAOF)来实现的,具体的实现流程是这样的: 触发重写机制后,主进程就会通过fork()函数来创建子进程,此时父子进程共享物理内存,子进程因为是重写文件,因此只会记录当前Redis中的最新数据,因此通过fork()的话就可以创建一个当前时刻的快照,它会将当前数据库中的数据以一个键值对的方式记录下来,也就是&#123;key=&gt;value&#125;的方式,然后将这个命令记录到重写日志中 重写过程会影响主进程处理命令吗? 不会,因为创建了父子进程,因此重写日志的子进程会得到和父进程一份一模一样的内存,然后子进程因为对这片内存是只读的,因此就能够读取到创建进程时刻的实际数据,而父进程还是可以继续操作指令的 那么这时候就问了,如果父进程需要修改内存中的数据,怎么办? fork()创建出来的父子进程的共享内存它是基于一个写时复制的技术实现的,具体来说,就是当父进程需要修改共享内存的数据的时候,它会将这一片数据内存自己拷贝一份出来,然后修改页表/段表中的映射,然后在之后,父进程就可以一直使用这个新修改的内存了,这就是写时复制技术 那么这时候还会问,如果父进程修改了内存中的数据,那么这时候还是会产生数据不一致的问题,因为子进程无法看到父进程的修改 Redis的解决方案是这样的,它通过增量日志的形式来实现这个内存数据的追加,它里面有一个叫做重写缓冲区的区域,它会将重写期间的所执行的日志都全部增量添加到这个AOF缓冲区中。 总结一下,也就是在AOF期间,主要要完成以下三个事情 执行客户端发来的命令 将执行后的指令追加AOF缓冲区中 将执行后的指令追加到AOF重写缓冲区中 那么这时候又要问了,为什么还要写AOF缓冲区?只写AOF重写缓冲区不行吗?反正最后都要被替换 你要注意一点,就是在Redis的重写的过程中,是有可能发生宕机的,一旦发生宕机,假设我们只写入AOF重写缓冲区,那么宕机之后,不但重写失败了,还将重写过程中的操作指令都丢失了! 因此为了保证健壮性,它在重写期间,还是会一直使用原本的AOF文件,只有在后来重写完成后,才会完成真正的替换 重写完之后是如何替换的? 当子进程完成AOF重写工作的时候,扫描数据库中的所有数据,逐一将内存数据的键值对转换成一条命令,再将命令记录到重写日志后,会向主进程发送一条信号,信号是进程间通讯的一种方式 主进程收到该信号之后,会调用一个信号处理函数,这个函数主要完成以下的工作 将AOF重写缓冲区中的所有内存内容追加到新的AOF文件中,使得新旧两个AOF文件所保存的数据库状态保持一致 新的AOF的文件进行改名,覆盖原来的AOF文件 信号函数执行完毕后,主进程就可以继续像往常一样处理命令了 RDB快照是如何实现的? 因为AOF日志记录的是操作命令,不是实际的数据,所以在使用AOF方法做故障恢复的时候,需要全量把日志执行一遍,一旦AOF日志非常多,那么Redis的恢复操作就会非常缓慢了 为了解决这个问题,Redis增加了RDB快照,所谓的快照就是记录某一个瞬间的东西,比如说记录当前数据库的数据,然后将这些数据导出到文件中,下次Redis启动的时候直接读取这些数据到内存中就可以了 为什么RDB恢复数据比AOF要快? 想想一下,原本内存是空白的,使用AOF的过程,大概是我们的Redis系统解析AOF日志中的内容,然后将解析得到的指令执行计算,得到结果集放入到内存中,一次是两次计算+一次内存赋值 而RDB是这样的,原本内存是空白的,通过RDB就可以直接对内存进行赋值,这样的话速度就非常快,少了那些复杂的计算过程 RDB做快照的时候会阻塞线程吗? Redis提供了两个命令来生成RDB文件,分别是save和bgsave,他们的区别就在于是否在主线程中执行,像save指令就是在主线程中执行RDB文件的生成,如果写入RDB文件的时间太长了,那么就会阻塞主线程 执行bgsave命令的时候,会创建一个子进程来生成RDB文件,这样的话可以避免主线程的阻塞 注意,也是通过fork()子进程来实现的,具体的指令是这样的: 123save 900 1#900秒之内做了一次修改,就会执行保存save 300 10#300秒之内做了一次修改,就会执行保存save 60 10000#60秒之内做了10000次修改,就会执行保存 Redis的快照是全量快照,也就是说每次执行快照的时候,都是吧内存中的所有数据都记录到磁盘中,所以执行快照是一个比较重量级的过程,如果太频繁了,可能会对Redis的性能产生影响,如果频率太低,服务器故障的时候,服务器会丢失很多数据 RDB在执行快照的时候,数据能够修改吗? 可以的,在执行bgsave的时候,Redis通过fork()出来的子进程和父进程之间的数据也是通过写时复制技术来实现数据共享安全的,具体流程: 在执行bgsave命令的时候,会通过fork()创建子进程,此时子进程和父进程是共享同一片内存数据的,因为创建子进程的时候,会复制父进程的页表,但是页表指向的物理内存是同一个,如果都是执行读写操作,那么主线程和bgsave子进程是互不影响的 但是如果是执行了写操作,那么就会新创建一个新的页框,然后将修改后的数据写进去,然后将父进程页表中的页表项执行修改就可以了 为什么会有混合持久化？ RDB的优点是数据恢复速度快,但是快照的频率不好把握,频率太低,丢失的数据就会比较多,频率太高,就会影响性能,AOF优点就是丢失数据少,但是数据恢复不快 为了集成两者的优点,Redis提出了混合使用AOF日志和内存快照,也叫做混合持久化,及保证了Redis的重启速度,又降低了数据丢失的风险 混合持久化发生在AOF日志重写的过程,当开启了混合持久化之后,在AOF重写日志的时候,fork()出来的重写子进程会先将与主线程共享的内存数据以RDB的方式写入到AOF文件中 然后主线程处理的操作命令会被记录在重写缓冲区中,重写缓冲区中的增量命令以AOF方式写入到AOF文件中,写入完成后通知主进程将新的含有RDB格式和AOF格式的AOF文件替换AOF文件 那么也就是说,当使用了混合持久化之后,AOF文件的前半部分就是RDB的全量数据,后半部分就是AOF格式的增量数据。 这样的好处就在于,重启Redis加载数据的时候,由于前半部分是RDB内容,这样加载的时候速度会很快 加载完RDB的内容后,才会加载后半部分的AOF内容 优点:混合持久化结合了RDB和AOF的优点,开头为RDB的格式,启动速度加快了,同时结合AOF的优点,减少了大量数据丢失的风险 缺点:AOF文件中添加了RDB格式的文件,会使得AOF文件的可读性很差,兼容性很差,如果开启了混合持久化,那么混合持久化AOF文件,就不能够用在Redis4.0之前的版本了 Redis如何来实现高可用? 什么叫高可用? 高可用指的是一个系统经过专门的设计,从而减少了因为故障而停工的时间,从而保持了其服务的高度可用性 假设我们只有一台Redis实例,当这台实例宕机了之后,那么在后续工作的时候就无法继续提供服务了,一个最简单的思路就是提供备用实例,当一个实例宕机之后,就马上启用第二个实例,并且在这个过程中还要实现主实例和备用实例之间的数据同步 什么叫主从复制? 主从复制在MySQL中是用来实现读写分离的,具体来说就是通过读写请求分流,将读请求分发到从节点上,写请求分发到主节点上,然后在这期间基于binlog日志来实现主从节点的数据同步 那么在Redis的基本模型也是这样的,主从复制是高可用服务最基础的保障,实现方案就是将从前的一台Redis服务器,同步数据多台从Redis服务器上,也就是一主多从的模式,而且主从服务器之间采用的是读写分离的模式 主服务器可以进行读写操作,当发生写操作的时候自动将写操作同步给从服务器，而从服务器通常都是只读的,并且接收主服务器同步过来的写操作指令,然后执行这条指令 也就是说,所有的数据修改都只在主服务器上进行,然后将最新的数据同步给从服务器,这样就可以使得主从服务器的数据是一致的,注意,主从服务器之间的命令复制都是基于异步执行的。 具体来说,在主从服务器命令传播阶段,主服务器收到新的写命令之后,会发送给从服务器,但是主服务器并不会等到从服务器实际执行完命令后再把结果响应给客户端 而是在主节点执行完执行后,就直接将结果返回到客户端,如果这时候从服务器还没有执行主服务器同步过来的命令,那么主从服务器的数据就会不一致了,因此Redis这种异步同步的方式无法实现强一致性。 假设一个场景,主节点突然间宕机了,有很多个从节点,但是现在客户端发现的是,无法写入数据,只能读取数据,只能够由运维人员手动切换主节点,如果每次都这样,那么无法高可用了,因为这会导致很长时间的停机 因此为了解决这个问题,提出了哨兵模式,所谓哨兵模式,就是部署特殊的Redis实例,这个Redis实例可以监控主从服务器,并且提供主从节点故障转移的功能 那么哨兵是如何工作的呢?首先哨兵也是一个特殊的Redis进程,它相当于是一个观察者节点,观察的对象是主从节点,通过内置的指令以及网络传输功能,来完成集群间的交互通信 哨兵节点主要负责三件事情:监控、选主、通知 哨兵节点是如何监控节点的?又是如何判断主节点是否真的故障了? 首先先来说说哨兵节点是如何执行监控的,它是通过内置的指令ping-pong来实现一个心跳功能,通过这个心跳功能就能够检查集群中实例的健康状态,哨兵监控机制是通过everysec的模式来实现的,哨兵每隔1s会给所有的主从节点发送ping命令,当主从节点收到这个ping命令后,就会发送一个响应回去,这样就可以判断它们是否在正确运行 然后主从节点没有在规定的时间内响应哨兵的ping命令,哨兵就会将它们标记为主观下线,这个规定的时间是通过配置项down-after-milliseconds参数设定的 什么是主观下线?什么是客观下线?什么要设置这两种状态? 客观下线只适用于主节点,之所以针对主节点设计主观下线和客观下线的状态，有可能是因为主节点并不是宕机挂掉了,而是因为主节点发送那个响应的时候,因为网络阻塞,导致响应没有在指定的时间被收到,如果这时候就判断主节点下线,就是一次误判了 所以,为了减少误判的情况,哨兵在部署的时候不会只部署一个节点,而是用多个节点部署成哨兵集群,通过多个哨兵节点一起判断,就可以避免单个哨兵没有网络状态的问题而误判,同时,多个哨兵的网络同时不稳定的概率较小,由它们一起做决策,误判率就能够降低 怎么判断主节点是客观下线呢? 当一个哨兵判断主节点主观下线后,就会向其他哨兵发起命令,当其他哨兵收到这个命令后,就会根据自身和主节点的网络状况,做出赞成投票或者拒绝投票的响应 比如说有三个哨兵形成一个集群,然后集群中有一个哨兵认为主节点下线了,于是这个哨兵就询问其他哨兵的意见,如果配置文件中配置的最小赞同票数为quorum=2的话,比如说有3个哨兵,首先发现主观下线的哨兵算一票,然后还需要征求其他哨兵的意见,如果能够其他哨兵有一个认为是主观下线的,那么是客观下线了 哨兵主从故障转移流程了解么? 当判断主节点客观下线了之后,这时候就要完成主从切换,实现主从故障转移了 那么由哨兵集群中的哪个节点来完成呢? 那么首先第一步,就是在哨兵集群中选取一个leader,由这个leader来执行主从切换,选举leader的过程其实就是一个投票的过程。 要确定你的leader要从哪个范围里面选取:哪个哨兵节点判断主节点是客观下线,那么这个哨兵就是一个候选者,所谓的候选者就是向当Leader的哨兵,举个例子,假设有三个哨兵,当哨兵B判断到主节点主观下线后,就会向其他节点发送is-master-down-by-addr的指令,然后其他哨兵就会根据自己和主节点的网络连接情况来投出赞成票或者拒绝的响应 注意,这时候复用了之前使用来判断节点是否客观下线的值quorum,通过收集到的票数(包含自己的那一票),大于等于了这个quorum并且拿到半数以上的赞成票,就可以使用这个节点来作为leader了 如果某个时间点,恰好有n个哨兵节点判断主节点为客观下线的,那么这时候就有n个候选者了,那么这时候推选Leader的时候,每一位候选者都会先给自己投一票，然后再向其他哨兵发起投票请求,如果投票者先收到候选者&#123;1,2,3,4,5,6,x...&#125;的投票请求,就会先投票给x,最先收到,意味着在这个节点看来,x发现得更快,x的网络情况更好 为什么哨兵节点会至少要有三个? 如果哨兵集群中的只有两个哨兵节点,此时如果一个哨兵想要成为Leader,那么必须获得2票,当一个哨兵节点挂掉了之后,就无法完成主从切换了,也就是说自动主从迁移的失效率是50%,几乎无法实现高可用。 主从故障转移的过程是怎么样的? 主从故障转移的目的主要是要从那些好的节点里面挑出一个最好的节点来作为新的主节点,同时妥善安置坏掉的那个主节点,还有让其他的从节点和这个新的主节点形成主从关系,在内部默默完成这些事情后,通知客户端新的主节点的位置,一般来说是这样的: 第一步:在其他从节点里面挑出一个从节点,并将其转换为主节点(选举出一个最合适的主节点) 第二步:让已下线的主节点属下的所有从节点修改复制的对象(让新的主节点和从节点形成一个主从关系) 第三步:将新主节点的IP地址和信息,通过发布/订阅机制通知到客户端(通知客户端新的主节点上线了) 第四步:监视旧的主节点,当这个旧的节点重新上线了之后,让它作为从节点就可以了(妥善安排旧的节点) 怎么知道一个节点是否是最合适的? 这个过程就是选举新的主节点的过程,一般来说会有几个指标: 网络连接状态:当节点的网络连接状态太差太差的时候,这时候可以断定这个节点不适合做主节点,因为主节点需要完成大量的网络IO操作,肯定不行,那么如何来判断呢?Redis中有一个叫做down-after-milliseconds*10的配置项,它是用来描述主从节点断联的最大超时时间,如果在down-after-milliseconds毫秒内,如果主从节点都没有ping通,那么就说明这个从节点的网络不好了,就不适合作为新的主节点 网络连接是评判是否能够成为主节点的隐形条件,通过这个条件就能够将不好的节点排除掉了 至此,我们就将网络状态不好的从节点过滤掉了,接下来就要对所有从节点进行三轮考察: 优先级:用户规定说哪个节点适合做主节点 1通过配置salve-priority配置项,就可以给节点设置优先级 复制进度:复制进度是最客观的标志,因为复制进度越靠前,那么就说明哪个节点的数据越完整 ID号:如果优先级和下标都相同,就选择ID最小的那个 什么是复制进度? 复制进度是说主从复制的进度,一般来说,主从复制有两种 有全量更新和增量,在第一次从节点加入集群的时候,这时候就会向主节点请求数据具体过程就是这样的: 首先从节点会发送一个数据卷ID到主节点上,然后主节点接到这个ID后,会校验和本地的数据卷ID是否一致,如果一致的话,那么就会继续查看offset,如果offset比当前主机上的offset要小,于是就将这个offset以后的数据发送到客户端,如果在这个期间主节点有数据写入,那么就会通过追加日志的方式,将刚才做的操作以日志的方式发送到新节点上,然后新节点补执行这些日志就可以了 第二种情况就是和本地的数据卷的ID不是一致的,如果不是一致的话,那么就会将本地的数据ID发送到从节点上,从节点接收到这个ID后,就将本地的同步号设置为这个数据卷的ID,然后开始同步过程,然后在这个期间主节点有数据写入,也是通过追加日志的方式来执行的，但是这个是一个全量同步,全量同步是基于RDB来实现的,但是为了减免性能损耗,它是使用了一个bgsave来实现的 然后选举出主节之后,这时候就可以完成主从节点的替换了 首先哨兵leader向被选中的从节点发送SALVAEOF no one(站起来不准跪),然后让这个从节点解除从节点的身份,将其变为新的主节点 然后在升级成为主节点的情况下,哨兵Leader会以每秒一次的频率向被升级的节点发送INFO命令,并且观察恢复中的角色信息,当被升级的角色信息从原来的slave变为master的时候,哨兵leader就知道被选中的节点已经顺利升级成为主节点了 怎么让新的主节点和从节点形成一个主从关系 这时候就要形成新的主从关系了,然后哨兵leader就可以向所有从节点发送SLAVEOF,让它们称为新主节点的从节点了 如何通知客户端说主节点已经切换了? 这是通过Redis的发布者订阅者机制来实现的,每个哨兵节点提供发布者/订阅者模式,客户端可以从哨兵订阅消息,客户端和哨兵建立了连接之后,客户端会订阅哨兵提供的频道,主从切换完成之后,哨兵就会向switch-master频道发布新主节点的IP地址和端口信息,这时候客户端就可以收到这条信息,然后用这里面的新主节点的IP地址和端口进行通信 通过发布者/订阅者机制,有了这些事件的通知,客户端不仅可以在主从切换后得到新主节点的连接信息,还可以监控主从节点切换过程中发生的各个重要事件。这样,客户端就就可以知道主从切换执行到哪一步了 如何妥善安置旧的那个节点呢? 故障转移操作最后要做的操作是,继续监视旧主节点,当旧主节点重新上线的时候,哨兵集群就会向它发送SLAVEOF命令,让它称为新主节点的从节点 哨兵集群是如何形成的? Redis的发布者订阅者机制是哨兵集群形成的集群,在配置哨兵的时候,只需要这样配置 1sentinel monitor &lt;master-name&gt; &lt;ip&gt; &lt;redis-port&gt; &lt;quorum&gt; 这样的话哨兵就添加到这个集群中了,不需要填写其他哨兵信息,那么是如何做到的呢? 在主从集群中,主节点上有一个名为__sentinel__hello:的频道,不同哨兵就是通过Redis的发布者/订阅者机制来先相互发现 比如说,哨兵A将自己的IP地址和端口的信息发布到这个频道上,然后哨兵B和C订阅了这个频道,那么此时,哨兵B和C就可以从这个频道获取到哨兵A的IP地址和端口号了,然后哨兵BC就可以和哨兵A建立网络连接了 通过这个方式,哨兵B和C也可以建立网络连接,这样一来,哨兵集群就形成了 哨兵集群会对从节点的运行状态进行监控,那么哨兵集群如何知道从节点的信息? 主节点知道所有从节点的信息,所以哨兵每10s的一次向主节点发送INFO命令来获取所有从节点的信息 可以根据当前从节点信息列表来获取相关的从节点信息 什么是切片集群模式? 假设这样一种场景,当Redis缓存数据量达到一台服务器无法缓存的时候,就需要使用Redis切片集群的方案,它将数据分布到不同的服务器上,以此来降低系统对单主节点的依赖,从而提高Redis服务的读写性能 Redis Cluster方案采用哈希槽,来处理数据和节点之间的映射关系,在Redis Cluster方案中,一个切片集群一共有16384个哈希槽,这些哈希槽类似于数据分区,每个键值对都会根据它的key,被映射到一个哈希槽中 什么是哈希槽?:哈希槽是一个数据分区的概念,每个键值对会根据它的key,被映射到一个哈希槽中,具体的过程是这样: 根据键值对的key,按照CRC16算法计算得到一个16bit的值 再用16bit值对16384进行取模,得到0~16383范围内的模数,每个模数都代表一个相应编号的哈希槽 平均分配:在使用cluster create命令创建Redis集群的时候,Redis会自动将所有的哈希槽平均分布到集群节点上,比如说集群中有9个节点,那么每个节点上槽的个数为16384/9个 手动分配:可以使用cluster meet命令手动建立节点间的连接,组成集群,再使用cluster addlots，指定每个节点上的哈希槽的个数 什么是脑裂问题?集群导致的脑裂问题要怎么解决? 首先要了解一下什么是脑裂问题,在集群中,我们说主节点只能够有一个,然而在某些情况下,系统中的主节点看起来就好像有两个一样,具体发生的案例是这样的: 在一个Redis集群系统中,初始时是一个一主多从的架构,然而在某一个时刻发生了这样的情况,此时主节点和集群中的其他节点都发生了失联,但是和客户端的连接是正常的,因此主节点依然在接收客户端的写入指令,但是由于和从节点失联了,因此这些写操作都不会同步到从节点上 直到有一个哨兵节点向主节点发送一个ping指令,然后发生在指定的时间内没有返回响应,那么在这样的情况下,哨兵认为主节点发生了主观下线,于是向其他哨兵发送请求指令is-master-down-by-ip,要求其他哨兵检测主节点是否下线,然后由于失联,因此都投出的是赞成票 然后经过哨兵集群中的leader选举,然后哨兵leader根据网络情况,优先级,同步进度,ID情况确定一个最合适的主节点,注意,此时由于客户端认为主节点还是存活的,因此就产生了一种情形,就是客户端认为主节点是将要替换掉的那个,而集群内部却认为新选举的那个是主节点 因此在这样的情况下,就好像在系统中存在了两个主节点,这就是所谓的脑裂问题。 在脑裂问题发生后,集群内部完成主从节点的替换后,哨兵就会监控之前失联的主节点,当失联的主节点恢复的时候,这时候会发生全量同步,从节点会将会基于bgsave生成一个RDB文件,然后旧的主节点就会接收这个RDB,然后完成同步,由于全量同步的机制是:将当前Redis实例上的数据全部清空,然后接收来自主节点的数据,那么之前客户端读取进来的数据就丢失掉了,这就是脑裂问题带来的后果 总结一下,就是主节点和客户端保持正常联系,从节点和哨兵集群与主节点失联,然后导致在主从切换的时候,客户端依旧在向主节点发送数据,主节点也在给出正确的响应,客户端认为与从节点/哨兵失联的那个是主节点,而集群内部认为新选举出来的那个才是主节点,从而导致两个主节点的现象发生,这就是脑裂问题,最终导致了数据的丢失 脑裂问题怎么解决? 当主节点发现从节点下线或者通信超时总数小于阈值的时候,那么禁止主节点进行写数据,并且将错误直接返回到客户端,在Redis的配置文件中有两个参数可以配置 min-slaves-to-write x,主节点必须有至少x个从节点连接,如果小于这个数,主节点会禁止写数据 min-slaves-max-lag x,主从数据复制和同步的延迟不能够超过x秒,如果超过,那么主节点就会禁止写数据 可以将这两个数据项搭配起来使用,假设要求是:主库连接的从库中至少有N个从库,和主库进行数据复制的时的ACK消息延迟不能够超过T秒,否则主库就不会再接收客户端的写请求了 即使是原主库是假故障,它在假故障期间也无法响应哨兵的心跳,也不能和从库进行同步,自然也就无法和从库进行ACK确认了,这样一来,min-slaves-to-write和min-slaves-max-lag的组合要求就无法得到满足了,原主库就无法接收来自客户端的请求了,也就能够避免数据丢失问题了 总结一下,就是通过两个变量,第一个变量是说当和主库连接的从库数量小于N个的时候,这时候就不要接收来自客户端的消息了,第二变量是说当从库完成同步后发回来的ACK的这个时间差,不能够超过多少秒,当超过了指定的秒数,也禁止写入数据 这样做能够破坏发生脑裂问题的第二个条件 Redis的使用过期删除策略是什么? Redis的使用过期删除策略可以简单描述成惰性删除和定期删除两种 首先先来看看Redis读取键值对的具体流程,在读取键值对中的时候,Redis会先检查这个key有没有在过期字典中,如果在过期字典中,那么就会先判断这个key和过期字典中规定的过期时间谁大 如果过期时间大于当前系统时间,那么就证明没有过期,如果过期时间小于当前系统时间,那么就证明过期了 那么在访问的时候,如果恰好访问到了一个过期时间小于当前系统的时间的key,就将它删除掉,当以此作为删除过期键值对的唯一时机的策略称为是惰性删除策略,它的特点是只有在主动访问键值对的时候才会删除键值对 而定时删除,是不管你有没有访问这个键值对,而是开启一个定时任务,定期检查过期字典中的数据,在Redis中,定期检查不是遍历整个字典,而是随机访问这个字典,也就是说从过期字典中随机抽取20个key,检查这20个key是否过期,并且删除已经过期的key,如果本轮检查的已经过期的key超过了5个的话,也就是已经过期的key的数量的占比随机抽取的key的比例超过了25%,那么就认为有极大可能产生了大面积过期的情况,否则的话就认为可以容忍,不继续检查,否则会继续这个流程,然后继续检查 惰性删除有什么优点?有什么缺点? 惰性删除首先是对CPU友好的,这是因为惰性删除意味着不用使用额外的CPU时间片对数据检查,要知道定期随机检查的特点是有可能导致检查到那些没有过期的key,这就意味着CPU时间片被白白浪费了,而惰性删除是只有在要被用到的时候,才会执行这个操作,因此不会导致额外的CPU工作量 但是对于内存来说是不友好的,假设一下这样的场景,Redis在一个时间段内加载了大量的数据,而且这些数据马上就过期了,但是在被访问过一次就不会被访问了,那么大量的数据在惰性删除的策略就不会删除,这种情况就叫做缓存污染的情形 定期删除有什么优点?有什么缺点? 定期删除对CPU资源是不友好的,因为它可能导致无效的检查,同时难以确定删除操作执行的时长和频率,如果执行地太频繁,那么势必会降低主线程对CPU的利用率,如果太长时间不执行,那么内存中就会有很多垃圾,但是通过定期检查,能够排除掉不必要的垃圾,从这个角度上,它解决了缓存污染的问题 既然各有利弊,那么Redis的策略就是做了一个折中,两种策略配合使用,在合理使用CPU时间和避免内存浪费之间取得平衡 Redis持久化的时候,对过期键会怎么处理? Redis持久化的时候有两种格式,分别是RDB和AOF,那么当访问到过期键的时候,会怎么处理呢? RDB文件分为两个阶段,RDB文件生成阶段和加载阶段 RDB文件生成阶段,从内存状态持久成RDB文件的时候,会对过期键进行检查,过期的键不会被保存到新的RDB文件中,因此Redis中的过期键不会对RDB文件产生任何影响 RDB文件加载阶段,从RDB文件加载到内存中的过程,有看主服务器和从服务器,他们有对应的情况: (1)首先,如果Redis是主服务器的话,那么在载入RDB的文件的时候,那么Redis进程会对文件中的键进行检查,过期键是不会被载入到内存数据库中的,所以过期键不会对载入RDB文件的主服务器造成影响 (2)如果Redis是从服务器的话,那么在载入RDB文件的时候,不论键是否过期,都会被载入到数据库中,但是由于主从服务器在进行数据同步的时候,从服务器的数据会被清空,所以一般来说,过期键值对载入RDB文件的服务器也不会造成影响 然后是AOF文件,AOF文件分为是写入阶段和重写阶段 AOF的写入阶段,AOF的写入阶段是这样的,如果键值对还没有被删除,那么就会用set指令保留下来,如果键值对准备删除了,那么通过显式地追加DEL指令就可以实现了 AOF的重写阶段,当执行AOF重写的时候,会对键值对进行检查,已经过期的键不会保存到重写后的AOF文件中,因此不会对AOF的重写造成任何影响 Redis主从模式下,对过期键会怎么处理? 当Redis运行在主从模式下,从库不会进行过期扫描,从库对过期的处理是被动的,也就是说即使从库中的key过期了,从库也不会主动去删除它,如果有客户端绕过了主节点直接去访问从节点,那么依然可以得到key所对应的值,因此它并不保证一个强一致性,它会像未过期一样返回 从库的键值对的过期是依赖于主节点来控制的,主库在key到期的时候,会在AOF文件中增加一条DEL指令,在repl_bak_log的尾部追加这条DEL指令来实现过期的key的删除 Redis内存打满会发生什么? 在Redis的运行内存达到了某个阈值的时候,就会触发一个内存淘汰机制,这个阈值就是设置的最大运行内存,这个值在Redis中的配置文件中可以找到,也就是maxmemory 内存淘汰机制策略有哪些? 不进行数据的淘汰 这种策略其实就是鸵鸟策略,开发者假设问题不会发生,当发生了也不去解决,当出错了之后就停止服务 进行数据的淘汰:进行数据的淘汰的时候,最理想的情况就是淘汰掉那些过期的键值对,于是在第一种情况下,就是直接在过期字段中挑选,一般来说,有: 随机淘汰法,在过期字典中任意挑选 打擂淘汰法,选择最早过期的键值对进行删除 lru思想,淘汰那些最久没有使用的键值对 lfu思想,淘汰那些最少使用的键值对 但是如果所有的key都没有设置过期时间呢?这时候只能够在所有的数据范围内进行淘汰 allkeys-random:随机淘汰任意键值 allkeys-lru:淘汰整个键值中最久没有使用的键值 allkeys-lfu:淘汰整个键值对中最少使用的键值 LRU算法和LFU算法有什么区别? 解释一下什么是LRU算法 LRU算法解释过来是最近最少使用优先淘汰算法,通常,它在实现是基于一个哈希链表实现的,它的具体运作流程是这样的,当一个元素被访问了之后,这时候这个元素就会将原来的位置删除,然后插入到表头,这样的话就是最近最先使用的,这样就形成一个特点,最近最少使用的那个元素总是在表尾,于是通过删除表尾的元素就可以完成淘汰了 Redis并没有使用这样的方式来实现LRU算法,因为传统的LRU算法存在的问题有: 需要用链表管理所有的缓存数据,这将带来额外的空间开销 当有数据被访问的时候,需要完成大量的链表的插入和删除的操作,降低了Redis的性能 Redis是如何实现LRU算法的? Redis实现的是一种近似LRU算法,目的是为了更好的节省内存,它的实现方式是在Redis的对象结构体中添加一个额外的字段,用来记录这个数据的最后一次访问时间 当Redis进行淘汰的时候,会使用随机采样的方式来淘汰数据,它是随机取5个值,然后淘汰掉最久没有使用的那个 但是它无法解决缓冲污染问题,所谓缓存污染问题就是:大批量的数据被短时间内加载到内存中,这些数据只会被读取一次,这些数据会留在Redis缓存中很长一段时间,会造成缓存污染 解释一下什么是LFU算法 LFU全称是最近最不常用的,LFU算法是通过数据访问频次来淘汰数据的,如果数据过去被访问多次,那么未来被访问的频率也会更高 所以LFU算法会记录每个数据的访问次数,当一个数据被再次访问的时候,就会增加该数据的访问次数,这样就解决了偶尔被访问一次之后,数据留存在缓存中很长一段时间的问题。 在 LRU 算法中，Redis 对象头的 24 bits 的 lru 字段是用来记录 key 的访问时间戳，因此在 LRU 模式下，Redis可以根据对象头中的 lru 字段记录的值，来比较最后一次 key 的访问时间长，从而淘汰最久未被使用的 key。 在 LFU 算法中，Redis对象头的 24 bits 的 lru 字段被分成两段来存储，高 16bit 存储 ldt(Last Decrement Time)，用来记录 key 的访问时间戳；低 8bit 存储 logc(Logistic Counter)，用来记录 key 的访问频次。 关于缓存雪崩 如何避免缓存雪崩? 如何避免,首先我们要知道缓存雪崩是怎么发生的,在一个后端系统中引入缓存能够大幅提高QPS 但是带来的问题是一个缓存和数据库的一致性的问题,我们通常会给缓存设置一个过期时间,当缓存数据过期以后,用户访问的数据如果不在缓存里面,业务系统就需要重新生成缓存,因此就会访问数据库,并且将数据更新到Redis中,这样的话后续请求就都可以直接命中缓存 症结在于,当缓存失效的时候,服务器就需要请求中间件中的缓存,但是这个访问是可大可小的,如果是很长一段时间只访问几次,那么在这样的情况下,不会带来很严重的问题 但是如果是短时间内访问很多次,就会带来非常严重的问题 根本原因还是数据库的处理能力远远低于中间件缓存的处理能力。 缓存雪崩就如它的名字一样,当大量缓存同时从缓存中间件中过期,由于重建缓存是需要时间的,因此在重建缓存期间,缓存中没有数据,因此在这种情况下就只能够去访问数据库,此时一下子上万的TPS打到数据库上,会导致数据库中的连接数过多而崩溃 那么可以怎么解决这个问题呢? 第一个方案:可以将缓存的过期时间随机化,这样的话就能够避免缓存中的数据在同一个时间段内同时过期,避免了缓存雪崩 第二个方案:互斥锁方案,我们的思路是为了避免数据库承受的压力太大,这是因为缓存重建期间,服务器无法找到数据,只能从数据库中取,在缓存重建期间避免线程去访问数据库,一个方法就是给缓存重建的权限加一个互斥锁,当有线程开始执行缓存重建的时候,就上一个互斥锁,让这些自旋等待或者阻塞,当互斥锁被释放了之后,这时候就让这些线程解除等待,可以去访问缓存了 实现互斥锁的时候,最好设置超时时间,不然的话第一个请求拿到了锁,然后发生了意外的话一直阻塞的话,就会一直不释放锁,这时候其他请求也一直拿不到锁,整个系统就会出现没有响应的情况 第三个方案:双key方案,在互斥锁的方案中,由于加锁会使得其他线程陷入阻塞等待的情况,这对用户的体验是很不好的,同时也会降低系统的吞吐量,更严重的是当发生请求积压的时候,可能导致系统发生OOM等异常,请求丢失,因此能不能提供一种方案,就是将阻塞等待的情况给去掉,当有线程到来发现有线程正在执行缓存重建的时候,返回一个过期的数据回去,这个方案简单来说就是两个key,主key代表着最新的数据,它是会过期的,当触发更新的时候,就会删除这个key,当这个key过期了,线程找不到的时候,就会用旧key返回回去,这样的话线程就不会阻塞,用户的请求也能达到响应。 第四种方案:后台更新缓存,业务线程不再负责去更新缓存,缓存也不再设置有效期,而是让缓存永久有效,并将更新缓存的工作交给后台线程定时更新,事实上,缓存数据不设置有效期,这也不意味着数据能够一直在内存中,这是因为内存是有限的,当内存达到了maxmemory的时候,就会触发缓存的过期淘汰策略,将一部分数据淘汰掉,从业务线程来看,这个数据就好像丢失了 于是为了解决这个问题,会有一个后台线程不断轮询缓存中是否失效了,如果失效了,那么就从数据库中重新都会数据,这样的话会导致CPU的实际利用率降低。 第二种策略是在业务线程发现数据为空的时候,就将这个重建请求发送到消息队列中,然后由消费者后台线程来执行这个消息队列中的请求,这样的话可以避免CPU忙轮询,这样的话更新更加及时 在业务刚上线的时候,最好提前将热点数据缓存起来,而不是等待用户来访问才构建缓存,这就是缓存预热。 Redis故障宕机了怎么办? Redis故障宕机后,如果Redis的宕机后很长时间无法启动起来,那么大量的请求就会落入数据库中 服务熔断或者请求限流机制 因为Redis故障宕机而导致缓存雪崩问题,可以启动服务熔断机制,暂停业务应用对缓存服务的访问,直接返回错误,不再继续访问数据库,从而降低对数据库的访问压力,保证数据库系统的正确运行,然后在Redis恢复正常运行后,再允许业务应用访问缓存服务 服务熔断机制是保护数据库的正常运行,但是暂停了业务应用访问缓存服务系统,全部业务都无法正常工作,为了减对业务的隐形,可以启用请求限流机制,只将少部分请求交给数据库进行处理,再多的请求就在入口直接拒绝服务,等到Redis恢复正常并把缓存预热完后,再接待处请求限流的极值 构建Redis缓存高可靠的集群 服务熔断或者请求限流机制是缓存雪崩发生后的应对方案,我们最好通过主从节点构建Redis缓存高可靠集群 如果Redis缓存的主节点故障宕机,从节点可以切换成主节点,继续提供缓存服务,避免了由于Redis故障宕机而导致的缓存雪崩的问题 什么是缓存击穿问题? 缓存击穿,它首先也是一种数据在缓存找不到,但是在数据库中能够找到的情况,这种现象主要针对于哪些hot key,在hot key过期的时候,此时大量的请求直接到达后端服务器,由于是热点数据过期了,因此在这种情况下就可以基于这个现象去实现解决方案: 基于互斥锁方案,当热点数据过期之后,给那些来访问数据库中的线程阻塞等待,这样的话就可以实现请求不至于一下子全部冲到数据库中了 基于逻辑过期的方案,所谓逻辑过期的方案就是在缓存中埋下一个过期时间,当业务线程访问缓存的时候,这时候会判断埋在缓存中的过期时间超过了,那么就通知后台异步线程更新缓存,然后重新设置过期时间。 什么是缓存穿透问题? 缓存穿透实际上是一个安全性的问题,也就是说恶意用户伪造大量不存在的key,然后通过脚本工具等将这些key直接发送到数据库中,这样的话就会导致数据库因为恶意攻击而崩溃 解决这个缓存穿透,有三种方案: 第一种:非法请求的限制,当有大量的请求访问不存在的数据的时候,也会发生缓存穿透,因此在API入口处要判断请求参数是否合理,请求参数是否含有非法值,请求参数是否符合格式,否则的话就会直接打回请求 第二种:缓存空值或者默认值,当线上业务发生缓存穿透现象的时候,可以针对查询的数据,在缓存中设置一个空值,这样的话在后续请求中就可以从缓存中拿到值了,避免了同一个key的缓存穿透的问题 第三种:基于布隆过滤器解决缓存穿透问题,在写入数据库的时候,使用布隆过滤器做个标记,然后在用户请求到来的时候,业务线程确认缓存失效后,可以通过布隆过滤器快速判断数据是否存在,如果不存在,那么就不用通过查询数据来判断数据是否存在。 如果发生了缓存穿透,大量请求只会查询Redis和布隆过滤器,而不会查询数据库,保证了数据库能够正常运行,Redis自身也是支持布过滤器 布隆过滤器的原理是这样的:它基于一个bitmap和若干个哈希函数来进行实现 第一步会通过这N个哈希函数分别对数据作 哈希计算,得到N个哈希值 第二步会通过这个N个哈希值对位图的数组长度取模,得到每个哈希值在位图数组的对应位置 第三步,将每个哈希值在位图数组的对应位置的值设置为1 布隆过滤器说这个数据不存在,它一定不存在,但是查询数据存在的时候,它不一定存在 如何设计一个缓存策略,可以动态地缓存热点数据呢? 由于数据存储受限,系统无法将所有的数据都存放到缓存中,而是只是将其中一部分热点数据缓存其来,所以要设计一个热点数据动态缓存的策略 热点数据动态缓存的策略的总体思路是:通过数据最新访问的时间来做排名,然后过滤掉那些不常访问的数据,只留下那些经常访问的数据 以电商平台为例,现在要求只缓存用户经常访问的TOP1000的商品,具体的细节如下 通过ZSet做一个排序队列,以时间戳作为得分,系统会根据商品的访问时间,更新队列信息,越是最近访问的商品排名越靠前 同时系统会定期过滤掉队列中排名最后的200个商品,然后再从数据库中随机读取200个商品加入到队列中 每次请求到达的时候,会先从队列中取商品的ID,然后再通过ID从另一个缓存结构中获取实际的数据 在Redis中可以用zadd方法和zrange方法来完成排序和获取操作 常见的缓存更新策略有哪些? 旁路缓存策略:所谓旁路缓存策略是基于业务对数据库和缓存进进行更新 写策略:先更新数据库,再删除缓存 读策略:如果缓存命中,那么直接读取,如果缓存不命中,那么就从数据库中读取数据,然后载入缓存 注意,当先删除缓存再更新数据库的时候,会导致并发错误 举个例子,假设某个用户的年龄是20,请求A要求更新用户的年龄为21,因此它会删除缓存中的数据,然后开始更新数据库,假设更新数据库时,线程阻塞了,此时有另外一个线程到来,发现缓存中没有数据,于是从数据库获取到年龄为20,此时线程时间片到,然后之前那个线程将21在数据库更新好了,然后写回到缓存中,接着另外那个线程将数据库中的原本的20写回到缓存中,最终导致问题的发生 那么先更新数据库,在删除缓存,就不会有问题了吗? 肯定还是有的,比如说缓存中原本没有数据,然后线程A读取数据库中的值(20),在没有写入缓存中的时候,另外一个线程B更新年龄为(21),然后删除了缓存,然后线程A将20的这个值写入到缓存中 既然还是会有并发的问题,那么为什么还是用这种方案呢? 这是因为一般来说删除缓存比数据库更新要快得多,像我举的这个例子,它是因为没有及时写入缓存才导致的,但是一般来说不会出现这样的情况 CacheAside的这种策略适合读多写少的场景,不适合写多读少的场景,因为当写入比较多的时候,就会导致缓存中的数据被频繁地清理,这样对缓存的命中率具有一定的影响,如果业务对缓存的命中率有严格的要求,那么应该要考虑两种方案: 加互斥锁,比如说在更新数据的时候也更新缓存,在更新缓存的是加一个分布式锁,这样就不会产生并发问题了 在更新数据库的的时候同时更新缓存,但是给缓存加一个很短的过期时间,缓存的数据也会很快过期 读写穿透策略 读穿透:查询缓存中数据是否存在?如果存在就直接返回,如果不存在就由缓存组件负责从数据库中查询数据,并且将结果写入到缓存组件中,最后缓存组件将数据返回给应用 写穿透:当有数据更新的时候,先查询要写入的数据是否已经存在,如果存在了,那么更新缓存中的数据,然后由缓存组件将数据同步到数据库中 如果缓存中不存在这个数据,那么直接更新数据库,然后返回 Write Back策略 所谓写回策略就是在更新数据的时候,只更新缓存,同时将缓存数据设置为脏的,然后交给后台线程执行刷盘操作,WriteBack特别适合写多的场景,因为当发生了写操作者的时候,只需要更新缓存,就立即返回了。持久化的任务是交给后台线程的 但是它不是强一致性的 Redis如何实现延迟队列? 延迟队列可以看成是线程池中的阻塞任务队列,比如说平台上支付任务,超过10min没有支付就自动取消,这个功能可以基于一个ZSet来实现,简单来说就是将订单等信息放到ZSet中,然后按照将时间戳作为score进行排序，开辟一个后台线程不断轮询是否超时,如果超时就马上删除这个订单。 Redis的大Key要如何处理? 什么是BigKey? 首先明确一点BigKey不是指&#123;key=&gt;value&#125;中的key很大,而是指value的值很大,一般来说有这样的: String的值超过10kb Zset、Set、List、Hash的数量超过了是500个元素 BigKey会导致什么? BigKey导致的问题主要可以用主线程阻塞/网络阻塞问题来概括 主线程阻塞:当对BigKey进行操作的时候,这时候可能导致主线程被阻塞了 网络阻塞:如果一个BigKey的大小是10MB,那么1s产生1000次请求的话,就会导致一秒10000MB的流量 阻塞后续执行处理:当主线程阻塞了之后,那么就会导致后续的指令也被阻塞了 内存分布不均:集群模型在slot分片均匀的情况下,会出现数据和查询倾斜的问题,也就是说当一些hot key或者大数据量的big Key被集中放到一个集群上的一个实例的时候,就可能导致这个实例就可能被压力冲垮了 如何排查BigKey? redis-cli –bigkeys:可以通过redis-cli --bigkeys来查找bigKeys。 注意:最好在从节点上执行这个指令,因为在主节点上执行这个指令的时候,就可能导致主节点的阻塞。 如果没有从节点,那么可以选择在Redis实例业务压力的低峰阶段进行扫描查询,以免影响实例的正确运行,或者可以使用-i参数控制扫描间隔,避免长时间扫描降低Redis实例的性能 该方式的不足之处 这个方法只能返回每种类型的最大的那个bigKey,无法得到大小排在前N位的bigKey 对于集合类型来说,这个方法只是统计集合元素中个数的多少,而不是统计实际占用的内存量,但是实际上,并不意味着一个集合中的元素多,一个集合的元素少,那么多的那个集合占用的内存就比集合元素少的那个集合占用内存少了。 可以基于SCAN命令查找BigKey 使用SCAN命令对数据库进行扫描,然后用TYPE命令获取返回的每一个KEY的类型 对于String类型,可以直接使用STRLEN命令获取字符串的长度,也就是占用的内存空间字节数 对于集合类型来说,有两种方法可以获得它占用的内存大小 如果能够预先从业务层知道集合元素的平均大小,那么可以使用下面的命令获取集合元素的个数,然后乘以集合元素的平均大小,这样就可以获得集合占用的内存大小了,List类型:LLEN,Hash类型HLen,ZSet类型ZCARD,Set类型SCARD 如果不能提前知道写入集合的元素大小,可以使用Memory USAGE命令,查询一个键值对占用的内存空间 可以使用Rdb Tools查找BigKey 怎么样来删除BigKey? 删除操作的本质是要释放键值对占用的内存空间,那么操作系统在做这个的时候： 将内存标记为未使用,这个过程需要将这个内存块插入到一个空闲内存块的链表中,以便后续进行管理和分配,这个过程本身就需要一定的时间,而且会阻塞当前释放内存的应用程序 如果你这个Key的占用内存很大,那么将这个内存块插入到空闲链表的时候就会很耗时。 如果很耗时,那么主进程被阻塞了,然后请求挤压,请求超时,造成Redis的连接耗尽,产生各种异常,那么具体要怎么做呢?可以执行: 分批次删除:所谓分批次删除,比如说吧,删除大Hash的时候,使用hscan,每次获取100个字段,然后使用hdel的指令,每次删除一个字段 异步删除:使用unlink来代替del指令,这样的话Redis会将这个key放入到一个异步线程中进行删除,这样的话就不会阻塞主线程,除了主动调用unlink命令实现异步删除之外,还可以通过配置参数,达到某些条件的时候自动进行删除 1234567lazyfree-lazy-eviction：表示当 Redis 运行内存超过 maxmeory 时，是否开启 lazy free 机制删除；lazyfree-lazy-expire：表示设置了过期时间的键值，当过期之后是否开启 lazy free 机制删除；lazyfree-lazy-server-del：有些指令在处理已存在的键时，会带有一个隐式的 del 键的操作，比如 rename 命令，当目标键已存在，Redis 会先删除目标键，如果这些目标键是一个 big key，就会造成阻塞删除的问题，此配置表示在这种场景中是否开启 lazy free 机制删除；slave-lazy-flush：针对 slave (从节点) 进行全量数据同步，slave 在加载 master 的 RDB 文件前，会运行 flushall 来清理自己的数据，它表示此时是否开启 lazy free 机制删除。 Redis的管道有什么用? **管道技术(pipeline)**是客户端提供的一种批处理技术,用于一次处理多个Redis命令,从而提高整个交互的性能 使用管道技术可以解决多个命令执行时的网络等待,它是将多个命令整合到一起发送给客户端处理之后,同一发送给客户端,这样就免去了每条命令执行后都要等待的情况,从而有效地提高了程序的执行效率 但使用管道技术也要注意避免发送的命令过大,或者管道内的数据太多而导致的网络的阻塞 要注意的是,管道技术本质上客户端提供的功能,而不是Redis服务器端的功能 Redis的事务支持回滚吗? 首先先来了解一下什么是Redis的事务 123MULTIdo something...DISCARD 不支持回滚的,Redis并不保证事务的原子性 Redis事务执行的过程中很少会在生产环境中报错,所以他认为没有为Redis开发回滚事务的功能 不支持事务回滚是因为这种复杂的功能和Redis的设计主旨不符合 Redis如何实现分布式锁? 首先介绍一些为什么需要分布式锁,在项目中使用的时候,为了保证在高并发的情况下库存扣减的合法性,那么就必须要实现加锁了,因为加锁可以使得只有一个请求对库存进行扣减,从而避免了多个线程同时对库存进行扣减 如果是一台tomcat,那么我们可以通过ReentrantLock或者synchronized来实现同步互斥,但是如果部署了集群呢?要知道JVM中的Minitor可都不是共通的,因此在这样的情况下,我们必须将锁的结构存储在一个所有tomcat都能够访问的地方,然后由这个地方来监视锁是否被获取,通常来说,Redis作为中间件,可以被多个Web服务所共同访问,那么就可以基于Redis来实现分布式锁 实现分布式锁,基本上来说要完成并发编程中锁的基本功能,可以参考可重入锁的机制来实现 首先第一点,既然是锁,那么就先要实现锁的互斥性,所谓互斥性,就是说你这把锁是独占的,每一个时间段只能有一个线程获取这把锁,那么在这样的情况下,可以基于Redis中的set nx来实现,这个指令特性是只有首次设置锁才会成功,其他的都会失败,因此可以基于这个指令,设置一个name为锁的名字,value为任意值的一个&#123;key=&gt;value&#125;,这样的话就可以实现锁的互斥性了 第二点,要保证安全性,所谓安全性的问题,就是说当线程发生异常后,这个锁能够自动释放,而不会导致死锁,在Redis中可以使用一个expires time的指令来实现,也就是说让锁自动过期,这样的话当线程挂掉了之后,锁也能够自动释放,避免了死锁问题 第三点,要保证加锁指令的原子性,在第一二点中,基本上对于一个分布式锁的实现可以基于set nx+expires time 来实现,但是这不是原子性的,也就是说有有可能还没有设置锁的超时时间之前,线程就挂掉了,因此在这样的情况,要保证加锁指令的原子性,最好的办法是基于Lua脚本来实现,也可以通过一条指令set nx expres 第四点,要保证加锁操作的可重入性,所谓可重入性,意思就是将当一个线程获取了这把锁,在此以后,这个线程就可以一直访问这把锁所控制的临界资源,而其他线程无法访问,那么怎么来实现呢?可以仿造JDK中的条件变量来实现,也就是在Redis中分布式锁的键值对中设置一个state,然后每次获取锁的时候,判断这个分布式锁中的线程ID+JVM标识是否和自己一致,如果是一致的,那么就将state++,这样代表重入了一次,解锁的话就让state--,当state==0的时候,就删除这把锁,此后就可以有其他线程可以访问这把锁所控制的临界资源了 第五点,可以实现锁的自动重试,在业务正常执行的情况下,一般来说持有锁的时间是比较短的,因此当线程无法获取锁的时候,这时候可以使用一个短时间内自动重试的机制来实现,一般来说设定一个重试次数,比如说重试100次,当重试100次都不成功,那么直接返回。 那么为什么要自动重试呢?这是因为让用户来重试的话,这就涉及到网络IO的问题了,既然是用户重试,那么肯定就会增加服务器的请求量,加重负担 第六点,要实现锁的自动续期,首先锁是要设置一个自动过期时间的来避免死锁的,但是如果业务执行时间异常,大于了过期时间的话,那么就会导致锁被提前释放,首先它可能会导致锁的误删问题,锁的误删问题可以基于JVM标识+线程ID来防止,但是在并发环境下可能导致的问题更加严重,虽然说锁不会被误删了,但是会导致多个线程同时对临界资源的同时访问,那么怎么做呢?可以基于看门狗机制来实现,所谓看门狗机制,就是说在JVM中开辟一个守护线程,让这个守护线程定期去更新锁的过期时间,在业务线程没有执行结束的时候,就一直更新锁的过期时间,这样的话就-可以避免锁被提前释放。同时这样不会导致死锁,因为我们说死锁是线程挂掉了但是没有释放锁,但是在这种情况下,如果持有线程的JVM都挂掉了,那么肯定执行业务的线程也挂掉了。 第七点,要实现锁的高可用,可以基于主从集群,哨兵机制来实现。 追问:什么是死锁?怎么避免死锁?怎么预防死锁? 所谓死锁,就是在线程执行过程中,产生了资源等待的循环链,A等待1资源的释放,占有2资源,B等待2资源的释放,占有1资源,这样就形成了死锁。形成死锁的四个必要条件是: 互斥访问:只有一个线程才能持有临界资源的访问权 占有而且等待:当一个线程获取了资源又尝试去获取新的资源的时候,不会释放已有的资源 不可剥夺:不可以强制剥夺线程已经获得资源 循环等待:形成了资源互相等待的循环链 死锁的避免和死锁预防本质都是从资源分配的角度做限制,一般来说,切入点有: 在进程运行前对资源做限制,之所以会发生死锁,这是因为在程序运行的过程中去申请资源,因此可以在进程运行之前就分配好进程所需要的资源,这样的话就破坏了占有而且等待的情况 在进程运行时对资源做限制,这种方法要考虑的情况比较多,首先第一种情况是这样的,我们可以给资源设置层级 只有申请了上一级的资源才能申请下一级的资源,比如说有1资源、2资源，A线程和B线程,只有申请了1才能申请2这样的话就不会出现A申请了2，又去等待1的情况,第二种方法是基于银行家算法来实现,所谓银行家算法就是说在运行时,判断每一次的资源分配有没有可能导致死锁,如果可能导致死锁，那么就直接放弃这次资源的分配。第三种情况是这样的,不对资源做限制，而是基于检测+解除来实现,定期检测是否产生死锁,如果发生了死锁，那么撤销这个进程 如何保证缓存和数据库的一致性? 在前面的旁路缓存策略中,我们分析了无论是先更新数据库再删除缓存,还是先删除缓再更新数据库 这两种策略都有可能导致并发的问题,但是只是说先删除缓存再更新数据库引发问题的概率小一些而已 为了确保万无一失,通常还可以给缓存数据加上过期时间,就算这期间存在缓存数据是不一致的,那么还会有过期时间来兜底,这样也能达到最终的一致性 但是这样,在用户看来,就是自己更新的数据,如果后端产生了异常,那么在他看来就是要过一段时间数据才会生效 那么什么时候会产生异常呢?我们的策略是先更新数据库,再删除缓存 那么在更新数据库成功后,如果删除缓存失败了,那么在缓存过期之前,用户得到的一直都是旧的数据,只有当缓存过期了才会得到最新的数据 那么如何来保证先更新数据库,再删除缓存能够同时操作成功呢? 第一种方案:重试机制,可以引入一个消息队列,将第二个要操作的数据封装成一个消息,由消费者来操作数据 如果应用删除缓存失败,可以从消息队列中重新读取数据,然后再次删除缓存,这个就是自动重试机制,但是如果重试超过了一定次数,就要上报到业务层了 如果删除缓存成功,就要将这个数据从pending-list中删除 第二种方案:订阅MySQL的binlog,然后操作缓存 如果第一步中更新数据库成功,那么就会产生一组bin log,然后通过Canal中间件来订阅这组bin log,将自己伪装成一个MySQL节点,Canal根据下游中间件的特性,将其转换为下游中间件能够读取的数据。","categories":[{"name":"题库","slug":"题库","permalink":"http://kaillliu.github.io/categories/%E9%A2%98%E5%BA%93/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://kaillliu.github.io/tags/Java/"},{"name":"面试题","slug":"面试题","permalink":"http://kaillliu.github.io/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"name":"题库","slug":"题库","permalink":"http://kaillliu.github.io/tags/%E9%A2%98%E5%BA%93/"}]},{"title":"MySQL 面试题总结回顾","slug":"MySQL基础回顾","date":"2023-08-13T07:00:00.000Z","updated":"2023-09-08T04:22:25.420Z","comments":true,"path":"2023/08/13/MySQL基础回顾/","link":"","permalink":"http://kaillliu.github.io/2023/08/13/MySQL%E5%9F%BA%E7%A1%80%E5%9B%9E%E9%A1%BE/","excerpt":"","text":"谈谈MySQL的基础架构? MySQL的基础架构可以分成是Server层和存储引擎层,其中Server层负责提供的是顶层的服务接口,顶层的服务接口通过调用底层的存储引擎来完成顶层的Server层的相关操作,而Server层是如何去调用存储引擎的API的话,它实际上可以通过一条SELECT的SQL语句来进行说明 首先,当用户编写了一条SQL,然后会将这条SQL发送MySQL进行执行 首先是用户发起登录请求,它会将用户名和密码基于TCP连接,将相关的消息发送到连接器上,连接器负责建立连接,并且在内部创建一个工作内存,此后此连接的所有操作都是基于连接中的内存实现的,因此当重置连接的时候,这个内存就会被释放 接着,会查询MySQL的内部中是否有一个缓存,通常来说,它的检查逻辑是这样的,首先检查你给的这条SQL是否执行过缓存,如果你执行的SQL在缓冲中命中了,那么就会直接返回,不会执行后面非常复杂的逻辑 否则的话,就会走下面的SQL编译执行流程 首先MySQL拿到你的SQL之后,它想要知道你的SQL想要干什么,因此它首先会经过一个分析器,这个所谓的分析器会经过两个流程,首先是经过一个词法分析,就是判断解析你的SQL中的关键字,比如说动作关键字,表名关键字,列名关键字等,然后解析完毕之后,就会经过语法分析,然后就判断你的语法是否正确,如果语法正确,那么就说明:MySQL已经知道了你的SQL想要干什么了 接着MySQL知道了你的SQL想要干什么,接下来它就会想要知道你的SQL要怎么做,怎么做是优化器决定的,它会根据你的SQL结构以及相关表中的索引等数据结构,来确定你的SQL具体如何执行 通过了优化器之后,MySQL就知道了怎么做了,然后就会将执行计划生成,下放到执行引擎中,执行引擎通过调用底层的存储引擎提供的接口,执行语句之前会先判断是否有权限 为什么要判断是否有权限? 这是因为在执行过程中,可能会涉及到触发器,那么触发器的执行是无法预料的,因此在这个过程还需要执行相关的权限验证 MySQL提供了哪些存储引擎? 可以通过show engines来查看MySQL提供的所有存储引擎 一般来说,MySQL提供了 InnoDB:默认存储引擎,提供事务,外键,行级锁、MVCC等高级特性,当读写操作较多,需要在并发环境下执行的话就可以使用这个引擎,核心设计理念是索引即数据 MyISAM:不支持事务,不支持外键,仅支持表级锁,在需要事务的是不要使用这个引擎,在并发下由于只支持标记锁,因此性能很差 Memory:内存存储驱动,不支持事务,不支持外键,只支持表锁,基于内存的读写快,不需要IO MyISAM和InnoDB的区别是什么? MyISAM通常来说支持读多写少的环境,但是它在崩溃后,没有日志来提供崩溃后的恢复 InnoDB通常来说在需要使用高并发的环境下使用 MyISAM为什么读的性能比InnoDB要高? 在InnoDB中是支持行锁和表锁的,并且在事务开启的时候,需要动态维护MVCC,在使用count的时候就它是通过扫描全表来执行的,它的索引结构是B+Tree,因此可以看出,MySQL在执行查询语句的时候,尽管你没有涉及到多事务的并发读写操作,它还是会在底层维护view等操作,这些额外的操作都会导致额外的性能开销 但是在MyISAM中,由于只有简单的表级锁X/S锁,因此在读多写少的情况下,只需要上一个共享的读锁就可以一直读写了 同时在索引的组织上,MyISAM和InnoDB索引存储方式是不一样的,InnoDB的表示根据主键展开的B+树的聚集索引,MyISAM中设计理念是说将索引和文件分开,然后通过索引文件来查询对应主键在数据文件中的偏移量,从索引的这个角度来说,InnoDB需要缓存数据块,MyISAM只需要缓存索引块,然后InnoDB寻址次数多,也就是说需要从索引找到块,然后还要从块找到行,而MyISAM的执行则是通过记录偏移量,将文件起始地址+记录偏移量就可以了 什么是事务 事务就是MySQL通过begin开始，以rollback/submit结束的一组原子性的指令,这些指令是原子性执行的不可分割,要么一起成功,一起失败,事务有ACID四大特性,这些特性就是: 原子性,它在InnoDB是基于undo log实现的,undo log的具体功能就是撤销数据的操作,比如说在SQL中执行insert、update、delete等语句的时候,它就会相对的,记录下来这条记录的ID,如果要回滚,那么就删除,如果是update,那么就相关的字段修改回来,如果是delete,那么就将原来的记录插入回来,由此实现了原子性 持久性,它在InnoDB是基于redo log实现的,redo log相比于undo log,它更加底层,它记录的是某个数据块中具体的操作,比如说修改了某个表空间中的某个位置上的物理量,那么它就会将这个redo log写入到磁盘文件中,然后基于这个文件执行初始化 隔离性:简单地说,就是控制多个事务并发执行的时候,数据库中的这些共享的数据的访问不会错乱,通常它解决的是读写冲突/写写冲突的问题,写写冲突是脏写问题,因此是不 允许发生的,但是在数据库中,一定程度的读写冲突是允许的,因此就有了事务的不同隔离级别,也就是可串行化、可重复读、已提交读、未提交读,在串行化的隔离级别下不会产生并发问题,可重复读会带来幻读问题,已经提交读会带来不可重复读的问题,未提交读会导致脏读的问题 一致性:一致性是通过上面三个特性来实现的 不可重复读和幻读有什么区别? 首先要了解什么是不可重复读和幻读 不可重复读:相同的SQL语句,在同一个事务先后没有对相关数据做任何操作,查询出来的结果却不一样,它针对的是查询结果的记录中,这些记录的数据发生变化了 幻读:相同给的SQL语句,在同一个事务先后没有对相关数据作任何操作,查询出来的结果的条数却发生了变化,它针对的是查询结果的记录中,这些记录的条数发生了变化 幻读从定义上理解,其实不就是不可重复读吗? 可以这么理解,但是从解决这两个问题的角度上来讲,解决不可重复读只需要对相关数据加锁就可以解决数据被其他事务篡改的问题了,但是幻读引发的症结是新插入的数据,而MySQL不可能对还不存在的记录加锁,因此解决幻读和不可重复读的方案是不一样的,一般来说,解决了幻读问题,那么也就解决了不可重复读,基于这个现象,就可以将对应的事务隔离级别进行再次划分。 那么MySQL是如何解决幻读问题的? MySQL是基于行级锁+MVCC来解决幻读问题的,行级锁一般分为有next-key lock、redocrd lock、gap lock,这些锁锁住的是一个区间,从现象上来讲这些区间中不允许插入别的数据,但是它其实是锁住了索引,避免了数据的插入而已,同时在多事务并发查询+快照读的机制下,实现了MVCC,基于undo log版本链就可以实现不同的事务在一定的启动时机内,看到的数据内容和事务刚启动时的一样 这样就解决了在其他事务并发穿插执行的时候,对数据进行新写入的时候,本事务还能看到的问题 注意,但是它并没有彻底解决幻读问题,在当前事务存在一个当前读的情况下,还是不能够解决幻读问题,比如: 123trx1:select * from tb where id = 1;#查询为nulltrx2:insert into tb(id,name) values(1,&#x27;zhangsan&#x27;);trx1:update tb set name = &#x27;lisi&#x27; where id = 1;#更新成功,这是因为update默认就是当前读 可以在开启事务的时候,同时使用锁定读,这样就可以给相关的数据上一个next-key lock了,避免了相关的间隙和相关的记录被修改 可以这样总结 当使用的是快照读的时候,它是基于MVCC来解决幻读问题的,在RR的隔离级别下,除非中途遇到当前读的语句,否则都将一直复用事务启动的时候的ReadView 当使用的是当前读的时候,会给相关的记录上一个next-key lock,从而避免了其他事务在这个区间插入数据,同时也避免了其他事务读这条记录的修改操作 什么是MVCC?原理是什么? MVCC的实现三剑客是undo log、roll poniter、trx_id,这三个字段共同实现了MVCC,在readview(快照读)的辅助下实现了MVCC 首先先来讲讲什么是快照读,快照读实际上就是当前事务执行环境的一个上下文环境,通常包括有四个字段 m_ids:当前活跃中的事务id,还未提交 min_id:活跃事务的最小id,这个字段用来标记那些一定已经提交的事务 max_id:即将分配的下一个事务id creator_trx_id:当前事务ID 通过这个readview就可以实现快照读或者当前读,以可重复读的隔离级别下的运用来说: 首先当用户发起一条SQL,注意这个SQL是不加for update或者in share mode的,因此这样的话就是快照读,然后先去索引树中查询对应的索引的位置,然后找到记录中,注意,这时候记录中的隐藏字段中记录了当前记录被哪个事务更改了,也就是这条记录的操作者事务,通过这个id就可以判断记录是谁修改的,具体的规则是这样的: 当记录头中记录的trx_id是大于max_id的,那么就证明这个事务是晚于当前事务启动的,对当前事务不可见,于是顺着roll_poniter去查询下一个undo log中记录的记录 当记录头中记录的trx_id是小于min_id的,那么就证明这个记录在当前事务启动之前就提交了,因此可见,直接返回到上层 当记录中记录的trx_id介于[min_id,max_id]之间,那么就证明这个事务可能是并发执行的,因此就查询这个trx_id是否在m_ids中,如果在的话那么就证明这个事务还没提交,修改是不可见的,否则的话就是可见的。因为在事务开始启动的时候,这个事务已提交,可见 详细解释一下InnoDB中的事务隔离级别和实现原理 读未提交的实现,对并发事务不做控制 串行化:通过加读写锁来实现,也就是说当对冲突数据进行操作的时候,基于S/X锁来实现事务的串行化读写 读提交:基于MVCC(快照读)中的ReadView来实现,它在每一次执行select的语句的时候都会重新生成一个readview,从而确保读取的数据是最新的事务提交的 1可重复读`:基于`MVCC(快照读)`和`Next-key Lock`实现的,在事务开始的时候就会生成一个`ReadView`,在之后就一直使用这个`ReadView 关于count()函数的使用 count()函数是一个聚合函数,它的主要作用是查询表中某个字段不为NULL的记录条数 因此通过这个函数的使用就可以实现表中记录条数的查询 用count(*)哪个存储引擎会更快? 使用MyISAM会更快,首先先来了解一下count()函数的执行流程,在通过count()函数来统计有多少个记录的时候,MySQL的server层会维护一个count的变量,在InnoDB下,它会通过调用底层存取数据的API,通过这个API,如果指定的字段的值不为NULL,那么就会将变量+1,直到退出循环,最后将count的值发送给客户端 而在MyISAM中,执行count()函数的方式是不一样的,通常在没有任何查询条件下的count(*),MyISAM速度要快于InnoDB,这是因为在底层的MyISAM所驱动的表中,表的元数据都会存储一个row_count的值,因此具体的查询只需要读取这个变量即可 当使用where的时候,两个的执行逻辑都需要对表进行全表扫描 表级锁和行级锁有什么区别? 表级锁和行级锁的区别在于锁的作用范围,通常来说表级锁是一个大类,下面包含了不同的实现,具体来说就是针对不同场景的实现 当需要对表的结构进行修改的数据,那么就是上元数据锁 当需要对全表的数据进行修改的话,那么就是上表锁 当需要对全表的一个公共字段,比如说自增ID进行共享访问的时候,这时候就是上一个AUTO-INC锁 具体的,当给表上一个S锁的时候,那么其他任何线程都可以做一个读操作,并让自己持有这把锁,当有线程试图对这个表申请一个X锁的时候,就会被阻塞,当线程持有读锁,但是尝试进行写操作的时候,此时就会提示非法操作 当给表上一个X锁的时候,那么其他任何线程都不得操作,体现的是互斥 什么是元数据锁? 元数据的具体实现就是MySQL中的information_schema,这个表中记录了各个表的名称以及外键索引等详细信息,那么元数据就是说在事务修改这个表的结构的时候,对这个表进行上锁,从而使得其他任何试图修改这个表的线程都会被阻塞 有什么注意点? 当使用元数据锁的时候,要避免阻塞,这是因为元数据锁在执行语句的时候上锁,在事务提交的时候解锁,因此如果在一个长事务中使用元数据锁,就有可能导致请求挤压 什么是意向锁 假设这样一个场景,一个表中有100w条数据,其中有一条记录加了行锁,然后现在有一个线程来了,试图加一个表锁,那么它就要扫描这100w数据,效率是非常低的 但是如果我在上这个行锁之前，给表加一个意向锁,当有一个线程检测到这个表上有意向锁,那么就意味着这个表中有行锁,无法上表锁了,简单的一次检测就可以避免检查表中所有的数据 什么是AUTO-INC锁? Auto-INC实际上是对表中的共享数据自增ID进行保护的手段,这个锁的实现方式有三种 在整条数据执行完毕后才会释放锁 在字段被赋值之后就会释放锁 在插入的语句条数是可以提前预知的时候,就可以在字段被赋值后就释放锁,在语句的条数不可预知的时候就使用第一种策略 Auto-INC锁有什么问题? 它在主从复制场景下,如果使用第二种策略的话就可能导致主库和从库数据的不一致,在主从复制的情况,如果规定binlog的行格式为STATEMENT的时候,这时候记录的是原始逻辑,在这种情况下,因为binlog中规定事务的语句是必须记录在一起的 主库中的id不是连续的,因为发生了并发 而从库中的id是连续的,因为在重放binlog的时候是直接按照原始逻辑进行重放的,而在从库的binlog中, 这写语句都是有序的,最终导致主库和从库的数据不一致 可以将binlog的日志格式设置为row,这样的话就可以记录实际的值了,但是会提高binlog的存储占用 什么是行级锁?行级锁有哪些? 什么是行级锁? InnoDB是支持行级锁的,而MyISAM是不支持行级锁的,也支持事务,行级锁的意思是说锁的粒度是以行为单位的,它的锁定单位是在表以下的,也就是说InnoDB的行级锁在上一个行级锁的时候,并不会导致其他线程对表的全部操作都被阻塞了 什么是锁定读 锁定读和快照读是相对的,具体来说: 锁定读:锁定读就是说在select语句的执行记录下当前的结果集,同时给这个结果集加锁,在以后的其他线程对这个数据进行访问的时候,根据in share mode还是for update来判断是否可以共享数据,锁定读,对范围内的数据将会产生一个独占和互斥的效果 快照读:快照读就是说在select语句的执行记录下当前的结果集,但是不加锁,然后后续根据这个快照读中的上下文信息来判断哪些数据是可见的,从而到达事务读取数据的时候,读取的数据总是和事务开始的时候一致的情况 行级锁有哪些? 行级锁是InnoDB引擎所特有的,其他的存储引擎并不支持这个行级锁,它以最小粒度控制了对记录的修改的并发,锁的类型有: Record Lock:锁定记录,锁定区间是[x,x] Gap Lock:锁定一个范围,不包含单条记录,也就是(x,y) Next-key Lock:锁定一个范围,包含有单条记录,也就是(x,y] 什么是插入意向锁? 插入意向锁可以看成是一种特殊的间隙锁,如果间隙锁锁住的是一个区间,那么插入意向锁住的就是一个点: 与之发生冲突的主要是GapLock、NetKeyLock这两种锁 1234567# 假设目前存在的是1,5这两条记录txA:insert into tb(id,name) values(3,&#x27;a&#x27;)...事务操作commit;txB:insert into tb(id,name) values(4,&#x27;b&#x27;); 在插入这条记录的时候,它看到已经被上了一个(1,5)的锁,这时候就会被阻塞,底层原理是先在内存中生成这个锁的结果,然后将这个锁的结构,然后将这个锁的锁状态设置为等待,然后加入到等待队列中 当事务A提交了事务,释放锁的时候,就会将等待的锁的状态设置为就绪,此时就可以使用了 什么SQL语句会加行级锁? 1234select * from tb where id = 1 for update;#加的是独占写锁select * from tb where id = 1 in share mode;#加一个写锁update tb set name = &#x27;haha&#x27; where id = 1;delete from tb where id =1; 到底是如何加锁的? MySQL的加锁原则 只有访问到的对象才会加锁 锁定的是索引 加锁的基本单位是Next-Key Lock,在特殊情况下会退化成Record Lock和Gap Lock 唯一索引等值查询是如何加锁的? 首先要记住,加行级锁的目的是为了解决幻读,那么如果要理解如何加锁,那么就要理解幻读的问题是如何产生的 1select * from tb where id = 1 for update; 查询这个数据,什么情况下会出现幻读? 第一种情况,当这条数据存在的时候,如果发生了幻读,那么就是说这个查询语句一开始查询出来是有的,后面就没有了,因此这时候上锁的是[1,1]这个区间,锁的是这个记录,因此只要我锁住了这条记录,就可以避免记录被删除,从而杜绝了幻读现象的产生 第二种情况,当这条数据不存在的时候,如果发生了幻读,那么就是说这条查询语句一开始查询出来是没有的,后面就有了,为了避免在两条数据的中间插入数据,因此要上的是间隙锁,是一个开区间的锁,比如说你有&#123;0,5&#125;这两条数据,那么你上的锁区间就是(0,5),如果说你有&#123;5&#125;这条数据,那么上锁的就是(-无穷,5)这个区间,上锁的是哪个索引?上锁的就是5这个索引,比如说: 当只有&#123;5&#125;这条数据的时候,那么它会走到最小记录上,然后检测下一条数据上是否上了间隙锁,如果上了间隙锁,那么就无法插入数据了 唯一索引的范围查询 假设有数据id=&gt;&#123;0,1,2&#125;那么什么情况下会发生幻读呢? 1select * from tb where id &gt;= 1 for update; 首先确定遍历的区间是[1,+无穷),只有访问到的记录才会被上锁,因此对于每一条记录都会上一个next-key lock,也就是当id = 1的时候,它首先会给id = 1的记录上一个RecordLock,这是为了放置数据被篡改,然后为了避免幻读问题,会上一个next-key Lock,也就是(1,2]的锁,然后对于后续的记录,我们也不允许插入,于是上一个(2,+无穷) +无穷如何在MySQL中表示 我们说页的数据表示中,第一条记录和最后一条记录都有特殊的行来代替,因此实际上是锁定了(2,特殊记录) 好了,知道了上面的逻辑,那么如何来判定呢? 1select * from tb where id &gt; 1 for update; 从解决幻读的角度来看待问题,我们的搜索区间是(1,+无穷),我们的数据是id=&gt;&#123;0,1,2&#125; 因此首先为了避免(1,2)中产生新的数据,同时避免数据[2,2]被篡改,因此一开始上的是(1,2]的next-key lock,然后最终再上一个(2,特殊记录) 1select * from tb where id &lt;=1 for update; 从解决幻读的问题的角度来看,首先会上一个next-key lock,这里要注意上锁的顺序啊,它是从左向右扫描的,因此这样的话,就是从最左边开始遍历,遍历到特殊记录,也就是(特殊记录,0] 然后继续遍历,此时上的锁的区间应该会是(0,1],然后继续向右扫描,此时没有符合条件的了,结束 为什么不用锁(1,2)? 这是因为这个是唯一索引,因此可以避免再插入一条相同值的记录,因此不用锁这个区间 而在非唯一索引的情况下,就要考虑这个问题了 非唯一索引的等值查询 假设一条SQL 1select * from tb where number &lt;=1 for update; 那么这时候加锁会发生什么呢?这时候数据是id=&gt;&#123;0,1,2&#125; 首先从左到右执行 第一阶段加锁,先加上(-无穷,0] 第二阶段加锁,加上(0,1] 第三节阶段加锁(1,2)注意上一个间隙锁 没加索引会锁全表吗? update没加索引会导致锁全表 这是因为next-key lock是为了避免幻读的,因为name这个字段是无序的,因此它在表中任意一个位置都有可能出现,那么为了避免幻读,就必须在所有的记录中都加上这个锁,从而就能够避免插入一些name = xxx的记录,这是因为update的时候可能导致并发,为了保证安全必须加一个锁,而且这个锁不是执行完update就会释放的,而是在等事务结束的时候才会释放掉 什么是索引?索引有哪些类型?有什么优缺点? 关于什么是索引这个问题,可以查书为例,当我们需要查阅书籍的时候,就可以基于索引,实现快速查询,比如说查字典,如果我们想要查询张这个字,那么我们就可以从Zhang开始的那一页开始查找 换到数据库中,索引的定义就是帮助存储引擎快速获取数据的一种数据结构,形象地说,索引就是数据的目录 存储引擎,说白了就是如何存储数据,如何为存储的数据建立索引和如何更新,查询数据等技术的实现方法 常见的索引模型有B+树、hash、数组 **关于树 ** 关于二叉搜索树，二叉树搜索树一个节点只有一个指针,因此一次的磁盘IO就只能够找到两个索引,这样的话就会导致树很高,比如说100w条数据需要20次的磁盘IO,这就导致加载速度慢了,而且索引的维护也是个问题,通常来说磁盘的IO是以数据块为单位的,如果一个数据块只能寻址两个数据,那么就太浪费了 那么解决这个问题的方法就是扩充一个数据块中的寻址限制,也就是通过一个数据块中的内容能够执行尽可能多的寻址操作 B-/B+树对寻址过程进行了优化,它允许一个节点具有多个指针,因此的话,一次IO操作就可以尽最大程度地传送尽可能多的数据项,数据项的个数和数据块的大小和索引项的大小相关,它设计的基本思路是一个数据块中可以存储多个指针,然后这些指针可以指向到下一层中的节点,其实这种数据结构就和操作系统中的多级页表是类似的,多级页表在页表项的基础上添加了页表项的页表,从而可以快速查找到每一项数据所在的页,而不需要将所有的页都装载到内存中,而是通过根节点到叶子节点的查询,就可以通过很少次的IO就可以将需要的页装载到内存中了 B-树和B+树有什么区别? 首先B-树是允许非叶子节点存储数据记录的,而B+树是仅在叶子节点中存储数据记录： B-树的查找效率不稳定,同时可能导致树的高度增高,导致IO的次数变多 B+树的查找效率是稳定的,因为每次查找数据都需要到达叶子节点,由于索引项都是存在非叶子节点上,因此在这种情况下,能够保证非叶子没有冗余的数据项,最终的效果就是限制了树的高度 它的优点是存储量大,少量的IO次数就可以存储大量的数据,以InnoDB的整数字段作为一个索引的数据结构的情况下,在树高为4层的情况下可以存储17亿的数据,一个数据块可以存储1200个索引项,仅4次磁盘IO就可以完成17亿数据的检索 但是它的缺点就是需要维护数据块中的索引的有序性,有可能导致页溢出的问题,这个问题是这样描述的: 如果插入数据不是顺序插入而是在中间插入的,那么就有可能导致一个情况,就是一条记录从一个物理存储块中插入,然后导致后续所有的记录都需要移动,可能导致满的一页中的数据溢出到下一页,然后下一页的数据再溢出到下一页,最终到表的结尾 为什么不用Hash结构? Hash类型的索引,其实就是&#123;key =&gt; value&#125;类型的索引,这种索引在定值查询的时候,效率非常高,因为它的原理是将输入的key基于hash()映射到具体的下标下,但是它的瓶颈就是在于它会出现哈希冲突,也就是说多个key映射到的是同一个下标,这时候通常会以拉链法进行解决,也就是将冲突的元素放到同一个下标下,组织成一个链表/红黑树 还有一种方法是再哈希法,就是依次组织&#123;h1(),h2(),h3()&#125;,当发生哈希冲突的时候,就依次使用新的函数,直到哈希冲突不再发生,那么在取值的时候,就会先将key丢进去h(),在得到了结果之后,就将这个结果进行比较,如果对不上就继续哈希,缺点就是Hash()结构容易引起全表查询,因为hash()组成的哈希表是无序的,除非使用了链表来组织这些元素,这是因为元素在被插入到数组的时候,他们之间的顺序并不是按照插入顺序来决定的 为什么用数组结构? 数组结构在等值查询和范围查询都能够达到最好的效果,因为可以直接通过表头+偏移量直接定位到数据,但是因为数组的内存总是连续的,因此一旦遇到索引的修改,就会导致大量的元素搬动 为什么索引要用B+树而不用红黑树? 红黑树相比于AVL树,在高度限制这一块做了调整但它依然无法解决树的高度过高的问题,因为你一个页面只能存储两个指针,假设你有100w条数据,你就需要20次磁盘IO,假设一次IO需要100ms,那么对于百万级的表,就需要2s的查询时间,于是在这样的情况下,即使使用红黑树,而不能解决IO的瓶颈 B树适用于什么场景 B树是一种平衡多路搜索树,B树在进行单个索引查询的时候,最快在O(1)的代价内就可以查询,从平均时间代价来看,会比B+树快一些,它适合在那种查询只有单个结果集的查询出现 索引的分类 总体来说,我们可以从四个角度来分析索引的设计 从索引的数据结构来说,索引可以分为哈希索引、数组索引、B+树索引 从索引的物理存储性质来说,索引可以分为聚簇索引,非聚簇索引 从索引的字段特性来说,索引可以分为唯一性索引,主键索引,普通索引,前缀索引 从索引所用的字段个数来说,索引可以分为联合索引和单列索引 按照数据结构的分类 在MySQL中： InnoDB的数据结构的索引是基于B+树使用的,它是不支持哈希索引的,但是在内存结构中有一个自适应的哈希索引,同时它支持全文索引 MyISAM的数据结构是基于B+树实现的,它不支持哈希索引,支持全文索引 Memory的数据结构是基于B+数和Hash索引实现的,它不支持全文索引 InnoDB中的数据存储格式都是基于聚簇索引存储的,这就要求驱动表一定要有一个主键索引,但是在使用的时候,可以不设定主键,这时候怎么办? 如果表中存在有一个唯一的索引(不包含NULL值),如果有多个候选者的,那么在这些候选者中选择第一个即可 如果没有这种字段,InnoDB就会启用行格式中的隐藏字段row_id,用这个字段来进行索引数的组织 什么是辅助索引? 简单来说,除了主键索引就都是辅助索引,也被称为是二级索引或者是非聚簇索引,创建的主键索引和二级索引默认使用的都是B+Tree索引,辅助索引在一定情况下不可以不回表查询。 简述索引的查询流程? 补充:页目录(Page Directory),因为在一页中,各个记录之间的存放是有序的,因此可以使用二分是搜索的方式进行查找,页目录实现了这个操作,将所有正常的记录(包括有最大记录和最小记录,不包括标记为已删除的记录)，划分为几个组,每个组的最后一条记录(也就是组内最大的那条记录)的头信息中的n_owned,属性表示该记录拥有多少条记录,也就是该组内公有几条记录。 之后每次插入一条记录,都会从页目录中找到主键值比本记录的主键值大并且差值最小的槽(相当于说是找到第一个大于本记录的主键值的槽),然后把该槽对应的记录的n_owned的值+1,表示这个组中又添加了一条记录,直到这个组中的记录数等于8个 通过二分确定记录所在的槽,并且找到这个槽中主键值最小的那条记录 通过记录的next-record属性遍历该槽所在组中的各个记录 索引查询流程具体如下,使用主键索引的查询流程,首先从根节点出发,根据主键值确定要遍历哪一个子节点,比如说根节点有3个子节点,范围是&#123;0~30,31~60,61~90&#125;,我们的id = 40,于是就到了&#123;31~60&#125;这个范围内,然后到了这个节点上,发现直接存储了数据,于是就开始使用槽定位的方式定位这个记录位于哪一组 &#123;37~42&#125;中假设分5个记录为一组,那么查询的时候,它会查询到第二组,也就是&#123;37~42&#125;这一组中,然后反手去找到前一组中的最后一条记录的位置,这样的话就能够得到&#123;37&#125;这条记录的位置了,然后顺着链表向下查找就可以了 由于数据库的索引和数据都是存储在硬盘中的,因此可以把读取一个节点当做是一个IO操作 通过二级索引查询商品的流程 首先通过二级索引查询到具体的记录所在的位置,然后要通过回表这个操作,回到聚簇索引所在的位置,然后再查询一次聚簇索引所组织的B+树来查询具体主键值所在的位置,获取整行数据,最终就完成了 具体是否需要回表需要看是否发生了覆盖索引,具体地说,查询的字段在二级索引组织的B+树中都有,这时候就不需要回表查询了。 主键查询:主键索引就是建立在主键字段上的索引,通常在创建表的时候一起创建,一张表最多只能有一个主键索引,索引列的值是不允许有空值的 1PRIMARY KEY (index_col) USING BTREE; 唯一索引:唯一索引建立在UNIQUE字段上的索引,一张表可以有多个唯一索引,索引列的值是必须唯一的,但是允许有空值 12CREATE UNIQUE INDEX index_name on table_name(index_col,...) 普通索引:普通索引就是建立在普通字段上的索引,既不要求字段为主键,也不要求字段为UNIQUE,在创建表的时候,创建普通索引的方式是这样的 12CREATE index indexNameon tbale_name(index_col,index_col); 前缀索引 前缀索引可以建立在字段为char、varchar、binary、varbinary的列上,它的作用是对字符类型的前几个字符建立索引,而不是在整个字段上建立索引 1234create TABLE table_name( column_list; INDEX(column_name(length))); 关于联合索引 建立在单列上的索引称为是单列索引,比如说有主键索引 建立在多列上的索引称为是联合索引 联合索引:通过将多个字段组合成一个索引,这个索引就被称为是联合索引,联合索引的非叶子节点的两个字段的值作为B+Tree的key值,在使用联合索引查询数据的时候,它会先按照product_no字段进行比较,在product_no相同的情况再按照name的字段进行比较,也就是说,联合索引的查询的B+Tree是先按照pn的值进行排序,然后再通过name字段进行排序 因此在使用联合索引的时候,存在一个最左匹配的原则,也就是按照最左优先的方式进行索引的匹配,在使用联合索引进行查询的时候,如果不遵循最左匹配原则,联合索引就会失效,这样就无法利用到索引快速查询的特性了 比如说创建了一个(a,b,c)联合索引,如果查询条件是: 123where a = 1where a = 1 and b = 2 and c = 3where a = 1 and b = 2 注意,由于存在查询优化器,因为a字段在where子句的顺序不重要 这样的话就可以匹配上联合索引,否则的话联合索引就会失效 123where b = 2;where c = 3;where b = 2 and c =3; 如上面的SQL,他们的索引将会失效,为什么呢? 这是因为索引的组织是按照(a,b,c)进行组织的,因此是先a有序,b有序,c有序 首先分析b = 2这个语句,这个语句将会触发全表扫描,因为b = 2 这个条件在表中并不是有序的,而是杂乱的分布在表中的 c = 2同理 总结:只有在前一个字段是相同的情况下,后面的字段才能是有序的,从而起到过滤/筛选一批数据的功能 联合索引的范围查询,如何判断是否会走索引? 联合索引有一些特殊情况,并不是查询过程使用了联合索引查询,就代表着联合索引中的所有字段都用上了 这种特殊情况就发生在范围查询的情况下以及一些like %通配符的相关情形,范围查询的例子有: 1SELECT * FROM tb WHERE a &gt; 1 and b = 2 有没有用到联合索引,就要看这个字段到底有没有起到过滤数据的作用? 首先可以知道,首先第一个条件就确定了查询范围对于a来说是(1,+无穷),也就是说,它会去扫描后面所有的元素,那么b=2会起到一个过滤作用吗?不会 1select * from tb where a &gt;= 1 and b = 2 首先也是要看这个字段有没有起到过滤作用 首先可以知道,第一个条件就确定了查询范围对于a来说是[1,+无穷),那么在查询的时候,就可以分成两端 a=1的时候,此时在a=1的这个字段范围中,呈现出来的就是b是有序的,因此这样就可以通过b=2条件减少需要扫描的二级索引记录范围,b字段可以利用联合索引进行索引查询,也就是说,从符合a=1 and b = 2的条件第一条记录开始向后扫描,而不需要扫描第一个a字段值为1的记录开始扫描 如何知道是否使用了索引? 可以通过执行计划中的key_len、key知道这一点 1select * from tb where a between 2 and 8 and b = 2 这个查询条件中的查询a字段的值是在2 &lt;= a &lt;= 8的,由于它符合符合字段顺序编排,而且有等值查询的情况,因此这样的话,就意味着不需要从a=2的第一条记录开始查询,而是直接从a = 2 &amp;&amp; b = 2 开始查询 1select * from tb where name like &#x27;j%&#x27; and age = 22; 首先这个索引的结构是j%,因此它首先先会定位符合前缀为j的name字段的第一条记录， 然后沿着记录所在的链表向后扫描，直到某条记录的name不为j为止 于是在确定需要扫描的二级索引的范围的时候,当二级索引记录的name的字段值为j的时候,可以通过age = 22的条件减少需要扫描的二级索引记录范围,age字段可以利用联合索引进行索引查询,也就是说从符合name = j and age = 22 条件的第一条记录时开始扫描,而不需要从第一个name为j的记录开始扫描 联合索引的最左匹配原则,在遇到范围查询如(&gt;、&lt;)的时候,就会停止匹配也就是范围查询的字段可以用到联合索引，但是在范围查询字段的后面的字段无法用到联合索引,但是对于&gt;=,&lt;=,between、 like前缀匹配的范围查询 不会停止匹配 看联合索引是否会走索引,关键就是看索引的字段能否过滤掉一批数据 什么是索引下推? 所谓索引下推优化就是说在使用二级索引进行查询的时候，不需要取出主键一个个地回表，而是通过在二级索引本身的字段，来减少一些不符合查询条件的记录，从而减少回表的次数 1select * from tb where name &gt;= &quot;zhangsan&quot; and age = 3; 如果组织的索引是name和age那么在二级索引树中,它首先会找到name = zhangsan的第一条记录，然后向后扫描回表,如果有索引下推的话,那么就能够在二级索引中直接排除那些age != 3的数据了 如果没有索引下推的话,那么他在查询的时候是这样的,它会拿到name == 'zhangsan'的第一条数据然后向后查询,然后发现每一条数据都去回表,这样的效率肯定是很慢的 如何设计联合索引? 建立联合索引的时候的字段顺序,对索引效率有很大影响,越靠前的字段被用于索引过滤的概率越高,在实际操作中,要将区分度大的字段排在前面,这样区分度大的字段就越有可能被更多的SQL使用到 所谓区分度,其实也是一个指标,就是某个字段的值的取值范围除于表的总行数就是区分度 比如,性别的区分度就很小,不适合建立索引或者不适合排在联合索引列靠前的位置,而UUID这类字段就比较做索引或者排在联合索引的靠前的位置 如果索引的区分度很小,假设字段的值分布很均匀,那么无论搜索哪个值都可能得到一半的数据,在这种情况下,还不如不用索引,因为MySQL有一个查询优化器,查询优化器发现某个值出现在表中的数据行的百分比很高的时候,它一般会忽略索引,进行全表索引 1select * from tb where status = 1 order by create_time asc; 这个字段要怎么建立联合索引? 最佳的选择是给(status,create_time)建立一个联合索引,因为这样可以避免MySQL数据库发生文件排序,因为在查询的时候,如果只用到status的索引,但是这条语句还要对create_time排序,这时候就会用到文件排序了,所谓文件排序需要对扫描出来的记录进行重排,但是如果我们建立了status,create_time这样的索引,那么在检索出来status = 1的情况,create_time就是天然有序的,因此就不需要文件排序了 什么时候不需要创建索引? 索引的优点是可以极大地提高查询效率,减少IO,但是索引也是有缺点的: 第一点,首先是索引的创建需要占用一定的空间,也就是在原本的数据之上,还需要建立多一层数据,这种创建本身就是一种性能的消耗 第二点,索引的创建和维护要消耗时间,随着数据量的增大而增大 第三点,最主要是索引的动态维护,这是因为索引数据结构要维护自身的有序性,因此一旦插入不符合要求的数据,那么这时候就可能会导致页分裂之类的严重性能问题 什么时候要建立索引? 字段有唯一性的限制的,这时候使用索引比较好,因为索引值是唯一的话,那么就能够提高命中率 经常用于where查询条件的字段,这样能够提高整个表的查询速度,如果查询速度不是一个字段的话,那么就可以建立联合所用 group by或者是order by后接的字段,这样在查询的时候就不需要再去做一次排序了,避免文件排序 什么时候不用创建索引? 对于那些Where、group by、order by里面用不到的字段,索引的价值是快速定位,如果起不到快速定位的字段通常是不需要建立索引的,因为索引会占用物理空间,但是因为乱序插入的页分裂问题可能导致查询效率更慢 对于在表中的那些值区分度小的,这时候不如不要建立索引,在这些情况下,因为MySQL有一个查询优化器,查询优化器发现某个值出现在表的数据行的比例很高的时候,它一般会忽略索引,进行全表扫描 经常更新的字段不用创建索引,因为更新意味着索引在B+Tree中的顺序发生了变化,这时候也有可能导致索引的重建,页分裂的问题 索引优化技巧 前缀索引优化:前缀索引就是使用某个字段中的字符串的前几个字符建立索引,使用前缀索引的好处是可以减少索引的大小,可以增加一个索引列中存储的索引个数,有效提高索引的查询速度,在一些大字符串的字段作为字段的时候,使用前缀索引可以减少索引项的大小,一般来说可以通过设计这样的字符串(前半段具有很强的区分性,后半段随机),这样的话既可以兼顾数据库字段值的安全,也可以充分利用索引 要注意: order by无法使用前缀索引 无法把前缀索引用作是覆盖索引 覆盖索引优化:使用二级索引可以提高查询的灵活性,但是比起主键索引来说,它的回表一直是一个痛点,于是为了减少回表这样的操作,就出现了覆盖索引优化这样的操作,所谓覆盖索引就是说,当你的查询字段在二级索引的树上都存在的话,那么就可以说发生了覆盖索引,这样的话就不需要回表,减少了大量的IO操作 主键索引最好是递增的 每当有一条新的数据插入的时候,分为两种情况: 当插入的数据是处于数据块中间的情况的时候,这时候就需要挪动后面的元素,如果要挪动的元素很多,那么就导致说需要加载很多个数据块,然后将数据重新写入,这样的操作是十分重量级的,然后最终可能导致数据库阻塞掉了 当插入的数据是处于数据块的最后面的情况的时候,这时候不需要挪动后面的元素,只需要将记录插入到最后即可,最坏的情况就是开辟一个新的物理页,然后放入记录即可,不会造成页分裂这样的情况 索引最好设置为NOT NULL的 为了更好的利用索引,索引列要设置为 NOT NULL约束的 第一个原因:索引列中存在NULL就会导致优化器在做索引选择的时候更加复杂,更加难以优化,这是因为NULL的列可能会导致索引、索引统计和值的统计都比较复杂,比如说在进行索引统计的时候,count()将会省略为NULL的行 第二个原因:NULL值是一个没有意义的值,但是它会占用内存空间,所以会带来存储空间的问题,因为InnoDB存储记录的时候,如果表中存在允许为NULL的字段,那么行格式至少会使用1个字节的空间存储NULL值列表 复习:Compact行格式 记录可以分为行头部和行数据体 行头部记录了每一个数据行的元信息 变长字段长度列表 NULL值列表 记录头信息 行数据体就是记录的真实数据,它有三个隐藏字段 row_id:当没有合适的主键的时候,这时候就会启用这个字段 trx_id:修改这条记录的事务ID roll_pointer:回滚指针,用于指向上一条的历史记录,指向的是undo log中的记录 索引什么时候会失效? 索引失效,就是索引没有起到过滤数据的作用,那么什么情况下会发生呢? 可以总结为两种情况,根据索引无法生成搜索区间,对索引的值做了篡改 首先第一种情况,模糊匹配产生的失效问题,首先正常来使用,a%这样的匹配它的搜索区间是[a,b),但是像: %a%,无法形成搜索区间 %a,无法形成搜索区间 第二种情况,对索引列做了计算,函数,类型转换等操作,都会导致索引失效,这是因为索引树中存储的是原始值,你对它做了修改,怎么可能能够按照原来的值来做计算呢? 第三种情况,联合索引没有按照最左匹配原则进行匹配,也就是说没有利用到索引的有序性,此时也无法形成有效的搜索区间,因此导致了索引失效 什么是最左匹配原则 所谓的最左匹配原则,就是需要根据索引在索引树中的有序性排布来确定搜索区间 具体的原理就是,当存在多个索引的时候,如果这多个索引,每个索引在等值的范围内,能够通过其他索引值来判断这个值是否能被过滤，这个就叫做过滤原则 第四种情况,使用了索引,也能够生成正确的搜索区间,但是却因为or这样的字段,导致了额外的搜索区间,从而导致原来的索引扫出来的那个范围没有用上 如何优化SQL? SQL优化可以通过explain关键字来实现,一般来说就是先通过: 12show VARIABLES like &#x27;%slow_query_log%&#x27;;show VARIABLES like &#x27;%log_output%&#x27;; 通过这个指令来看出这哪些SQL的耗时严重,或者是通过开启慢查询日志的方式,然后查询这个日志就能够知道哪个SQL是十分耗时的 然后再通过 1explain SQL; 就能够知道SQL的具体执行情况了,然后我们再根据执行情况来指定优化策略: possible_keys这个说的是这个SQL可能用到哪些索引,然后查看是否存在索引失效现象,重新设计SQL key字段表示实际用到的索引,判断是否使用到了索引 key_len表示索引的长度 rows表示扫描的数据行数 type表示数据的扫描类型 type字段是十分关键的,这是因为这个字段描述了所需数据时使用的扫描方式是什么?常见的扫描类型的执行效率从低到高的顺序为: All(全表扫描) index(全索引扫描) range(索引范围扫描) ref(非唯一索引扫描) eq_ref(唯一索引扫描) const(结果只有一条的主键或者唯一索引的扫描) 详细解释一下: 首先All是性能很差的情况,因为它意味着要扫描全表 index意味着它使用了索引进行全表扫描,这样做的好处是不需要对数据进行排序,甚至如果涉及到回表的话,可能会比全表扫描的开销更大 range表示说使用了索引范围扫描,一般来说使用了&gt; 、&lt;等关键字的时候,就是这种情况了,它的作用是索引起到了过滤一部分数据的作用,但是还是一个范围查询,意味着过滤掉了一批数据之后,还有一次遍历 ref表示了采用了非唯一索引,或者是唯一索引的非唯一性前缀,它虽然使用了索引,但是该索引列的值不是唯一的,这就意味着在查找到这一条数据后需要向后继续顺序查找。 1eq_ref`表示使用了唯一索引,通常使用在多表联查中,比如说用户表,关联条件是两张表的`user_id`是相等的,而且`user_id`是唯一索引,那么使用`EXPLAIN`进行执行计划查看的时候,type就会显示`eq_ref const类型表示使用了主键或者唯一索引与常量值进行比较 extra Using filesort:当查询语句中包含group by或者是order by操作的时候,当无法利用索引的天然有序的特性进行扫描的时候,这时候就可能会通过文件排序,效率很低 Using temporary:使用了临时表保存中间会出现这种情况,比如说子查询,会通过在底层生成临时表的方式来实现,由于临时表是不包含索引的,因此如果数据量一大起来就会导致查询效率低了 Using Index,所需要的数据在索引就可以全部获得,避免了回表操作 数据库范式如何理解? 第一范式:第一范式要求一行中的每个单元都应该要有单一值,而且不能够出现重复,比如说像CS_101这样的设计是不符合第一范式的,第一范式可能带来插入异常,删除异常,更新异常 比如说数据库系统中想要删除一个系的时候,或更新一个系的名称的时候,这时候就可能导致这个与这个系关联的所有列都将迎来一次更新 第二范式:从学术上的角度上来说,第二范式消除了非主属性对码的部分函数依赖,非主属性必须完全依赖于候选键,不能够存在部分依赖,从现象上来看,就是表中的每一个列都是用来描述这个实体的,每一个表都只能够表现一个实体,如果有一列描述了其他的东西,就应该拿掉它,并且放入一张单独的表,比如说学生表 学生表应该要描述学生的个体信息,如果在学生表中还要存储这个学生的选课信息,那么我们就应该要新建一个选课表,然后将学生ID和选课信息加入到一张新的表中,这是因为选课信息描述了一门课,因此不符合第二范式 比如说表ORDERS(order_id,date_customer_name)因为这张表示存储订单了,但是customer_name描述了一名客户,而不是描述一个订单,因此不符合第二范式 如果一个用户订购了多个订单,首先第一个问题就是浪费空间,在这种情况下,每一个订单都会冗余存储订单的客户名称,如果后续还需要添加客户的其他信息,那么就会导致其他的列的更改,因此第二范式将会导致更新异常或者删除异常 第三范式:从学术的角度上来说,第三范式要求表中的所有属性只能由那组关系的候选键来决定,而不能是任何其他的非主属性 比如说有发票表INVOCIES(invoce_total,payment_total,balance) 说明,invoce_total是结余的总量,payment是支付的总量,balance是剩余的 那么在这个表中有一个关系,就是说invoice_total = patment+balance 那么这个将会导致什么问题呢?也就是说当更新payment的时候,意味着需要同时更新balance 从现象来看就是发生了更新异常 表中的列不应该从其他列中派生出来,就好像说payment可以由非主键的invoice_total和balance推断出来一样 如何分析MySQL的死锁问题? 1show engine innodb status; 首先先分下加锁情况,给出的表的情况是这样的: 12345678CREATE TABLE `t_student` ( `id` int NOT NULL, `no` varchar(255) DEFAULT NULL, `name` varchar(255) DEFAULT NULL, `age` int DEFAULT NULL, `score` int DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 在这里面,唯一索引是id,其他的均为非唯一索引,首先分析第一条语句 1update students set score = 100 where id = 25; 由于执行的是update语句,因此会上个锁来防止幻读,由于是唯一索引的等值查询,那么就来分析什么时候会发生幻读的情形: 首先是因为它是唯一索引,因此在这样的情况下,而且数据是不存在的,那么这时候为了防止幻读,因此会上一个间隙锁,也就是上一个(20,30)的间隙锁 1update students set score = 100 where id = 26 首先是因为它是唯一索引,因此在这样的情况下,而且数据是不存在的,那么为了放置幻读,因此会上一个间隙锁,也就是上一个(20,30)的锁 然后执行 1insert into students(id,no,name,age,score) values(25,&#x27;s0025&#x27;,&#x27;sony&#x27;,28,90) 这时候它执行插入,此时因为是插入操作,插入区间是(20,30),这时候事务A就产生了阻塞,这时候就会产生一个插入意向锁 关于插入意向锁的时机,每插入一条新的记录,都需要看一下待插入的记录的下一跳记录上是加了间隙锁,如果已经加了间隙锁,那么这时候就产生一个插入意向锁,然后将锁的状态设置为等待 接着事务B交替执行,然后执行 1insert into students(id,no,name,age,score) values(26,...); 然后这时候它也一样会因为事务A的(20,30)所产生的间隙锁而阻塞 MySQL中有哪些日志? 当执行一条update的语句将会涉及到三个日志,因为更新的过程涉及到并发、持久化等操作 undo log(回滚日志):回滚日志是Innodb实现的,实现了事务中的原子性,主要用于事务回滚和MVCC redo log(重做日志):实现了事务的持久性 bin log(归档日志):是server层的日志,用来做数据备份和主从复制 为什么需要undo log? 当在执行一条增删改的语句的时候,虽然没有使用begin开启事务和commit/rollback来结束事务,但是MySQL将会隐式的开启事务,执行一条语句是否自动提交事务,是由auto commit参数决定,当执行一条update语句的时候也是会使用事务的 它主要是为了实现数据库的崩溃后的恢复,也就是说,当事务执行到一半,发生错误或者数据库崩溃的时候,就可以通过undo log来实现之前所做的操作的撤销,也就是说undo log可以保证原子性 undo log的记录格式通常是这样的: 在插入一条记录的时候,要把这条记录的主键值记录下来,这样在之后回滚的只需要将这个主键值所对应的记录删除掉就可以了 在删除一条记录的时候,要把这条记录的内容都记录下来,这样的话回滚的时候就再把这些内容组成的记录插入到表中就可以了 在更新一条记录的时候,要把被更新的列旧值记录下来,这样的话回滚的时候再把这些值更新为旧值就可以了 不同的操作,需要记录的内容也是不同的,因此不同类型的操作产生的undo log的格式也都是不同的。 一条记录的每一次更新更新操作产生的undo log格式有一个roll_pointer和一个trx_id事务id 通过trx_id可以知道这个记录是哪个事务修改的 通过roll_pointer可以将这些undo log串成一个链表,这个链表就是版本链 undo log还有一个作用,就是可以基于ReadView+undo log实现MVCC的多版本的控制 对于读提交和可重复读隔离级别的事务来说,它们的快照读是通过Read View+undo log来实现的,它们的区别在创建ReadVuew的时机不同 读提交:是在每个select都会生成一个新的ReadView,也意味着事务期间的多次读取同一条数据,前后两次读的数据可能会出现不一致,因为可能这期间另外一个事务修改了该记录,并且提交了事务 可重复读:仅在事务启动的时候开启一个ReadView,然后在这之后的事务执行过程中,一直使用这个ReadView即可 总结:undo log的两大作用有 实现事务的回滚,保障事务的原子性,在事务的处理过程中,如果出现了错误或者需要回滚的时候,MySQL可以利用undo log中的历史数据将数据恢复到事务开始之前的状态 实现MVCC(多版本并发控制)关键因素之一,MVCC是通过ReadView+undo log实现的,undo log为每条记录保存多份历史记录,MySQL在执行快照读的时候,会根据事务执行过程中的Read View来找到哪些记录是可见的 undo log是如何刷盘的? undo log在MySQL中存储是以Undo页面的方式存储的,既然是物理页面,那么它当然可以通过redo log来实现,这个Undo页面是存储在buffer pool中的,对undo页面的修改都会持久化到redo log中,redo log每秒都会刷盘。 什么是buffer pool MySQL中的数据都存储在磁盘中的,当我们需要更新一条数据的时候,得先从磁盘读取该记录,然后在内存中修改这条记录,那么修改完这条记录后是选择直接写回磁盘?还是缓存到一个读写速度较快的区域? MySQL的性质决定了它是一个写操作比较多的RMDBS,因此在这样的情况下,如果每次写入都需要将数据刷回磁盘,意味着频繁的IO操作,这样的话性能必然是很差的 因此最终设计了一个Buffer Pool,这个Buffer Pool暂时存储了从磁盘上来的数据,它的设计思想我认为就像一个虚拟内存的技术,而且从Linux的角度上来看,Buffer Pool也是基于虚拟内存技术实现的 在MySQL启动的时候,可以看到buffer Pool的内存占用是0,只有在后续触发缺页中断的时候,才会将物理块缓存到Buffer Pool中 当读取数据的时候,如果数据在BufferPool中,那么客户端就会直接读取BufferPool中的数据,否则才会触发缺页中断 当修改数据的时候,如果数据存在于BufferPool中,那么就直接修改BufferPool中的数据,然后将其页设置为脏页,该页的内存数据和磁盘上的数据已经不一致了,为了减少磁盘IO,不会立即将脏页刷回磁盘,后续由后台线程选择一个合适的时机将脏页写回磁盘 BufferPool缓存了什么? 它实际上存储了从磁盘中加载的数据,在MySQL启动的时候,InnoDB会为BufferPool申请一篇连续的内存空间,然后按照默认的16kb的大小划分出一个个的页,BufferPool中的页就叫做缓存页,此时这些缓存页都是空闲的,之后随着程序的运行,才会有磁盘上的页被缓存到BufferPool中 BufferPool缓存的是数据库中存储数据的物理页,BufferPool除了缓存索引页和数据页 还包括有Undo页,插入缓存,自适应哈希索引,锁信息等 Undo页面记录的Undo log的具体信息 查询一条记录,就只需要缓冲一条记录吗?当我们查询一条记录的时候,InnoDB是会将整个页的数据加载到BufferPool中的,将页加载BufferPool后,再通过页里的页目录去定位到某条具体的面记录 为什么需要redo log? Buffer Pool确实提高了读写效率,但是Buffer Pool是基于内存的,如果一旦在Buffer Pool中的数据没有刷盘之前产生了数据库崩溃,那么这时候损失就会很惨重了,为了防止这样的问题发生,于是就当有记录需要更新的时候,InnoDB引擎就会先更新内存,然后将这个数据页标记为脏页,然后对这个页的修改以redo log的形式持久化下来,这时候更新就算完成了 这个技术就叫做WAL技术,就是在实际写操作之前先写日志,在合适的时机执行这些日志 什么是redo log redo log是物理日志,记录某个数据页做了什么样的修改,比如说对XXX表空间中的YYY数据页ZZZ偏移量做了AAA更新,每当执行一个事务的就会产这样的一条日志,在事务提交的时候,只需要将redo log持久化到磁盘即可,可以不需要将缓存到BufferPool中的脏页数据持久化到磁盘 修改了Undo页面,需要记录redo log吗 需要,这是因为Undo页面本质上也算一个物理页,因此对物理页做修改,需要将被更新的列的旧值记下来,也就是要生成一条undo log,undo log会写入到BufferPool中的Undo页面 事务提交之前发生了崩溃,重启后会通过undo log回滚事务,事务提交后发生了崩溃,重启后会通过redo log恢复事务 redo log要写到磁盘,数据也要写到磁盘上,为什么要多此一举? 这是因为写入redo log的方式使用的是追加写,也就是说磁盘操作是顺序写,而随机写则是需要先查找到写的位置,才能将记录写入到磁盘,顺序写通常来说只需要一次磁盘寻道,而随机写几乎每一次都需要磁盘寻道,这是因为MySQL的写操作并不是马上更新到写磁盘上的,而是先记录到日志上,然后在合适的时间内更新到磁盘上 实现了事务的持久性,让MySQL有崩溃后恢复的能力,能够保证MySQL在任何时候突然崩溃,重启后那些数据都不会丢失 将写操作从随机写变成了顺序写,提升了MySQL写入磁盘的能力 redo log也是写一条记录然后刷一条记录回磁盘的吗? 不是的,实际上在执行一个事务的过程中,产生的redo log也不是立即写入磁盘的,因为这样会产生大量的IO操作,所以redo log也有自己的缓存,redo log buffer,每当产生一条redo log的时候,就会先写入到redo log buffer中,后续持久到磁盘中 刷盘时机? MySQL正常关闭的时候,这时候会将redo log buffer中内容全部写入到磁盘中 当redo log buffer中记录的写入量大于redo log buffer内存空间的隔一般的时候 InnoDB的后台线程每隔1s,将redo log buffer持久化到磁盘 每次事务提交的时候,都会将缓存在redo log buffer中的redo log直接持久化到磁盘 当innodb_flush_log_at_trx_commit有不同的参数的时候,会触发不同的刷盘策略 当参数为0的时候,这时候事务提交不会主动触发写入磁盘的事件,后台线程每隔1s,就会通过write(),将数据写入到操作系统内核中,然后调用fsync(),MySQL进程的崩溃会导致上一秒钟的所有事务的数据的丢失 当参数为1的时候,表示每次事务提交的时候,都将缓存到redo log buffer中的redo log直接持久化到磁盘 当参数为2的时候,将redo log buffer中的数据持久化到pageCache中,也就是写入到了操作系统内核,每隔1s调用fsync() redo log文件写满了怎么办? 默认情况下,InnoDB存储引擎下有一个重做日志文件组,这两个redo日志文件ib_logfile0和ib_logfile1,重做日志是以循环写的方式工作的,从头开始写,写到末尾就又回到开头,相当于一个环形 redo log是为了防止buffer Pool中的脏页丢失而设计的,如果buffer pool中的脏页被刷回到了磁盘中的话,那么此时redo log中的记录也就没用了,这时候擦除这些记录,以便腾出空间来使用 redo log是循环写的方式,相当于一个环形,InnoDB用write pos表示redo log当前写的位置,而check point到write pos表示还没有持久到磁盘中的脏页 而之前的就都可以刷新掉了 如果write pos == checkpoint的话,那么就意味着redo log文件满了,这时候MySQL就不能够再执行新的更新操作了,也就是说MySQL会被阻塞。 为什么需要bin log? bin log是Server层的日志,这意味着不仅InnoDb有,其他存储引擎也有。 它的特点是这样的:在事务提交的时候,会将这个事务执行过程中产生的所有binlog统一写入到binlog文件中 为什么有了binlog还要有redo log? 这是因为最开始并没有InnoDB引擎,只有MyISAM,而binlog设计之初并没有crash-safe的能力,binlog日志只能够用于归档,如果添加上check point等机制,实际上bin log可以实现其他日志的功能 redo log和bin log有什么区别? 适用对象不同: bin log是MySQL的Server层实现的日志,所有存储引擎可以使用 redo log是InnoDB存储引擎实现的日志 文件格式不同: binlog有三种格式类型,分别是STATEMENT、ROW、MIXED STATEMENT:逻辑归档日志,有动态函数的问题 ROW:记录物理数据日志,存储的是具体的数值 MIXED:包含了STATEMENT和ROW,根据具体情况使用 redo log物理日志,记录的是某个数据页的操作 写入的操作不同 binlog是追加写,写满了一个文件之后,就创建一个新的文件继续写,不会覆盖之前的日志 redo log是循环写,日志空间大小是固定,全部写满就从头开始,保存未被刷入磁盘的脏页日志 主从复制的实现流程 MySQL的主从复制依赖于binlog,也就是说记录MySQL上的所有变化并以二进制的形式保存在磁盘上,复制的过程就是将binlog中的数据从主库传送到从库上 写入binlog:主库写入binlog日志,提交事务,更新本地缓存 同步binlog:通过dump线程,将binlog发送到从库上,然后从库上的IO线程读取dump线程发来的日志信息 回放binlog:从库中的SQL线程读取relay log,然后执行 bin log什么时候刷盘 在事务提交的时候,执行器把binlogcache中的完整事务写入到binlog中 当0 的时候,表示每次提交事务都只write,不fsync,后续操作由操作系统决定何时将数据持久化到磁盘中 当1的时候,表示每次提交事务都会write,然后马上执行fsync 当N的时候,表示每次提交事务都write,但是累计N个事务才fsync 执行一条update语句会发生什么? 首先是通过链接器,验证你的权限和管理你的连接 然后是通过分析器,经过词法分析和语法分析,判断你的SQL是否正确以及知道你的SQL想要干什么 然后是通过是优化器,通过优化器就知道在知道怎么操作 然后就生是通过执行器: 执行器负责具体执行,它会执行优化器中解析出来的命令,然后交给底层的存储引擎,通过主键索引获取id= 1的这一条记录 如果数据本身就在bufferpool的话,那么就直接返回 如果数据不在bufferpool的话,那么就需要从磁盘中调入 执行器在得到聚簇索引记录后,会看一下更新前的数据和更新后的数据是否是一致的,如果是一致的话,那么就直接返回,否则进入更新流程 开启事务,InnoDB层更新记录前,首先要记录相应的undo log,因为这是更新操作,需要记录一个undo log,然后这个undo log会写入到buffer Pool中的undo页面中,执行完后写入对应的redo log InnoDB层开始记录,会先更新内存,然后将记录写入到redo log中,这时候更新就算完成了,为了减少磁盘IO,不会立即将脏页写入到磁盘中,而是由后台选择一个合适的时机将脏页写入到磁盘中,这就是WAL技术","categories":[{"name":"题库","slug":"题库","permalink":"http://kaillliu.github.io/categories/%E9%A2%98%E5%BA%93/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://kaillliu.github.io/tags/Java/"},{"name":"面试题","slug":"面试题","permalink":"http://kaillliu.github.io/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"name":"题库","slug":"题库","permalink":"http://kaillliu.github.io/tags/%E9%A2%98%E5%BA%93/"}]},{"title":"JVM 面试题总结回顾","slug":"JVM 面试题回顾","date":"2023-08-12T07:00:00.000Z","updated":"2023-09-08T04:18:35.029Z","comments":true,"path":"2023/08/12/JVM 面试题回顾/","link":"","permalink":"http://kaillliu.github.io/2023/08/12/JVM%20%E9%9D%A2%E8%AF%95%E9%A2%98%E5%9B%9E%E9%A1%BE/","excerpt":"","text":"堆和栈有什么区别? 首先我们从操作系统的角度上来看,堆和栈在操作系统中的分布: 假设我们的地址空间是0x0~0xffff,那么在这个地址空间中,堆和栈的分配逻辑是不同的 堆的内存分配是从小地址到大地址,也就是从0x0向0xfff申请内存分配 栈的内存分配是从大地址到小地址分配,也就是0xfff向0x0申请内存分配 然后堆和栈中间那些还没有使用的内存,就是可以被申请的 那么栈是如何工作的呢? 如上图所示,假设在执行这一段函数,那么它会先将a压栈,将b压栈,然后通过操作数寄存器将a+b的结果压栈,在这个过程中,栈顶指针总是指向下一个写入的位置,这也就是说,栈顶指针指向的位置总是可以写 入的,是还没有申请空间的,然后当要使用这些变量的时候,就会通过CPU上的寄存器,比如说rbp,esp等寄存器的值,加上一个偏移量,就能够得到栈中变量的位置了 新创建的对象的死亡率高,这意味着这些对象容易频繁地被回收,从而频繁的导致内存整理,而生存下来的对象因为不容易被回收,从而内存整理的频率会更低一些,为了避免在整理内存的过程中,去导致那些存活下来的对象因为新创建的对象的内存整理而频繁移动,因此一个好的办法就是设置一个分区,将对象的存活情况作为指标,界定这些对象应该要放在哪个区域中,从而使得内存整理频率高的分区,能够快速执行内存整理,而不需要惊动那些不需要进行频繁回收的对象 那么这种机制就是一种分代的机制,它将对象分成了若干个分区 新创建的对象被分配到新生代、伊甸园区,这个区域中的对象不是很长命,因此会涉及到频繁的内存整理,因为这个分区中的对象比较短命,因此通常来说他们的内存整理效率比较高 而那些长命的对象所在的对象的内存整理频率不高,因此说没必要将长命对象和短命对象放在一起,短命对象被回收,移动的是整个内存区域中的对象,如果把他们放在一起,那么就会导致长命的也跟着一起移动 如图所示,Java会将新建的对象放入到Eden中,当Eden中触发MinorGC的时候,它此时并不会直接在Eden执行整理,而是将当前的对象复制到Survivor中, 1-XX:SurvivorRatio=8(默认)`,也就说`Eden:Survior = 8 :1 那么Survior的对象去哪里呢? 它会进入到一个称为是老年代的地方,那么如何才能进入到老年代呢?这设计到分代分配和分代回收的机制,详细描述一下这个流程: 首先对象新建之后,就会被分配到Eden,然后当Eden满的时候,就会将对象复制到Survivor0上,此时每次Eden满都会复制到Survior0上,然后当Survivor0满的时候,就会对Survivor0上的对象进行清除,然后将Survivor0上的存活对象复制到Survivor1上,在这个过程就会对存活的对象的头部中的age+1,最终实现了一个老年代的晋升 Java的堆分成哪些部分? 从对象的角度来讲,对象的实例数据是存储在堆中的,为了提高内存分配/回收的效率,不同的虚拟机对堆存储的数据有不同的规定,比如说HotSpot中原来是将对象的元数据,比如说类信息,CodeCache都存储在堆中的永久代分区中,但是在后面使用了元空间,将这个空间从堆中抽离出来了 HotSpot为了提高内存的分配/回收效率,那么它堆的内存分成了以下这几个部分 Eden区:当对象被新建的时候,就会将这个对象分配到这个区域上 S1/S0区:当Eden发生GC的时候,就会将存活的对象复制到S1/S0上,当一个区(S0/S1)发生的时候,就会将对象来回复制,每复制一次,就会使得对象头部的分代年龄字段+1,最终达到一个阈值之后就会晋升到老年代 老年代:存储的是比较稳定的对象,只有当老年代的空间不足的时候才会触发GC 常见的垃圾收集器 Serial Collector(串行垃圾收集器) 它是一个单线程的垃圾收集器,具体的执行流程: 当触发GC的时候,首先执行Mark,就会触发一个STW,然后基于根追踪+双色标记法来判断对象的存活情况,假设黑色是存活的,白色的是不可达的对象,然后在STW期间就会将白色的对象给sweep掉 为什么串行收集器不使用三色标记法？ 这是因为串行收集器的Mark&amp;&amp;sweep是一个原子性的动作,也就是说中间不会产生Mutation,因此这样的话就不会出现三色标记法中引入的那个不确定标记,只需要在STW期间完成Mark&amp;&amp;sweep即可 使用场景是: 吞吐量小,内存回收工作量不大 容忍延迟,不在意卡顿 单核,内存小:0~100M 1-XX:+UseSerialIGC 并行垃圾收集器 并行垃圾收集器是串行垃圾收集器的升级版,它的升级主要体现在它支持多线程垃圾回收,它尽最大努力提供最大的吞吐量,它的执行流程:首先当遇到GC的时候,就会直接触发STW,然后在STW期间完成Mark&amp;Sweep的操作,那么它的吞吐量是要高于串行的吞吐量的,因为在多核环境下,两个线程来处理GC任务要更快一些 它的使用场景是吞吐量的要求要高于延迟的要求的 1-XX:+UseParalleIGC 并发标记收集垃圾收集器(CMS) 这个垃圾收集器优化的宗旨主要是将STW的时间降到最低,Mark的阶段并不是STW的,从而提高了吞吐量,当所有的Mark操作完成了之后,才会执行Sweep Compact Copy,具体的执行流程: (1)初始标记过程,相当于一个初始化,仅标记一下GCRoots能够直接关联的对象,并且将这些对象加入到不确定状态的集合(灰色集合), (2)并发标记过程,执行三色标记算法,具体的过程就是:从灰色集合中取出元素,然后将这个元素标记为黑色(原本灰色),然后将取出的元素相连的白色元素放入到灰色集合中,反复这个过程,直到所有元素都被遍历过了一次 (3)remark阶段,由于在标记和mark之间存在一个mutation,因此为了避免诸如在之前标记好的要删除的元素突然产生了关联,因此在这个过程,就要执行remark,这个过程相对来说比较短,为了保证程序的正确性,因此使用了STW,暂停其他线程,然后遍历对象,如果对象有灰色的,那么就继续扫描它的子节点。 (4)在STW的状态下,将标记过的对象删除 问题:在Mark期间发生了修改,到底是如何操作的? 条件1： 白色节点被黑色节点引用(白色节点被挂在了黑色节点下，须知黑色节点是不会重新扫描的) 条件2： 灰色节点和可达关系的白色对象之间的应用遭到了破坏(删除灰白引用) 增量更新：所谓的增量就是在并发标记过程中,把复制的这种新增的引用,用一个集合存起来,在重新标记的时候,就会找到集合中的引用,然后重新去扫描,将源头标记为灰色 写屏障:写屏障是增量更新的实现基础,写屏障具体来说就是在赋值操作的前面加一个方法,赋值的后面做一些操作 跨带引用会带来什么问题? 比如说我们要对年轻代进行GC,可以断定NSPQ都是存活的,因此可以标记,如果我们不对老年代中的对象进行分析的话,就不知道年轻代的对象V还有被老年代引用的,因此可以看出,当存在跨代引用的时候,需要对其他分区的对象也进行检索,然而为了新生代的GC而去全局遍历老年代,这种做法的效率是很低的,为了避免这种老年代的性能开销,通常的分代垃圾回收期会引入一种记忆集的技术,简单来说,记忆集就是同来记录跨代引用的表 在拥有记忆集的情况下,我们就可以知道年轻代中的哪些对象存在跨带引用了 在分代GC下的GC分类 MinorGC:当新生代无法分配更多的JVM内存了,那么就会触发MinorGC,这个GC会把新生代中的对象进行一次标记,问题:假设这个新生代的要被回收了,而且老年代中有一个对象,仅有这个新生代对象的引用?这时候要不要回收老年代中的这个对象? MajorGC:老年代的垃圾回收 FullGC:MinorGC和MajorGC同时发生 什么是浮动垃圾? 在一次周期有一些垃圾本来要被回收的,但是在本次标记失败了,只能在下一个周期中删除这些垃圾 G1垃圾收集器 它的目标是解决大内存的问题,主要的解决思路就是将大内存,也就是原本的伊甸园区/S区/老年代的这些大内存区域,将这些区域再次划分成一个个的小区域,那么就彻底了解决大内存的问题,每次执行垃圾回收,只需要使用一个线程去扫描这一个个小的区域,就能够完成垃圾回收了。 执行流程: 但是比较复杂,里面的对象还有一些引用的关系,比如说一个小区域引用了另外一个小区域中的对象,一个小区域引用了另外一个大区域中的对象 解释一下常见的垃圾收集器,以及区别在哪里 如果对延迟要求高,可以考虑哪种GC,优先考虑ZGC,CMS等 内存空间很大的情况下推荐哪种GC?考虑G1 ZGC收集器 这个收集器的特点是对延迟的容忍度很低,它的最大延迟只能是几个ms,暂停的时间不会随着堆带下,存活的对象数目的增加而增加,通常来说内存大小的适应度约是8MB~16TB JVM调试工具实操 JMeter:测量性能,一般可以用来做QPS,压力测试等 线程组: Ramp-up:意思说在几秒内到达线程总数 Loop Count:每个用户的请求次数 采样器:可以增加参数等 监听器:Graph Result 123ServerSocker serverSocket = new ServerSocker(8080);//它本质上就是一个文件,这个文件中存储了所有客户端的连接描述符也就是Client fd//所有连接过来的连接都被存储在了这个文件中了 jps 可以通过jps来查看当前系统的Java进程,如何实现远程监控? jstatd 2 &gt; &amp;1 &gt; log.txt &amp;在后台运行,在后台运行的守护进程 1jps 192.168.132.128 可以通过shell脚本,提前输入各个节点的IP地址,如何执行定时的监控 jstat JVM统计监控工具,一般来说可以看GC的维度,class的维度,可以使用gcutils来查看相关的信息 1jstat -gcutil PID YGC:产生YGC的次数 YGCT:YGC所消耗的时间 FGC:产生FullGC的次数 FGCT:FullGC消耗的时间 CCS:压缩的类,这是说在64位的机器上,因为不需要使用过大的空间来存储这个类 12345jcmd PID GC.heap_info# 可以看到具体的GC内容,比如说每个分区的使用情况# committed:JVM进程真实使用的内存# reverved:JVM进程预定的内存大小,类似于一个虚拟内存,在具体使用的时候才申请# 堆的内存是真实使用的,而不是预定的虚拟内存空间 jmap PID dump:整个Java进程的内存情况 clstats:打印类加载器的信息 jhat dump之后的文件 jinfo:查看和修改虚拟机的配置,可以远程操作,它可以避免Java进程的重启而直接修改,注意并不是所有的参数都能够实时更改 jstack:打印Java的Stack,远程调试就是基于这个工具实现的 jconsole:图形界面,然后选择进程,是一个实时的监控,实际上是基于其他工具的具体数据来实现的 字节码实战 将.java文件编译为.class文件,这个过程中,.class文件还是存在磁盘上的 1javac A.java 反汇编指令查看 1javap -c A.class &gt;&gt; A.txt 指令一般来说按照功能可以分为 invoke(调用函数) 123456789 - invokespecial:调用构造函数,如super(),init(),private - invokedynamic,临时生成的程序,`duck typing` - invokestatic - invokevirtual:虚函数,可以重写的函数,除了static、private、final修饰之外的方法 - invokeinterface- ``` load(将参数压栈) ,将某个对象压入栈中 - load variable =&gt; stack - getXXX store(存储)=&gt;ref =&gt; local variable,比如说将已知的值写入到其他地方上 计算 =&gt; add/mul/div/sub 跳转指令 =&gt; jsr/jsr_w Java对象在内存中的结构 Object是如何初始化的(生命周期) (1)类加载:初始化的过程,首先会先将.java文件通过javac指令编译成.class文件,注意此时.class文件还是在磁盘上的,然后经过ClassLoader就会将.class中的内容转换为bytecode,存储到磁盘中。此时类因为是首次加载的,因此就会执行static静态代码块,那么为什么会触发初始化呢?这是因为有线程new/访问静态成员/loader加载这些类了,就会导致初始化,但是这些类在被初始化过一次之后,就不会再执行初始化了,经过这个状态之后就是一个loaded了 这个过程是线程安全的吗?是线程安全的,这个过程是基于单线程来完成的 (2)对象的创建过程,第一步,读取类信息,通过类信息确定要给对象分配多大的内存空间,也就是申请内存空间,第二步,执行构造函数,也就是一个&lt;init&gt;,注意,在Java中是允许部分初始化的这种情况出现的,经过这个过程就是一个create了 这个过程是线程安全的吗?不是线程安全的,它允许部分初始化,也就是说它允许一种情况,就是提前将引用返回了,但是初始化工作没有完成 (3)对象使用中,在生命周期中是这样的被使用=&gt;不可见=&gt;不可达 被使用:就是通过规定的RootSet就可以找到这个对象,而且这个对象是真真切切的被使用了的 泄漏:就是通过RootSet可以找到,但是没有被使用 不可达:通过RootSet不可以找到 (4)对象被回收,标记=&gt;执行finalize=&gt;回收内存空间,这一步的具体过程与垃圾回收算法有关 Object在内存中是如何存储的 在HotSpot的Object的格式如下: Mark Word(ObjectHeader) klassOop(ObjectHeader)普通对象指针 arraylength(ObjecterHeader),数组特有的字段 实例数据(Instance data) padding MarkWord hashcode:对象的hashcode age:分代年龄 标志位(3bit) 123456789 - unlocked(无锁) - light-weight-locked(轻量级锁) - heavy-weight-locked(重量级锁) - marked for gc(标记了GC) - biased(偏向锁)- ``` Lock Record Address - 轻量级锁(指向栈中的锁记录) - 检查MarkWord是否指向当前线程的栈 Monitor Address Forwarding Address:gc自己使用,在gc遍历的时候可以用这个 kclass:类信息指针 padding:将对象补齐为8个字节的倍数 总结: 它有严格的定义 不同的虚拟机可能会不同 分成头部和数据,可能还有padding 空Object有多大? 16个字节。在64位下,MarkWord有8个Byte,kclassPointer有8个Byte,因此一共是16 ClassLoader是什么 ClassLoader是一个运行时组件,它能够将.class文件(磁盘)转成bytecode(内存),然后在运行时将bytecode交给执行引擎进行存储 那么在这个过程中,ClassLoader充当一个加载器的角色,也就是将.class文件转换为在执行过程需要用到的bytecode 只有一个ClassLoader够不够用? 首先要了解这个问题,.class的来源是多样的,也就是说可以来源于本地文件,可以来源于内存,来源于网络,来源于其他jar包,正是因为这些.class文件的来源多样,那么就意味着处理这些文件可能具有不同的策略 不一样的缓存策略:比如说要将.class文件存储在哪里?如果在磁盘上怎么处理,如果在网卡的缓冲区中,怎么处理,如果想要从本地文件中读取.class,那么直接打开IO流即可,如果想要从远程读取.class,那么可能还要建立一个TCP/Socket来进行文件的传输 不一样的安全策略:比如说在第三方的jar包中,开发者不希望使用者看到里面的实现细节,那么如何来实现呢? 不一样的统计策略:这个范围比较广泛,主要说的是在加载不同来源的.class的统计逻辑可能是不一样的 不一样的代理策略:就是说类中的特定字段信息,可以被classLoader进行修改,比如说,在某段字节码之前,夹带私货,在那之前添加一段代码 软件设计到遇到多样化的需求的时候,怎么办? 考虑继承、封装、组合,比如说I/O Stream,I/O本质上就是从流中读取字节,但是为了适应不同的需求,比如说从文件中读取,从远程网络读取,读取字符等这些需求,JDK基于I/O Stream实现了不同的流,然后通过这些不同的流来执行相关的代码 版本问题 问题:比如说有一个类A1.0版本依赖了JDK1.7的HashMap,然后类1.1依赖了JDK1.8的HashMap,那么在使用的时候,它的解决思路可以是这样的:就是类A1.0使用一个Loader,由这个Loader去完成类A1.0所需要所有类的加载,然后类1.1也使用一个Loader,然后由这个Loader去完成类1.1所有的类的加载 这样做的好处是边界会很清晰,也就是说能够确保一个Loader中加载类不会和第二个Loaer加载的类冲突掉 但是有个缺点就是相同的类会导致多次加载 在这种情况下,提出了一种树状的Loader,也就是设计一个顶级Loader,然后其他的Loader都基于这个Loader实现基础类的加载 如下图所示,在这个基础上实现不同的ClassLoader之间的依赖传递,这个设计让Foo和Bar之间是不可见的,但是它可以让ClassLoader中的东西可见,Bar也可以让这个ClassLoader中的东西可见 简单来说,就是对于一些通用的类,交给它的父级Loader去加载,设置为可见的 加载之后,会在ClassLoader内部中设置一个缓存,代表这个类已经被加载过了 Java类加载模型? 树状关系 Root Class Loader Left Class Loader(边缘加载器,比如说加载第三方的jar包等) 委托模型 子Class Loader委托父Class Loader完成工作 缓存设置在父节点 ClassLoader BootStrap Class Loader:加载Java的核心类,比如说JDK中的类 Extensions Class Loader:例如JRE目录下的lib/ext Application Class Loader:classpth Custom Class Loader:用户自定义 简单来说,双亲委派模型可以用下面的实例来进行理解 假设用户指定了一个类加载器,然后试图加载一个类,那么首先用户类加载器会检查自己是否已经加载过了这个类,如果已经加载过了,那么就直接返回加载成功。 如果没有加载过,那么就会价交给系统类加载器,这个加载器会检查自己是否已经加载过了这个类,如果没有加载,那么继续传递依赖上去,直到到达根加载器 然后根加载器就会试图加载这个类,如果根加载失败了,那么就会向下传递任务,直到加载成功或者抛出异常 如何来打破双亲委派模型 1234567891011121314class BinLoader extends ClassLoader&#123; @Override protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; if(name == &quot;hello.go&quot;)&#123; try&#123; //自己生成一个类 return defineClass(&quot;hello&quot;,new byte[],0,100); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125; &#125; super.findClass(name); &#125;&#125; 自定义Loader,并且重写findClass() JVM 对运行时数据区的理解 对运行时数据区的理解,重点是要放在运行时这个字眼进行理解,由于各个虚拟机之间的实现不同,这里我以最熟悉的HotSpot虚拟机作为一个切入点进行理解 假设JVM进程在运行过程中,执行了一条语句new A(),假设A从来没有被加载过: 首先是将A.java文件编译为A.class文件,此时.class文件存储在磁盘上 接着就是.class文件ClassLoadSystem转换为byteCode,然后存储到内存中,注意这个bytecode其实就是机器能够执行运行的机器码,又称为opCode,这个byteCode会被存储到JVM进程中的一个称为元空间的区域 接着完成对象的初始化,此时一般来说会完成两件事情,完成对象A()的初始化①根据对象A的类信息为对象A分配内存②执行构造函数,注意,此时有可能有一种情况,就是说有可能提前返回这个对象的内存引用地址,而此时的构造函数并没有完成,在调用new A()的栈上分配一个引用,这个引用就是实际对象在堆上的地址 上面这个过程涉及到两个区域,第一个区域是调用函数所使用的虚拟机栈,第二个区域就是分配对象内存的堆区域,虚拟机栈区域是私有的,每个线程都有一个自己的栈,这样做的意义是在上下文切换调度的时候,防止各个线程之间互相篡改栈中的数据 接着构造完毕对象后,之前的虚拟机栈就会继续执行,执行过程需要依赖程序计数器,这个程序计数器记录的是下一条指令的地址 注意,Java语言它本身并没有执行程序的权限,也就是说它无法直接使用CPU的资源,而是通过操作系统给出的系统调用函数,通过系统调用函数来执行相关的程序,那么底层的程序在运行也是需要一定的内存区域的,这各区域就称之为本地方法区,也就叫做Nativa Memory,在这个区域中存储了有C/C++语言的堆或者栈 直接内存区域:这个区域比较特殊,通常用来高速传输数据,减少拷贝次数,比如说在Java通过Socket完成数据的传输,那么在这个过程中,网卡缓冲区中的数据通常会通过DMA设备,不需要CPU的干预,通过窃取总线周期,将数据传送到操作系统内核缓冲区中,然后当JVM进程需要使用这个内存的时候,它会有一个映射指针,通过这个指针就能够直接访问到这个内存了 堆和栈的本质区别 栈是辅助程序执行不可或缺的工具,它的功能主要有: (1)作为函数执行的备忘录(局部变量表),在函数执行过程中,通常会有大量的变量,当需要使用这些变量的时候,就会将这些变量压栈,然后通过rbp、esp等CPU寄存器的值来存储栈顶指针,然后通过这个指针来获取相关的值,比如说有 123int a = 2;int b = 3;int c = a+b; 这时候就可以看到栈中就有5 3 2 这样顺序压下来的栈了 (2)作为函数执行的活动记录,栈中有一个很重要的概念是栈帧,通过栈帧,记录一次函数执行的过程,比如说在即将调用一次函数的时候,首先会将函数返回地址压栈,接着申请一块空间为返回值留空间,在函数执行完毕后就会将返回地址弹出,作为jmp的操作数了 从上面可以看出,栈是用来辅助函数执行用的,没有栈,函数就无法运行,而函数脱离了堆实际上也是可以运行的,但是通常我们会有需求说要让线程可以共享一块区域,那么这一块区域就是堆内存了 方法区和永久代的关系 首先要说的是什么是方法区,在一个.class文件ClassLoader加载之后,这个.class中的信息,例如类名,方法名,字段信息,静态变量、以及JIT编译器编译后产生的OpCode等信息都需要被存储到一个全局可见的位置,这个位置就是方法区 那么在虚拟机规范中,方法区它是一个概念,具体的实现是交给了具体的虚拟机,以HotSpot为例,它的实现有方法区和元空间,它会将解析后的信息存储到元空间/永久代中 问题:为什么要将永久代替换为元空间? 这和堆内存通过年龄分代进行划分的道理是一样的,在过去,如果触发了老年代的垃圾回收,那么也就会触发永久代的垃圾回收,由于永久代中的对象的生命周期远远长于老年代的生命周期,如果每次触发老年代的GC都回去遍历永久代的情况,那么就会极大的降低效率,从这个角度来说: (1)为了提高GC的效率,根据对象数据的生命周期,更能够能体现分代机制的优势 (2)对于一些常量,这些常量通常来说不会被GC,没有必要将其纳入堆中,受堆的管控 (3)对于一些例如字符串这样的对象,由于会被大量使用,因此最好定期做GC 如何调整元空间的大小? 1-XX : MaxMetaspacesize:设置最大的元空间的大小 JVM常量池 1常量池 == Class常量池`,`.java文件被编译成.class`文件,Class文件除了包含类的版本,字段,方法,接口等描述信息之外,还有一项就是常量池,常量池是当`Class`文件被Java虚拟机加载进来后放在方法区各种`字面量`和`符号引用 字面量:Java语言层面常量的概念,可以理解为魔法值,比如说1(基本数据类型的值),”haha”(文本字符串),声明为final的常量值 符号引用:类的结构和完全限定名,类符号引用,字段符号引用,方法符号引用,接口方法的引用 运行时常量池是什么? 运行时常量池是方法区中的一部分,运行时常量池是当.class文件被加载到内存后,Java虚拟机会将Class文件常量池中的内容转移到运行时常量池中(运行时常量也是每个类都有一个),在程序的执行过程中,如果产生了常量,那么就有可能将文件常量池中的值放入到运行时常量池 什么是字符串常量池? 字符串常量池又被称为是字符串池,String Pool,JVM为了提升性能和减少内存的开销,避免字符串的重复创建,维护了一块特殊的内存空间,这个空间由String类来进行维护 说说原理吧,由于Java底层实际上是C++,因此它的底层是一个叫做stringTable.cpp的东西,这个东西其实就是一个HashSet,这个stringTable保存的是这个字符串对象的引用,这个引用是一个指针,指向的是堆中的字符串对象，JDK1.8版本的字符串常量池中存储的是字符串对象以及字符串常量值 在JDK1.7之前,字符串常量放在永久代中,在1.7之后,字符串常量和静态变量被移动到了堆中 为什么?这是因为永久代(方法区)的GC回收效率太低了,只有在整堆收集的才会被执行GC,而Java的字符串通常来说也是朝生夕灭的,将这些对象放在堆中,才能被GC执行引擎管辖,否则的话就会在内存中堆积大量没有使用的字符串 123String s1 = &quot;abc&quot;;String s2 = &quot;abc&quot;;s1 == s2? 结论:它输出的是true,采用字面值创建一个字符串的时候,JVM首先去字符串池中查找是否有abc这个对象,如果没有这个对象,那么就会在字符串池中缓存这个abc对象,然后将这个abc的引用对象返回给s1 接着s2的赋值也是如此,它首先回去字符串串池中查找是否有abc这个对象,如果有,那么就直接返回这个引用 由于引用地址相同,因此直接返回true,那么创建了几个对象呢?创建了一个对象 123String s1 = new String(&quot;abc&quot;);String s2 = new String(&quot;abc&quot;);s1 == s2? 结论:首先我们记住,使用new,会在堆上产生一个新的字符串对象 首先第一句,JVM首先会去字符串常量池中看有没有abc这个对象,如果没有则生成并且缓存,否则啥也不干,然后在堆上生成一个值为abc的对象,然后执行第二句,也是在堆上生成一个值为abc的对象 总之,生成了三个对象 关于intern()方法 一个初始化为空的字符串池,它由String类独自维护,当调用intern()的时候,如果池中已经包含了一个等于此String对象的字符串的时候,那么就直接返回池中的字符串,否则就将这个String添加到池中,然后返回这个池中的对象的引用 Java对象的创建过程 12A a = new A();A aa = new A(); 执行这两条语句,会发生什么? 执行第一条语句 这是类A被第一次加载到JVM中,要执行下面的流程 (1)类加载流程:当虚拟机遇到一条new指令后,首先会先去检查这个指令的参数是否能够在常量池中定位这个符号的引用,如果缺失了,那么就会触发类的加载流程 (2)对象的内存分配,对象的内存分配通常来说会有两种风格,指针碰撞风格和空闲列表风格 指针碰撞风格:常见于堆内存被划分为了规整的区域,这种分配方式会保存一个边界指针,这个边界指针指向了还没有分配的区域和已经分配的区域的边界,每次只要指针向后边移动相关的内存偏移即可,通常用于标记-整理算法 空闲列表风格:常见于堆内存不规整的情况,这种分配方式会保存一个空闲分区表,它会将一个空闲分配分区保存到一个链表中,然后当需要分配内存的时候,就将遍历这个链表,然后基于一定的算法来选择出最佳的空闲分区 内存分配是线程安全的吗? 不是,内存分配是多个线程可以同时操作的,并且操作的是每个线程都可见的堆内存区域,JVM在执行这个的时候并没有加锁,而是基于预分配+CAS来实现的 预分配TLAB:通过这个TLAB,每个线程都会有自己的一块空间,其他线程无法访问这个TLAB,这样的话在内存大小许可的情况下,就可以一直在这里面分配内存了,只有当内存不足的时候,才会申请其他空间 CAS+重试:通过CAS轮询内存区域是否被分配,如果被分配了就重试 (3)初始化零值:这个过程就是将对象所得到的内存空间都初始化为0,这一步保证了对象的实例字段在Java代码中不赋值就可以直接使用,程序能够访问到这些字段的数据类型所对应的零值 (4)设置对象头:就是设置Object head,包括有Mark word、hashcode、array_length、age (5)执行方法:执行构造方法 执行第二条语句 (1)发现类已经被加载过了,于是跳过.class的加载 同(2)-(4) 对象访问定位的两种方式?有什么优缺点? 句柄模式:是这样描述的,引用指向的是句柄池中的一个句柄,这个句柄包含有一个实际对象在堆中的指针,还有一个对象的类型的指针 直接指针模式:是这样描述的,引用指向的就是堆中的实际对象,然后再通过这个实际对象的头部的类信息字段去找到具体的类信息 这两种对象的访问方式各有优势,由于在发生GC的时候,有可能会发生对象的移动,在这个过程中,那么直接指针模式,就需要修改每一个栈上引用的引用地址,这将会带来性能的下降 句柄模式的最大优点就是句柄的地址是稳定的,当对象被移动的时候,只需要修改句柄的引用就可以了 但是句柄模式在查找对象的时候是二次寻址,而直接指针是一次寻址。 分代分配回收算法是什么?什么情况下会进入老年代? 分代年龄机制的理论是这样描述的: 那些新创建出来的对象,往往是朝生夕死的,也就是很快就不会被使用,需要GC,GC大概率会收集掉这些对象 那些经历过多次GC的对象,往往很难被GC掉,因此GC的一般不会收集掉这些对象 那么在设计的时候,通常来说就需要做一个分区,也就是将那些容易被GC的放一个区,那些不容易被GC的放一个区。这就是分代分配回收堆内存模型的一个基本思想,在分代分配回收机制下,通常会分为这样的区域 伊甸园区(Eden区):新创建的对象都会放在这里 S0/S1区:在伊甸园区经历了GC之后,会基于标记/复制算法,将对象在这来回复制 老年代:当S0/S1的对象经历了足够多次的GC之后,就会晋升为老年代中的对象 具体的流程是: 当new出来一个对象,就会放入Eden,然后Eden发生MinorGC的时候,就会将那些存活的对象复制到S0 当S0满了,就会将S0中存活的对象全部拷贝复制到S1中,循环往复 如果S0/S1中存在有age达到能够晋升到老年代的对象,那么就将这个对象晋升上去 如果老年代满了,那么就会触发一个MajorGC,这个GC会删除那些老年代中死亡的独享 当永久代满了,就会触发FullGC 如何判断对象是否死亡? 一般来说,判断对象是否死亡可以通过引用计数法/可达性分析法 首先新来讲讲引用计数法,这个方法可以基于对象的头部来做,就是在对象的头部埋下一个字段,称为说是被引用的次数,当有对象引用它了,那么count++,当取消引用了就count–,当count == 0,就可以标记这个对象为可以删除了,但是它有一个致命的问题,就是说这个不能出现循环引用,比如说A B C在程序中没有被使用了,但是A B C相互引用,最终就会导致对象无法被删除掉 可达性分析法:是一种比较好的方法,它的具体思路是从JVM进程中注册的那些GC Roots出发，向下BFS或者DFS去查询这GCRoots及其子节点,通常来说有双色标记法和三色标记法来实现这个算法,当节点为黑色的,那么就代表不用删除节点,当节点为白色的,那么就需要删除节点 哪些对象可以作为GC Roots? 虚拟机栈(栈帧中的本地变量表)中引用的对象,比如说有一个线程 123private void func()&#123; A a = new A();&#125; 本地方法栈(Native 方法)中引用的对象 方法区中类静态属性引用的对象 方法区中常量引用的对象 所有被同步锁持有的对象 对象可以被回收,就一定会被回收吗? 不一定,及时在可达性分析法中不可达的对象,也并非是非死不可的,这时候他们暂时处于缓刑的阶段,要真正宣告一个对象死亡,至少要经历两次标记的过程,可达性分析法中不可达的对象被第一次标记并且进行一次过滤,过滤的条件是说这个对象是否有必要执行finalize方法,当对象没有覆盖finalize方法,或者finalize方法已经被虚拟机调用过的时候,虚拟机将这两种情况视为没有必要执行 被判定为需要执行的对象将会被放在一个队列中进行第二次标记,除非这个对象与引用链上的任何一个对象建立关联,否则就会被真的回收 还有的一个就是在引用类型不同的时候会有不同的情况发生 引用类型总结 强引用:如果一个对象具有强引用,那么垃圾回收器就绝对不会回收它的,当内存空间不足,Java虚拟机宁愿抛出OOM错误,也不会回收这些拥有强引用的对象 软引用:如果一个对象只有软引用,那么就类似于可有可无的生活用品,如果内存足够,那么垃圾回收器就不会回收它,如果内存空间不足了,那么就会回收这些对象的内存,软引用可以用来实现一些内存大小敏感的高速缓存 弱引用:如果一个对象只有弱引用,那么也是可有可无的,但是它比软引用的生命周期要更短,一旦遇到垃圾回收,那么无论空间是否充足,都会回收这个对象 虚引用:形同虚设,与其他几种引用都不同,虚引用并不会决定对象的生命周期,如果一个对象只有虚引用,那么它就和没有任何引用一样,在任何时候都可能被垃圾回收 虚引用主要用来跟踪对象被垃圾回收的活动 虚引用和弱引用的一个区别在于:虚引用和引用队列必须联合使用,当垃圾回收期准备回收一个对象的时候,如果发现它还有虚引用,那么就会在回收对象的内存之前,把这个虚引用加入到与之关联的引用队列中,程序可以通过判断引用队列中是否加入了虚引用,通过检查队列中是否存在这个对象,来了解这个对象是否被GC了。 软引用可以加速JVM对垃圾内存的回收速度,可以维护系统的运行安全,防止OOM等问题的发生 如何判断一个常量是废弃的 JDK1.7之前的运行时常量池逻辑包含字符串常量池存放在方法区,此时hotspot虚拟机对方法区的实现为永久代 JDK1.7字符串常量被从方法区拿到了堆中,这里没有提到运行时常量池,也就是说字符串常量池被单独拿到堆,运行时常量池剩下的东西还在方法区,也就是hotspot中的永久代 JDK1.8 hotspot移除了永久代用元空间取代,这时候字串常量池还在堆中,运行时常量池还在方法区,只不过方法区的实现从永久代转换成了元空间 假如在字符串常量池中的存在字符串abc,如果当前没有任何String对象引用这个常量的时候,那么就证明废弃了,如果此时发生了内存回收的话而且有必要的话,abc就会被系统清理出常量池了 如何判断一个类是无用的? 方法区主要回收的是无用的类,那么如何判断一个类是无用的类? 该类所有的实例都被回收了,Java堆中不存在该类得到任何实例 加载这个类的ClassLoader已经被回收了,这也就意味着ClassLoader中没有这个类的缓存了 该类对应的java.lang.Class对象没有任何地方被引用,无法通过任何地方通过反射访问这个类的方法 可达性分析的流程?哪些对象可以作为GC Roots? 可达性分析的流程,首先要从GC Roots的选取说起,它大约是从进程所必须要使用的对象开始向下搜索,这个搜索一般来说来自于: (1)虚拟机栈中引用的对象,它表示说在函数执行过程中引用了这些对象,不能够轻易解除这些对象 (2)本地方法栈中引用的对象,同理,就是在执行本地方法的时候,如果需要涉及Java堆中的对象的时候,就会将这些对象给保留 (3)方法区中对象,方法区中一般存储的是常量,方法区中类静态属性引用的对象,方法区中常量引用的对象 (4)所有被同步锁持有的对象 那么可达性分析的流程大概是这样的,一般来说有三个过程,Mark=&gt;Mutation=&gt;Sweep 那么可达性分析的过程: (1)首先是初始化标记,它会将GC Roots下的第一个对象给标记起来,然后标记成灰色 (2)并发标记,就是将灰色的对象弹出集合,然后将灰色对象下的子节点全部标记成灰色之后,将父灰色对象标记成黑色,然后不断循环这个过程 (3)由于并发标记的过程中,可能存在一个并发修改的问题,也就是说原本黑色的对象下增加了一个引用,如果不加以修正,那么就会导致对象被误删除,解决这个问题的思路是增量更新,所谓增量更新就是将新增引用,比如说A=&gt;B,将A这个对象加入到一个集合中,然后在remark阶段中,取出这个集合中的元素,然后再次标记子节点 (4)并发标记的过程中,还会存在一个问题,就是一个对象从一个灰色对象的引用被取消了,这种情况下,有导致两种情况的发生这个白色对象接到了一个黑色对象的下面,这样的话就会导致白色对象被删除了,还有一种情况是这个白色对象接到一个灰色对象的下面,这样的话不会出现问题,首先第一种情况非常严重,因此为了避免这种情况,提出了原始快照的方案,这种方案是讲,当从灰色对象下解除一个对象的引用的时候,会记录这一条引用,然后在remark标记的过程中,还是会去扫描这一条引用 这种方式,由于在并发的过程中,看到的对象引用关系和一开始的是一样的,因此称之为原始快照 跨代引用问题了解吗?怎么解决的? 首先跨代引用问题说的是:在遍历一个分区的时候,由于涉及到了另外一个分区的引用的情况,从而导致不得不去扫描另外一个分区的现象称为跨代引用问题 假设一下,有一个年轻代对象A引用了老年代对象B,假设我们要回收老年代的对象,扫描的对象都都是基于老年代为根的,由于这个对象无法通过老年代的对象扫描到,因此这个老年代对象B就好像没有被引用到了导致误删。那么怎么解决的呢? 它是通过一张表,我们通常称为是记忆集,这个记忆集记录了所有跨代的引用关系,那么在遍历其中一个代的时候,还会扫描这张表,如果这张表存在老年代中的对象,就会标记,从而避免了又要去遍历另外一个代中的对象。 垃圾回收的算法有哪些?有什么特点? 一般来说,垃圾回收算法有四种模型,这四种模型其实都是基于操作系统中的内存管理来实现的: 标记-清除算法:这种算法通常来说,还需要配合空闲链表进行实现,因为无法内存区域是不规整的,那么在这样的情况下,无法使用指针碰撞的规则,它的主要思路是,在标记结束后,就会直接删除这个对象,然后将可用的内存空间描述加入到空闲链表中,它的效率很高,因为不需要做额外的操作,但是它会使得内存空间产生大量的不连续碎片 标记-整理算法:这种算法是基于了第一种标记-清除算法,这种算法致力于使得内存空间变得规整,在这种模式下,不需要空闲链表了,因为在这种算法下,会使得内存空间被严格分成了没有分配的空间和有分配的空间,只要将分配指针向后移动就可以了,这种模式叫做指针碰撞 标记-复制算法:这种算法也是基于了第一种标记-清除算法,这种算法也是致力于使得内存空间变得规整,可以使用指针碰撞来分配内存 为什么标记整理算法的效率是比较低下的? 因为复制算法只需要把活的对象拷贝到S区,这个过程中只需要考虑移动堆顶指针,然后按照顺序分配内存即可,实现起来十分简单,运行高效,而标记整理算法,还需要考虑每个对象的大小以及位置,其中涉及的指针计算是比较复杂的,同时在移动对象的时候还需要移动指针的同时,复制内存数据,因此是十分低效的 但是它的内存利用效率是比较低的,因为每次只能使用一部分的内存空间 分代回收算法:当前虚拟机垃圾收集都是基于分代回收算法实现的,根据分代年龄假说,新生的对象都是朝生夕灭的,因此我们可以为新生的对象设置一个分区,每次回收这个分区,都大概率会有大量的对象被GC,那么选择什么算法呢?可以使用标记-复制算法,这是因为每次存活下来的对象都是很少的,因此每次的复制量都会比较低,因此使用这种算法能够取得更高的收益,而老年代的对象因为对象较大,而且每次GC只能回收很少的空间,如果采用复制的话,那么就意味着内存利用率会很低,此时使用标记-清除/标记-整理 为什么分为新生代和老年代? 新生代/老年代的出现是为了针对不同的年龄的对象执行不同的GC算法,比如说对新生代的GC每次存活下来的对象很少,因此它对内存空间的敏感程度是低于指针计算复杂度的敏感程度的,因此适合使用标记-复制算法 老年代由于对象较大,因此它对内存空间的敏感程度是高于指针计算复杂度的敏感程度的,因此适合使用标记-清除/标记-整理算法 说说常见的垃圾收集器 串行收集器 主要的执行流程:在需要GC的时候,此时会触发STW,然后使用一个单线程的垃圾收集线程去执行Mark Sweep直到收集执行,因此在这个过程中,标记算法可以使用双色标记法,因为中间没有线程在做修改 新生代采用的是标记复制算法,老年代采用的是标记整理算法 吞吐量小,内存回收工作量不大 容忍延迟,不在意卡顿 单核,内存小:0~100M ParNew收集器 ParNew的执行工作量实际上是要大于单线程的执行的,但是由于多核的优势,它可以提高吞吐量(指的是降低GC的时间占比)，它特点就是在触发GC的时候,使用STW,然后启动多线程,用多线程执行GC 它在新生代会使用标记复制算法,在老年代会执行标记整理算法 Parallel Scavenge收集器 这个收集器主要是对于老年代有不同的收集策略 12-XX:+UseParallelGC #老年代串行执行-XX:+UseParallelOldGC #老年代并行执行 Parallel Scavenge收集器关注的是吞吐量(高效率的利用CPU),CMS等垃圾收集器的关注点更多的是用户线程的停顿时间,使用了这个垃圾收集器选项,就可以将内存管理优化的工作交给虚拟机去完成 Serial Old收集器 它是串行收集器的老年代版本,意思是在老年代执行STW+Mark+Sweep,其中老年代执行的是标记整理算法 Parallel Old Parallel Scavenge的老年代版本,使用多线程和标记整理算法,在注重吞吐量和CPU资源的场合 CMS收集器 CMS(Concurrent Mark Sweep)收集器是一种以获取最短回收停顿时间为目标的收集器,它非常符合在注重用户体验的应用上的使用 标记-清除算法,它的运作过程实现了让垃圾收集线程与用户线程基本上同时工作,分为四个步骤: 初始标记:暂停所有的线程(STW),并且记录下与root相连的对象,速度是很快的 并发标记:同时开启GC和用户线程,用一个闭包结构去记录那些可达的对象,但是在这个阶段结束之后,这个闭包结构并不能保证当前的标记是正确的,这是因为并发用户线程可能还会删除各自的引用,导致问题的发生 增量更新:就是当添加一个白色对象到黑色对象的时候,这时候会将这个对象通过写屏障的方式(代理),将这个对象添加到一个集合中,然后在重新标记过程中处理 原始快照:就是当删除一个灰色对象下的白色对象的时候,会记录下这个引用关系,在重新标记过程中处理 重新标记:STW,重新标记阶段就是为了修正并发标记期间因为用户程序运行而导致标记变动的那一部分的标记记录,这个阶段的停顿时间一般会比初始标记阶段的时间稍长 并发清除:STW,回收垃圾对象 对CPU资源是敏感的 无法处理浮动垃圾 它使用的回收算法,标记清除,将导致大量的外碎片 G1收集器 空间整合：与CMS的标记-清除算法不同，G1从整体来看是基于标记-整理算法实现的收集器，从局部（两个Region之间）上来看是基于“复制”算法实现的。但无论如何，这两种算法都意味着G1运作期间不会产生内存空间碎片，收集后能提供规整的可用内存。这种特性有利于程序长时间运行，分配大对象时不会因为无法找到连续内存空间而提前触发下一次GC。 在G1之前的其他收集器进行收集的范围都是整个新生代或者老年代，而G1不再是这样。在堆的结构设计时，G1打破了以往将收集范围固定在新生代或老年代的模式，G1将堆分成许多相同大小的区域单元，每个单元称为Region。Region是一块地址连续的内存空间 G1收集器将整个Java堆划分为多个大小相等的独立区域（Region），虽然还保留有新生代和老年代的概念，但新生代和老年代不再是物理隔离的了，它们都是一部分Region（不需要连续）的集合。Region的大小是一致的，数值是在1M到32M字节之间的一个2的幂值数，JVM会尽量划分2048个左右、同等大小的Region G1收集器之所以能建立可预测的停顿时间模型，是因为它可以有计划地避免在整个Java堆中进行全区域的垃圾收集。G1会通过一个合理的计算模型，计算出每个Region的收集成本并量化，这样一来，收集器在给定了“停顿”时间限制的情况下，总是能选择一组恰当的Regions作为收集目标，让其收集开销满足这个限制条件，以此达到实时收集的目的。 G1收集的运作过程大致如下： 初始标记（Initial Marking）：仅仅只是标记一下GC Roots能直接关联到的对象，并且修改TAMS（Next Top at Mark Start）的值，让下一阶段用户程序并发运行时，能在正确可用的Region中创建新对象，这阶段需要停顿线程，但耗时很短。 并发标记（Concurrent Marking）：是从GC Roots开始堆中对象进行可达性分析，找出存活的对象，这阶段耗时较长，但可与用户程序并发执行。 最终标记（Final Marking）：是为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在线程Remembered Set Logs里面，最终标记阶段需要把Remembered Set Logs的数据合并到Remembered Set中，这阶段需要停顿线程，但是可并行执行。 筛选回收（Live Data Counting and Evacuation）：首先对各个Region的回收价值和成本进行排序，根据用户所期望的GC停顿时间来制定回收计划。这个阶段也可以做到与用户程序一起并发执行，但是因为只回收一部分Region，时间是用户可控制的，而且停顿用户线程将大幅提高收集效率。 全局变量和栈中引用的对象是可以列入根集合的，这样在寻找垃圾时，就可以从根集合出发扫描堆空间。在G1中，引入了一种新的能加入根集合的类型，就是记忆集（Remembered Set）。Remembered Sets（也叫RSets）用来跟踪对象引用。G1的很多开源都是源自Remembered Set，例如，它通常约占Heap大小的20%或更高。并且，我们进行对象复制的时候，因为需要扫描和更改Card Table的信息，这个速度影响了复制的速度，进而影响暂停时间。 有个场景，老年代的对象可能引用新生代的对象，那标记存活对象的时候，需要扫描老年代中的所有对象。因为该对象拥有对新生代对象的引用，那么这个引用也会被称为GC Roots。那不是得又做全堆扫描？成本太高了吧。 HotSpot给出的解决方案是一项叫做卡表（Card Table）的技术。该技术将整个堆划分为一个个大小为512字节的卡，并且维护一个卡表，用来存储每张卡的一个标识位。这个标识位代表对应的卡是否可能存有指向新生代对象的引用。如果可能存在，那么我们就认为这张卡是脏的。 在进行Minor GC的时候，我们便可以不用扫描整个老年代，而是在卡表中寻找脏卡，并将脏卡中的对象加入到Minor GC的GC Roots里。当完成所有脏卡的扫描之后，Java虚拟机便会将所有脏卡的标识位清零。 想要保证每个可能有指向新生代对象引用的卡都被标记为脏卡，那么Java虚拟机需要截获每个引用型实例变量的写操作，并作出对应的写标识位操作。 什么是字节码?类的文件结构的组成是什么? 在Java中,JVM可以理解的代码就叫做字节码(扩展名为.class文件),它不面向任何特定的处理器,只面向虚拟机,Java语言通过字节码的方式,在一定程度上解决了传统解释型语言执行效率低的问题,同时又保留了解释型可移植的特点,所以Java程序在运行的时候是比较高效的,字节码转换为bytecode的过程实际上是JIT编译器完成的,JIT编译器会根据当前操作系统的底层决定将字节码编译为什么样的指令集 魔数(每个Class文件的头4个节点称为是魔数,唯一的作用是确定这个文件是否为一个能被虚拟机接收的Class文件) Class文件版本号 常量池(Constant Pool),它主要存放的是两大常量,字面量和符号引用 访问标志 当前类 字段表集合 方法表集合 属性表集合 类的生命周期?类的加载过程? 类的生命周期是从.class文件被加载到虚拟机内存中开始到被卸载出内存为止,因此它的整个生命周期可以概括为: (1)加载:通过全类名获取定义此类的二进制字节流,将字节流所代表的静态存储结构转换为方法区的运行时数据结构,在内存中生成bytecode,以及将解析出来的数据存储到方法区中。 每一个Java类都有一个引用指向加载它的ClassLoader,例如是数组类,数组类的ClassLoader是它的基元类型,这个过程可以控制到底是哪一个类加载器来执行类构造的方法,通过loadClass()方法来执行相关方法 (2)验证:验证是连接的第一步,它主要是将存储在内存中的bytecode以及class中的字节流中的信息是一个合法的类文件,否则会危害虚拟机甚至是操作系统的安全,主要是要验证.class的文件格式,元数据验证(比如说这个类是否有父类,这个类是否继承了不允许继承的类final)、字节码的验证(程序语义是否正确)、符号引用的验证(类的正确性验证) (3)准备:准备阶段就是说这个类通过了验证,是一个合法的.class文件,准备阶段是正式为类变量分配内存并且设置类变量初始化的节点,这些内存都在方法区中分配 此时完成内存分配的变量仅有类变量 在JDK1.7之后,HotSpot就将原本放在永久代中的常量放到堆上了 (4)解析,解析阶段就是虚拟机将常量池内的符号引用替换为直接引用的过程,解析的动作针对类、接口、字段、类方法、接口方法、方法类型、方法句柄和调用限定符7类符号引用执行 在程序执行方法的时候,系统明确知道这个方法所在的位置,Java虚拟机为每个类都准备了一张方法表来存放类中的所有方法,当需要调用一个类的方法的时候,只要知道这个方法在方法表中的偏移量就可以直接调用这个方法了,通过解析操作符号引用就就可以直接转变为目标方法在类中方法表的位置,从而使得方法就可以被调用 (5)初始化,执行初始化方法&lt;clinit&gt;(),注意,这个是说类的初始化,这一步才开始真正地执行代码,这个方法是线程安全的,所以在多线程环境下进行类的初始化的话可能会引起多个线程阻塞,并且这种阻塞很难被发现 当遇到 new 、 getstatic、putstatic 或 invokestatic 这 4 条直接码指令时，比如 new 一个类，读取一个静态字段(未被 final 修饰)、或调用一个类的静态方法时。 当 jvm 执行 new 指令时会初始化类。即当程序创建一个类的实例对象。 当 jvm 执行 getstatic 指令时会初始化类。即程序访问类的静态变量(不是静态常量，常量会被加载到运行时常量池)。 当 jvm 执行 putstatic 指令时会初始化类。即程序给类的静态变量赋值。 当 jvm 执行 invokestatic 指令时会初始化类。即程序调用类的静态方法。 使用 java.lang.reflect 包的方法对类进行反射调用时如 Class.forname(&quot;...&quot;), newInstance() 等等。如果类没初始化，需要触发其初始化。 初始化一个类，如果其父类还未初始化，则先触发该父类的初始化。 当虚拟机启动时，用户需要定义一个要执行的主类 (包含 main 方法的那个类)，虚拟机会先初始化这个类。 MethodHandle 和 VarHandle 可以看作是轻量级的反射调用机制，而要想使用这 2 个调用， 就必须先使用 findStaticVarHandle 来初始化要调用的类。 (6)使用 (7)卸载,该类的所有的实例对象都已经被GC了,堆中没有这个类的对象,该类没有在其他任何地方被引用,该类的类加载器已经被GC 因此由我们自定义的类加载器的类是可以被卸载的 双亲委派模型是什么?不想用双亲委派模型要怎么破坏? 类加载的作用是什么? 类加载的作用是获取类的基本信息,比如说这个类的类名,实现了什么接口,父类是什么,有哪些字段,有哪些方法,是否是公有的,当我们新建一个对象的时候,因为要为这个对象分配内存,那么就需要要提前知道这个对象需要多大的空间,如何来调用这个对象中的方法,如何来执行这个对象的方法,因此加载类的作用就是为了创建对象,一般来说,类的基本信息会被加载到虚拟机中的方法区中,比如说在HotSpot中,就会被加载到元空间 有哪些类加载器? BootstrapClassLoader:它是最底层的加载类,主要是用来加载Java的核心类库的,它是JVM的一部分,通常是用NULL的表示的,比如说你对String去getClassLoader,得到的是null ExtentsionClassLoader:扩展加载器,主要负责加载%JRE_HOME%/lib/ext目录下的jar包 AppClassLoader:应用程序加载类,面向用户的加载类,负责加载当前应用classpath下的所有jar包和类 除此之外,还可以使用自定义的类加载器,通过自定义的类加载器,就可以实现自定义的类加载逻辑,比如说可以通过对字节码文件加密,只有我们自定义的类加载器才能进行解密 什么是双亲委派模型? 双亲委派模型描述的是JDK中推荐的一种的加载类的方式,它的核心思想是自底向上查找类是否被加载过,如果被加载过了,那么就无序加载,然后自顶向下去尝试加载类。执行流程可以详细描述为: 在类加载的过程中,系统会先判断这个类是否被加载过了,已经被加载的类会直接返回,否则才会尝试嘉爱这个类,类加载器在进行类加载的时候,它首先不会自己去尝试加载这个类,而是将这个请求向上传递到父级请求,这样的话,基于双亲委派模型的类加载器,最终都会收集到所有的请求,只有当父加载器无法实现这个加载的时候,子加载器才会尝试去自己加载 如何判定两个Java类是否相同? JVM不但要判断类的全路径类名是否相同,还要判断此类的加载器是否相同,只有两者都相同的情况下,才能说这两个类相同 自定义类加载器,如果不打破双亲委派模型的话,那么可以: 首先继承ClassLoader 重写findClass() 无法被父类加载的类最终会通过这个方法被加载 如果想要打破双亲委派模型,那么就需要重写findClass()方法了 这是因为findClass()定义的是从哪里去加载这个类,如果是默认的话就会向上递归,直到父加载器完成加载 例如说Tomcat服务器为了能够优先加载Web应用目录下的类,然后再通过加载其他目录下的类,就自定义了WebAppClassLoader 双亲委派模型有什么好处? 双亲委派模型保证了Java程序运行的稳定性,可以避免类的重复加载,JVM区分不同类的方式不仅仅根据类名,想用的类文件被不同的类加载器加载也算作是不同的两个Class,同时,如果保证了双亲委派模型,那么如果有恶意第三方库伪造了一个JDK中的核心类,那么就会导致安全的问题,使用双亲委派模型能够保证使用的核心类是安全的。 默认类加载器? 默认的类加载器有三种: BootStrapClassLoader:这个加载器是JVM中的一个组件,它是虚拟机的一部分,本身不是使用Java语言实现的,因此在ClassLoader中getParent的时候就会得到null ExtentsionClassLoader:这个加载器用来加载特定的包,比如说%JRE_HOME%/lib下的jar包,通过这个可以实现第三方库的加载 ApplicationClassLoader:用户类加载器 JVM性能监控工具? 可以使用jps进行Java进程监控,包括其PID jstat:收集HotSpot虚拟机各方面的数据 jinfo:显示虚拟机的配置信息 jmap:查看Java的堆栈信息 如何排查死锁? 第一步,通过Linux的ps -aux | grep java指令,查看运行中的Java进程,查看运行时间长的进程 第二步,通过jstack PID,就能够打印出哪些线程引发了死锁 重要的参数? 如何指定堆内存:指定最大堆和最小堆 12-Xms&lt;heapSize&gt;[unit]-Xmx&lt;heapSize&gt;[unit] 如何设定新生代内存 1234567-XX:NewSize=&lt;youngSize&gt;[unit]-XX:MaxNewSize=&lt;youngSize&gt;[unit]#配置新生代的最小内存256m,最大内存1024m-XX:NewSize=256m-XX:MaxNewSize=1024m#设置最小和最大一致-Xmn256m 如何调节老年代和新生代的比例?(重要) 1-XX:NewRatio=1 指定元空间的大小 12-XX:PermSize=N-XX:MaxPermSize=N 1234-XX:+UseSerialGC-XX:+UseParallelGC-XX:+UseParNewGC-XX:+UseG1GC 遇到的GC问题如何解决? YoungGC频繁怎么办? 假设有关任务会频繁地调用一个接口,YoungGC的次数在某一个时间点飙升,同时伴随着Old区域内存的快速升高,然后最终会导致一次Full GC,这样的情况一般可以将问题归结于对新生代的管理不当,一般来说有这样的情况: 新生代的Eden区的配置太小,导致Eden的频繁GC,服务器的内存配置满足不了现有的业务量,优先对内存进行扩容,可以通过jmap -histo并且结合dump堆文件作进一步分析,查看是哪个对象占用了大量内存不释放。 YoungGC和OldGC都很频繁怎么办? 思路: GC样本采集 如果是因为FullGC导致的系统卡顿,首先需要对GC情况进行一些数据的采集,下面的指令能够知道发生GC的次数和耗时 1jstat gc -pid 2000 10000 结合GC样本和JVM参数配置,分析堆内存中的对象流转情况 结合之前的GC次数以及JVM参数中的新生代和老年代中的空间,分析FootPrint 结合对象挪动到老年代的规则,验证并且调优 定位内存突然飙升导致的OOM异常 123# 执行堆栈分析,生成当前的堆栈快照,此时会生成两个文件,分别是.dump和.log文件jmap -dump:format=b,file=A.log PID# 通过查看导出的dump文件(可以使用jvisualvm进行解析,就可以看到某个实例在内存中的占比,然后根据代码定位即可) CPU飙升怎么办? 1CPU`飙升是CPU密集型的操作过多,正常操作的时候基本上很少出现,此时就需要快速定位CPU过高的原因并且排除,一般来说有两种情况:`程序中出现了死循环`、`线程数无限增大(比如使用了CachedThreadPool) 一般步骤是 通过top指令查看当前哪个Java进程的CPU占用最高 通过top -H查看这个进程中的线程运行情况,就可以看到哪个线程的占用最高 然后将TID=&gt;十六进制,然后通过jstack PID |grep -A TID 就可以从堆栈信息查询到相关的代码了","categories":[{"name":"题库","slug":"题库","permalink":"http://kaillliu.github.io/categories/%E9%A2%98%E5%BA%93/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://kaillliu.github.io/tags/Java/"},{"name":"面试题","slug":"面试题","permalink":"http://kaillliu.github.io/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"name":"题库","slug":"题库","permalink":"http://kaillliu.github.io/tags/%E9%A2%98%E5%BA%93/"}]},{"title":"JUC 面试题总结回顾","slug":"JUC 面试题回顾","date":"2023-08-11T07:00:00.000Z","updated":"2023-09-08T04:13:36.216Z","comments":true,"path":"2023/08/11/JUC 面试题回顾/","link":"","permalink":"http://kaillliu.github.io/2023/08/11/JUC%20%E9%9D%A2%E8%AF%95%E9%A2%98%E5%9B%9E%E9%A1%BE/","excerpt":"","text":"什么是进程?什么是程序?什么是线程?什么是协程? 在Java中,进程它指的是一个JVM进程,它是资源分配的最小单元,它是系统运行程序的最小单位,因此你可以把它理解成动起来的程序,系统运行一个程序就是一个进程从创建,运行到消亡的过程 在Java中,线程指的是一个Thread,通常来说可以通过new Thread()、implements Runnable、implement Callable&lt;T&gt;三种方式来实现一个线程,其中new Thread()出来的线程是由当前运行中的线程创建出来的,因此属于一个子线程,而Runnable也是归属于子线程,但是它没有返回值,适合做一些定时调度任务,而Callable&lt;T&gt;的返回值为T,适合做一个异步调用 Java20提出了虚拟线程,这个所谓的虚拟线程其实就是协程的概念,协程它本质上来说就是一个可以在某个地方挂起的特殊函数,并且可以在重新挂起的地方继续运行,一个线程内的多个线程的运行都是串行的 因此协程它本质上是串行执行的,因此不适合计算密集型场景,协程适合IO阻塞型场景 那么它和线程相比有什么用呢?首先它使得CPU的利用率更高了,比如说有5个IO任务,如果交给线程来执行,那么就会导致这5个线程阻塞,而线程的维护是需要开销的,因此就浪费掉了 但是使用线程的话,只使用1个线程,就能够开启5个协程,然后同时发出IO指令,这样的话就很快了,并且线程资源能够得到很好的运用 进程和线程有啥区别? 这个问题可以从JVM的角度来分析: 首先进程是资源分配的最小单位,每个进程都有自己独一无二的内存空间,包括有PCB,PCB中保存了当前进程运行的相关信息,各个进程之间除非使用IPC通信,比如说管道通信,通过fork()、消息队列等方式进行通信,各个进程之间的运行都是毫不相干的 而线程是CPU调度的最小单位,每个线程共享进程内的空间,但是对于一些影响到线程运行逻辑的数据结构进行了隔离,比如说本地方法栈,它是给本地方法在运行的时候使用的,虚拟机栈,它是给线程方法在运行的时候使用的,每一个栈中有若干个栈帧,每一个栈帧就代表着一次函数调用,栈中会有局部变量表,这个表的存在解释了为什么有实参和形参这两种不同的参数,有一个操作数栈,这个操作数栈记录了某次的临时计算结果,比如说a+b+c等,需要记录中间运算的过程。还有的比如说有程序计数器,这个东西也是私有的,这是因为线程被发明出来就是被调度的,假设A线程被调度上CPU,执行到一半时间片到,然后这个需要记录当前这个线程方法执行到哪了 然后就会将程序计数器中的值记录下来,等到下一次再上CPU的时候使用 什么叫并发?什么叫并行 并发指的是:一个CPU单核,多个线程在上面轮转 并行指的是:一个CPU多核,多个线程同时运行 什么叫同步?什么叫异步? 同步:当发出一个调用之后,在没有得到结果之前,这个调用就不可以返回,一直等待 异步:当发出一个调用之后,无论结果是否被得到了,这个调用都可以返回,直到用户主动获取结果 使用多线程有什么好处? 从多核的角度来说,由于CPU多核结构的存在,因此一个CPU多核,意味着一个CPU可以同时执行多条指令流,如果只有单线程的话,那么多核结构就被浪费掉了 从单核的角度来说,因为CPU的资源是很珍贵的,我们希望尽量的利用CPU,如果只有一个线程,那么当这个线程发起阻塞IO的时候,那么这个线程就啥也没干,CPU也没有参加到运算中,最终就导致了CPU的利用率低 那么从应用的角度上来说,由于线程的上下文的切换更加轻量级,不需要切换页表,因此多线程相比于多进程来说,能够减少开销,利用多线程可以提高系统的并发能力 线程的生命周期和状态 线程的生命周期通常可以分为以下几种: 1NEW`:新建状态,也就是说此时线程刚被创建出来,但是还没有调用`start() RUNNABLE:运行状态,线程调用了start()等待运行的状态 BLOCKED:阻塞状态,一般来说是因为锁而被阻塞 1WAITING`:等待状态,表示该线程正在等待某些事情发生,比如说被`notify() TIME_WAITING:等待超时状态,比如说使用了sleep(seconds)的时候,当到了seconds的时候就会自动返回成为RUNNABLE Terminated:终止态,表示线程运行完毕 那么这些状态是如何转换的知道吗? 当一个线程被New()出来之后,就是进入了NEW的状态 当一个线程被调用了start()的之后,就是进入了RUNNABLE的状态 当一个线程执行了wait()方法之后,这个线程就进入了WAITING的状态,进入等待状态的线程需要依靠其他线程的通知才能返回到运行的状态 当一个线程调用了sleep(seconds)或者wait(seconds)的时候,就相当于在等待的状态上增加了超时限制,此时会进入一个TIMED_WAITIING的状态,当超时时间结束之后,线程将会返回到RUNNABEL的状态 当线程进入了synchronized方法/快调用wait()后,然后被notify()之后重新进入了synchronized的时候,但是因为锁被其他线程占用,此时线程就会进入到一个BLOCKED的状态 线程在执行完了run()方法之后就会进入到TERMINATED的状态 什么叫上下文切换? 当发生1.线程的CPU时间片用完之后2.发生垃圾回收3.有更加高级的线程需要运行的时候4.当线程自己调用了sleep、yield、wait、join、park、synchronized、lock等方法的时候,就会发生线程上下文切换 当ContextSwitch发生的时候,需要由操作系统保存当前线程的状态,并且恢复另一个线程的状态,Java中对应的概念就是程序计数器(Program Counter Register),它的作用就是记住下一条JVM指令的执行地址,是线程私有的 状态包括程序计数器,虚拟机栈中每个栈帧的信息,如局部变量、操作数栈、返回地址等 ContextSwitch频繁发生会影响性能 上下文的切换可以分成三种 系统调用的上下文切换 系统调用的上下文切换,本质上就是同一个进程,调用不同函数的过程,但是由于要从用户空间切换到内核空间,因此需要对CPU的运行环境进行切换,比如说保存当前用户态的程序计数器和CPU寄存器到系统内核中,然后加载调用系统调用所需要的上下文信息到CPU环境中,然后完成后,从内核中取出相关数据到CPU中 进程的上下文切换 进程的上下文切换,指的是多个进程间的任务切换,它的做法是将当前的CPU运行环境保存到PCB中,这个过程中,由于进程是由内核来管理的,因此进程的切换只能发生在内核态,因此进程的上下文切换不仅包括有内存堆栈、寄存器等内核空间的状态,还包括有虚拟内存、栈、全局变量等用户空间的资源 因此进程的上下文切换还会导致页表等用户空间数据的切换,等新的进程被加载到CPU上的时候,还需要刷新新的进程的虚拟空间和用户栈 线程的上下文切换 首先要明白,线程是CPU调度的基本单位,而进程是资源分配的基本单位,内核中的任务调度,实际上的调度对象是线程,同一个进程中的所有线程共享进程的虚拟内存、全局变量等资源 它的上下文切换通常是切换私有方法栈以及程序计数器等内容,这些数据结构所占用的内存更小,因此通常来说是更加轻量级的操作 什么是线程死锁?如何避免死锁? 线程死锁指的是多个线程同时阻塞了,它们中的一个或者全部都在等待某个资源被释放,由于线程被无限期的阻塞,因此程序不可能正常终止,产生死锁有四个条件 互斥:就是导致死锁的资源是互斥的,一旦一个线程占用了这个资源,其他线程试图获取的时候就会被阻塞 占用且等待:当线程占用资源的时候,它在申请新的资源的时候不会释放原有的资源 不可强制剥夺:指的是其他线程不可强制剥夺某个线程所占用的资源,重复操作系统干预 形成循环等待链:指的是线程之间互相等待资源释放 如何来避免死锁? 首先互斥条件一般来说是不能破坏了,如果资源失去了互斥的特性,那么就起不到保护的作用了,因此一般不会将互斥条件破坏掉 其次是占用且等待,说的意思是线程占用资源的时候,它申请资源的时候不会释放原有的资源,这个条件可以通过资源预分配的方案来实现,也就是破坏后面半句话中的申请新资源,在线程开始执行任务的时候就提前计算好资源量,如果当前的资源是足够的,那么就让线程运行,否则的话就不允许线程运行 第二个就是角度可以通过不释放原有的资源来进行破解,也就是说当线程申请新资源的时候,如果申请不到新资源的话,那么就会释放原有的资源,让其他线程来获取 第三个就是破坏循环等待的条件,可以通过按序申请资源来预防,按照某一个顺序来申请资源,释放资源则反序释放 如何来预防死锁? 预防死锁可以使用银行家算法,这个算法运行的具体逻辑就是通过估算当前线程执行任务的时候,所需要的资源的个数,当存在一个资源分配序列可以满足当前线程的运行,那么就证明这次分配是安全的,一旦出现某次分配导致线程无法推进的时候,就有可能导致死锁的发生,于是放弃分配,具体的流程就是一个试探性分配的过程,也就是说当将资源分配到P1的时候,会检查当前的进程队列,如果进程队列中没有任何一个进程能够运行完毕并且释放资源的话,就会被判断为不安全的状态,此时就会导致死锁的发生 sleep()和wait()方法对比 sleep()和wait()都能够暂停线程的执行 sleep()没有释放锁,而wait()释放了锁 wait()通常用于线程间交互/通信,sleep()通常用于暂停执行 wait()方法被调用了之后,线程会自动苏醒,或者也可以使用wait(long timeout)超时后线程会主动苏醒 sleep()是Thread类的静态本地方法,而wait()是Object的本地方法 当线程调用了sleep()和wait()都会导致线程进入阻塞状态 为什么wait()方法不定义在Thread? 这个问题可以从wait()方法的特性上来说,这个方法是为了让获得对象锁的线程实现等待,会自动释放当前线程所占有的对象锁,每个对象都拥有一个对象锁,既然是要释放当前线程占有的对象锁并让其进入WAITING状态,自然是要操作对应的对象Object而非当前的线程Thread sleep()定义在Thread中,是因为让线程暂停运行,不涉及到对象类,也不需要获取对象锁 可以直接调用Thread的run()方法吗? 这取决于开发者的目的,我们说一个线程的生命周期是NEW=&gt;RUNNABLE=&gt;RUNNING 当使用start()的时候,此时线程并不会立即开始执行run()中代码,而是由分派器决定,当线程获得了时间片之后才会执行run()中的方法 当使用run()的时候,此时线程会立即执行run()中的代码,此时会将run()当做是main()线程下普通方法来执行,并不会在某个线程中执行它,所以这并不是真正的多线程工作 说说CPU的多级缓存结构 CPU的多级缓存结构主要是为了处理CPU处理速度和内存处理速度不对等的问题,对于访问速度来说: 1磁盘的访问速度`&lt;`内存的访问速度`&lt;`CPUCache的访问速度`&lt;`寄存器的访问速度 这是由各个存储介质的空间大小来决定的,当存储介质的空间越小,意味着查询的速率就会越快 一般来说,CPU的多级缓存是这样工作的,当CPU需要访问某一部分数据的时候,就会将内存中的内容写入到cache中,然后当CPU需要使用的时候就直接从cache中取出数据来用就可以了 但是在并发的环境下是有问题的,比如说有线程1试图修改进程A中的数据i=1,使得i++,但是执行到一半,还没有刷回到内存中的时候,线程2抢占CPU,然后视图修改进程A中的数据i=1,使得i++,然后线程1和线程2将修改后的CpuCache中的数据同时刷回内存,这时候内存中的数据就是i=2了,这就导致了并发计算结果的不一致。 怎么解决? 操作系统通过定义内存模型以及一系列的规范来解决这个问题 什么是叫指令重排序? 指令重排序,简单来说就是执行代码的时候并不一定是按照你写的代码的顺序执行的,常见的指令重排序有: 编译器优化重排:编译器(包括JVM、JIT编译器等),在不改变单线程程序语义的前提下,重新安排语句的指令顺序 指令并行排序:现代处理器采用指令级并行技术来将多条指令重叠执行,简单来说就是当指令之间不存在一个数据的依赖关系的话,那么处理器就可以改变语句对应及其指令的执行顺序 内存系统也有一个重排序的操作,但是不是真正意义上的重排序,在JMM中via噢西安为主存和本地内存的内容可能不一致,进而导致程序在多线程下执行可能出现问题 Java源代码会经历编译器优化重排=&gt;指令并行重排=&gt;内存系统重排的过程,最终才会变成操作系统可执行的指令序列 指令重排序可以保证串行语义一致,但是没有义务保证多线程间的语义也一致,所以在多线程下,指令重排序可能会导致一些问题的发生 编译器和处理器的指令重排序的处理方式不一致,对于编译器,通过禁止特定类型的编译器重排序的方式来禁止重排序,对于处理器,通过插入内存屏障的方式来禁止特定类型的处理器重排序,指令并行排序和内存系统排序都是属于处理器级别的指令重排序 内存屏障是一种CPU指令,它是用来禁止处理器指令发生重排序,从而保障指令执行的有序性,另外,为了达到屏障的效果,它也会使得处理器写入、读取值之前,将主内存中的值写入到高速缓冲区中,清空无效队列,从而保障变量的可见性 什么是JMM?为什么需要JMM? JMM(JavaMomoryModel):其中文名称是Java内存模型,其主要的目的就是为了解决指令重排序和线程本地内存和主存之间的数据不一致的问题,主要目的是为了简化多线程编程,增强程序的可移植性 在各个操作系统中也会开发出一套关于线程=&gt;主存之间数据缓存一致性的规范,Java完全可以复用操作系统的内存模型来解决多线程下,变量可见性的问题以及指令重排序的问题,但是由于Java是跨平台的,所以这样的话就可能导致同一套代码在不同的操作系统中运行就会产生不一样的结果 为此,Java提供了JMM这一套内存模型来屏蔽系统的差异,它说白了就是通过定义一些规范来解决这些问题,开发者可以利用这些规范来更好地解决多线程编程的问题,可以直接使用并发相关的关键字和类,比如说synchronized和Lock、AQS等 JMM具体是如何的? 在JDK1.2之前,Java内存模型总是从主存中读取数据的,那么这样的做法就是安全而稳定,但是每次CPU都需要到主存中读取数据,从而导致性能较差 那么在当前的Java的内存模型之下,它将内存区域抽象成了本地内存和主存,但是这样的设计可能带来的问题就是数据的不一致,就好像是我们的CPU的三级缓存,如果没有设计CPU的三级缓存,那么就会导致Java内存数据的不一致,比如说线程A和线程B都读取了内存中变量小a的变量,然后当线程A将小a的值写回到主存中的时候,这时候就会出现一个情况:就是线程B依然读取的是本地内存中的拷贝,最终就导致了数据的不一致性 具体说说什么是主内存?什么本地内存? 具体来说,就是一种cache技术,它将主存中的数据复制一份到本地内存中,然后当线程执行过程中需要相关的数据之后,就可以直接从自己的本地内存中读取了,本地内存是线程私有的,只有本线程才能读取,而主存是所有线程是所公有的,所有线程创建的实例对象都存放在主内存中,因此是属于一个共享内存的范畴 本地内存则是每个线程都有一个私有的本地内存来存储共享变量的副本,并且每个线程都只能够访问自己的本地内存,无法访问其他线程的本地内存,它是JMM抽象出来的概念,存储了主内存中的共享变量副本 那么线程是如何操作JMM的呢? 假设现在有线程A和线程B,有共享变量小a存在主存中,然后线程A和线程B就将一份副本a1和a2分别拷贝到线程A和线程B中的本地内存中,然后执行相关的操作 如果线程A和线程B要进行通信的话,那么必须通过以下的步骤 线程A将本地内存中修改过的共享变量的副本刷回到主存中 线程B将读取主存中的共享变量 但是这依然会产生线程安全问题,这是因为线程A和线程B读取共享变量的时机是不确定的 也就是说线程B读取共享变量a的时候,有可能线程A还没有将数据刷回到主存中,也有可能线程A已经将数据刷会到了主存中了。 Java内存区域和Java内存模型有什么区别? Java内存区域它指的是JVM进程中各个数据段的划分,比如说有堆内存,运行时数据区,方法区,以及线程所私有的程序计数器,本地方法栈,虚拟机栈,以及存储在栈中的操作数栈,局部变量表等,可见Java的内存模型它定义的JVM进程中的内存分布,定义了各个数据段的划分 Java内存模型指的是工作/本地内存和主内存之间交互的细节,如果说Java的内存区域管理对标的是os中的内存管理,那么Java内存模型管理对标的是os中的进程管理,它规定了进程内部中的线程是如何访问共享内存的,通过指定一系列的规范来简化并发编程 什么是可见性?什么是原子性? 所谓可见性,它指的是在多个线程之间,一个线程对volatile变量的修改对另外一个线程是可见的,但是不能够保证原子性,通常用在一个写线程和多个读取线程的情况 比如说有 1234567static int i = 0;new Thread(()-&gt;&#123; i++;&#125;).start;new Thread(()-&gt;&#123; i--;&#125;).start(); 在预想情况下,应该i=0,但是在指令交错的情况下还是会导致一个i = -1的情况 一般来说,线程获取这个静态变量值的过程是: 指令1(getstatic):先读取主存中的值,然后将这个主内存中的值存储到工作内存中 指令2(iconst_1):将工作内存中的值交给执行引擎 指令3(iadd/isub):将执行引擎中得到的值执行的运算 指令4(putstatic):将工作内存的值刷回到主存中 正常情况下应该要是 12线程1: 1=&gt;2=&gt;3=&gt;4,此时刷回去的值为1线程2: 1=&gt;2=&gt;3=&gt;,此时刷回去的值为0 但是在指令交错的情况下就变成了 1234线程1: 1=&gt;2线程2: 1=&gt;2线程1: 3=&gt;4,此时刷回去的值为1线程2: 3=&gt;4,注意,此时线程工作内存中的值为`0`,因此最终刷回去一个`-1` 综上所述:volatile只能够保证线程之间对变量的一个可见性,但是无法保证因为指令交错而导致的一个原子性 如何终止掉一个线程 方法1:使用线程对象的stop()暴力关停线程,如果此时线程锁住了资源,可能导致死锁 方法2:设置一个boolean变量,定义为volatile的,然后在外面的线程中修改这个变量即可 什么叫做犹豫模式,这个所谓的犹豫模式就是设置一个变量,如果在某件事执行之前检查有没有其他线程开启了这个方法了,如果有的话就不执行,这个模式就是基于volatile实现的,通过volatile强行看到最新的数据+synchronized的方式来保证原子性和可见性 什么是有序性? 指令重排:指的是在单线程下不影响程序的运行结果的前提下,将Java指令代码重排序以提高CPU的执行效率,但是这种指令重排将会在多线程下产生问题 为什么要做指令重排? 现代处理器会设计为一个时钟周期完成一条执行时间最长的CPU指令,为什么这么做呢?这是因为想到指令还可以划分为一个个更小的阶段,比如说每条指令都可以分为 取指令=&gt;指令译码=&gt;执行指令=&gt;内存访问=&gt;数据写回的五个节点 那么在现代处理器中,由于现代CPU的支持多级指令流水线,例如支持同时执行 取指令=&gt;指令译码=&gt;执行指令=&gt;内存访问=&gt;数据写回 就可以称之为五级指令流水线,此时CPU可以在一个时钟周期内,同时运行5条指令的不同阶段,相当于一条执行时间最长的复杂指令,流水线技术不能能够缩短单条指令的执行时间,但是它变相地提高了指令的吞吐率 例子? 12345678910111213boolean ready = false;int nums = 0;new Thread(()-&gt;&#123; if(ready)&#123; r.r1 = num+num; &#125;else&#123; r.r1 = 1; &#125;&#125;).start();new Thread(()-&gt;&#123; num = 2; ready = true;&#125;).start(); 上面如果发生了指令重排序,那么最终可能会导致输出为0的结果 这是因为发生了这样的指令重排 12ready = true;num = 2; volatile原理是什么? volatile的底层实现原理是内存屏障 对volatile变量的写指令后会加入写屏障 对volatile变量的读执行前会加入读屏障 如何保证可见性? 123456789101112131415volatile boolean ready = false;int nums = 0;new Thread(()-&gt;&#123; //在这之前加入读屏障,在这之后的读操作都会读取主存中的内容 if(ready)&#123; r.r1 = num+num; &#125;else&#123; r.r1 = 1; &#125;&#125;).start();new Thread(()-&gt;&#123; num = 2; ready = true; //在这添加了写屏障,写屏障之前的所有改动都会全部同步到主存当中&#125;).start(); 如何保障有序性? 123456789101112131415volatile boolean ready = false;int nums = 0;new Thread(()-&gt;&#123; //在这之前加入读屏障,可以保障在这之前的数据不会被指令重排到当前这个读屏障之后 if(ready)&#123; r.r1 = num+num; &#125;else&#123; r.r1 = 1; &#125;&#125;).start();new Thread(()-&gt;&#123; num = 2; ready = true; //在这添加了写屏障,可以保障在对volatile之前的代码在它的后面&#125;).start(); 总结一下,volatile能够生成两种内存屏障 写屏障之前的更改都会直接同步到主内存中,写屏障之前的指令不会指令重排到写屏障之后,不会对写屏障之前的指令进行指令重排序,这样的话就能够避免之前的指令重排序导致其他线程发生异常 读屏障之后的读取都会直接从主内存中读取,不会将读屏障之后的代码排在读屏障之前,不会对读屏障之后的代码进行指令重排序,这样的话就能够避免读取到不一样的值 double-checked locking是什么 1dcl问题 懒汉式的单例模式 12345678910111213public final class Singleton&#123; private Singleton()&#123;&#125; private static Singleton INSTANCE = null; public static Singleton getInstance()&#123; if(INSTANCE == null)&#123;//在这判断不加锁 //只有进到这里的时候才会加锁 synchronized(Singleton.class)&#123; INSTANCE = new Singleton(); &#125; &#125; return INSTANCE; &#125;&#125; 为什么要加synchronized? 这是因为存在一个线程安全问题,当有两个线程同时判断INSTNACE==NULL的时候,就会同时进入到创建对象的流程中,最终就会导致出现两个对象,破坏了单例模式 synchronized锁的是什么? 这个关键字锁的是static关键字修饰的方法,因此锁的是类对象 并且只有需要创建对象的时候才需要加一个同步锁,在创建完毕之后不会加锁 有什么问题? 注意,最外层的if(INSTANCE == null)是在同步代码块之外的,因此这个判断没有受到synchronized的保护,因此就会导致有序性、可见性、原子性这三个特性得不到保障,从而导致问题的发生 主要的原因是: 一般来说创建对象的时候,先1.创建一个对象出来,2.然后赋值引用地址,3.然后调用init()构造函数,4.然后才给INSTANCE赋值的 但是在指令重排的时候,可能是先12然后43,这在JVM中是可能发生的 如果外面的线程在判断if(INSTANCE == null)的时候,如果先调用了4,而还没有调用3,那么就会这个线程所使用的对象的变量还没有被赋初值,就会导致问题的发生 解决办法,给INSTANCE实例使用volatile即可,可以解决这个问题的原因是volatile能够生成内存屏障,在这里的话就是生成一个写屏障,这个写屏障能够避免前面的代码被重排到后面去,这样的话就可以杜绝先赋值对象地址再执行初始化的发生 而读屏障呢则是避免读屏障之后的代码跑到前面去 什么是happends-before? happends-before规定了对共享变量的写操作对其他线程的读操作是可见的,它是可见性和有序性的一套规则的总结,JMM并不能够保证一个线程对共享的写,对其他线程对该共享变量的读可见 12345678910111213static int x;static Object m = new Object();new Thread(()-&gt;&#123; synchronized(m)&#123; x=10;//对x进行写入的操作 &#125;&#125;).start();new Thread(()-&gt;&#123; synchronized(m)&#123; sout(x);//获取x的值来读取 &#125;&#125;).start(); 可以的话就保证了同步了,因此就是可见的 线程对volatile变量的写,接下来其他线程对其他变量的读是可见的 1234567volatile static int x;new Thread(()-&gt;&#123; x= 10;&#125;).start();new Thread(()-&gt;&#123; sout(x);&#125;).start() 线程start前对变量的写,对该线程开始后的,变量是可见的 12345static int x;x = 10;new Thread(()-&gt;&#123; sout(x);&#125;).start(); 线程结束前对变量的写,对其他线程得知它结束后的读是可见的 12345678static int x;Thread t1 = new Thread(()-&gt;&#123; x= 10;&#125;);t1.start();t1.join();sout(x); 线程t1打断t2前对变量的写,对于其他线程得知t2被打断后的对变量的读是可见的 查看进程/线程的方法 windows 12tasklist#查看进程的列表taskkill#杀死进程 linux 12345ps -fe #查看所偶遇进程ps -fT -p &lt;PID&gt; 查看某个进程(PID)kill -9 pID#给某个进程发信号,-9是说停止程序的运行top -H#通常也会使用top -n1,每隔一段时间就会采集当前系统的负载 java 123jps#查看所有的Java进程jstack &lt;PID&gt;查看某个Java进程的所有线程状态jconsole &lt;PID&gt;查看某个进程中线程的运行情况 可以使用jsconsole图形化监控工具来监控进程,支持本地连接和远程连接 什么叫栈?什么是栈帧? JVM中有堆栈和方法区,每个线程启动之后,虚拟机就会为其分配一块栈的内存 每个栈由多个栈帧来组成,对应着每次方法调用时所占用的内存增加一块栈帧 每次的方法调用都会产生一块栈帧 简述一下函数调用的过程 从main()被执行开始,会先为main()函数分配一块栈帧,这个栈帧里面有自己的局部变量表,返回地址,操作数栈,这个操作数栈中记录了栈帧中计算数据的中间结果 接着按照程序流,将代码载入到程序计数器中,然后内核执行这些代码,当遇到一个新的方法调用的时候,就会开辟一块新的栈帧空间,并且记录当前的返回地址,用来表示在这个函数执行完毕之后要返回到哪里继续运行 当函数执行完毕后,就弹出这块栈帧即可,弹出的时候,会将返回地址中的地址取出,然后将当前的栈指针指向这个地址 线程的常见方法有哪些? 1start()`:让线程进入就绪状态,等待被CPU调度,以分派器的决定为准,每个线程对象的`start()`只能够运行一次,如果调用了多次就会出现`IllegalThreadStateException run():线程启动后会调用的方法 join():等待线程运行结束,也就是说,当线程1正在运行,正在计算某个结果,线程2想要获取这个计算结果,就可以通过join()方法等待计算结果的产生,等到线程运行结束了就可以获取结果了 123456Thread t1 = new Thread(()-&gt;&#123; sleep(1); r = 10;&#125;).start();t1.join();sout(r); join(long n):等待线程运行结束,最多等待n秒 getState():获取线程运行状态 isInterrupted():判断是否被打断 sleep(long n):让当前执行的线程休眠n秒,休眠时让出CPU的时间片给其他线程,让线程休眠,其他线程可以使用interupt来打断当前正在sleep()的线程,这时候sleep就会抛出中断异常,睡眠结束后的线程因为被是退回到就绪态,因此不会有立即上CPU运行的效果 yield():提示线程调度器让出当前对CPU的使用,这个方法是让当前线程从Running进入到Runnable的状态 1就绪状态`还是有机会到`运行状态的`,但是`阻塞状态`是无法直接到`运行状态的 什么是线程的优先级 线程优先级会提示分派器优先调度该线程,但是它仅仅只是个提示,具体起不起作用以分派器的决定为主,调度器完全可以忽略这个hint 在CPU繁忙的时候,一般来说会将更多的时间片分配给高优先级的线程,在CPU空闲的时候,线程的优先级不会起什么作用。 1sleep()`可以防止`CPU`的占用`100% 在没有利用CPU来进行计算的时候,不要让while(true)控制来浪费CPU,这时候可以使用yield或者sleep来让出CPU的使用权 说说interrupt() 阻塞状态的线程操作系统不会考虑这些线程,这个方法可以打断那些处于阻塞状态的进程,打断sleep()的线程,会清空它的打断状态,以sleep为例 1234567Thread t1 = new Thread(()-&gt;&#123; Thread.sleep(5000);&#125;);t1.start();//主线程打断这个线程t1.interrupt();//此时t1的状态是什么?反正不会是被打断的状态,因为sleep会将这个打断标记清除 两阶段终止模式 1当线程被设置为中断状态的时候,那么这时候就是说在这个中断状态的时候,给一个料理后事的机会 这是因为stop()可能会导致线程没有释放锁而直接被杀死,可能引发死锁 123456789101112131415161718192021222324Thread t1 = new Thread(()-&gt;&#123; //后台监控线程 while(true)&#123; if(isInterrupted())&#123; sout(&quot;释放资源....&quot;); break; &#125; try&#123; sleep(25); &#125;catch(Exception e)&#123; sout(&quot;打断了&quot;); current.interrupt(); &#125; 监控日志.... &#125;&#125;);public void start()&#123; t1.start();//准备被调度上CPU&#125;public void stop()&#123; t1.stop();&#125; interrupted()会将打断标志给重置 简单来说两阶段终止就是:首先第一个阶段就是被终止,这个阶段线程会被打上终止的标志,但是不会立即终止,第二阶段就是收尾,只有当收尾工作完成了,才算被彻底终止 什么叫临界区?什么叫竞态条件 问题出现在多个线程访问共享资源,多个线程共享资源的时候,如果发生了指令交错,那么就会产生线程安全区问题 这个问题从本质上就是说出现了临界资源的访问问题,如果不对临界资源进行同步和互斥的控制,那么就会出现并发的问题,临界区就是说有一段代码存在了对共享资源的多线程读写操作,临界资源就是说有多个线程同时访问的资源 多个线程在临界区内执行,由于代码的执行序列不同而导致结果无法预测,称之为发生了竞态条件 怎么解决竞态条件? 为了避免临界区的竞态条件的发生,有多种手段可以达到目的 阻塞式的解决方案:synchronized(对象锁,互斥,同一时刻只能有一个线程执行被同步关键字修饰的代码区域)、Lock 非阻塞式的解决方案:原子变量 什么叫同步?什么叫互斥?有什么区别? 同步就是说一个线程需要等待另外一个线程执行到指定位置后再运行,这是因为线程在并发的环境下无法控制其指令的执行顺序,因此为了达到一些条件,必须使得线程之间的执行相互制约 互斥是说的是对临界资源的访问,这是因为临界区中的竞态条件发生,同一时刻只能有一个线程执行临界区的代码 123synchronized(任意的对象)&#123;//线程1进来,获取对象上的锁,线程2再来,就会将线程2加入到阻塞队列中 临界区代码&#125; 如何理解synchronized? syncronized关键字中锁的对象可以想象成一个房间,有唯一入口(门),房间只能一次进入一人进行计算,线程t1和t2想象成两个人,当线程t1,t2,t3同时到达,那么这些线程就同时竞争这个门的钥匙,这时候t1拿到了这把钥匙,于是这个门锁对应的房间的owner字段就被标记为了t1的ID 然后t2和t3就会被阻塞等待,加入到一个队列中,这期间假设t1的时间片用完了,那么t1也不会将门锁让出来,而是休眠,等到t1被唤醒,再次进入到这个门中,因为owner是它自己,因此它可以获得同步代码段的执行权限,然后就进去执行 等到t1执行完毕之后,它就会把t2和t3都给唤醒,然后他们俩再去竞争锁 synchronized解决了什么问题? synchronized解决的问题是:它将同步代码块中的代码的执行设置成了原子性的,也就是说这个代码段中的代码不会被其他线程所打断,不会产生不同线程同时执行这些代码,然后产生指令交错的问题 123456789101112//这种方式是保证了整个for循环都是原子性的synchronized(obj)&#123; for(int i = 0; i &lt; 5000 ;i++)&#123; count++; &#125;&#125;//这种方式是保证了里面的那条count++指令是原子性的for(int i = 0; i &lt; 5000; i++)&#123; synchronized(obj)&#123; count++; &#125;&#125; 原子性:指的是被synchronized修饰的代码段是原子性的,不会被线程的上下文切换而导致指令交错 锁对象:执行代码必须上锁,进行代码控制的必须是同一把锁 12345678public synchronized void save()&#123; &#125;public void save()&#123; synchronized(this)&#123; &#125;&#125; 这两种写法是等价的 123456public synchronized static void save()&#123;&#125;public static void save()&#123; synchronized(this.class)&#123; &#125;&#125; 如何判变量是否是线程安全的 判断变量是否是线程安全的,最本质的就是看这个变量是否有可能被多个线程所共享 一般来说,局部变量不会导致线程安全的问题,这是因为局部变量的作用域是栈帧,一旦栈帧被弹出,这个局部变量就会被弹出,这就不会导致线程安全问题,因为每个栈帧都是线程所独有的 同时,如果局部变量是对象类型,还要考虑一下对象是否会逃逸出当前的作用范围,如果逃逸出去了,那么这个对象就有可能被别的线程所竞争,最终造成线程安全的问题 常见的线程安全类 String Integer StringBuffer Random Vector HashTable JUC 线程安全是说多个线程调用同一个实例的某个方法的时候,是线程安全的,每个方法都是线程安全的,但是组合起来使用并不是线程安全的 比如说有 123456789101112131415public static void main(String[] args)&#123; Vector&lt;Integer&gt; v = new Vector&lt;Integer&gt;; new Thread(()-&gt;&#123; for(int i = 0;i &lt; 10;i++)&#123; v.add(i); &#125; &#125;).start(); new Thread(()-&gt;&#123; int size = v.size(); for(int i = 0;i &lt; size;i++)&#123; v.add(i); &#125; &#125;).start();&#125;//最终这个执行结果都会导致不同的Vector的值 或者有经典的 123if(table.get(&quot;key&quot;) == null)&#123; table.put(&quot;key&quot;,value);&#125; String类中的值不能被修改,它是线程安全的吗? String中的char[]的值是不会被改变的,因此无论外部线程如何操作,他们都是线程安全的。 Java对象头了解过吗? Java中的对象结构主要分为对象头和对象中存储的数据,对象头中一般存储了有 MarkWord:标记位(25位为hashcode) Klass Word:类对象的标识符,用来表示这个对象属于什么类型,通过这个标识符就能找到对应的类对象 Monitor(锁) Minitor被翻译为监视器或者是管程,每个Java对象都可以关联一个Minitor对象,如果使用synchronized给对象上锁(重量级锁)之后,该对象头中的MarkWord就被设置指向Minitor对象的指针 初始的时候,Minitor中的Owner为NULL,也就是这把锁并没有没有任何线程所占有 于是此时有一个线程Thread1到来,然后当这个Thread1到来的时候,会先检查这个对象头部的MarkWord,如果这个MarkWord中的后面两位不是10的时候,那么就会为这个对象找一个监视器 这个监视器是操作系统底层分配的,通过监视器可以得知当前同步代码块中线程的竞争情况 首先,如果Minitor的Owner为空的话,那么这个线程就会上去,将自己的线程ID填入到Owner字段中,然后执行任务,接着线程2和线程3到来,检查对象obj所对应的监视器,如果这个监视器的owner不为空而且owner的ID不是自己,那么就会加入到entryList中,这个列表又被称为是阻塞队列的一种结构,当线程1时间片下来的时候,它修改owner字段,也不会唤醒entryList对应的线程 只有当线程1执行代码完毕后,才会释放这个锁,然后唤醒entryList中的线程,但是这个唤醒不一定是公平的,这个取决于JDK底层的实现 这个就解释了,为什么锁的对象不一样,就会导致锁不到相关的代码,本质上因为对象中关联的Minitor不一样 从底层字节码的运行角度上来看,当线程进入同步代码块的时候,先会执行一条monitorenter的指令,这个指令要完成的工作是,将当前的lock对象头的hashCode(),分代年龄等信息临时存储到Monitor中,然后将Markword的前30位设置为Monitor的地址,接着会将这个lock对象引用保存一份,便于在后续解锁使用,接着就是执行计算,在计算完成之后,就会执行monitorexit指令,这个指令会将之前保存到Monitor中的hashcode等信息还原到obj中,然后将entryList中的指定线程唤醒,让他们重新竞争 执行同步方法,出错了会怎么样? 在这个synchronized执行的时候,实际上从字节码可以观察到JVM层面是会监听同步代码块中是否有发生异常的,如果抓到了对应的异常,那么就执行锁的释放,也就是唤醒entryList中的线程,然后恢复obj 说说synchronized的优化原理 轻量级锁阶段:在这个阶段,如果一个对象虽然有多线程访问,但是多线程的访问时间是错开的,也就是没有发生竞争的现象,那么就可以使用轻量级锁来优化,避免直接使用重量级锁 12345678910111213static final Object obj = new Object();//两次加锁的动作public static void method1()&#123; synchronized(obj)&#123; method2(); &#125;&#125;public static void method2()&#123; synchronized(obj)&#123; //同步块 &#125;&#125; 如何加锁的? 首先先创建锁记录(LockRecord)对象,每个线程的栈帧都会包含一个锁记录的结构,内部可以存储对象的MarkWord,以及锁记录对象的引用地址,便于找到这个对象,在使用完毕后解锁 然后在线程的执行过程中,一旦遇到同步代码块,就执行加锁,轻量级锁的加锁流程是这样的,将对象头的MarkWord先交换记录到LockRecord中,这个过程是基于CAS来实现的,对象头中存储了锁记录地址和状态00,表示由该线程给对象加锁 第一种情况,如果CAS成功,那么就证明之前没有人和我竞争,那么就可以继续使用轻量级锁 第二种情况,如果CAS失败,那么就证明有人和我竞争,进入了锁膨胀的过程 如果是自己执行了synchronized锁重入,那么就再添加一条Lock Record作为重入的计数 这条LockRecord会保留锁对象的引用,但是会在记录Lock的MarkWord的字段设置为null 当在解锁的时候如果发现有一条记录的MarkWord的字段为null,表示有重入,那么就直接去掉这条记录,解锁即可,如果发现记录的MarkWord的字段不为null,那么就证明是最先开始加的锁,然后将LockRecord中的MarkWord字段恢复到原对象的头部中 当退出synchronized代码块的时候,如果不为NULL,而且CAS失败,那么说明轻量级锁已经膨胀了,那么就进入重量级锁的解锁流程 锁膨胀的阶段 就是当CAS失败的时候,这时候就会触发锁膨胀的过程,这个过程将会将MarkWord替换为锁监视器的地址,然后将当前线程加入到Monitor中的entryList中,等到线程退出同步块解锁的时候,就使用CAS将MarkWord的值恢复到对象头,此时肯定是会失败的,然后按照重量级锁的流程,将EntyrList中的阻塞线程给唤醒 自旋优化 重量级锁竞争的时候,还可以使用自旋锁来进行优化,如果当前线程自旋成功,这时候持有锁的线程已经退出了同步块,这时候的线程就可以避免阻塞 自旋指的是先不要让当前线程进入阻塞状态,而是先尝试,这样的话就可以避免上下文切换,但是如果长期自旋失败,那么就会直接失败,进入阻塞队列中 偏向锁 轻量级锁在没有竞争的时候,每次重入依然需执行CAS操作,比如说线程1进入了同步代码块1,加锁的对象是obj,然后需要进入同步代码块2,这时候还需要对对象MarkWord中的锁记录地址进行比较,此时肯定是失败的了,但是它可以通过MarkWord中的00后两位来判断是轻量级锁,因此就会加入一条新的RecordLock 那么我们就想要将这个CAS的过程优化掉,于是引入了偏向锁来改进这个问题,只有第一次使用CAS将线程ID设置到对象的MarkWord的时候,就会将线程的ID设置到MarkWord中,后续再发生了锁重入,那么就直接判断MarkWord的是否等于线程的ID,如果等于的话就直接重入即可,前30位为线程的ID 那么当MarkWord中的ID不是自己的ID,那么就说明发生了竞争,最终就发生一个锁的升级 当调用了hashcode()的时候就会将偏向锁撤销,这是因为偏向锁的信息都是存储在对象头的,一旦调用hashcode()就会导致偏向锁的信息没有地方存储 当偏向锁的状态发生竞争的时候,就会将偏向锁升级为轻量级锁 批量重偏向 当对象虽然被多个线程访问,但是没有发生竞争,这时候偏向了线程T1的对象依然有机会重新偏向T2,重偏向会重置对象的ThreadId,当撤销偏向锁的阈值超过20次之后,JVM会认为取偏向的过程产生了错误,于是会在个这些对象加锁的时候不要撤销偏向了,而是重新偏向到加锁线程 批量撤销 当撤销偏向锁的阈值超过40次之后,jvm会如认为确实是偏向错了,根本不应该偏向,于是整个类的对象都会变为是不可偏向的,新建的喜爱那个也是不可偏向的 wait-notify wait-notify执行原理 执行原理是owner线程发现执行条件不满足，于是调用wait方法,就进入了waitSet变为了WAITING状态,BLOCKED和WAITING的线程都处于阻塞状态，不会占用CPU的时间片 BLOCKED线程都会在owner线程释放锁的时候被唤醒 WAITING线程会在Owner线程调用notify或者notifyAll()的时候被唤醒,但是唤醒并不意味着立即获得锁,而是和之前的EntryList中的线程一起竞争锁。 什么是虚假唤醒? 虚假唤醒指的是唤醒的是错误的线程,唤醒不应该唤醒的线程,这是因为notify()是挑选一个线程后唤醒,没有特定的规律而言 什么是ReentrantLock? 相对于synchronized来说,它具有如下的特点 可以中断:使用lockInterruptibly()的这个api,如果线程在竞争这个锁的时候,会进入阻塞队列,但是有其他线程可以给当前线程打上中断标记,lock()和synchronized是不支持打断的,基本的编写逻辑为:当catch到中断异常的时候,就直接退出, 可以设置超时时间: 可以设置为公平锁 可以支持多个条件变量 支持可重入:如果同一个线程首次获得了这把锁,那么因为它是这把锁的持有者,因此就有权利再次获取这把锁,如果是不可重入锁,那么在第二次获得锁的时候,自己也会被挡住导致死锁 syncronized加锁的代码段不可以进行中断,同时当竞争重量级锁失败的时候,会加入到Monitor中的entryList中,这时候就会阻塞直到唤醒 但是ReentrantLock则是在等待一定的时间失败后就会直接返回,不再阻塞了,回去执行其他的逻辑,执行公平锁的目的是为了防止饥饿,所谓的饥饿就是说有一些线程被长期忽视,得不到调度运行的机会 12345ReentrantLock lock = new ReentrantLock();lock.lock();//临界代码段lock.unlock(); 锁超时机制是什么? tryLock():如果其他线程没有在指定的时间内释放锁,那么就会直接返回,从而可以避免死锁 锁的公平性 ReentrantLock:它本身是不公平,不是按照底层的阻塞队列来实现的,当在构造的时候传入一个true,就代表是公平锁,其底层是将AQS实现的 条件变量 1synchronized`中也有条件变量,就是那个`waitSet`休息室时,当条件不满足的时候,获得锁的线程调用`wait()`方法就会进入`waitSet`中等待,等待持有锁的线程唤醒`waitSet 缺点是由于notify()是随机唤醒任意一个线程,notifyAll()是唤醒全部,可能导致唤醒了不该唤醒的线程,因此不灵活 ReentrantLock支持多个休息室,也就是说支持多个条件变量,这就好比: synchronized是哪些不满足条件的线程都在一间休息室中等消息 而ReentrantLock则是支持多间休息室,在唤醒的时候可以唤醒指定的线程 await在执行前需要获取锁 await在执行后会释放锁,进入conditionObject等待 await的线程被唤醒,取重新竞争lock锁 竞争lock成功后,从await后继续执行 什么是CAS 1CAS`比较并设置对应的值的过程,`CompareAndSwap 它简单来说就是一条指令,它具有两个操作数 12boolean compreaAndSwap(int o1,int o2);//只有在内存中的值为op1的时候才将o2写进去 比如说 123456789int prev = balance.get();//此时可能发生并发,有人修改过了balance.get()的值int next = prev - amount;if(balance.compareAnde(prev,next))&#123; //此时它会将prev和实际上的balance.get()中的值进行比较 //如果相同,那么它就认为没有人修改过 //如果不相同,那么就认为有人修改过,修改失败 break;&#125; CAS的底层实现是基于lock cmpxchg指令实现的,在单核CPU和多核CPU都能够保证指令的原子性 在多核状态下,某个核执行到带lock的指令的时候,CPU会让总线锁住,当这个核把指令执行完毕后再开启总线,简单来说就是一个开中断和关中断的机制 获取共享变量的时候,为了保障该变量的可见性,需要使用volatile进行修饰,它可以用来修饰成员变量和景甜成员变量,当它插入了读屏障的时候,它会确保当前以及之前的语句都会从主存中去读取最新的值,从而避免了工作缓存中的值和主存中的值不一致的现象 CAS必须借助于volatile来实现,因此CAS必须借助于volatile来实现 CAS为什么快? 无锁情况下,即使重试失败,线程也都是在高速运行的,没有停止,而synchronized会让线程在没有获得锁的情况下发生上下文切换,而上下文切换是会导致一定的开销的,但是无锁的代价就是CPU忙等,CPU的利用率低 CAS是基于乐观锁的,最乐观的估计,它认为竞争并不激烈,就算修改了也没有关系 synchronized是基于悲观锁的,它认为时时刻刻都有线程来修改共享变量,它体现的是无锁并发,无阻塞并发,因为没有使用synchronized,所以线程不会陷入阻塞,从而提高了效率 竞争激烈的情况下,线程本身就对CPU的需求高,而CAS导致CPU忙等,最终反而反而导致效率下降 如何使得线程交替打印? 1234567891011121314151617181920212223242526272829303132333435static final Object lock = new Object();static int print = 1;static int loopNumber = 5 ;public static void print(char c,int waitFlag,int nextFlag)&#123; for (int i = 0; i &lt; loopNumber; i++) &#123; synchronized (lock)&#123; while(print != waitFlag)&#123; try &#123; lock.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; //当满足调节后会到这里 System.out.println(c); print = nextFlag; lock.notifyAll(); &#125; &#125;&#125;public static void main(String[] args) &#123; new Thread(()-&gt;&#123; print(&#x27;a&#x27;,1,2); &#125;).start(); new Thread(()-&gt;&#123; print(&#x27;b&#x27;,2,3); &#125;).start(); new Thread(()-&gt;&#123; print(&#x27;c&#x27;,3,1); &#125;).start();&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061package leetcode_acm.concurrent;import com.beust.ah.A;import java.util.concurrent.locks.Condition;import java.util.concurrent.locks.ReentrantLock;/** * 功能描述 * * @author: 张庭杰 * @date: 2023年03月25日 10:21 */public class PrintValue &#123; public static void main(String[] args) &#123; AwaitSignal awaitSignal = new AwaitSignal(5); Condition a = awaitSignal.newCondition(); Condition b = awaitSignal.newCondition(); Condition c = awaitSignal.newCondition(); new Thread(()-&gt;&#123; awaitSignal.print(&#x27;a&#x27;,a,b); &#125;).start(); new Thread(()-&gt;&#123; awaitSignal.print(&#x27;b&#x27;,b,c); &#125;).start(); new Thread(()-&gt;&#123; awaitSignal.print(&#x27;c&#x27;,c,a); &#125;).start(); try&#123; awaitSignal.lock(); a.signal(); &#125;finally &#123; awaitSignal.unlock(); &#125; &#125; private static class AwaitSignal extends ReentrantLock&#123; private int loopNumber = 0; public AwaitSignal(int loopNumber)&#123; this.loopNumber = loopNumber; &#125; public void print(char c,Condition current,Condition next)&#123; for (int i = 0; i &lt; loopNumber; i++) &#123; lock(); try&#123; current.await(); System.out.println(c); next.signal(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; unlock(); &#125; &#125; &#125; &#125;&#125; AQS原理 AbstractQueuedSynchronized是阻塞式锁和相关的同步器工具的框架 特点: 用state属性来表示资源的状态(分为独占模式和共享模式),子类需要定义如何维护我这个状态,控制如何获取锁和释放锁 getState:获取state状态 setState:设置state状态 compareAndSetState:乐观锁机制设置state状态 独占模式是只有一个线程能够访问资源,而共享模式可以允许多个线程访问资源 提供了基于FIFO的等待队列,类似于Monitor的EntryList 条件变量来实现等待、唤醒机制,支持多个条件变量,类似于Monitor的WaitSet 简单来说,它是一个框架,用来为构建锁和同步锁提供了一些通用功能的实现 AQS的核心思想是什么? 如果请求的资源是空闲的,那么就将当前请求资源的线程设置为有效的工作线程,将共享资源设置为锁定的状态,如果共享资源被占用,就需要一定的阻塞等待唤醒机制来保障锁的分配,这个机制主要是依托于CLH队列的变体实现的,将暂时获取不到锁的线程加入到了队列中 CLH:是单向链表,而AQS魔改了CLH,将其变成了虚拟双向队列,AQS通过将每条请求共享资源的线程封装成一个节点来实现锁的分配 AQS使用一个Volatile的int类型的成员变量来表示同步状态,通过内置的FIFO队列来完成资源获取的排队工作,通过CAS完成对STATE值的修改 说说AQS对类中的数据结构 12345678private class Node&#123; int waitStatus;//当前节点在对类中的状态 Thread thread;//线程的引用,表示处于该节点的线程 Node prev;//前驱指针 Node predecessor()&#123;&#125;//返回前驱节点 nextWaiter();//指向下一个处于`Condition`状态的指针 Node next;//next指针&#125; 什么是State变量? AQS中维护一个名为state的字段,含义是同步状态,可以通过修改State字段表示的同步状态来实现多线程的独占模式和共享模式,AQS定义两种资源的共享方式: Exclusive:独占模式,只有一个线程能够执行 Share:多个线程可以同时执行 如何实现一个自定义同步器? 12345tryAcquire(int);tryRelease(int);tryAcquireShared(int);tryReleaseShared(int);isHeldExclusively(); 模板设计通过设计这些钩子方法,来让子类完成具体的模板操作,自己只是完成定义而已 说说ReentrantLock的原理? ReentrantLock是如何加锁的? 当线程刚被new出来试图加锁的时候,就会使用aqs中的compareAndSet(0,1)来修改条件变量,如果能够修改成功,那么就将这个锁的持有者的ID修改为当前线程 如果线程加锁失败,那么就会重试一次,如果重试再不成功,那么就会进入一个addWaiter的逻辑 这个逻辑主要就是构建一个等待队列,如果初始时,AQS中的head == null,那么就会创建一条链表,这条链表上存储了当前因为加锁失败的线程所对应的节点,在这条链表上的线程节点会在一个死循环中不断尝试获取锁,失败后进入park()阻塞,如果自己是第二个节点,也就是实际链表的第一个节点,那么就会再次重试获取锁,如果获取锁失败了,那么就会将前一个节点的waitStatus = -1,这表示着,你的前一个节点有义务去唤醒你的后继节点 ReentrantLock是如何解锁的? 解锁的操作主要是将exclusiveOwnerThread设置为null,然后将state设置为0,或者是state-- 通过调用unlock()进行解锁,然后会调用内部类的Sync的Rekease方法,这个方法继承自AQS Release中会调用tryRelease(),需要自定义同步器实现,释放成功后,所有处理都是由AQS完成的 那么在这个操作中,实际上在底层的队列中,取得需要释放锁的节点,然后这个节点会显式地通知下一个节点解除阻塞,使得下一个线程检查到锁已经被释放了,最终就会导致锁的获取成了 ReentrantLock是如何实现可重入的? ReenttrantLock实现可重入的原理是通过修改底层的state变量来实现的 具体的流程是:当线程来获取锁的时候,如果还没有被加锁,那么就会使用CAS将STATE从0修改成1,然后接着当其他线程到来的时候,就会将当前线程包装成一个Node,这个Node中包含了一个线程的引用,以及当前线程的状态 然后当这个线程被获取锁失败的时候,就会将当前线程包装成Node,然后添加到尾部,然后将前一个线程的状态设置成-1,代表着,当前一个线程释放锁的时候,它要来显式地通知这个线程 那么在实现锁重入的时候,就会将AQS中的内置state变量执行++,然后在解锁的时候执行--,这是因为lock()和unlock()通常是成对出现的 这里的话讲述一下AQS队列是如何处理这种情况的,首先它会知道队列中距离这个head最近的第一个没有处于Cancel的节点,然后检查这个是不是空的,空的话意味着没有线程可以唤醒,结束 如果非空,并且这个节点的状态不是0,也就是说是-1,就是说它有义务去唤醒下一个线程的执行,那么它就会唤醒下一个节点,然后在这时候,如果加锁成功了,那么就会将原来的头节点删除,将当前的节点的值设置为null,顶上去作为新的头节点,通知成功 如果竞争失败了,也就是说是有竞争的表现,非公平的,那么就会保持不变,不会做任何的删除","categories":[{"name":"题库","slug":"题库","permalink":"http://kaillliu.github.io/categories/%E9%A2%98%E5%BA%93/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://kaillliu.github.io/tags/Java/"},{"name":"面试题","slug":"面试题","permalink":"http://kaillliu.github.io/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"name":"题库","slug":"题库","permalink":"http://kaillliu.github.io/tags/%E9%A2%98%E5%BA%93/"}]},{"title":"Java基础面试题回顾","slug":"Java基础面试题回顾","date":"2023-08-10T07:00:00.000Z","updated":"2023-09-08T04:10:52.180Z","comments":true,"path":"2023/08/10/Java基础面试题回顾/","link":"","permalink":"http://kaillliu.github.io/2023/08/10/Java%E5%9F%BA%E7%A1%80%E9%9D%A2%E8%AF%95%E9%A2%98%E5%9B%9E%E9%A1%BE/","excerpt":"","text":"Java中有哪些容器? Java的容器可以分为单值集合和键值对集合,这两种集合的父分别是Collection和Map这两大类 而Colletion又可以分为有List、Set这些都是存储一个元素的,其中,List一族的集合可以存储重复的元素,而Set不可以存储重复的元素,下面来讲讲具体的实现类 List的实现类有ArrayList、LinkedList、Vector、Stack Set的实现类有HashSet、TreeSet、LinkedHashSet Map的实现类有HashMap、LinkedHashMap、TreeMap、ConcurrentHashMap、HashTable 怎么选择这些集合? 首先按照存储对象分类,如果存储的对象是一个对象,也就是存储并不要求能使用&#123;key=&gt;value&#125;寻址的,那么在这样的情况下,就可以使用单值集合,这样又分为以下的情况 当存储的元素比较少删除同时插入都是在尾部的话,并且要满足以O(1)的时间查询的时候,这时候就可以用ArrayList 当存储的元素比较少删除同时插入都是在头部或者尾部的话,并且不经常查询中间的数据的时候,这时候就可以使用LinkedList了 当存储的元素是单值元素,并且在要求这个集合中只能够存储一个相同的元素的时候,这时候就要选用Set类的 当是普通的寻址查询的话,那么这时候使用HashSet就可以了 当要求遍历的时候要以插入的顺序遍历的时候,这时候使用LinkedHashSet就可以了 当要求集合中的元素是有序的时候,这时候就可以使用TreeSet了 当存储的元素需要满足某些特定的规则,比如说先进先出,后进先出这样的规则的时候,就需要使用队列或者是栈结构了 Collcetion和Collcetions有什么区别? Collection是一个接口,它定义了集合容器的基本操作,比如说add()、size()这些都是由它来抽象定义类的 Collcetions是一个包装类,包含有很多静态的方法,无法被实例化,可以对执行排序Collections.sort(list) 讲讲List/Set/Map有什么区别? 这三个集合的区别主要可以从以下方面进行讲述,元素是否有序?是否允许元素重复? 首先先来讲讲有序是啥意思?有序就是说元素在集合中存储的顺序它是按照插入顺序的,List可以保证插入的元素是有序的,同时允许元素重复,Set的话它的实现思路通常是基于hash()来实现的,因此存储的顺序通常不是由插入顺序来决定的,而是由hashCode()来实现的,但是也可以通过链表的方式,通过链表寻址的方式来确定这些方式,而Map的话它也是无序的,为什么无序和Set为什么无序是一样的 接着来讲讲是否允许元素重复,直接说结论,List可以重复,而Set和Map是不可重复的 这和add()和put()的逻辑有关,add()的话通常来说就是分配一块新的内存空间,然后将数据存进去 而put()的逻辑则是计算一个hash(),然后根据这个hash()来计算下标来决定你这个东西要放到哪里,姑且不谈hashCode()相同的场景,在相同的hash()的情况下,你的这个值是会被覆盖,具体逻辑是:当put()一个元素的时候,如果当前位置上没有这个key,那么就新建插入,否则就覆盖了 HashMap和HashTable的区别 主要的区别可以从三个方面进行讲述: (1)第一个方面可以从线程安全方面进行讲述,HashMap是线程不安全的,而HashTable是线程安全的,这是因为HashMap默认并且推荐在单线程环境下使用,因此对于多线程并发操作没有做任何的保护,而HashTable底层因为对每一个方法使用了synchronized()关键字进行修饰,因此在这样的情况下,它是线程安全的 (2)第二方面可以从键值对的存储的角度上进行讲述,HashMap可以存储空key和空value,而HashTable不能够存储空key和空value 原因是什么? 这是因为在多线程环境下,空key和空value会造成歧义,当get(key)这个方法的时候,如果这时候返回一个null的时候,这时候会有两种情况: 本来就不存在你这个key=&gt;value的映射 你有这个key=&gt;value的映射,但是value为null 那么这时候就要调用containsKey(key)来判断你的key是否存在了,如果这时候有一个线程调用了put(key,null)的方法,那么这时候就会导致一个问题 如果线程并发下,如果先执行了containsKey(key),再执行put(key,value),这时候就会返回false 如果先执行了put(key,value),再执行containsKey(key),那么就会返回true 这时候就产生了歧义了,产生了并发测试环境下,代码路径的不稳定性,解决办法也简单,就是在代码块中加入synchronized来确保原子性 问题,那么为什么HashMap又允许你这个key,value为空呢?这样就不会产生歧义了么? 由于是单线程,那么在判断contains(key)的时候,这时候就不会产生歧义,包含就是包含,代码的执行逻辑是稳定的 LinkedHashMap是什么?是如何实现的? LinkedHashMap继承自HashMap,因此它本质上还是一个HashMap,但是我们知道,你这个HashMap中的元素组织起来是无序的,它的底层还是基于数组+红黑树来实现的,LinkedHashMap在这个基础上,将你的HashMap中的元素根据插入顺序,组织成了一个双向链表,在遍历的时候,只需要获取到头部元素,就可以遍历到全表了 如何确定使用HashMap和TreeMap? 对于在Map中插入、删除、定位一个元素这种操作,HashMap是最好的选择,因为相对而言,HashMap的插入会更快一些,但是如果对一个key需要实现一个有序的遍历,那么TreeMap就最好了 总结一下:就是需要实现一个&#123;key=&gt;value&#125;的映射,同时你需要在遍历的时候,要按照你定义的规则进行排序,这样的话最好就使用这个了 讲讲HashMap的实现原理是怎么样的? 简单讲一下,首先从HashMap的底层实现来看,它的底层是基于数组+链表/红黑树实现的,后面讲的这个链表就是用来解决哈希冲突的,HashMap最关键的两个方法就是put()和get()方法,通过这两个方法的实现逻辑,我们就可以知道它的原理是怎么样的 put()流程,首先先对输入的key进行一个key.hashCode()的计算,然后通过一个叫做扰动函数的处理后,得到一个hash值,通过这个hash值来确定你这个元素要存放在数组中的哪个位置上 如果发现你这个数组这个位置上的这个bucket不是空的,那么就要遍历这个链表或者红黑树,如果上面有元素和当前的key是相同的,那么就覆盖这个value 如果发现你这个数组这个位置上的这个bucket是空的,那么就直接插入 get()流程,首先对输入的key执行相同的操作,也就是说先进行一个key.hashCode()，然后同一个叫做扰动函数的处理,得到一个hash,根据你这个值来确定你这个元素在哪个位置上,如果有链表,那么就顺着查,如果顺着查有key'==key 的话,那么就直接返回,否则遍历完返回空 说说红黑树的转换逻辑 转换逻辑会有两个参数,第一个参数是单个链表中的长度阈值,第二参数是数组的长度 将链表转换成红黑树之前会先判断,如果当前数组的长度小于了64,那么就会先进行数组扩容,而不是转换为红黑树 将链表转换为红黑树,条件是这样:当数组的长度大于等于64,并且当前看表的长度大于8,就会变化成红黑树 当树中的元素小于6的时候,又会退化为链表 讲讲这些参数的由来 首先第一个6-8这个参数怎么来的 还有选择6和8，中间有个差值7可以有效防止链表和树频繁转换。假设一下，如果设计成链表个数超过8则链表转换成树结构，链表个数小于8则树结构转换成链表，如果一个HashMap不停的插入、删除元素，链表个数在8左右徘徊，就会频繁的发生树转链表、链表转树，效率会很低。 如果 hashCode 分布良好，也就是 hash 计算的结果离散好的话，那么红黑树这种形式是很少会被用到的，因为各个值都均匀分布，很少出现链表很长的情况。在理想情况下，链表长度符合泊松分布，各个长度的命中概率依次递减，当长度为 8 的时候，概率仅为 0.00000006。这是一个小于千万分之一的概率，通常我们的 Map 里面是不会存储这么多的数据的，所以通常情况下，并不会发生从链表向红黑树的转换。 HashSet是如何检查重复的 在JDK1.8的源码中,HashSet的add()方法只是简单的调用了HashMap的put()方法,并且判断了一下返回值,将是否有重复元素的反馈到用户 12345public boolean add(E e)&#123; return map.put(e,PRESENT) == null; // 这个意思就是讲,当有重复元素的时候就返回false的 // 然后覆盖掉这个对象&#125;","categories":[{"name":"题库","slug":"题库","permalink":"http://kaillliu.github.io/categories/%E9%A2%98%E5%BA%93/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://kaillliu.github.io/tags/Java/"},{"name":"面试题","slug":"面试题","permalink":"http://kaillliu.github.io/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"name":"题库","slug":"题库","permalink":"http://kaillliu.github.io/tags/%E9%A2%98%E5%BA%93/"}]},{"title":"三个线程如何交替打印 0 - 100？","slug":"三个线程交替打印","date":"2023-08-09T07:00:00.000Z","updated":"2023-09-08T04:08:34.128Z","comments":true,"path":"2023/08/09/三个线程交替打印/","link":"","permalink":"http://kaillliu.github.io/2023/08/09/%E4%B8%89%E4%B8%AA%E7%BA%BF%E7%A8%8B%E4%BA%A4%E6%9B%BF%E6%89%93%E5%8D%B0/","excerpt":"","text":"Java多线程 三个线程如何交替打印 0 - 100？ 主要考察多线程的**==线程安全==**和==等待唤醒==机制 解法： synchronized + wait / notifyAll ReentrantLock + await / signalAll ReentrantLock + await / signal 思路 判断当前打印数字和线程数的取余，**==不等于==**当前线程数则处于等待状态。 每次循环结束==唤醒所有等待==线程 代码例子 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647@Log4j2public class PrintExample &#123; private static final Object LOCK = new Object(); private static final int THREAD_COUNT = 3; private static volatile int start = 0; private static final int END = 100; private static class Print implements Runnable &#123; private final int index; public Print(int index) &#123; this.index = index; &#125; @Override public void run() &#123; while (start &lt; END) &#123; synchronized (LOCK) &#123; while (start % THREAD_COUNT != index) &#123; try &#123; LOCK.wait(); &#125;catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; if (start &lt;= END) &#123; log.info(&quot;Thread&#123;&#125; 打印结果：&#123;&#125;&quot;, index + 1, start); &#125; start++; LOCK.notifyAll(); &#125; &#125; &#125; &#125; public static void main(String[] args) &#123; for(int i = 0; i &lt; THREAD_COUNT; i++) &#123; new Thread(new Print(i)).start(); &#125; &#125; &#125; 在LOCK.wait()方法之后的代码，包括if (start &lt;= END)判断条件、日志输出、start++自增和LOCK.notifyAll()方法，只有在线程被唤醒后才会执行。这意味着这段代码不会在调用LOCK.wait()的线程处于等待状态时执行。而是在被唤醒后，重新获得锁之后执行。 简而言之，LOCK.wait()方法之后的代码需要等待其他线程的唤醒才能执行。","categories":[{"name":"题库","slug":"题库","permalink":"http://kaillliu.github.io/categories/%E9%A2%98%E5%BA%93/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://kaillliu.github.io/tags/Java/"},{"name":"面试题","slug":"面试题","permalink":"http://kaillliu.github.io/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"name":"题库","slug":"题库","permalink":"http://kaillliu.github.io/tags/%E9%A2%98%E5%BA%93/"},{"name":"多线程","slug":"多线程","permalink":"http://kaillliu.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"Spring 知识总结","slug":"Spring","date":"2023-08-08T07:00:00.000Z","updated":"2023-09-08T04:06:13.612Z","comments":true,"path":"2023/08/08/Spring/","link":"","permalink":"http://kaillliu.github.io/2023/08/08/Spring/","excerpt":"","text":"什么是Spring框架 Spring是一款开源的Java开发框架,旨在于提高开发人员的效率,它是很多模块的集合,使用这些模块可以很方便地协助进行开发,基于IoC(Inversion of Control)控制反转和AOP(Aspect-Oriented Programming)面向切面编程,可以很方便地对数据库进行访问,可以很方便地集成第三方组件,支持RestfultJava应用程序的开发 Spring通过其内置的IoC和AOP功能实现了这些功能集成的开箱即用的特性 Spring中包含了什么模块? 两大核心模块:AOP+IoC,而AOP是依赖于IoC执行的。 Spring-core:这是Spring框架最基础的部分,它提供了依赖注入DI特征来实现容器对Bean的管理,核心容器的主要组件就是BeanFactory,是任何Spring应用的核心,它将IoC将应用配置和依赖从实际的应用代码中分离出来了。 Spring-Context:如果说BeanFactory使得Spring成为容器的话,那么上下文模块就是Spring成为框架的原因。因为它扩展了BeanFactory,增加了对国际化消息，事件传播、验证的支持。 SpringAOP:Spring在它的AOP模块中提供了面向切面编程的丰富支持,SpringAOP模块为基于Spring的应用程序提供了事务管理服务,提供使用SpringAOP,不用依赖于组件，就可以将声明性事务集成到应用程序中。可以自定义拦截器、切点、日志等操作 SpringDAO：提供了JDBC的抽象层和异常层次结构，消除了繁琐的JDBC编码和数据库厂商特有的错误代码解析，用于简化JDBC SpringORM:Spring提供了ORM模块,Spring并不试图实现自己的ORM方案，而是为ORM框架提供了集成方案 SpringWebMVC:Spirng为构建web应用提供了一个功能完全的MVC框架,使用IoC对控制逻辑和业务对象提供了完全的分离 SpringWebFlux模块:SpringFramework支持反映流ReactiveStream背压 Spring、SpringMVC、SpringBoot之间的关系 Spring:包含了多个功能模块,其中最重要的是Spring-core(主要提供了IoC依赖注入功能的支持),Spring中的其他模块(例如Spring MVC)的功能基本都需要依赖于这个模块 SpringMVC:是Spring中一个很重要的模块,主要赋予了Spring快速构建MVC应用程序的能力,MVC是Model、View、Controller的简写,其核心思想是通过将业务逻辑、数据、显示分离来组织代码 SpringBoot的出现简化了Spring的配置,如果需要构建MVC架构的Web程序,那么还是需要使用MVC作为框架,但是SpringBoot为我们简化了MVC中的很多配置 对SpringIoC的理解 IoC(Inversion of Control)控制翻转:它是一种控制思想,而不是一个具体的技术实现,IoC思想简单来说就是将程序中手动创建对象的控制权,交给Spring框架来管理 控制翻转 控制:指的是对象创建(实例化、管理)的权利 反转:控制权交给外部环境(Spring框架、IoC容器) 将对象之间的相互依赖关系交给IoC容器来管理,并且由IoC容器完成对象的注入,这样可以很大程度上简化应用的开发,把应用从复杂的依赖关系中解放出来,IoC容器就像一个工厂一样,当我们需要创建一个对象的时候,只需要配置好配置文件/注解即可,完全不用考虑对象是如何被创建出来的 在实际项目中一个Service类可能依赖了很多其他的类,假如我们需要实例化这个Service,可能需要每次都搞清楚这个Service所有底层类的构造函数,如果利用IoC的话,就只需要配置好,你的这个Service需要哪些实例作为依赖,然后在需要地方引用就可以了,增加了项目的可维护性而且降低了开发难度 1IoC`容器本质上就是一个`Map`,这个`Map`是以`&#123;name&#125; =&gt; &#123;bean&#125;`作为键值对格式的一个`Map`,`Spring`我们一般通过`XML`配置来配置`Bean`,后来`SpringBoot`就以一种简略的`注解配置`来替代了`XML配置 谈谈对SpringBean的理解 简单来说,Bean就是那些被IoC容器所管理的对象,我们需要告诉IoC容器要注册那些对象,这个是通过配置元数据来实现的,配置元数据可以是XML文件、注解或者Java配置类 如何将一个类声明为Bean @Component:通用的注解,可以标注任意一个 Spring组件,如果一个Bean不知道属于哪个层,就可以使用@Component注解标注 @Repository:对应持久层也就是DAO层,主要用来执行对数据库的操作 @Service:对应服务层,主要涉及一些复杂的逻辑,需要使用到DAO @Controller:对应SpringMVC控制层,主要用来接收用户的请求并且调用Service层返回数据给前端页面 @Component和@Bean的区别是什么? @Component注解是用在类上的,而@Bean是用在方法上的 SpringIoC容器管理一个或者多个Bean,这些Bean都需要在@Configuration注解下进行创建,在一个方法下使用@Bean注解就表明这个方法需要交给Spring进行管理 @Bean是一个方法级别上的注解,添加的beanId为方法名 @Component通常是通过类路径扫描来自动侦测以及自动装配到Spring容器中,可以使用@ComponentScan注解定义要扫描的路径,从中找出表示了需要装配的类,自动装配到Spring的容器中,@Bean注解通常是我们在标有该注解的方法中定义这个bean,@Bean告诉了Spring容器这是某个类的实例,当需要使用到的时候,就将这个Bean返回来 @Bean注解比@Component注解的自定义性更强,而且很多地方都只能够通过@Bean来实现Bean的注册 @Autowired和@Resource的区别是什么? 1Autowired`属于是Spring的内置注解,默认的注入方式为`byType(根据类型进行注入)`,也就是说会优先根据接口类型去匹配并且注入`Bean(接口的实现类) byType的最大问题在于,当接口存在多个实现类的话,byType这种方式就无法正确注入对象了,因为这时候Spring会同时找到多个满足条件的选择,默认情况下它不知道选择哪一个 这种情况下,Autowired的注入方式会自动变成byName,这个名称通常就是类名首字母小写 比如说有这样的实现类 12345678910111213141516class SmsServiceImpl1 implements SmsService&#123;&#125;class SsmServiceImpl2 implements SmsService&#123;&#125;//正确注入了对象@Autowiredprivate SmsService smsServiceImpl1;//没有正确注入对象@Autowiredprivate SmsService smsService;//可以使用@Qualified@Autowired@Qualifier(value = &quot;smsServiceImpl1&quot;)private SmsService smsService;@Resource`是属于`JDK`提供的注解,默认的注入方式为`byName`,如果无法通过名称匹配到对应的`Bean`的话,注入方式会变成`byType 1234public @interface Resource &#123; String name() default &quot;&quot;; Class&lt;?&gt; type() default Object.class;&#125; 使用方法 123456@Resource private SmsService smsService;//byName和byType都无法匹配到Bean@Resourceprivate SmsService smsServiceImpl1;//可以正确注入@Resource(name = &quot;smsServiceImpl1&quot;)private SmsService smsService;//可以正确注入 简单总结 @Autowired是Spring提供的注解,@Resource是JDK提供的注解 @Autowired默认的注入方式为byType(根据类型进行匹配),当有多个候选的话,就会转换为byName,@Resource默认注入的方式为byName(根据名字进行匹配),在byName不成功后,才会byType 当一个接口存在多个实现类,@Autowired和@Resource都需要通过名称才能正确匹配到对应的Bean,@Autowired可以通过@Qualified注解来显式指定名称,@Resource可以通过name来显式指定名称 Bean的作用域有哪些? singleton:IoC容器中只有唯一的bean实例,Spring中的bean默认都是单例的,是对单例设计模式的使用 prototype:每次获取都会创建一个新的bean实例,也就是说,连续getBean()两次,得到的bean实例是不一致的 request(Web服务):每一次的HTTP请求都会产生一个新的bean(请求bean),这个bean仅在当前HTTP request内有效 session(Web服务):每一次来自新Session的Http请求都会产生一个新的bean(会话bean),该bean仅在当前HTTP session内有效 application/global-session(Web服务):每一个Web应用在启动的时候创建一个bean(应用该Bean),该Bean仅在当前应用启动时间内有效 websocket:每一次webSocket会话都会产生一个新的bean 单例Bean存在线程安全问题吗? 大部分时候我们并没有在项目中使用多线程,因此很少会有人关注这个问题,单例Bean存在线程安全问题,主要是因为多个线程操作同一个对象的时候是存在资源的竞争的 常见的有两种解决办法: 在Bean中尽量避免定义可变的成员变量 在类中定义一个ThreadLocal成员变量,将需要的可变成员变量保存在ThreadLocal中 不过大部分的Bean都是无状态的,也就是说没有实例变量,在这种情况下Bean是线程安全的 Bean的生命周期说一下 首先Bean它首先是一个普通的Java对象,那么Java对象的初始化大致可以划分为: 类加载检查(如果类被加载过了,那么就不需要加载了,否则就会进入类的初始化流程)=&gt;根据对象所属于的类,为这个对象分配内存空间,通常来说有指针碰撞法和空闲链表法,在对象内存分配完毕后,先会设置对象头,比如说设置它的hashcode()等=&gt;然后将对象的内存空间对应的变量设置为0值=&gt;然后执行方法=&gt;对象投入使用=&gt;被GC,因此大致就是实例化=&gt;该对象不再使用的时候被GC 而对于SpringBean来说,就是 1实例化=&gt;属性赋值=&gt;初始化=&gt;销毁 可以这样进行描述,首先对bean进行初始化,需要设定一个init-method(),然后在配置文件中显式的配置它,接着对于bean的优雅删除策略,需要设定一个destory-method() 那么在Bean的初始化过程中,它首先设置了两个切入点,一个切入点是Bean后处理器before()方法,这个方法设定在init()之前实现,然后在init()之后,还设定了Bean后处理器的after()方法 然后在执行init()方法之前还会执行initalizing方法 同时,对于这个Bean的一些基础属性,比如说设定Bean的名称,它是在Bean后处理器before()之前执行的,通过一些专属接口比如说BeanNameAware、BeanClassLoaderAware等这些接口来实现 在初始化完毕后,就会投入使用,当Bean下线的时候,会有两个动作,第一个动作是先检查是否实现DisposableBean接口,然后执行destory(),当要销毁Bean的时候,如果Bean在配置文件中定义包含有destory-method属性的时候,就会执行指定的方法 谈谈对SpringAOP的理解 AOP的作用主要是将我们在业务开发中的那些横向交叉业务进行分离,什么叫横向交叉业务? 就是那些与实际的业务无关,但是却必须在业务模块编写相关的业务代码,比如说日志,在执行之前都要执行日志的记录,比如说事务的开启,在执行数据库操作之前选择是否开启事务,在业务结束之后提交事务,权限控制,在某段特定的业务代码执行之前要判断这个代码的执行者是否有权限。 这样的话可以减少系统的重复代码,降低模块间的耦合度,并且有利于未来的扩张和维护 Spring AOP是基于动态代理实现的,如果要带代理的对象实现了某个接口,那么Spring AOP就会使用JDK Proxy,去创建一个代理对象,而对于没有实现接口的对象,就无法使用JDK Proxy去代理了,此时Spring AOP就会使用CG lib去生成一个被代理对象的子类来作为代理 连接点 Joinpoint 在程序的整个执行流程中，可以织入切面的位置。方法的执行前后，异常抛出之后等位置。 切点 Pointcut 在程序执行流程中，真正织入切面的方法。（一个切点对应多个连接点） 通知 Advice 通知又叫增强，就是具体你要织入的代码。 通知包括： 前置通知 后置通知 环绕通知 异常通知 最终通知 切面 Aspect 切点 + 通知就是切面。 织入 Weaving 把通知应用到目标对象上的过程。 代理对象 Proxy 一个目标对象被织入通知后产生的新对象。 目标对象 Target SpringAOP和AspectJ AOP有什么区别 SpringAOP属于是运行时增强,AspectJ是编译时增强,SpringAOP基于代理实现的,而AspectJ是基于字节码操作实现的,SpringAOP已经集成了AspectJ,如果切面太多了最好使用AspectJ,它比SpringAOP要快很多 AspectJ定义的通知类型有哪些? Before(前置通知) After(后置通知) AfterReturning(返回通知):目标对象的方法调用完成,返回结果值之后触发 AfterThrowing(异常通知):目标方法的对象在运行中抛出/触发异常后触发 Around(环绕通知) 切面的执行顺序如何控制 @Order 实现Ordered 谈谈你对SpringMVC的理解 可以这样说,SpringMVC是Spring全家桶中对MVC架构实现得最淋漓尽致的一个框架 要谈到SpringMVC,那么就必须要先了解什么是MVC,MVC机制是这样的: Model:是数据层,在开发中就是处理数据/或者数据本身的组件,比如说DAO/Service等 View:负责将产生的数据回显给用户,通过页面或者其他形式渲染数据,不负责数据的产生 Controller:它是MVC架构的核心,实际上它并不参与实际数据的操作,而是说起到一个中转站的作用,它负责解析用户的请求,选定要用什么样的逻辑来处理这些请求参数,然后交给Model层来处理数据,等到Model层返回数据后,将这些做好的数据返回给view,然后view渲染数据即可 一般来说,MVC架构在开发体现为三层架构 第一层:View层,也就是前面的页面 第二层:Service层,负责具体的业务的处理,不涉及到底层数据的操作 第三层:DAO层,负责具体的数据的处理,它负责与DB操作 第四层:DB,负责具体的数据的持久化工作 SpringMVC的核心组件有哪些? 它的核心组件其实也是围绕着Servlet来进行布局的,首先是Controller DispatcherServlet:核心的中央处理器,它的作用是将来自用户的请求进行分发,并且将解析完成的数据完成分发 HandlerMapping:在一个Web服务中,通常会有很多的URI,那么如何来确定这些URI所对应的具体处理逻辑?此时就需要一个容器,通过这个容器就能够找到对应的处理器,然后基于这个处理器来执行相关的操作 HandlerAdapter:它是适配器,简单来说就是基于Handler和HandlerMapping之间的桥梁,通常的逻辑就是中央控制器通过查询HandlerMapping查询到了具体的Handler,然后将参数等信息交给HandlerAdapter,由这个组件完成参数的相关封装,然后将参数传给Handler使用 Handler:真正业务逻辑的处理者,负责接收来自Adapter的请求,并且将数据返回回去 ViewResolver:视图解析器,根据Handler返回的逻辑视图/视图,解析并渲染真正的视图,并且渲染真正的视图,并且传递给DispatcherServlet SpringMVC的执行流程是怎么样的? 首先是客户端发送一个HTTP请求,然后Dispatcher就拦截到了这个请求,然后Dispatcher拿着这个请求所对应的URL,去查找内部的HandlerMapping,然后就会找到这个URL所对应的Handler以及一系列的拦截器 接着Dispatcher就会将这个请求的相关参数给到HandlerAdapter,这个适配器会将相关的参数进行封装,将封装好的参数传递给具体的Handler,Handler完成这些操作之后,会产生一个ModelAndView,这个包含了具体的数据模型和逻辑视图,逻辑视图并不是用户看到的真正的视图,而是这个视图的一部分,因此Dispatcher就还要将这个ModelAndView基于ViewResolve解析成真正的视图,接着还要完成Model的渲染,也就是具体的数据体现,它会将数据传给View,由View将数据渲染上去,最终将View返回给用户 为什么SpringMVC要这样设计? 这是因为一个Web服务非常复杂,比如说,基于HTTP协议传输的话,那么在HTTP/1.0的时候,里面的数据都是文本类型的,那么如果只有简单的三层结构,比如说Controller负责将请求丢给Service完事,那么Service就要负责将一个String解析成对象,还要将计算出来的结果转换为String,然而,这些和业务完全没有关系,那么能否提供一个中间层,它可以在Service都没有察觉的情况下,就将前台的参数转换为Service想要的参数,然后将Serivce计算结果转换成想要的结果呢? 这就是引入HandlerAdapter以及各种解析器原因了 统一异常处理要怎么做? 统一的异常处理通常是通过AOP+提前注册的Handler实现的 AOP是基于捕获到异常的通知实现的,当捕捉到异常后,就会执行相关的Handler方法","categories":[{"name":"知识点梳理","slug":"知识点梳理","permalink":"http://kaillliu.github.io/categories/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://kaillliu.github.io/tags/Java/"},{"name":"知识点梳理","slug":"知识点梳理","permalink":"http://kaillliu.github.io/tags/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86/"},{"name":"Spring","slug":"Spring","permalink":"http://kaillliu.github.io/tags/Spring/"},{"name":"题库","slug":"题库","permalink":"http://kaillliu.github.io/tags/%E9%A2%98%E5%BA%93/"}]},{"title":"Redis 知识总结","slug":"Redis","date":"2023-08-07T07:00:00.000Z","updated":"2023-09-08T04:04:24.930Z","comments":true,"path":"2023/08/07/Redis/","link":"","permalink":"http://kaillliu.github.io/2023/08/07/Redis/","excerpt":"","text":"Redis 一个基于 C 语言开发的开源数据库（BSD 许可），与传统数据库不同的是 Redis 的数据是存在内存中的（内存数据库），读写速度非常快，被广泛应用于缓存方向。并且，Redis 存储的是 KV 键值对数据。 为什么快 Redis 基于内存，内存的访问速度是磁盘的上千倍； Redis 基于 Reactor 模式设计开发了一套高效的事件处理模型，主要是单线程事件循环和 IO 多路复用（Redis 线程模式后面会详细介绍到）； Redis 内置了多种优化过后的数据结构实现，性能非常高。 分布式锁的应具备的条件 互斥：任意一个时刻，锁只能被一个线程持有。 高可用：锁服务是高可用的，当一个锁服务出现问题，能够自动切换到另外一个锁服务。并且，即使客户端的释放锁的代码逻辑出现问题，锁最终一定还是会被释放，不会影响其他线程对共享资源的访问。这一般是通过超时机制实现的。 可重入：一个节点获取了锁之后，还可以再次获取锁。 除了上面这三个基本条件之外，一个好的分布式锁还需要满足下面这些条件： 高性能：获取和释放锁的操作应该快速完成，并且不应该对整个系统的性能造成过大影响。 非阻塞：如果获取不到锁，不能无限期等待，避免对系统正常运行造成影响。 分布式锁的常见实现方式有哪些？ 基于关系型数据库比如 MySQL 实现分布式锁。 基于分布式协调服务 ZooKeeper 实现分布式锁。 基于分布式键值存储系统比如 Redis 、Etcd 实现分布式锁。 关系型数据库的方式一般是通过唯一索引或者排他锁实现。不过，一般不会使用这种方式，问题太多比如性能太差、不具备锁失效机制。 基于 ZooKeeper 或者 ==Redis== 实现分布式锁这两种实现方式要用的更多一些，我专门写了一篇文章来详细介绍这两种方案：分布式锁常见实现方案总结。 基于Redis实现分布式锁 在 Redis 中， SETNX 命令是可以帮助我们实现互斥。SETNX 即 ==SET if Not eXists== (对应 Java 中的 setIfAbsent 方法)，如果 key 不存在的话，才会设置 key 的值。如果 key 已经存在， SETNX 啥也不做 释放锁的话，直接通过 DEL 命令删除对应的 key 即可。 这种方式实现分布式锁存在一些问题。就比如应用程序遇到一些问题比如释放锁的逻辑突然挂掉，可能会导致锁无法被释放，进而造成共享资源无法再被其他线程/进程访问。 为了避免锁无法被释放，我们可以想到的一个解决办法就是：给这个 key（也就是锁） 设置一个==过期时间== 。 一定要保证设置==指定 key 的值和过期时间是一个原子操作==！！！ 不然的话，依然可能会出现锁无法被释放的问题。 这样确实可以解决问题，不过，这种解决办法同样存在漏洞：如果操作==共享资源的时间==大于==过期时间==，就会出现==锁提前过期==的问题，进而导致==分布式锁直接失效==。如果锁的==超时时间设置过长==，又会影响到性能。 你或许在想：如果操作共享资源的操作还未完成，锁过期时间能够==自己续期==就好了！ Redisson Redisson 中的分布式锁自带自动续期机制，使用起来非常简单，原理也比较简单，其提供了一个专门用来监控和续期锁的 Watch Dog（ 看门狗），如果操作共享资源的线程还未执行完成的话，Watch Dog 会不断地延长锁的过期时间，进而保证锁不会因为超时而被释放。 只有未指定锁超时时间，才会使用到 Watch Dog 自动续期机制。 集群环境下分布式锁的问题和实现 Redlock 算法的思想是让客户端向 Redis 集群中的多个独立的 Redis 实例依次请求申请加锁，如果客户端能够和半数以上的实例成功地完成加锁操作，那么我们就认为，客户端成功地获得分布式锁，否则加锁失败。 Redlock 实现比较复杂，性能比较差，发生时钟变迁的情况下还存在安全性隐患。实际项目中不建议使用 Redlock 算法，成本和收益不成正比。 Redis 数据结构 Redis 常用的数据结构有哪些？ ==5 种==基础数据结构：String（字符串）、List（列表）、Set（集合）、Hash（散列）、Zset（有序集合）。 3 种特殊数据结构：HyperLogLogs（基数统计）、Bitmap （位存储）、Geospatial (地理位置)。 String String 是一种二进制安全的数据结构，可以用来存储任何类型的数据比如字符串、整数、浮点数、图片（图片的 base64 编码或者解码或者图片的路径）、序列化后的对象。 应用场景 需要==存储常规数据==的场景 举例：缓存 session、token、图片地址、序列化后的对象(相比较于 Hash 存储更节省内存)。 相关命令：SET、GET。 需要==计数==的场景 举例：用户单位时间的请求数（简单限流可以用到）、页面单位时间的访问数。 相关命令：SET、GET、 INCR、DECR 。 ==分布式锁== 利用 SETNX key value 命令可以实现一个最简易的分布式锁（存在一些缺陷，通常不建议这样实现分布式锁） List Redis 中的 List 其实就是链表数据结构的实现 通过 LRANGE 查看对应下标范围的列表元素： 通过 LRANGE 命令，可以基于 List 实现分页查询，性能非常高 应用场景 ==信息流展示== 举例：最新文章、最新动态。 相关命令：LPUSH、LRANGE。 消息队列 Redis List 数据结构可以用来做消息队列，只是功能过于简单且存在很多缺陷，不建议这样做。 相对来说，Redis 5.0 新增加的一个数据结构 Stream 更适合做消息队列一些，只是功能依然非常简陋。和专业的消息队列相比，还是有很多欠缺的地方比如消息丢失和堆积问题不好解决。 Hash（哈希） Redis 中的 Hash 是一个 String 类型的 field-value（键值对） 的映射表，特别适合用于存储对象，后续操作的时候，你可以直接修改这个对象中的某些字段的值。 Hash 类似于 JDK1.8 前的 HashMap，内部实现也差不多(数组 + 链表)。不过，Redis 的 Hash 做了更多优化。 应用场景 对象数据存储场景 举例：用户信息、商品信息、文章信息、购物车信息。 相关命令：HSET （设置单个字段的值）、HMSET（设置多个字段的值）、HGET（获取单个字段的值）、HMGET（获取多个字段的值） Set Redis 中的 Set 类型是一种无序集合，集合中的元素没有先后顺序但都唯一，有点类似于 Java 中的 HashSet 可以基于 Set 轻易实现==交集==、==并集==、==差集==的操作，比如你可以将一个用户所有的关注人存在一个集合中，将其所有粉丝存在一个集合。这样的话，Set 可以非常方便的实现如共同关注、共同粉丝、共同喜好等功能。这个过程也就是求交集的过程。 应用场景 需要存放的数据不能重复的场景 举例：网站 UV 统计（数据量巨大的场景还是 HyperLogLog更适合一些）、文章点赞、动态点赞等场景。 相关命令：SCARD（获取集合数量） 需要获取多个数据源交集、并集和差集的场景 举例：共同好友(交集)、共同粉丝(交集)、共同关注(交集)、好友推荐（差集）、音乐推荐（差集）、订阅号推荐（差集+交集） 等场景。 相关命令：SINTER（交集）、SINTERSTORE （交集）、SUNION （并集）、SUNIONSTORE（并集）、SDIFF（差集）、SDIFFSTORE （差集） Sorted Set（有序集合） Sorted Set 类似于 Set，但和 Set 相比，Sorted Set 增加了一个==权重参数==score，使得集合中的元素能够按 score 进行有序排列，还可以通过 score 的范围来获取元素的列表。有点像是 Java 中 HashMap 和 TreeSet 的结合体 应用场景 需要随机获取数据源中的元素==根据某个权重进行排序==的场景 举例：各种排行榜比如直播间送礼物的排行榜、朋友圈的微信步数排行榜、王者荣耀中的段位排行榜、话题热度排行榜等等。 相关命令：ZRANGE (从小到大排序)、 ZREVRANGE （从大到小排序）、ZREVRANK (指定元素排名 需要存储的数据有==优先级==或者==重要程度==的场景 举例：优先级任务队列。 相关命令：ZRANGE (从小到大排序)、 ZREVRANGE （从大到小排序）、ZREVRANK (指定元素排名) String 还是 Hash 存储对象数据更好呢？ String 存储的是序列化后的对象数据，存放的是整个对象。Hash 是对对象的每个字段单独存储，可以获取部分字段的信息，也可以修改或者添加部分字段，节省网络流量。 如果对象中**==某些字段==需要==经常变动==或者经常需要==单独查询==对象中的==个别字段==**信息，Hash 就非常适合。 String 存储相对来说更加==节省内存==，缓存相同数量的对象数据，String 消耗的内存约是 Hash 的一半。并且，存储具有多层嵌套的对象时也方便很多。如果系统对性能和资源消耗非常敏感的话，String 就非常适合。 在绝大部分情况，我们建议使用 ==String== 来存储对象数据即可 购物车信息用 String 还是 Hash 存储更好呢? 由于购物车中的商品频繁修改和变动，购物车信息建议使用 Hash 存储： 用户 id 为 key 商品 id 为 field，商品数量为 value 那用户购物车信息的维护具体应该怎么操作呢？ 用户添加商品就是往 Hash 里面增加新的 field 与 value； 查询购物车信息就是遍历对应的 Hash； 更改商品数量直接修改对应的 value 值（直接 set 或者做运算皆可）； 删除商品就是删除 Hash 中对应的 field； 清空购物车直接删除对应的 key 即可。 使用 Redis 实现一个排行榜怎么做？ Redis 中有一个叫做 sorted set 的数据结构经常被用在各种排行榜的场景 使用 Set 实现抽奖系统怎么做？ 如果想要使用 Set 实现一个简单的抽奖系统的话，直接使用下面这几个命令就可以了： SADD key member1 member2 ...：向指定集合添加一个或多个元素。 SPOP key count：随机移除并获取指定集合中一个或多个元素，适合不允许重复中奖的场景。 SRANDMEMBER key count : 随机获取指定集合中指定数量的元素，适合允许重复中奖的场景。 💠Redis 持久化机制 快照（snapshotting，==RDB==） 只追加文件（append-only file, ==AOF==） RDB 和 AOF 的混合持久化(Redis 4.0 新增) RDB （快照） Redis 可以通过**创建==快照==**来获得存储在内存里面的数据在 某个时间点 上的副本。 对快照进行备份，可以将快照复制到其他服务器从而创建具有相同数据的服务器副本（Redis ==主从结构==，主要用来提高 Redis 性能） 可以将快照留在原地以便重启服务器的时候使用 Redis默认设置 RDB 创建快照时会阻塞主线程吗？ Redis 提供了两个命令来生成 RDB 快照文件： save : 同步保存操作，会阻塞 Redis 主线程； bgsave : fork 出一个子进程，子进程执行，不会阻塞 Redis 主线程，默认选项。 AOF持久化 与快照持久化相比，AOF **持久化的==实时性==**更好。默认情况下 Redis 没有开启 AOF（append only file）方式的持久化（Redis 6.0 之后已经默认是开启了），可以通过 appendonly 参数开启 1appendonly yes AOF 工作基本流程是怎样的？ AOF 持久化功能的实现可以简单分为 5 步： 命令追加（append）：所有的写命令会追加到 **AOF ==缓冲区==**中。 文件写入（write）：将 AOF 缓冲区的数据**==写入到 AOF 文件==中。这一步需要调用write函数（==系统调用==），write将数据写入到了==系统内核缓冲区==之后直接返回**了（延迟写）。注意！！！此时==并没有同步到磁盘==。 文件同步（fsync）：AOF 缓冲区根据对应的持久化方式（ fsync 策略）向**==硬盘做同步操作==。这一步需要调用 fsync 函数（系统调用）， fsync 针对单个文件操作，对其进行==强制硬盘同步==，fsync 将阻塞直到写入磁盘完成后返回**，保证了数据持久化。 文件重写（rewrite）：随着 AOF 文件越来越大，需要定期对 AOF 文件进行重写，达到压缩的目的。 重启加载（load）：当 Redis 重启时，可以加载 AOF 文件进行数据恢复。 Linux 系统直接提供了一些函数用于对文件和设备进行访问和控制，这些函数被称为 ==系统调用==（syscall）。 这里对上面提到的一些 Linux 系统调用再做一遍解释： write：写入系统内核缓冲区之后直接返回（仅仅是写到缓冲区），不会立即同步到硬盘。虽然提高了效率，但也带来了数据丢失的风险。同步硬盘操作通常依赖于系统调度机制，Linux 内核通常为 30s 同步一次，具体值取决于写出的数据量和 I/O 缓冲区的状态。 fsync：fsync用于强制刷新系统内核缓冲区（同步到到磁盘），确保写磁盘操作结束才会返回。 AOF持久化方式（三种） appendfsync always 每次 wait之后都刷盘 主线程调用 write 执行写操作后，后台线程（ aof_fsync 线程）立即会调用 fsync 函数同步 AOF 文件（刷盘），fsync 完成后线程返回，这样会严重降低 Redis 的性能（write + fsync）。 appendfsync everysec 后台线程每秒刷一次盘 主线程调用 write 执行写操作后立即返回，由后台线程（ aof_fsync 线程）每秒钟调用 fsync 函数（系统调用）同步一次 AOF 文件（write+fsync，fsync间隔为 1 秒） appendfsync no 由操作系统决定 主线程调用 write 执行写操作后立即返回，让操作系统决定何时进行同步，Linux 下一般为 30 秒一次（write但不fsync，fsync 的时机由操作系统决定）。 AOF 为什么是执行完命令之后记录日志 避免==额外的检查开销==，AOF 记录日志==不会对命令进行语法检查==； 在命令执行完之后再记录，不会阻塞==当前的命令执行==。 这样也带来了风险（我在前面介绍 AOF 持久化的时候也提到过）： 如果刚==执行完命令== Redis 就宕机会导致对应的==修改丢失==； 可能会**阻塞==后续其他命令==**的执行（AOF 记录日志是在 Redis 主线程中进行的） AOF文件重写（压缩） 介绍： 当 AOF 变得太大时，Redis 能够在后台自动重写 AOF 产生一个新的 AOF 文件，这个新的 AOF 文件和原有的 AOF 文件所保存的==数据库状态一样==，但**==体积更小==**。 有 大量写入 ，因此使用子线程 创建新的AOF文件 因为在重写期间，服务器也会有写命令输入 AOF 文件重写期间，Redis 还会维护一个 ==AOF 重写缓冲区==，该缓冲区会在子进程创建新 AOF 文件期间，记录服务器执行的所有写命令。当子进程完成创建新 AOF 文件的工作之后，服务器会将重写缓冲区中的所有内容==追加==到新 AOF 文件的末尾，使得新的 AOF 文件保存的数据库状态与现有的数据库状态一致。最后，服务器用新的 AOF 文件替换旧的 AOF 文件，以此来完成 AOF 文件重写操作。 AOF校验机制 在启动时对 AOF 文件进行检查，以判断文件是否完整，是否有损坏或者丢失的数据。这 个机制的原理其实非常简单，就是通过使用一种叫做 ==校验和（checksum）== 的数字来验证 AOF 文件。 这个校验和是通过对整个 AOF 文件内容进行 CRC64 算法计算得出的数字。 如果文件内容发生了变化，那么校验和也会随之改变。 因此，Redis 在启动时会比较计算出的校验和与文件末尾保存的校验和（计算的时候会把最后一行保存校验和的内容给忽略点），从而判断 AOF 文件是否完整。 如果发现文件有问题，Redis 就会拒绝启动并提供相应的错误信息。 RDB + AOF AOF 重写的时候就直接把 RDB 的内容写到 AOF 文件开头，缺点是RDB部分可读性差 RDB 和 AOF 选择 RDB的优势 空间复杂度： RDB 文件存储的内容是经过压缩的二进制数据， 保存着某个时间点的数据集，==文件很小==，适合做数据的备份，灾难恢复。 AOF 文件存储的是每一次写命令，类似于 MySQL 的 ==binlog== 日志，通常会比 RDB 文件大很多。 当 AOF 变得太大时，Redis 能够在后台自动重写 AOF。新的 AOF 文件和原有的 AOF 文件所保存的数据库状态一样，但体积更小。 不过， Redis 7.0 版本之前，如果在重写期间有写入命令，AOF 可能会==使用大量内存==，重写期间到达的所有写入命令都会**==写入磁盘两次==**。 时间复杂度 使用 RDB 文件恢复数据，直接解析还原数据即可，不需要一条一条地执行命令，速度非常快。 而 AOF 则需要==依次执行==每个写命令，速度非常慢。也就是说，与 AOF 相比，恢复大数据集的时候，RDB 速度更快。 AOF的优势 数据安全性 RDB 的数据安全性不如 AOF，没有办法实时或者秒级持久化数据。生成 ==RDB 文件==的==过程==是比较==繁重==的， 虽然 BGSAVE 子进程写入 RDB 文件的工作不会阻塞主线程，但会对机器的 CPU 资源和内存资源产生影响，严重的情况下甚至会直接把 Redis 服务干宕机。==AOF== 支持秒级数据丢失（取决 fsync 策略，如果是 everysec，最多丢失 1 秒的数据），仅仅是追加命令到 AOF 文件，==操作轻量==。 兼容性问题 RDB 文件是以**==特定的二进制格式==保存的，并且在 Redis 版本演进中有多个版本的 RDB**，所以存在老版本的 Redis 服务不兼容新版本的 RDB 格式的问题。 文件可解释性 AOF 以一种易于理解和解析的格式包含所有操作的==日志==。你可以轻松地导出 AOF 文件进行分析，你也可以直接操作 AOF 文件来解决一些问题。比如，如果执行FLUSHALL命令意外地刷新了所有内容后，只要 AOF 文件没有被重写，删除最新命令并重启即可恢复之前的状态。 💠Redis 线程模型 Redis 基于 ==Reactor 模式==设计开发了一套高效的事件处理模型，开发了自己的网络事件处理器：这个处理器被称为文件事件处理器（file event handler）。 虽然文件事件处理器以单线程方式运行，但通过使用 ==I/O 多路复用==程序来==监听多个套接字== Redis 通过 IO 多路复用程序 来监听来自客户端的大量连接（或者说是监听多个 socket），它会将感兴趣的事件及类型（读、写）注册到内核中并监听每个事件是否发生。 这样的好处非常明显：I/O 多路复用技术的使用让 Redis 不需要额外创建多余的线程来监听客户端的大量连接，降低了资源的消耗（和 NIO 中的 Selector 组件很像） Redis6.0 之前为什么不使用多线程（三个原因）？ 使用单线程模型能带来**==更好的可维护性==**，方便开发和调试； 使用单线程模型也能==并发的处理客户端的请求==（IO 多路复用）； Redis 服务中运行的绝大多数操作的性能==瓶颈都不是 CPU==； Redis6.0 之后为何引入了多线程？ 为了提高网络 IO 读写性能 添加了其他线程异步处理的删除操作 UNLINK、FLUSHALL ASYNC 和 FLUSHDB ASYNC 对大键值对，异步的操作更节省时间 Redis 后台线程了解吗？ 通过 bio_close_file 后台线程来==释放== AOF / RDB 等过程中产生的==临时文件资源==。 通过 bio_aof_fsync 后台线程调用 fsync 函数将**==系统内核缓冲区==还未同步到到磁盘的数据==强制刷到磁盘==**（ AOF 文件）。 通过 bio_lazy_free后台线程==释放==大对象（已删除）占用的内存空间 Redis 内存管理 Redis 给缓存数据设置过期时间有啥用？ 过期时间除了有助于缓解内存的消耗 很多时候，我们的业务场景就是需要某个数据只在某一时间段内存在，比如我们的短信验证码可能只在 1 分钟内有效，用户登录的 token 可能只在 1 天内有效。 Redis 是如何判断数据是否过期的呢？ 通过一个叫做==过期字典==（可以看作是 hash 表）来保存数据过期的时间。过期字典的==键指向 Redis 数据库中的某个 key==(键)，过期字典的值是一个 long long 类型的整数，这个整数保存了 key 所指向的数据库键的过期时间（毫秒精度的 UNIX 时间戳）。 过期数据删除策略 惰性删除 只会在==取出 key 的时候==才对数据进行过期检查。这样对 CPU 最友好，但是可能会造成太多过期 key 没有被删除 定期删除 每隔一段时间抽取一批 key 执行删除过期 key 操作 定期删除对内存更加友好，惰性删除对 CPU 更加友好。两者各有千秋，所以 Redis 采用的是 定期删除+惰性/懒汉式删除 。 但是，仅仅通过给 key 设置过期时间还是有问题的。因为还是可能存在定期删除和惰性删除漏掉了很多过期 key 的情况。这样就导致大量过期 key 堆积在内存里，然后就 Out of memory 了 Redis 内存淘汰机制了解么（六种）？ volatile：已设置过期时间 allkeys：所有键 ttl：将要过期 lru：最近最少使用 lfu：最不经常使用 volatile-lru（least recently used） volatile-ttl volatile-random allkeys-lru（least recently used） allkeys-random no-eviction Redis 4.0之后新增 volatile-lfu（least frequently used） allkeys-lfu（least frequently used） Redis事务（使用较少） Redis通过 MULTI（开始记录），EXEC（执行记录的事务），DISCARD （取消事务）和 WATCH（监听KEY） 等命令支持事务 不支持原子性，因为事务中执行出错不能回滚 通过 AOF 和 RDB ，可以支持持久化 💠Redis性能优化 使用批量操作减少网络传输 发送命令 命令排队 命令执行 返回结果 第 1 步和第 4 步耗费时间之和称为 Round Trip Time (RTT,==往返时间==) ，也就是数据在网络上传输的时间。 原生批量操作命令 MGET(获取一个或多个指定 key 的值)、MSET(设置一个或多个指定 key 的值)、 HMGET(获取指定哈希表中一个或者多个指定字段的值)、HMSET(同时将一个或多个 field-value 对设置到指定哈希表中)、 SADD（向指定集合添加一个或多个元素） … pipeline（流水线） 对于不支持批量操作的命令，我们可以利用 pipeline（流水线) 将一批 Redis 命令封装成一组，这些 Redis 命令会被一次性提交到 Redis 服务器，只需要一次网络传输。 bigkey（大key） 概念： 一个 key 对应的 value 所占用的内存比较大 如何发现 使用 Redis 自带的 --bigkeys 参数来查找 借助开源工具分析 RDB 文件。 借助公有云的 Redis 分析服务。 解决方法 分割 bigkey 手动清理 采用合适的数据结构 开启 lazy-free（惰性删除/延迟释放）：异步删除，随机过期时间 hotkey（热key） 概念 访问次数比较多且明显多于其他 key 的话 如何发现 使用 Redis 自带的 --hotkeys 参数来查找，4.0版本新增，前提是使用lfu算法 使用MONITOR 命令。 一种实时查看 Redis 的所有操作的方式 借助开源项目 根据业务情况提前预估。 业务代码中记录分析 借助公有云的 Redis 分析服务。 如何解决 读写分离，主从 使用 Redis Cluster：将热点数据分散存储在多个 Redis 节点上。 二级缓存：hotkey 采用二级缓存的方式进行处理，将 hotkey 存放一份到 JVM 本地内存中（可以用 Caffeine）。 慢查询 命令执行 耗时长 如何找到 在 redis.conf 文件中，我们可以使用 slowlog-log-slower-than 参数设置耗时命令的阈值，并使用 slowlog-max-len 参数设置耗时命令的最大记录条数 内存碎片 Redis 存储存储数据的时候向操作系统申请的内存空间可能会大于数据实际需要的存储空间。 频繁修改 Redis 中的数据也会产生内存碎片 如何查看 使用 info memory 命令即可查看 Redis 内存相关的信息 mem_fragmentation_ratio （内存碎片率）= used_memory_rss (操作系统实际分配给 Redis 的物理内存空间大小)/ used_memory(Redis 内存分配器为了存储数据实际申请使用的内存空间大小) 如何清理 直接通过 config set 命令将 activedefrag 配置项设置为 yes 即可。 💠Redis生产问题 缓存穿透 解决方法 做好参数校验 缓存无效 key 布隆过滤器 布隆过滤器说某个元素存在，小概率会误判。布隆过滤器说某个元素不在，那么这个元素一定不在。 使用布隆过滤器中的哈希函数对元素值进行计算，得到哈希值（有几个哈希函数得到几个哈希值）。 根据得到的哈希值，在位数组中把对应下标的值置为 1。 缓存击穿 请求的 key 对应的是 热点数据 ，该数据 存在于数据库中，但不存在于缓存中（通常是因为缓存中的那份数据==已经过期==） 解决办法： 设置热点数据==永不过期或者过期时间比较长==。 针对热点数据**==提前预热==**，将其存入缓存中并设置合理的过期时间比如秒杀场景下的数据在秒杀结束之前不过期。 请求数据库写数据到缓存之前，先==获取互斥锁==，保证只有一个请求会落到数据库上，减少数据库的压力。 缓存雪崩 缓存在同一时间大面积的==失效==，导致大量的请求都直接落到了数据库上，对数据库造成了巨大的压力。 解决办法： 针对 Redis 服务不可用的情况： 采用 Redis ==集群==，避免单机出现问题整个缓存服务都没办法使用。 ==限流==，避免同时处理大量的请求。 针对热点缓存失效的情况 设置**==不同的失效时间==比如随机设置缓存的失效时间**。 缓存永不失效（不太推荐，实用性太差）。 设置二级缓存。 如何保证缓存和数据库的一致性 内存淘汰策略:不需要自己进行维护,利用Redis的内存淘汰机制,当内存不足的时候就会自动淘汰部分数据,下次查询的时候更新缓存,一致性很差 超时删除:给缓存数据添加TTL时间,给数据添加TTL时间,到期后就能够自动删除缓存,下次查询的时候就会自动更新缓存,并非强一致性,是否一致和key的淘汰策略有关 主动更新:编写业务逻辑,在修改数据库的时候同时缓存数据,确保一致性,并非完全一致 旁路缓存策略 旁路缓存策略:由缓存调用者,在更新数据库的同时更新缓存,它比较适合读请求比较多的情况,这个模式的工作流程是这样的: 首先从缓存中取出数据,如果命中则直接返回 如果缓存没有命中,那么就需要数据库中去读取 将数据库中读取的结果的副本加载到缓存中 写操作:更新数据库,删除缓存中的数据 读写穿透策略 先查cache,如果cache中不存在,那么直接更新db 如果cache中存在,那么就先更新cache,然后cache服务自己更新db(同时更新cache和db) 异步缓存写入策略 调用者只使用缓存,比如说在消息队列中消息的异步写入,由其他线程异步地将数据持久化到数据库中,保证最终的一致性。 阻塞情况 Redis常见阻塞原因总结) O(n) SAVE创建RDB快照 两种RDB快照的生成方式：save和bgsave，bgsave使用子线程执行，不会阻塞。 AOF 日志记录 刷盘 重写 大key 清空数据库 Swap 内存交换 CPU竞争 网络问题 Redis集群 Redis Sentinel Redis Cluster 限流算法","categories":[{"name":"知识点梳理","slug":"知识点梳理","permalink":"http://kaillliu.github.io/categories/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://kaillliu.github.io/tags/Java/"},{"name":"知识点梳理","slug":"知识点梳理","permalink":"http://kaillliu.github.io/tags/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86/"},{"name":"Redis","slug":"Redis","permalink":"http://kaillliu.github.io/tags/Redis/"}]},{"title":"MySQL 知识总结","slug":"MySQL","date":"2023-08-06T07:00:00.000Z","updated":"2023-09-08T04:03:40.519Z","comments":true,"path":"2023/08/06/MySQL/","link":"","permalink":"http://kaillliu.github.io/2023/08/06/MySQL/","excerpt":"","text":"MySQL 基本 MySQL 是一种关系型数据库，主要用于持久化存储我们的系统中的一些数据比如用户信息。 char 是定长字符串，varchar 是变长字符串。 decimal 是定点数，float/double 是浮点数。decimal 可以存储精确的小数值，float/double 只能存储近似的小数值。 text 类型（长文本数据）用的很少，但偶尔会用，blob 类型（长文本数据）就属于是基本不用 不能有默认值。 在遇到使用临时表的情况时，无法使用内存临时表，只能在磁盘上创建临时表（《高性能 MySQL》这本书有提到）。 检索效率比 char 和 varchar 低 不能直接创建索引，需要指定前缀长度。 会消耗大量的网络和 IO 带宽。 可能会导致表上的 DML 操作都变得较慢 Timestamp 只需要使用 4 个字节的存储空间，但是 DateTime 需要耗费 8 个字节的存储空间。Timestamp 表示的时间范围更小。 NULL 跟 ''(空字符串)是两个完全不一样的值 NULL 代表一个不确定的值 MySql架构图 MySql存储引擎 存储引擎是基于表的，而不是数据库。 MyISAM 和 InnoDB 有什么区别？ MyISAM 不支持事务和行级锁，而且最大的缺陷就是崩溃后无法安全恢复。 InnoDB 支持行级锁(row-level locking)和表级锁,默认为行级锁。 InnoDB 提供事务支持，实现了 SQL 标准定义了四个隔离级别，具有提交(commit)和回滚(rollback)事务的能力。并且，InnoDB 默认使用的 REPEATABLE-READ（可重读）隔离级别是可以解决幻读问题发生的（基于 MVCC 和 Next-Key Lock）。 InnoDB 支持数据库异常崩溃后的安全恢复，恢复的过程依赖于 redo log 。 InnoDB支持MVCC， 可以看作是行级锁的一个升级，可以有效减少加锁操作，提高性能。 索引实现不一样，使用 B+Tree 作为索引结构，但是 MyISAM 叶节点的 data 域存放的是数据记录的 地址 ，首先按照 B+Tree 搜索算法搜索索引，如果指定的 Key 存在，则取出其 data 域的值，然后以 data 域的值为地址读取相应的数据记录。这种索引文件和数据文件是分离被称为 “非聚簇索引（非聚集索引）”。 InnoDB 数据文件本身就是索引文件。表数据文件本身就是按 B+Tree 组织的一个索引结构，树的叶节点 data 域保存了完整的数据记录。索引的 key 是数据表的主键，因此 InnoDB 表数据文件本身就是主索引。这被称为“聚簇索引（聚集索引）” 其余的索引都作为 辅助索引 ，辅助索引的 data 域存储相应记录主键的值而不是地址 根据主索引搜索时，直接找到 key 所在的节点即可取出数据；在根据辅助索引查找时，则需要先取出主键的值，再走一遍主索引。 MySql 事务 事务是逻辑上的一组操作，要么都执行，要么都不执行 ACID特性 原子性（Atomicity）：事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用； 一致性（Consistency）：执行事务前后，数据保持一致，例如转账业务中，无论事务是否成功，转账者和收款人的总额应该是不变的； 隔离性（Isolation）：并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的； 持久性（Durability）：一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。 并发事务带来了哪些问题 脏读 丢失修改 不可重复读 幻读 并发事务的控制方式有哪些？ 锁 和 MVCC 锁： 共享锁（S 锁）：又称读锁，事务在读取记录的时候获取共享锁，允许多个事务同时获取（锁兼容）。 排他锁（X 锁）：又称写锁/独占锁，事务在修改记录的时候获取排他锁，不允许多个事务同时获取。如果一个记录已经被加了排他锁，那其他事务不能再对这条记录加任何类型的锁（锁不兼容）。 MVCC (Multi-Version Concurrency Control): 多版本并发控制方法，即对一份数据会存储多个版本，用于在多个并发事务同时读写数据库时保持数据的一致性和隔离性。 通过事务的可见性来保证事务能看到自己应该看到的版本 通常会有一个全局的版本分配器来为每一行数据设置版本号，版本号是唯一的。 MVCC 在 MySQL 中实现所依赖的手段主要是: 隐藏字段、read view、undo log。 undo log : undo log 用于记录某行数据的多个版本的数据。 read view 和 隐藏字段 : 用来判断当前版本数据的可见性。 MVCC: InnoDB存储引擎对MVCC的实现 MVCC 通过创建数据的多个版本和使用快照读取来实现并发控制。 InnoDB使用 MVCC + Next - key - Lock 防止幻读 在快照读的情况下，RR 隔离级别只会在事务开启后的第一次查询生成 Read View ，并使用至事务提交。所以在生成 Read View 之后其它事务所做的更新、插入记录版本对当前事务并不可见，实现了可重复读和防止快照读下的 “幻读” 执行 select…for update/lock in share mode、insert、update、delete 等当前读， 在当前读下，读取的都是最新的数据，如果其它事务有插入新的记录，并且刚好在当前事务查询范围内，就会产生幻读！InnoDB 使用 Next-key Lock来防止这种情况。当执行当前读时，会锁定读取到的记录的同时，锁定它们的间隙，防止其它事务在查询范围内插入数据。只要我不让你插入，就不会发生幻读 MySQL事务隔离级别 READ-UNCOMMITTED(读取未提交) READ-COMMITTED(读取已提交) REPEATABLE-READ(可重复读) SERIALIZABLE(可串行化) MySQL 锁 表级锁 并发效率低，对全表加锁 行级锁 针对索引字段加的锁 类别 记录锁（Record Lock）：也被称为记录锁，属于单个行记录上的锁。 间隙锁（Gap Lock）：锁定一个范围，不包括记录本身。 临键锁（Next-Key Lock）：Record Lock+Gap Lock，锁定一个范围，包含记录本身，主要目的是为了解决幻读问题（MySQL 事务部分提到过）。记录锁只能锁住已经存在的记录，为了避免插入新记录，需要依赖间隙锁。 共享锁（S 锁 、读锁） 和 排他锁（ X 锁，写锁） 读锁，事务在读取记录的时候获取共享锁，允许多个事务同时获取**（锁兼容）** 称写锁/独占锁，事务在修改记录的时候获取排他锁，不允许多个事务同时获取。（锁不兼容） 意向锁 快速判断是否可以对某个表使用表锁。 💠MySql 索引 索引是一种用于==快速查询==和==检索数据==的数据结构，其本质可以看成是一种==排序好的数据结构==。 在Mysql中，使用 B+ tree 作为索引结构 索引的优缺点 优点： 加快 数据的检索速度（减少索引的数据量），大多数情况下降低 进行全表查询的次数。 缺点： 创建和维护索引 ==费时== 对表中的数据进行==增删改==的时候，如果数据有索引，那么也需要**==动态的修改索引==**，降低 SQL 执行效率。 索引底层数据结构选型 哈希表 Hash 索引不支持顺序和范围查询，不选择 二叉查找树 二叉查找树的性能非常依赖于它的平衡程度，不选择 AVL （自平衡二叉查找）树 保证任何节点的左右子树高度之差不超过 1 需要通过 旋转 保持平衡，磁盘IO次数高 红黑树（在 TreeMap、TreeSet 以及 JDK1.8 的 HashMap 底层都用到了红黑树） 每个节点非红即黑； 根节点总是黑色的； 每个叶子节点都是黑色的空节点（NIL 节点）； 如果节点是红色的，则它的子节点必须是黑色的（反之不一定）； 从根节点到叶节点或空子节点的每条路径，必须包含相同数目的黑色节点（即相同的黑色高度）。 ==B 树 &amp; B+ 树== （多路平衡查找树） B 树的所有节点既存放键(key) 也存放数据(data)，而 ==B+树==只有叶子节点存放 key 和 data，其他内节点只存放 key。 B 树的叶子节点都是独立的; B+树的叶子节点有一条引用链指向与它相邻的叶子节点。 B 树的检索的过程相当于对范围内的每个节点的关键字做==二分查找==，可能还没有到达叶子节点，检索就结束了。而 B+树的检索效率就很稳定了，任何查找都是**==从根节点到叶子节点==**的过程。 在 B 树中进行范围查询时，首先找到要查找的下限，然后对 B 树进行中序遍历，直到找到查找的上限；而 B+树的范围查询，只需要对**==链表==**进行遍历即可 MyISAM 引擎中，B+Tree 叶节点的 data 域存放的是数据记录的地址。搜索时，根据Key查找到对于的data地址，再根据地址读取相应的数据记录。这被称为“非聚簇索引（非聚集索引）” InnoDB 引擎中，其数据文件本身就是索引文件。数据文件本身就是按 B+Tree 组织的一个索引结构，树的叶节点 data 域保存了完整的数据记录。这个索引的 key 是数据表的主键，因此 InnoDB 表数据文件本身就是主索引。这被称为“聚簇索引（聚集索引）”，而其余的索引都作为 辅助索引，辅助索引的 data 域存储相应记录主键的值而不是地址 索引类型总结 按照数据结构维度划分： BTree 索引：MySQL 里默认和最常用的索引类型。只有叶子节点存储 value，非叶子节点只有指针和 key。存储引擎 MyISAM 和 InnoDB 实现 BTree 索引都是使用 B+Tree，但二者实现方式不一样。 哈希索引：类似键值对的形式，一次即可定位。 RTree 索引：一般不会使用，仅支持 geometry 数据类型，优势在于范围查找，效率较低，通常使用搜索引擎如 ElasticSearch 代替。 全文索引：对文本的内容进行分词，进行搜索。目前只有 CHAR、VARCHAR ，TEXT 列上可以创建全文索引。一般不会使用，效率较低，通常使用搜索引擎如 ElasticSearch 代替。 按照底层存储方式角度划分： 聚簇索引（聚集索引）：索引结构和数据一起存放的索引，InnoDB 中的主键索引就属于聚簇索引。 非聚簇索引（非聚集索引）：索引结构和数据分开存放的索引，二级索引(辅助索引)就属于非聚簇索引。MySQL 的 MyISAM 引擎，不管主键还是非主键，使用的都是非聚簇索引。 按照应用维度划分： 主键索引：加速查询 + 列值唯一（不可以有 NULL）+ 表中只有一个。 普通索引：仅加速查询。 唯一索引：加速查询 + 列值唯一（可以有 NULL）。 覆盖索引：一个索引包含（或者说覆盖）所有需要查询的字段的值。 联合索引：多列值组成一个索引，专门用于组合搜索，其效率大于索引合并。 全文索引：对文本的内容进行分词，进行搜索。目前只有 CHAR、VARCHAR ，TEXT 列上可以创建全文索引。一般不会使用，效率较低，通常使用搜索引擎如 ElasticSearch 代替。 MySQL 8.x 中实现的索引新特性： 隐藏索引：也称为不可见索引，不会被优化器使用，但是仍然需要维护，通常会软删除和灰度发布的场景中使用。主键不能设置为隐藏（包括显式设置或隐式设置）。 降序索引：之前的版本就支持通过 desc 来指定索引为降序，但实际上创建的仍然是常规的升序索引。直到 MySQL 8.x 版本才开始真正支持降序索引。另外，在 MySQL 8.x 版本中，不再对 GROUP BY 语句进行隐式排序。 函数索引：从 MySQL 8.0.13 版本开始支持在索引中使用函数或者表达式的值，也就是在索引中可以包含函数或者表达式。 索引失效 创建了组合索引，但查询条件未遵守最左匹配原则; 在索引列上进行计算、函数、类型转换等操作; 以 % 开头的 LIKE 查询比如 like '%abc'; LIKE子句的效果与=类似，但是在使用字符串作为条件的时候可以使用%来模糊匹配 查询条件中使用 or，且 or 的前后条件中有一个列没有索引，涉及的索引都不会被使用到; 发生隐式转换; 分库分表 分库 就是将数据库中的数据分散到不同的数据库上。分表 就是对单表的数据进行拆分，可以是垂直拆分，也可以是水平拆分。 引入分库分表之后，需要系统解决事务、分布式 id、无法 join 操作问题。 ShardingSphere 绝对可以说是当前分库分表的首选！ShardingSphere 的功能完善，除了支持读写分离和分库分表，还提供分布式事务、数据库治理等功能。另外，ShardingSphere 的生态体系完善，社区活跃，文档完善，更新和发布比较频繁。 分库 垂直分库 就是把单一数据库按照业务进行划分，不同的业务使用不同的数据库，进而将一个数据库的压力分担到多个数据库。 水平分库 是把同一个表按一定规则拆分到不同的数据库中，每个库可以位于不同的服务器上，这样就实现了水平扩展，解决了单表的存储和性能瓶颈的问题。 分表 垂直分表 是对数据表列的拆分，把一张列比较多的表拆分为多张表。 水平分表 是对数据表行的拆分，把一张行比较多的表拆分为多张表，可以解决单一表数据量过大的问题。 常见的分片算法 分片算法主要解决了数据被水平分片之后，数据究竟该存放在哪个表 哈希分片： 求指定 key（比如 id） 的哈希，然后根据哈希值确定数据应被放置在哪个表中。哈希分片比较适合随机读写的场景，不太适合经常需要范围查询的场景。 范围分片： 按照特性的范围区间（比如==时间区间==、ID 区间）来分配数据，比如 将 id 为 1~299999 的记录分到第一个库， 300000~599999 的分到第二个库。范围分片适合需要经常进行范围查找的场景，不太适合随机读写的场景（数据未被分散，容易出现热点数据的问题）。 地理位置分片： 很多 NewSQL 数据库都支持地理位置分片算法，也就是根据地理位置（如城市、地域）来分配数据 三大日志 redolog（重做日志） 是InnoDB存储引擎独有的，它让MySQL拥有了==崩溃恢复能力==。 比如 MySQL 实例挂了或宕机了，重启时，InnoDB存储引擎会使用redo log恢复数据，保证数据的持久性与完整性。 redo log buffer 刷盘策略 0：设置为 0 的时候，表示每次事务提交时不进行刷盘操作 1：设置为 1 的时候，表示每次==事务提交时==都将进行刷盘操作（默认值） 2：设置为 2 的时候，表示每次事务提交时都只把 redo log buffer 内容写入 page cache 后台线程，每隔 1 秒，把 redo log buffer 中的内容写到文件系统缓存（page cache），然后调用 fsync 刷盘。 日志文件组 硬盘上存储的 redo log 日志文件不只一个，而是以一个日志文件组的形式出现的，每个的redo日志文件大小都是一样的。 采用的是环形数组形式，从头开始写，写到末尾又回到头循环写 binlog（归档日志） 保证了MySQL集群架构的数据一致性。 MySQL数据库的数据备份、主备、主主、主从都离不开binlog，需要依靠binlog来同步数据，保证数据一致性。 对比： redo log 它是物理日志，记录内容是“在某个数据页上做了什么修改”，属于 InnoDB 存储引擎。 binlog 是逻辑日志，记录内容是语句的原始逻辑，类似于“给 ID=2 这一行的 c 字段加 1”，属于MySQL Server 层。 记录格式 statement 指定statement，记录的内容是==SQL语句原文==，update_time=now()这里会获取当前系统时间，直接执行会导致与原库的数据不一致。 row 包含操作的具体数据，但是需要==更大的容量==来记录，比较占用空间，恢复与同步时会更消耗IO资源，影响执行速度 mixed MySQL会==判断==这条SQL语句是否可能引起数据不一致，如果是，就用**row**格式，否则就用statement格式 写入机制 binlog的写入时机也非常简单，事务执行过程中，先把日志写到**binlog cache，事务==提交==的时候，再把binlog cache写到binlog**文件中 事务的binlog不能被拆开，所以系统会给**==每个线程==分配一个块内存作为binlog cache**。 write和fsync的时机，可以由参数**sync_binlog**控制，默认是1。write指把日志写入缓存 page cache ，速度快；fsync才是将数据持久化到磁盘 两阶段提交 redo log（重做日志）让InnoDB存储引擎拥有了崩溃恢复能力。 binlog（归档日志）保证了MySQL集群架构的数据一致性。 为了解决两份日志之间的逻辑一致问题，InnoDB存储引擎使用两阶段提交方案。 将redo log的写入拆成了两个步骤**prepare和commit，这就是两阶段提交**。 依赖binlog实现数据库的主从复制和读写分离 为什么使用主从复制和读写分离 主从复制、读写分离就是为了数据库能支持更大的并发，提高数据库的可用性 例如有 3 台数据库，一台负责 写 ，两台负责 读 原理 实现了主从复制之后，如何实现读写分离 代理方式 多加一个代理层，统一分离读写请求。 组件方式，引入 jar包，例如 sharding-jdbc。 使用 AOP 的方式，通过方法名判断，方法名中有get、select、query开头的则连接slave，其他的则连接master数据库。 undolog（回滚日志） 恢复机制是通过 回滚日志（undo log） 实现的，所有事务进行的修改都会先记录到这个回滚日志中，然后再执行相关的操作。 回滚日志会先于数据持久化到磁盘 MVCC 的实现依赖于：隐藏字段、Read View、undo log InnoDB 通过数据行的 DB_TRX_ID 和 Read View 来判断数据的可见性 不可见的话，通过数据行的 DB_ROLL_PTR 找到 undo log 中的历史版本 在同一个事务中，用户只能看到该事务创建 Read View ==之前==已经提交的修改和该事务本身做的修改 总结 MySQL InnoDB 引擎使用 redo log(重做日志) 保证事务的持久性，使用 undo log(回滚日志) 来保证事务的原子性。 MySQL数据库的数据备份、主备、主主、主从都离不开binlog，需要依靠binlog来同步数据，保证数据一致性。","categories":[{"name":"知识点梳理","slug":"知识点梳理","permalink":"http://kaillliu.github.io/categories/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://kaillliu.github.io/tags/Java/"},{"name":"知识点梳理","slug":"知识点梳理","permalink":"http://kaillliu.github.io/tags/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86/"},{"name":"MySQL","slug":"MySQL","permalink":"http://kaillliu.github.io/tags/MySQL/"}]},{"title":"Java Spring IOC AOP 知识总结","slug":"IOC和AOP","date":"2023-08-05T07:00:00.000Z","updated":"2023-09-08T04:01:09.402Z","comments":true,"path":"2023/08/05/IOC和AOP/","link":"","permalink":"http://kaillliu.github.io/2023/08/05/IOC%E5%92%8CAOP/","excerpt":"","text":"Ioc注解式开发 注解回顾 注解的存在主要是为了简化XML的配置,Spring倡导全注解开发 注解定义的回顾 12345678910@Target(value = &#123;ElementType.METHOD,ElementType.ANNOTATION_TYPE&#125;)//target元注解,标准注解的注解,告诉你这个注解能在哪里出现//使用某个注解,如果属性名为value,那么value可以省略掉//使用某个注解,如果属性值为数组,并且数组只有一个元素,那么大括号可以省略掉//@Retention(RetentionPolicy.RUNTIME)//保持性策略:运行时存在,标注注解最终保留在哪,最终可以被反射机制所识别//@Retention(RetentionPolicy.CLASS),保留在CLASS文件中,最终无法被反射所识别@Retention(RetentionPolicy.SOURCE)//最终只在JAVA源文件中存在,一经编译成为class文件则注解就不存在了public @interface Component &#123; String[] values();&#125; 反射与注解 12@Component(values = &quot;userBean&quot;)public class User &#123;&#125; 12345678910//通过反射机制读取注解Class&lt;?&gt; clazz = Class.forName(&quot;com.orm.domain.User&quot;);//判断类上面是否有注解if (clazz.isAnnotationPresent(Component.class)) &#123; //如果有,获取类上的注解 Component annotation = clazz.getAnnotation(Component.class); //如果想获取值? String[] values = annotation.values(); System.out.println(values[0]);&#125; 组件扫描原理 用户指定你一个包名,然后你的扫描程序就去扫描这个包下的所有的类,一旦有这个类,你就把这个类造出来,放到容器里面去 123456789101112131415161718192021222324252627282930313233343536public static void main(String[] args) throws Exception &#123; Map&lt;String,Object&gt; map = new HashMap&lt;&gt;(); String packageName = &quot;com.orm.domain&quot;; //然后问题就是你怎么去扫这个包下的所有的类? //1.将包名变成路径 //在正则表达式,要表达普通的.字符,那么就需要用/. String packagePath = packageName.replaceAll(&quot;\\\\.&quot;, &quot;/&quot;); //这个packagePath,是在类路径下的 URL resource = ClassLoader.getSystemClassLoader().getResource(packagePath); assert resource != null; String path = resource.getPath(); //拿到绝对路径后,获取绝对路径下的所有文件 File file = new File(path); List&lt;String&gt; classNames = new ArrayList&lt;&gt;(); if(file.isDirectory())&#123; //拿到所有子文件 File[] files = file.listFiles(); assert files != null; Arrays.stream(files).forEach(file1 -&gt;&#123; String[] split = file1.getName().split(&quot;\\\\.&quot;); classNames.add(split[0]); &#125;); &#125; System.out.println(classNames); //然后通过反射机制 for (String className : classNames) &#123; Class&lt;?&gt; clazz = Class.forName(packageName + &quot;.&quot; + className); if (clazz.isAnnotationPresent(Component.class)) &#123; Component annotation = clazz.getAnnotation(Component.class); map.put(annotation.values()[0],clazz.newInstance()); &#125; &#125; for (Map.Entry&lt;String, Object&gt; stringObjectEntry : map.entrySet()) &#123; System.out.println(stringObjectEntry.getKey()+&quot;,&quot;+stringObjectEntry.getValue()); &#125;&#125; 声明bean的注解 声明Bean的注解 @Component:通用 1234567891011121314@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Indexedpublic @interface Component &#123; /** * The value may indicate a suggestion for a logical component name, * to be turned into a Spring bean in case of an autodetected component. * @return the suggested component name, if any (or empty String otherwise) */ String value() default &quot;&quot;;&#125; @Controller:View 123456789101112131415@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Componentpublic @interface Controller &#123; /** * The value may indicate a suggestion for a logical component name, * to be turned into a Spring bean in case of an autodetected component. * @return the suggested component name, if any (or empty String otherwise) */ @AliasFor(annotation = Component.class)//别名 String value() default &quot;&quot;;&#125; @Service:Service 123456789101112131415@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Componentpublic @interface Service &#123; /** * The value may indicate a suggestion for a logical component name, * to be turned into a Spring bean in case of an autodetected component. * @return the suggested component name, if any (or empty String otherwise) */ @AliasFor(annotation = Component.class) String value() default &quot;&quot;;&#125; @Repository:DAO 123456789101112131415@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Componentpublic @interface Repository &#123; /** * The value may indicate a suggestion for a logical component name, * to be turned into a Spring bean in case of an autodetected component. * @return the suggested component name, if any (or empty String otherwise) */ @AliasFor(annotation = Component.class) String value() default &quot;&quot;;&#125; 123456789101112@Retention(RetentionPolicy.RUNTIME)@Target(&#123;ElementType.METHOD&#125;)@Documentedpublic @interface AliasFor &#123; @AliasFor(&quot;attribute&quot;) String value() default &quot;&quot;; @AliasFor(&quot;value&quot;) String attribute() default &quot;&quot;; Class&lt;? extends Annotation&gt; annotation() default Annotation.class;&#125; Spring注解的使用 配置扫描文件 markup 123456789101112131415&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:p=&quot;http://www.springframework.org/schema/p&quot; xmlns:c=&quot;http://www.springframework.org/schema/c&quot; xmlns:util=&quot;http://www.springframework.org/schema/util&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;!--给Spring框架指定要扫描哪些包--&gt; &lt;context:component-scan base-package=&quot;com.orm.domain&quot;/&gt;&lt;/beans&gt; 在Bean上配置 然后测试程序即可 123ClassPathXmlApplicationContext classPathXmlApplicationContext = new ClassPathXmlApplicationContext(&quot;Spring.xml&quot;);Student studentBean = classPathXmlApplicationContext.getBean(&quot;StudentBean&quot;, Student.class);System.out.println(studentBean); 默认名称是你的类名的首字母小写 如果是多个包怎么办? 在配置文件中指定多个包,用逗号隔开 指定多个包的共同父包 12&lt;!--给Spring框架指定要扫描哪些包--&gt;&lt;context:component-scan base-package=&quot;com.orm.domain,com.orm.dao&quot;/&gt; 12&lt;!--给Spring框架指定要扫描哪些包--&gt;&lt;context:component-scan base-package=&quot;com.orm&quot;/&gt; 选择性实例化Bean 假设某个包下有很多bean,有Component,Controller…现在只允许Controller参与Spring管理,其他的不实例化 1234567&lt;!--给Spring框架指定要扫描哪些包--&gt;&lt;context:component-scan base-package=&quot;com.orm.domain&quot;&gt; &lt;!--它不参与扫描了--&gt; &lt;context:exclude-filter type=&quot;annotation&quot; expression=&quot;org.springframework.stereotype.Component&quot;/&gt; &lt;context:exclude-filter type=&quot;annotation&quot; expression=&quot;org.springframework.stereotype.Repository&quot;/&gt; &lt;context:exclude-filter type=&quot;annotation&quot; expression=&quot;org.springframework.stereotype.Service&quot;/&gt;&lt;/context:component-scan&gt; 负责注入的注解 注入:让对象和对象之间产生关系、关联 @Value:当属性的类型是简单类型的时候,用此属性进行注入,用来代替property,前提是这个对象的实例将会交给IOC容器管理,这时候@Value注解才会生效 12345678@Component(value = &quot;StudentBean&quot;)public class Student &#123; private String id; @Value(&quot;张三&quot;) private String name; private Teacher tutor; private Set set;&#125; 1234@Value(&quot;张三&quot;)public void setName(String name) &#123; this.name = name;&#125; @Value注解也可以用在方法上,如上的set方法 同时还可以用在构造方法上 12345public Student(String id, @Value(&quot;张三&quot;) String name, Teacher tutor) &#123; this.id = id; this.name = name; this.tutor = tutor;&#125; @AutoWired与@Qualifier @AutoWired注解可以用来注入非简单类型,自动装配就是它,单独使用@Autowired是默认根据类型进行装配的 基于XML的自动装配有 根据名称进行自动装配 根据类型进行自动装配 12&gt;&lt;bean id = &quot;UserService&quot; class = &quot;com.domain.UserService&quot; autowire=&quot;byName&gt; &lt;bean id = &quot;UserService&quot; class = &quot;com.domain.UserService&quot; autowire=&quot;byType&quot;&gt; 这个注解可以用在哪? 构造方法 方法上 形参上 属性上 注解上 其作用是根据类型进行自动装配,如果接口有多个实现类的,那么@Autowired就无法实现自动装配了 这是因为它无法知道你实际上想要的是哪个实现类 如果想要解决以上的问题,只能根据名字进行装配 方法是使用@AutoWired和@Qualifier联合使用,可以根据名字进行装配 在@Qualifier(&quot;&quot;)中指定你的BeanId 当你没有在属性上加@AutoWired的时候,也可以在setXxxx()上加,也可以实现自动注入 同时,也可以在构造方法上指向,也可以实现自动注入,也可以在构造方法上的参数上执行 满足以下条件可以省略掉@Autowired 属性名和构造方法的参数名一致 构造方法中的参数只有一个,只有一个构造方法的时候,注解可以省略 @Resource @Resouce注解可以完成非简单类型的注入,与@Autowired注解有什么区别? @Resource是JDK扩展包中的一部分,该注解是标准的注解 @Autowired是Spring框架所特别提供的 @Resource注解默认根据名称装配byName,没有指定name的时候,使用属性名作为name,通过name找不到的话会自动启动通过类型byType进行装配 @Autowired注解默认根据类型装配byType,如果想要根据名称进行装配,需要配合@Qualifier注解一起使用 @Resource注解用在属性上,setter方法上 @Autowired注解用在属性上,setter方法上,构造方法上,构造方法的参数上 123456789101112131415@Target(&#123;TYPE, FIELD, METHOD&#125;)@Retention(RUNTIME)public @interface Resource &#123; String name() default &quot;&quot;; String lookup() default &quot;&quot;; Class&lt;?&gt; type() default java.lang.Object.class; enum AuthenticationType &#123; CONTAINER, APPLICATION &#125; AuthenticationType authenticationType() default AuthenticationType.CONTAINER; boolean shareable() default true; String mappedName() default &quot;&quot;; String description() default &quot;&quot;;&#125; 1234//配置文件@Configuration@ComponentScan(&#123;&quot;com.client&quot;,&quot;com.orm&quot;&#125;)//指明扫描哪个包public class SpringConfig &#123; &#125; 12345@Testpublic void testNoXml()&#123; AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(SpringConfig.class);&#125; GoF之代理模式 对代理模式的理解 生活场景1：牛村的牛二看上了隔壁村小花，牛二不好意思直接找小花，于是牛二找来了媒婆王妈妈。这里面就有一个非常典型的代理模式。牛二不能和小花直接对接，只能找一个中间人。其中王妈妈是代理类，牛二是目标类。王妈妈代替牛二和小花先见个面。（现实生活中的婚介所）【在程序中，对象A和对象B无法直接交互时。】 生活场景2：你刚到北京，要租房子，可以自己找，也可以找链家帮你找。其中链家是代理类，你是目标类。你们两个都有共同的行为：找房子。不过链家除了满足你找房子，另外会收取一些费用的。(现实生活中的房产中介)【在程序中，功能需要增强时。】 西游记场景：八戒和高小姐的故事。八戒要强抢民女高翠兰。悟空得知此事之后怎么做的？悟空幻化成高小姐的模样。代替高小姐与八戒会面。其中八戒是客户端程序。悟空是代理类。高小姐是目标类。那天夜里，在八戒眼里，眼前的就是高小姐，对于八戒来说，他是不知道眼前的高小姐是悟空幻化的，在他内心里这就是高小姐。所以悟空代替高小姐和八戒亲了嘴儿。这是非常典型的代理模式实现的保护机制。代理模式中有一个非常重要的特点：对于客户端程序来说，使用代理对象时就像在使用目标对象一样。【在程序中，目标需要被保护时】 业务场景：系统中有A、B、C三个模块，使用这些模块的前提是需要用户登录，也就是说在A模块中要编写判断登录的代码，B模块中也要编写，C模块中还要编写，这些判断登录的代码反复出现，显然代码没有得到复用，可以为A、B、C三个模块提供一个代理，在代理当中写一次登录判断即可。代理的逻辑是：请求来了之后，判断用户是否登录了，如果已经登录了，则执行对应的目标，如果没有登录则跳转到登录页面。【在程序中，目标不但受到保护，并且代码也得到了复用。】 在Java程序中代理模式的作用 当一个对象需要收到保护的时候,可以考虑使用代理对象去完成某个行为 需要给某个对象的功能进行功能增强的时候,可以考虑找一个代理进行增强 A对象和B对象无法直接交互的时候,可以使用代理模式进行解决 代理模式是GOF23种设计模式之一,属于结构型的设计模式 代理模式的作用是:为其他对象提供一种代理以控制对这个对象的访问,在某些情况下,一个客户不想或者不能直接引用一个对象,这时候可以通过一个称之为对代理的第三者来实现简介引用,代理对象可以在客户端和目标对象之间起到中介的作用,并且可以通过代理对象去掉客户不应该看到的内容和服务或者添加客户所需要的额外服务,通过引入一个新的对象来实现对真实对象的操作或者将新的对象作为真实对象的一个替身,这种实现机制就是代理模式,通过引入代理对象来间接访问一个对象,这就是代理模式的模式动机。 代理模式的三大角色:目标对象(演员),代理对象(替身演员),目标对象和代理对象的公共接口(演员和替身演员有相同的行为和动作),客户端是无法察觉你的上面的动作的,它只会觉得是在使用目标对象,在使用代理对象的时候就像在使用目标对象 静态代理 如果现在要统计每个方法的执行耗时,执行方案如下: 硬编码:在每个方法中都添加统计执行耗时的代码 做了功能扩展的时候修改了源代码,破坏了OCP原则,代码没有得到复用 编写子类,编写业务类的子类,让子类继承业务类,对每个业务方法进行重写 1234567891011121314151617181920212223242526package com.powernode.mall.service.impl;public class OrderServiceImplSub extends OrderServiceImpl&#123; @Override public void generate() &#123; long begin = System.currentTimeMillis(); super.generate(); long end = System.currentTimeMillis(); System.out.println(&quot;耗时&quot;+(end - begin)+&quot;毫秒&quot;); &#125; @Override public void detail() &#123; long begin = System.currentTimeMillis(); super.detail(); long end = System.currentTimeMillis(); System.out.println(&quot;耗时&quot;+(end - begin)+&quot;毫秒&quot;); &#125; @Override public void modify() &#123; long begin = System.currentTimeMillis(); super.modify(); long end = System.currentTimeMillis(); System.out.println(&quot;耗时&quot;+(end - begin)+&quot;毫秒&quot;); &#125;&#125; 违反了里式替换原则,重写了父类的方法,暴力地破坏了父类方法中的代码,同时用了耦合度高的继承关系。 相同的代码也要写很多遍,没有实现代码的复用 采用代理模式解决,方案如下: 为service提供一个代理类,让这个代理类去实现公共的接口,这样做: 保证客户端能够正常使用服务,屏蔽了底层的实现细节 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package com.powernode.mall.service;/** * @author 动力节点 * @version 1.0 * @className OrderServiceProxy * @since 1.0 **/public class OrderServiceProxy implements OrderService&#123; // 代理对象 // 目标对象,将目标对象作为代理对象的属性,关联/聚合关系,比继承的关系的耦合度要低 // 写一个公共接口,耦合度低 private OrderService orderService; // 通过构造方法将目标对象传递给代理对象 public OrderServiceProxy(OrderService orderService) &#123; this.orderService = orderService; &#125; @Override public void generate() &#123; long begin = System.currentTimeMillis(); // 执行目标对象的目标方法 orderService.generate(); long end = System.currentTimeMillis(); System.out.println(&quot;耗时&quot;+(end - begin)+&quot;毫秒&quot;); &#125; @Override public void detail() &#123; long begin = System.currentTimeMillis(); // 执行目标对象的目标方法 orderService.detail(); long end = System.currentTimeMillis(); System.out.println(&quot;耗时&quot;+(end - begin)+&quot;毫秒&quot;); &#125; @Override public void modify() &#123; long begin = System.currentTimeMillis(); // 执行目标对象的目标方法 orderService.modify(); long end = System.currentTimeMillis(); System.out.println(&quot;耗时&quot;+(end - begin)+&quot;毫秒&quot;); &#125;&#125; 使用代理模式的客户端代码 12345678// 创建目标对象OrderService target = new OrderServiceImpl();// 创建代理对象OrderService proxy = new OrderServiceProxy(target);// 调用代理对象的代理方法proxy.generate();proxy.modify();proxy.detail(); 这种方式是符合OCP原则的,采用的是关联关系has a,所以程序的耦合度低,所以这种方案是被推荐的 但是这种方法依然会产生类爆炸的问题 此时应该使用动态代理来解决,只需要将相对固定的代码写入到内存中(字节码生成技术),而不需要开发者再去维护这些类,同时一套代码也可以一直复用。 动态代理概述 在程序的运行阶段,在内存中动态生成代理类,被称为动态代理,目的是为了减少代理类的数量,解决代码复用的问题 其本质是生成字节码并且存储在内存中,供客户端程序调用Test 在内存中动态生成类的技术包括有 JDK动态代理技术:只能够代理接口 CGLIB：CodeGenerationLibrary,在运行期间扩展Java类与实现Java接口,既可以代理接口,也可以代理类,底层是通过继承的方式实现的,性能比JDK动态代理要好,底层有一个小而快的字节码处理框架ASM Javassist动态代理技术 JDK动态代理 123456789//创建目标对象TestDAOImpl testDAOImpl = new TestDAOImpl();//创建代理对象,JDK做这件事情newProxyInstance():新建代理对象实例,执行这个方法就会在底层创建代理对象//3个参数//类加载器//代理类要实现的接口//调用处理器Object proxyObj = Proxy.newProxyInstance();//使用方法 其中关键是三个参数 123public static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) newProxyInstance():在底层动态生成类,并且生成了类之后创建了对象 类加载器:作用是在你生成了class字节码文件后,通过这个类加载器加载到JVM中。并且JDK要求目标类的类加载器和代理类的类加载器使用同一个 代理类要实现的接口:代理类和目标类要实现同一个接口或者同一些接口,必须要告诉JDK,你这个代理类要实现哪些接口 调用处理器(InvocationHandler h):主要用来告诉JDK,你想要实现什么样的增强代码,你要把这个代码告诉JDK后,它才能处理,既然是接口,就要写接口的实现类 使用方法如下: 123456public class TimeInvocationHandler implements InvocationHandler &#123; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; return null; &#125;&#125; invoke() 因为一个类实现接口就必须实现接口中的方法 JDK已经提前将调用invoke()方法的相关代码写好了,你只需要补充代码即可,调用方是JDK 当代理对象调用代理方法的时候,注册到InvocationHandler调用处理器当中的invoke()方法被调用,但是在这一步,目标对象的方法没有被调用,需要知道,如果要做增强,目标对象的目标方法需要执行。 下面解析一下invoke()方法的三个参数 proxy(Object):代理对象的引用,这个参数使用较少 method:目标对象上的目标方法,要执行的目标方法就是它 args[]:目标方法上的实参 1234567891011121314151617public class TimeInvocationHandler implements InvocationHandler &#123; //invoke方法执行过程中,使用method来调用目标对象的目标方法 private Object target;//目标对象 public TimeInvocationHandler(Object target)&#123; this.target = target; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; //这个地方就是为了编写增强的代码的 System.out.println(&quot;invoke1&quot;); //调用目标对象上的目标方法 //方法四要素:对象,方法,参数,返回值 Object retVal = method.invoke(target, args); System.out.println(&quot;invoke2&quot;); return null; &#125;&#125; 关于返回值 如果按照上面的,就拿不到返回值,一定要把目标对象的目标方法的返回值给返回 到这里,我们梳理一下JDK的动态代理的底层实现 首先JDK的动态代理会在运行期间生成一个动态代理类$Proxy0,它继承了Proxy类,同时根据反射机制,获取到被代理类中的所实现的接口,然后这个$Proxy0也会去实现这些接口 因此在这种情况下,由于Java不支持多继承,因为其本身继承了Proxy的,因此它不能够去extends其他类,而只能够implements其他接口,那么在继承这个Proxy的时候,作用其实就是获取这个InvocationHandler这个类,那么从使用功能的角度来讲,将继承改成组合,也完全是可以的,这样做的话就可以代理类了。 那么从类的角度上分析完之后,我们分析它的执行机制是怎么样的 首先第一步,当我们使用newProxyInstance的时候,这时候就会创建对应的代理类,然后使用对应的代理类中的方法,那么这个方法怎么来的呢? 就是通过我们所写的Handler中invoke方法来调用 解释一下,为什么我们只重写了一个方法,但是所有代理的方法都变成了invoke了? 这是因为反射机制中提供了method,在执行方法的时候,可以解析获取调用方法的信息,从而可以在方法体内部精确地调用原方法。 这时候还有一个小问题,就是为什么要继承InvocationHandler呢?继承了之后它是怎么操作的呢? 代理类继承Proxy类,其主要目的还是为了传递InvocationHandler,所以的话,它是一种设计的上的思路,仅仅只是为了复用之前设计的类结构,它在产生那个$Proxy0的时候,会将Handler也给它传递过去,最终就可以用了 同时这种设计的好处就是能够减少类的初始化开销,因为注入对象也是需要开销的 同时继承自Proxy的关键特征,能够很好地说明某一个类是经过动态代理产生的 动态代理工具类 1234567public class ProxyUtils &#123; public static Object newProxyInstance(Object target)&#123; return Proxy.newProxyInstance(target.getClass().getClassLoader(), target.getClass().getInterfaces(), new TimeInvocationHandler(target)); &#125;&#125; 2.5 CGLIB动态代理 CGLIB既可以代理接口也可以代理类,它的底层是采用继承的方式实现的,所以被代理的目标类是不能用final修饰符的 所谓底层采用继承,也就是说底层是生成一个目标类的子类,来提供代理的,因此既可以代理类,也可以代理接口 代理类:增强被代理类的功能 代理接口:动态接口接口的实现类 1234567@Overridepublic Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; System.out.println(&quot;invoke1&quot;); Object ret = methodProxy.invokeSuper(o, objects); System.out.println(&quot;invoke2&quot;); return ret;&#125; 12345678910111213//CGLib//创建字节码增强器对象,核心对象Enhancer enhancer = new Enhancer();//告诉CGlib父类是谁?enhancer.setSuperclass(Entry.class);//设置回调函数//在CGLIB中不是InvocationHandler接口,而是方法拦截器接口MethodInterceptorenhancer.setCallback(new TimeMethodInterceptor());//创建代理对象//在内存中生成Entry的子类//创建代理对象Entry entry = (Entry) enhancer.create();System.out.println(entry.getKey()); 面向切面编程AOP 深入理解切面编程 IoC使得软件的组织松耦合,而AOP能够让你捕捉系统中经常使用的功能,并将其转化为组件 AOP(Aspect Oriented Programming):面向切面编程 AOP是对OOP的补充和延伸,AOP的底层实现就是动态代理 Spring的AOP所实现的动态代理技术是:JDK的动态代理+CGLIB的动态代理技术,Spring在这两种动态代理中灵活切换,如果是代理接口,那么默认使用的是JDK的动态代理,如果需要代理类而且这个类没有实现接口,就会切换使用CGLIB 切面:在业务流程中和你的业务逻辑不挂钩的通用代码 事务管理 日志模块 安全管理 如果在每一个业务的处理过程中,都掺杂这些交叉业务的话,问题: 交叉业务代码在多个业务流程中反复出现,显然这个交叉业务代码没有得到复用,修改也很麻烦 程序员无法专注于业务逻辑的编写,在编写核心业务的时候同时还需要处理这些交叉的业务 对AOP的理解:将与核心业务无关的代码(交叉业务)独立的抽取出来,形成一个独立的组件,然后以横向交叉的方式应用到业务流程当中的过程就叫做AOP 交叉业务就是一些通用的逻辑代码,例如说日志啊，安全啊这些 面向切面编程的术语 连接点JoinPoint:在程序的整个执行流程中,可以组织切入切面的位置,方法的执行前后,异常抛出之后等位置,它描述的是位置 切点PointCut:在程序执行流程中,真正织入切面的方法(一个切点对应多个连接点),描述的是方法,应用切面的具体的方法叫做切点,就是具体需要增强的方法 通知Advice:通知又叫做增强,就是你具体要织入的代码,通知描述的是代码 包括有前置通知:放到目标方法之前 后置通知:放到目标方法之后 环绕通知:前也有,后也有 异常通知:捕捉到异常 最终通知:finally语句块中的 切面Aspect:切点+通知就是切面 织入Weaving:把通知应用到目标对象上的过程 代理对象Proxy:一个目标对象被织入通知后产生的新对象 目标对象Target:被织入通知的对象 切点表达式 切点表达式用来定义通知在哪些需要增强的方法上进行切入 1execution([访问控制权限修饰符] 返回值类型[全限定类名]方法名(形式参数列表)[异常]) 访问控制权限修饰符:可选项,没写的话就是4个权限都包括,写public就表示只包括公开的方法 返回值类型:必填项,*表示返回任意类型 全限定类名:可选项,两个.代表当前包以及子包下的所有类,省略时表示所有的类 方法名:*表示所有方法,set*表示所有的set方法 形式参数列表:必填项,()表示没有参数,(…)表示参数类型和个数随意,(*)只有一个参数的方法 SpringAOP 实现概述 Spring对AOP的实现包括以下三种方式 Spring框架结合AspectJ框架实现的基于注解方式的AOP Spring框架结合AspcetJ框架实现的基于XML文件方式的AOP Spring框架自身实现的AOP,基于XML配置方式 实现环境 导入如下依赖 123456789101112131415&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;5.2.10.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;5.2.10.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aspects&lt;/artifactId&gt; &lt;version&gt;5.2.10.RELEASE&lt;/version&gt;&lt;/dependency&gt; 然后在xml文件中引入相关的命名空间 12xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot;xmlns:context=&quot;http://www.springframework.org/schema/context&quot; 基于AspectJ的AOP注解式开发 123456789101112131415161718192021222324252627package com.orm.service.impl;@Service(&quot;studentService&quot;)public class StudentServiceImpl implements StudentService&#123; private StudentDAO studentDAO; public StudentServiceImpl()&#123; System.out.println(&quot;执行了构造方法&quot;); &#125; public StudentServiceImpl(StudentDAO studentDAO)&#123; System.out.println(&quot;执行了构造方法&quot;); this.studentDAO = studentDAO; &#125; private static final Logger logger = LoggerFactory.getLogger(StudentService.class); @Override public void saveStudent(Student student) &#123; logger.info(&quot;执行了保存对象的方法....&quot;); //studentDAO.addStudent(student); &#125; //定义set方法,这样符合DAO规范,底层是依赖于拼装set方法来invoke对应的方法的. public void setStudentDAO(StudentDAO studentDAO) &#123; System.out.println(&quot;装配了DAO对象&quot;+studentDAO.toString()); this.studentDAO = studentDAO; &#125;&#125; 1234567891011@Component(&quot;logAspect&quot;)@Aspectpublic class LogAspect &#123; private static final Logger log = LoggerFactory.getLogger(LogAspect.class); //通知以方法的形式出现,前置通知 //execution(修饰符 返回值类型 方法名(形式参数列表)) @Before(&quot;execution(* com.orm.service.StudentService.*(..))&quot;)//前置通知,标注的方法就是一个前置的通知,要标注上切点表达式 public void beforeAdvice()&#123; log.info(&quot;学生服务启动&quot;); &#125;&#125; 123456789101112131415161718192021&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:p=&quot;http://www.springframework.org/schema/p&quot; xmlns:c=&quot;http://www.springframework.org/schema/c&quot; xmlns:util=&quot;http://www.springframework.org/schema/util&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;!--给Spring框架指定要扫描哪些包--&gt; &lt;context:component-scan base-package=&quot;com.orm&quot;/&gt; &lt;!--开启自动代理--&gt; &lt;!--检查Aspect注解--&gt; &lt;!--spring容器在扫描类的时候,检查这个类上是否有@Aspect注解,如果有,就给这个类生成代理对象--&gt; &lt;!--当proxy-target-class为true表示强制使用cglib的动态代理--&gt; &lt;aop:aspectj-autoproxy proxy-target-class=&quot;true&quot;/&gt;&lt;/beans&gt; 通知类型 前缀通知:使用@Before,目标方法执行之前的通知 后置通知:使用@AfterReturning,目标方法执行之后的通知 环绕通知:使用@Around,目标方法之前添加通知,同时目标方法执行之前添加通知 异常通知:使用@AfterThrowing发生异常之后所添加的通知 最终通知:使用@After放在finally语句块中的通知 123456789101112131415161718192021222324252627282930@Component(&quot;logAspect&quot;)@Aspectpublic class LogAspect &#123; private static final Logger log = LoggerFactory.getLogger(LogAspect.class); //通知以方法的形式出现,前置通知 //execution(修饰符 返回值类型 方法名(形式参数列表)) @Before(&quot;execution(* com.orm.service.StudentService.*(..))&quot;)//前置通知,标注的方法就是一个前置的通知,要标注上切点表达式 public void beforeAdvice()&#123; log.info(&quot;学生服务启动&quot;); &#125; @AfterReturning(&quot;execution(* com.orm.service.StudentService.*(..))&quot;) public void afterAdvice()&#123; log.info(&quot;后置通知&quot;); &#125; @Around(&quot;execution(* com.orm.service.StudentService.*(..))&quot;) public Object aroundAdvice(ProceedingJoinPoint proceedingJoinPoint) throws Throwable &#123; log.info(&quot;前环绕通知&quot;); Object proceed = proceedingJoinPoint.proceed();//执行目标 log.info(&quot;后环绕通知&quot;); return proceed; &#125; @AfterThrowing(&quot;execution(* com.orm.service.StudentService.*(..))&quot;) public void throwingAdvice()&#123; log.info(&quot;异常通知&quot;); &#125; @After(&quot;execution(* com.orm.service.StudentService.*(..))&quot;) public void afterAdviceFinally()&#123; log.info(&quot;最终通知&quot;); &#125;&#125; 要特别注意这个环绕通知的写法,它需要用户来指定你的目标方法的位置 切面的先后顺序 当业务流程中有多个切面的时候,比如说有的切面负责控制事务,有的进行的是安全控制,如果多个切面的话,可以使用@Order注解来标识切面类,为@Order注解的value指定一个整数型的数字,数字越小,优先级越高 通用切点 1234567891011121314151617181920212223242526272829303132public class LogAspect &#123; private static final Logger log = LoggerFactory.getLogger(LogAspect.class); @Pointcut(&quot;execution(* com.orm.service.StudentService.*(..))&quot;) public void genericPointCut()&#123; &#125; //通知以方法的形式出现,前置通知 //execution(修饰符 返回值类型 方法名(形式参数列表)) @Before(&quot;genericPointCut()&quot;)//前置通知,标注的方法就是一个前置的通知,要标注上切点表达式 public void beforeAdvice()&#123; log.info(&quot;学生服务启动&quot;); &#125; @AfterReturning(&quot;genericPointCut()&quot;) public void afterAdvice()&#123; log.info(&quot;后置通知&quot;); &#125; @Around(&quot;genericPointCut()&quot;) public Object aroundAdvice(ProceedingJoinPoint proceedingJoinPoint) throws Throwable &#123; log.info(&quot;前环绕通知&quot;); Object proceed = proceedingJoinPoint.proceed();//执行目标 log.info(&quot;后环绕通知&quot;); return proceed; &#125; @AfterThrowing(&quot;genericPointCut()&quot;) public void throwingAdvice()&#123; log.info(&quot;异常通知&quot;); &#125; @After(&quot;genericPointCut()&quot;) public void afterAdviceFinally()&#123; log.info(&quot;最终通知&quot;); &#125;&#125; 配置类 12345//配置文件@Configuration@ComponentScan(&#123;&quot;com.client&quot;,&quot;com.orm&quot;&#125;)//指明扫描哪个包@EnableAspectJAutoProxy(proxyTargetClass = true)public class SpringConfig &#123; &#125; 基于XML的开发 123456789&lt;bean id=&quot;timeAspect&quot; class=&quot;com.orm.aspects.LogAspect&quot;&gt;&lt;/bean&gt;&lt;aop:config&gt; &lt;!--切点表达式--&gt; &lt;aop:pointcut id=&quot;myPointCut&quot; expression=&quot;execution(* com.orm.service..*(..))&quot;/&gt; &lt;aop:aspect ref=&quot;timeAspect&quot;&gt; &lt;!--切面:通知+切点--&gt; &lt;aop:around method=&quot;aroundAdvice&quot; pointcut-ref=&quot;myPointCut&quot;/&gt; &lt;/aop:aspect&gt;&lt;/aop:config&gt; AOP的实际案例:事务处理 项目中对于事务的控制是必须的,在一个业务流程当中,可能需要多条DML语句来共同完成,为了保证数据的安全,这多条DML语句要么同时成功,要么同时失败,这就需要添加事务控制的代码 123456789101112131415161718192021222324package com.powernode.spring6.biz;import org.aspectj.lang.ProceedingJoinPoint;import org.aspectj.lang.annotation.Around;import org.aspectj.lang.annotation.Aspect;import org.springframework.stereotype.Component;@Aspect@Component// 事务切面类public class TransactionAspect &#123; @Around(&quot;execution(* com.powernode.spring6.biz..*(..))&quot;) public void aroundAdvice(ProceedingJoinPoint proceedingJoinPoint)&#123; try &#123; System.out.println(&quot;开启事务&quot;); // 执行目标 proceedingJoinPoint.proceed(); System.out.println(&quot;提交事务&quot;); &#125; catch (Throwable e) &#123; System.out.println(&quot;回滚事务&quot;); &#125; &#125;&#125;","categories":[{"name":"知识点梳理","slug":"知识点梳理","permalink":"http://kaillliu.github.io/categories/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://kaillliu.github.io/tags/Java/"},{"name":"知识点梳理","slug":"知识点梳理","permalink":"http://kaillliu.github.io/tags/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86/"},{"name":"Spring","slug":"Spring","permalink":"http://kaillliu.github.io/tags/Spring/"}]},{"title":"Java JVM 知识总结","slug":"JVM","date":"2023-08-05T07:00:00.000Z","updated":"2023-09-08T03:57:32.554Z","comments":true,"path":"2023/08/05/JVM/","link":"","permalink":"http://kaillliu.github.io/2023/08/05/JVM/","excerpt":"","text":"JVM 线程私有的： 程序计数器 虚拟机栈 本地方法栈 线程共享的： 堆 方法区 直接内存 (非运行时数据区的一部分) 程序计数器 字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理。 在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了。 虚拟机栈 生命周期和线程相同 栈由一个个栈帧组成，而每个栈帧中都拥有：局部变量表、操作数栈、动态链接、方法返回地址。 局部变量表 主要存放了编译期可知的各种数据类型、对象引用 操作数栈 主要作为方法调用的中转站使用，用于存放方法执行过程中产生的中间计算结果 以及 临时变量 动态链接 主要服务一个方法需要调用其他方法的场景 ​ 将符号引用转换为调用方法的直接引用，这个过程也被称为 动态连接 。 Java 方法有两种返回方式，一种是 return 语句正常返回，一种是抛出异常 栈帧随着方法调用而创建，随着方法结束而销毁。无论方法正常完成还是异常完成都算作方法结束。 程序运行中栈可能会出现两种错误： StackOverFlowError： 若栈的内存大小不允许动态扩展，那么当线程请求栈的深度超过当前 Java 虚拟机栈的最大深度的时候，就抛出 StackOverFlowError 错误。 OutOfMemoryError： 如果栈的内存大小可以动态扩展， 如果虚拟机在动态扩展栈时无法申请到足够的内存空间，则抛出OutOfMemoryError异常。 本地方法栈 虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务。 堆 Java 虚拟机所管理的内存中最大的一块，Java 堆是所有线程共享的一块内存区域，在虚拟机启动时创建。 此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例以及数组都在这里分配内存。 Java 堆是垃圾收集器管理的主要区域，因此也被称作 GC 堆（Garbage Collected Heap） 方法区 当虚拟机要使用一个类时，它需要读取并解析 Class 文件获取相关信息，再将信息存入到方法区。 方法区会存储已被虚拟机加载的 类信息、字段信息、方法信息、常量、静态变量、即时编译器编译后的代码缓存等数据。 运行时常量池 存放编译期生成的各种字面量（Literal）和符号引用（Symbolic Reference）的 常量池表(Constant Pool Table) 常量池表会在类加载后存放到方法区的运行时常量池中。 字符串常量池 字符串常量池 是 JVM 为了提升性能和减少内存消耗针对字符串（String 类）专门开辟的一块区域，主要目的是为了避免字符串的重复创建。 直接内存 直接内存是一种特殊的内存缓冲区，并不在 Java 堆或方法区中分配的，而是通过 JNI 的方式在本地内存上分配的。 类似的概念还有 堆外内存 堆外内存就是把内存对象分配在堆（新生代+老年代+永久代）以外的内存，这些内存直接受操作系统管理（而不是虚拟机），这样做的结果就是能够在一定程度上减少垃圾回收对应用程序造成的影响。 💠对象创建过程 Java 对象的创建过程我建议最好是能默写出来，并且要掌握每一步在做什么。 Step1:类加载检查 虚拟机遇到一条 new 指令时，首先将去检查这个指令的参数是否能在常量池中定位到这个类的符号引用，并且检查这个符号引用代表的类是否已被加载过、解析和初始化过。如果没有，那必须先执行相应的类加载过程。 Step2:分配内存 在类加载检查通过后，接下来虚拟机将为新生对象分配内存。对象所需的内存大小在类加载完成后便可确定，为对象分配空间的任务等同于把一块确定大小的内存从 Java 堆中划分出来。分配方式有 “指针碰撞” 和 “空闲列表” 两种，选择哪种分配方式由 Java 堆是否规整决定，而 Java 堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。 内存分配的两种方式 （补充内容，需要掌握）： 指针碰撞： 适用场合：堆内存规整（即没有内存碎片）的情况下。 原理：用过的内存全部整合到一边，没有用过的内存放在另一边，中间有一个分界指针，只需要向着没用过的内存方向将该指针移动对象内存大小位置即可。 使用该分配方式的 GC 收集器：Serial, ParNew 空闲列表： 适用场合：堆内存不规整的情况下。 原理：虚拟机会维护一个列表，该列表中会记录哪些内存块是可用的，在分配的时候，找一块儿足够大的内存块儿来划分给对象实例，最后更新列表记录。 使用该分配方式的 GC 收集器：CMS 选择以上两种方式中的哪一种，取决于 Java 堆内存是否规整。而 Java 堆内存是否规整，取决于 GC 收集器的算法是&quot;标记-清除&quot;，还是&quot;标记-整理&quot;（也称作&quot;标记-压缩&quot;），值得注意的是，复制算法内存也是规整的。 内存分配并发问题（补充内容，需要掌握） 在创建对象的时候有一个很重要的问题，就是线程安全，因为在实际开发过程中，创建对象是很频繁的事情，作为虚拟机来说，必须要保证线程是安全的，通常来讲，虚拟机采用两种方式来保证线程安全： CAS+失败重试： CAS 是乐观锁的一种实现方式。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。虚拟机采用 CAS 配上失败重试的方式保证更新操作的原子性。 TLAB： 为每一个线程预先在 Eden 区分配一块儿内存，JVM 在给线程中的对象分配内存时，首先在 TLAB 分配，当对象大于 TLAB 中的剩余内存或 TLAB 的内存已用尽时，再采用上述的 CAS 进行内存分配 Step3:初始化零值 内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头），这一步操作保证了对象的实例字段在 Java 代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。 Step4:设置对象头 初始化零值完成之后，虚拟机要对对象进行必要的设置，例如这个对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的 GC 分代年龄等信息。 这些信息存放在对象头中。 另外，根据虚拟机当前运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式。 Step5:执行 init 方法 在上面工作都完成之后，从虚拟机的视角来看，一个新的对象已经产生了，但从 Java 程序的视角来看，对象创建才刚开始，&lt;init&gt; 方法还没有执行，所有的字段都还为零。所以一般来说，执行 new 指令之后会接着执行 &lt;init&gt; 方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全产生出来 对象的内存布局 对象头、实例数据和对齐填充。 对象头： 用于存储对象自身的运行时数据（哈希码、GC 分代年龄、锁状态标志等等） 类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。 实例数据： 对象真正存储的有效信息，也是在程序中所定义的各种类型的字段内容。 对齐填充： 起占位作用 对象的访问定位 句柄、 直接指针 使用句柄来访问的最大好处是 reference 中存储的是稳定的句柄地址，在对象被移动时只会改变句柄中的实例数据指针，而 reference 本身不需要修改。 使用直接指针访问方式最大的好处 就是速度快，它节省了一次指针定位的时间开销。 JVM垃圾回收机制 Java 堆是垃圾收集器管理的主要区域，因此也被称作 GC 堆（Garbage Collected Heap）。 从垃圾回收的角度来说，由于现在收集器基本都采用分代垃圾收集算法，所以 Java 堆被划分为了几个不同的区域，这样我们就可以根据各个区域的特点选择合适的==垃圾收集算法==。 在 JDK 7 版本及 JDK 7 版本之前，堆内存被通常分为下面三部分： 新生代内存(Young Generation) 老生代(Old Generation) 永久代(Permanent Generation) ---- 元空间 Eden 区、两个 Survivor 区 S0 和 S1 都属于新生代，中间一层属于老年代，最下面一层属于永久代。 JDK 8 版本之后 PermGen(永久) 已被 Metaspace(==元空间==) 取代，元空间==使用的是直接内存== 。 另一张图 内存分配和回收原则 对象优先在 Eden 区分配 大对象直接进入老年代 大对象就是需要大量连续内存空间的对象（比如：字符串、数组）。 长期存活的对象将进入老年代 主要进行 gc 的区域 针对 HotSpot VM 的实现，它里面的 GC 其实准确分类只有两大种： 部分收集 (Partial GC)： 新生代收集（Minor GC / Young GC）：只对新生代进行垃圾收集； 老年代收集（Major GC / Old GC）：只对老年代进行垃圾收集。需要注意的是 Major GC 在有的语境中也用于指代整堆收集； 混合收集（Mixed GC）：对整个新生代和部分老年代进行垃圾收集。 整堆收集 (Full GC)：收集整个 Java 堆和方法区。 空间分配担保 死亡对象判断方法（ 2 种） 引用计数法 问题：**==循环引用==**无法解决 方法原理： 每当有一个地方引用它，计数器就加 1； 当引用失效，计数器就减 1； 任何时候计数器为 0 的对象就是不可能再被使用的。 可达性分析算法 以 “GC Roots” 的对象作为起点，从这些节点开始向下搜索，节点所走过的路径称为引用链，当一个对象到 GC Roots 没有任何引用链相连的话，则证明此对象是不可用的，需要被回收。 Object 6 ~ Object 10 之间虽有引用关系，但它们到 GC Roots 不可达，因此为需要被回收的对象。 哪些对象可以作为 GC Roots 呢？ 虚拟机栈(栈帧中的本地变量表)中引用的对象 本地方法栈(Native 方法)中引用的对象 方法区中类静态属性引用的对象 方法区中常量引用的对象 所有被同步锁持有的对象 JNI（Java Native Interface）引用的对象 引用类型 弱引用和虚引用在每次 垃圾回收的时候都会回收 虚引用主要用来跟踪对象被垃圾回收的活动。 在程序设计中一般很少使用弱引用与虚引用，使用软引用的情况较多，这是因为软引用可以加速 JVM 对垃圾内存的回收速度，可以维护系统的运行安全，防止内存溢出（OutOfMemory）等问题的产生。 虚引用与软引用和弱引用的一个区别在于： 虚引用必须和引用队列（ReferenceQueue）联合使用。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中。程序可以通过判断引用队列中是否已经加入了虚引用，来了解被引用的对象是否将要被垃圾回收。程序如果发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取必要的行动。 怎么判断一个类是无用的类 该类所有的实例都已经被回收，也就是 Java 堆中不存在该类的任何实例。 加载该类的 ClassLoader 已经被回收。 该类对应的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。 虚拟机可以对满足上述 3 个条件的无用类进行回收，这里说的仅仅是“可以”，而并不是和对象一样不使用了就会必然被回收。 垃圾收集算法（ 4 种) 标记-清除算法 分为“==标记==（Mark）”和“==清除==（Sweep）”阶段：首先标记出所有不需要回收的对象，在标记完成后统一回收掉所有没有被标记的对象。 它是最基础的收集算法，后续的算法都是对其不足进行改进得到。这种垃圾收集算法会带来两个明显的问题： 效率问题：标记和清除两个过程效率都不高。 空间问题：标记清除后会产生大量不连续的**==内存碎片==**。 复制算法 将内存分为大小相同的==两块==，每次使用其中的一块。当这一块的内存使用完后，就将还存活的对象复制到另一块去，然后再把使用的空间一次清理掉。这样就使每次的内存回收都是对内存区间的一半进行回收。 虽然改进了标记-清除算法，但依然存在下面这些问题： 可用内存变小：可用内存缩小为原来的一半。 不适合老年代：如果存活对象数量比较大，复制性能会变得很差。 标记-整理算法 根据老年代的特点提出的一种标记算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象回收，而是让所有存活的对象向一端移动，然后直接清理掉端边界以外的内存。 复制 存活 ------&gt; 全部清理原来的内存 优点 该算法不会像标记-清除算法那样产生大量的碎片空间。 缺点 如果存活的对象过多，整理阶段将会执行较多复制操作，导致算法效率降低，适合老年代。 分代收集算法 根据对象存活周期的不同将内存分为几块。一般将 Java 堆分为新生代和老年代，这样我们就可以根据各个年代的特点选择合适的垃圾收集算法。 在新生代中，每次收集都会有大量对象死去，所以可以选择”标记-复制“算法，只需要付出少量对象的复制成本就可以完成每次垃圾收集。而老年代的对象存活几率是比较高的，而且没有额外的空间对它进行分配担保，所以我们必须选择“标记-清除”或“标记-整理”算法进行垃圾收集。 垃圾收集器（ 8 种 ) JDK 默认垃圾收集器（使用 java -XX:+PrintCommandLineFlags -version 命令查看）： JDK 8：Parallel Scavenge（新生代）+ Parallel Old（老年代） JDK 9 ~ JDK20: G1 Serial（串行）收集器 是一个单线程收集器了。它的 “单线程” 的意义不仅仅意味着它只会使用一条垃圾收集线程去完成垃圾收集工作，更重要的是它在进行垃圾收集工作的时候必须暂停其他所有的工作线程（ “Stop The World” ），直到它收集结束。 新生代采用标记-复制算法，老年代采用标记-整理算法。 特点： 简单高效，但是在GC过程中要完全暂停用户线程 ParNew 收集器 Serial 收集器的多线程版本，除了**使用==多线程==**进行垃圾收集外，其余行为（控制参数、收集算法、回收策略等等）和 Serial 收集器完全一样。 在 Server 模式下的虚拟机的首要选择，除了 Serial 收集器外，只有它能与 CMS 收集器（真正意义上的并发收集器，后面会介绍到）配合工作。 并行和并发概念补充： 并行（Parallel）：指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。 并发（Concurrent）：指用户线程与垃圾收集线程同时执行（但不一定是并行，可能会交替执行），用户程序在继续运行，而垃圾收集器运行在另一个 CPU 上。 Parallel Scavenge 收集器 Parallel Scavenge 收集器关注点是**==吞吐量==（高效率的利用 CPU）。CMS 等垃圾收集器的关注点更多的是用户==线程==的==停顿时间==**（提高用户体验） 提供了很多参数供用户找到最合适的停顿时间或最大吞吐量 JDK1.8 默认收集器 Serial Old 收集器 Serial 收集器的老年代版本，它同样是一个单线程收集器。它主要有两大用途：一种用途是在 JDK1.5 以及以前的版本中与 Parallel Scavenge 收集器搭配使用，另一种用途是作为 CMS 收集器的后备方案。 Parallel Old 收集器 Parallel Scavenge 收集器的老年代版本。使用多线程和“标记-整理”算法。在注重吞吐量以及 CPU 资源的场合，都可以优先考虑 Parallel Scavenge 收集器和 Parallel Old 收集器。 CMS 收集器 以获取最短回收停顿时间为目标的收集器。它非常符合在注重用户体验的应用上使用。 是 HotSpot 虚拟机第一款真正意义上的==并发收集器==，它第一次实现了让垃圾收集线程与用户线程（基本上）同时工作。 “标记-清除” 实现 整个过程分为四个步骤： 初始标记： 暂停所有的其他线程，并记录下直接与 root 相连的对象，速度很快 ； 并发标记： 同时开启 GC 和用户线程，用一个闭包结构去记录可达对象。但在这个阶段结束，这个闭包结构并不能保证包含当前所有的可达对象。因为用户线程可能会不断的更新引用域，所以 GC 线程无法保证可达性分析的实时性。所以这个算法里会跟踪记录这些发生引用更新的地方。 重新标记： 重新标记阶段就是为了修正并发标记期间因为用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段的时间稍长，远远比并发标记阶段时间短 并发清除： 开启用户线程，同时 GC 线程开始对未标记的区域做清扫。 这里就能很明显的看出，为什么CMS要使用标记清除而不是标记压缩，如果使用标记压缩，需要多对象的内存位置进行改变，这样程序就很难继续执行。但是标记清除会产生大量内存碎片，不利于内存分配 CMS的提出是想改善GC的停顿时间，在GC过程中的确做到了减少GC时间，但是同样导致产生大量内存碎片，又需要消耗大量时间去整理碎片，从本质上并没有改善时间 主要优点：并发收集、低停顿。但是它有下面三个明显的缺点： 对 CPU 资源敏感； 无法处理浮动垃圾； 它使用的回收算法-“标记-清除”算法会导致收集结束时会有大量空间碎片产生 G1 收集器 针对配备多颗处理器及大容量内存的机器. 以极高概率满足 GC 停顿时间要求的同时,还具备高吞吐量性能特征. 并行与并发：G1 能充分利用 CPU、多核环境下的硬件优势，使用多个 CPU（CPU 或者 CPU 核心）来缩短 Stop-The-World 停顿时间。部分其他收集器原本需要停顿 Java 线程执行的 GC 动作，G1 收集器仍然可以通过并发的方式让 java 程序继续执行。 分代收集：虽然 G1 可以不需要其他收集器配合就能独立管理整个 GC 堆，但是还是保留了分代的概念。 空间整合：与 CMS 的“标记-清除”算法不同，G1 从整体来看是基于“标记-整理”算法实现的收集器；从局部上来看是基于“标记-复制”算法实现的。 可预测的停顿：这是 G1 相对于 CMS 的另一个大优势，降低停顿时间是 G1 和 CMS 共同的关注点，但 G1 除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为 M 毫秒的时间片段内，消耗在垃圾收集上的时间不得超过 N 毫秒。 上面提到的垃圾收集器，收集的范围都是整个新生代或者老年代，而G1不再是这样。使用G1收集器时，Java堆的内存布局与其他收集器有很大差别，它将整个Java堆划分为多个大小相等的独立区域（Region），虽然还保留有新生代和老年代的概念，但新生代和老年代不再是物理隔阂了，它们都是一部分（可以不连续）Region的集合。 G1的新生代收集跟ParNew类似，当新生代占用达到一定比例的时候，开始出发收集。 和CMS类似，G1收集器收集老年代对象会有短暂停顿。 在后台维护了一个优先列表，每次根据允许的收集时间，优先选择回收价值最大的 Region(这也就是它的名字 Garbage-First 的由来) 。这种使用 Region 划分内存空间以及有优先级的区域回收方式，保证了 G1 收集器在有限时间内可以尽可能高的收集效率（把内存化整为零）。 类的加载过程 7个阶段：加载（Loading）、验证（Verification）、准备（Preparaton)、解析（Resolution）、初始化（Initialization）、使用（Using）和卸载（Unloading） 加载 Class 文件需要加载到虚拟机中之后才能运行和使用 系统加载 Class 类型的文件主要三步：加载-&gt;连接-&gt;初始化。连接过程又可分为三步：验证-&gt;准备-&gt;解析。 类加载过程的第一步，主要完成下面 3 件事情： 通过全类名获取定义此类的二进制字节流。 将字节流所代表的静态存储结构转换为方法区的运行时数据结构。 在内存中生成一个代表该类的 Class 对象，作为方法区这些数据的访问入口 加载这一步主要是通过我们后面要讲到的 ==类加载器== 完成的。类加载器有很多种，当我们想要加载一个类的时候，具体是哪个类加载器加载由 ==双亲委派模型== 决定 加载阶段与连接阶段的部分动作(如一部分字节码文件格式验证动作)是**==交叉进行==**的，加载阶段尚未结束，连接阶段可能就已经开始了。 验证 验证是连接阶段的第一步，这一阶段的目的是==确保 Class 文件的字节流==中包含的信息==符合==《Java 虚拟机规范》的全部==约束要求==，保证这些信息被当作代码运行后不会危害虚拟机自身的安全。 验证阶段主要由四个检验阶段组成： 文件格式验证（**==Class 文件格式==**检查） 元数据验证（**==字节码语义==**检查） 字节码验证（**==程序语义==**检查） 符号引用验证（**==类的正确性==**检查） 准备 准备阶段是正式==为类变量==分配内存并==设置类变量初始值==的阶段，这些内存都将在方法区中分配 这时候进行内存分配的仅包括类变量（==静态变量==），而不包括实例变量。实例变量会在对象实例化时随着对象一块分配在 Java 堆中。 类变量所使用的内存都应当在 方法区 中进行分配 JDK 7 之前，HotSpot 使用永久代来实现方法区的时候，实现是完全符合这种逻辑概念的。 而在 JDK 7 及之后，HotSpot 已经把原本放在永久代的字符串常量池、静态变量等移动到堆中，这个时候类变量则会随着 Class 对象一起存放在 Java 堆中。 这里所设置的初始值&quot;通常情况&quot;下是==数据类型默认的零值==（如 0、0L、null、false 等）。 但是，如果有加上 final 关键字，那么准备阶段value就会被赋值 比如我们定义了public static int value=111 ，那么 value 变量在准备阶段的初始值就是 0 而不是 111（初始化阶段才会赋值） 解析 解析阶段是==虚拟机==将==常量池==内的==符号引用==替换为==直接引用==的过程 初始化 初始化阶段是执行初始化方法 &lt;clinit&gt; ()方法的过程，是类加载的最后一步，这一步 JVM 才开始真正执行类中定义的 Java 程序代码(字节码)。 说明：&lt;clinit&gt; ()方法是编译之后自动生成的。 对于&lt;clinit&gt; () 方法的调用，虚拟机会自己确保其在多线程环境中的安全性 当遇到 new、 getstatic、putstatic 或 invokestatic 这 4 条字节码指令时，比如 new 一个类，读取一个静态字段(未被 final 修饰)、或调用一个类的静态方法时。 当 jvm 执行 new 指令时会初始化类。即当程序创建一个类的实例对象。 当 jvm 执行 getstatic 指令时会初始化类。即程序访问类的静态变量(不是静态常量，常量会被加载到运行时常量池)。 当 jvm 执行 putstatic 指令时会初始化类。即程序给类的静态变量赋值。 当 jvm 执行 invokestatic 指令时会初始化类。即程序调用类的静态方法。 使用 java.lang.reflect 包的方法对类进行**==反射调用==**时如 Class.forname(&quot;...&quot;), newInstance() 等等。如果类没初始化，需要触发其初始化。 初始化一个类，如果其**==父类还未初始化==**，则先触发该父类的初始化。 当虚拟机启动时，用户需要定义**==一个要执行的主类==** (包含 main 方法的那个类)，虚拟机会先初始化这个类。 MethodHandle 和 VarHandle 可以看作是轻量级的反射调用机制，而要想使用这 2 个调用， 就必须先使用 findStaticVarHandle 来初始化要调用的类。 「补充，来自issue745open in new window」 当一个接口中定义了 JDK8 新加入的默认方法（被 default 关键字修饰的接口方法）时，如果有这个接口的实现类发生了初始化，那该接口要在其之前被初始化 类卸载 卸载类即该类的 Class 对象被 ==GC==。 卸载类需要满足 3 个要求: 该类的所有的实例对象都已被 GC，也就是说堆不存在该类的实例对象。 该类没有在其他任何地方被引用 该类的类加载器的实例已被 GC 所以，在 JVM 生命周期内，由 jvm 自带的类加载器加载的类是不会被卸载的。但是由我们自定义的类加载器加载的类是可能被卸载的。 只要想通一点就好了，JDK 自带的 BootstrapClassLoader, ExtClassLoader, AppClassLoader 负责加载 JDK 提供的类，所以它们(类加载器的实例)肯定不会被回收。而我们自定义的类加载器的实例是可以被回收的，所以使用我们自定义加载器加载的类是可以被卸载掉的。 类加载器详解 类加载器的主要作用就是加载 Java 类的字节码（ .class 文件）到 JVM 中（在内存中生成一个代表该类的 Class 对象） 规则 JVM 启动的时候，并不会一次性加载所有的类，而是根据需要去动态加载。也就是说，大部分类在具体用到的时候才会去加载 对于已经加载的类会放在 ClassLoader 中。 在类加载的时候，系统会首先**==判断==当前类是否被加载过**。已经被加载的类会直接返回，否则才会尝试加载。也就是说，对于一个类加载器来说，相同二进制名称的类只会被加载一次。 总结 JVM 中内置了三个重要的 ClassLoader： BootstrapClassLoader(启动类加载器)：最顶层的加载类，由 C++实现，通常表示为 null，并且没有父级，主要用来加载 JDK 内部的核心类库（ %JAVA_HOME%/lib目录下的 rt.jar、resources.jar、charsets.jar等 jar 包和类）以及被 -Xbootclasspath参数指定的路径下的所有类。 ExtensionClassLoader(扩展类加载器)：主要负责加载 %JRE_HOME%/lib/ext 目录下的 jar 包和类以及被 java.ext.dirs 系统变量所指定的路径下的所有类。 AppClassLoader(==应用程序类==加载器)：面向我们用户的加载器，负责加载当前应用 classpath 下的所有 jar 包和类。 除了 BootstrapClassLoader 是 JVM 自身的一部分之外，其他所有的类加载器都是在 JVM 外部实现的，并且全都继承自 ClassLoader抽象类。这样做的好处是用户可以自定义类加载器，以便让应用程序自己决定如何去获取所需的类。 每个 ClassLoader 可以通过getParent()获取其父 ClassLoader，如果获取到 ClassLoader 为null的话，那么该类是通过 BootstrapClassLoader 加载的。 自定义类加载器 除了 BootstrapClassLoader 其他类加载器均由 Java 实现且全部继承自java.lang.ClassLoader。 如果我们要自定义自己的类加载器，很明显需要**==继承==** ClassLoader抽象类。 loadClass ： 加载指定二进制名称的类，实现了双亲委派机制 findClass ：根据类的二进制名称来查找类，默认实现是空方法。 双亲委派机制 ClassLoader 类使用委托模型来搜索类和资源。 双亲委派模型要求除了顶层的启动类加载器外，其余的类加载器都应有自己的父类加载器。 ClassLoader 实例会在试图亲自查找类或资源之前，将搜索类或资源的任务委托给其父类加载器。 在类加载的时候，系统会首先判断当前类是否被加载过。已经被加载的类会直接返回，否则才会尝试加载（每个父类加载器都会走一遍这个流程）。 类加载器在进行类加载的时候，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成（调用父加载器 loadClass()方法来加载类）。这样的话，所有的请求最终都会传送到顶层的启动类加载器 BootstrapClassLoader 中。 只有当父加载器反馈自己无法完成这个加载请求（它的搜索范围中没有找到所需的类）时，子加载器才会尝试自己去加载（调用自己的 findClass() 方法来加载类）。 JVM 判定两个 Java 类是否相同的具体规则：JVM 不仅要看类的全名是否相同，还要看加载此类的类加载器是否一样。只有两者都相同的情况，才认为两个类是相同的。 如果没有使用双亲委派模型，而是每个类加载器加载自己的话就会出现一些问题，比如我们编写一个称为 java.lang.Object 类的话，那么程序运行的时候，系统就会出现两个不同的 Object 类。双亲委派模型可以保证加载的是 JRE 里的那个 Object 类，而不是你写的 Object 类。这是因为 AppClassLoader 在加载你的 Object 类时，会委托给 ExtClassLoader 去加载，而 ExtClassLoader 又会委托给 BootstrapClassLoader，BootstrapClassLoader 发现自己已经加载过了 Object 类，会直接返回，不会去加载你写的 Object 类 JVM参数总结 最重要的JVM参数总结 | JavaGuide(Java面试 + 学习指南) 堆内存相关 JDK 监控和故障处理工具总结 JDK监控和故障处理工具总结 | JavaGuide(Java面试 + 学习指南) JVM 线上问题排查和性能调优 JVM线上问题排查和性能调优案例 | JavaGuide(Java面试 + 学习指南)","categories":[{"name":"知识点梳理","slug":"知识点梳理","permalink":"http://kaillliu.github.io/categories/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://kaillliu.github.io/tags/Java/"},{"name":"知识点梳理","slug":"知识点梳理","permalink":"http://kaillliu.github.io/tags/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86/"}]},{"title":"Java 并发 知识总结","slug":"Java并发","date":"2023-08-04T07:00:00.000Z","updated":"2023-09-08T03:55:46.743Z","comments":true,"path":"2023/08/04/Java并发/","link":"","permalink":"http://kaillliu.github.io/2023/08/04/Java%E5%B9%B6%E5%8F%91/","excerpt":"","text":"Java并发 线程和进程 区别 线程是一个比进程更小的执行单位。一个进程在其执行的过程中可以产生多个线程。 同类的多个线程共享进程的**==堆==和==方法区==资源，但每个线程有自己的程序计数器**、虚拟机栈和本地方法栈， 关系 堆和方法区是所有线程共享的资源： 堆： 是进程中最大的一块内存，主要用于存放新创建的对象 (几乎所有对象都在这里分配内存) 方法区： 主要用于存放已被加载的类信息、常量、静态变量、即时编译器编译后的代码等数据 并发与并行 并发：两个及两个以上的作业在同一 时间段 内执行。 并行：两个及两个以上的作业在同一 时刻 执行。 关键区别是 是否 ==同时== 执行 同步与异步 同步：调用之后，没有得到结果之前，==一直等待==。 异步：调用之后，不用等待返回结果，==直接返回==。 线程的生命周期和状态 死锁 互斥条件： 该资源任意一个时刻只由一个线程占用。 请求与保持条件： 一个线程因请求资源而阻塞时，对已获得的资源==保持不放==。 不剥夺条件： 线程已获得的资源在未使用完之前==不能被==其他线程==强行剥夺==，只有自己==使用完毕==后**才==释放==**资源。 循环等待条件： 若干线程之间形成一种**==头尾相接==的==循环等待==**资源关系。 预防死锁 破坏请求与保持条件： 一次性申请所有的资源。 破坏不剥夺条件： 占用部分资源的线程进一步申请其他资源时，如果==申请不到==，可以**==主动==释放它==占有的资源**==。 破坏循环等待条件： 靠**==按序申请==资源**来预防。按某一顺序申请资源，释放资源则反序释放。破坏循环等待条件 sleep()方法和wait()方法 共同点：两者都可以暂停线程的执行。 区别： sleep() 方法没有释放锁，而 wait() 方法释放了锁 。 wait() 通常被用于线程间交互/通信，sleep()通常被用于暂停执行。 wait() 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 notify()或者 notifyAll() 方法。sleep()方法执行完成后，线程会自动苏醒，或者也可以使用 wait(long timeout) 超时后线程会自动苏醒。 sleep() 是 Thread 类的静态本地方法，wait() 则是 Object 类的本地方法。为什么这样设计呢？下一个问题就会聊到。 wait() 需要 获取 对象锁 ，让获得对象锁的线程实现等待，会自动释放当前线程占有的对象锁。 操作的是对象的锁，不是操作线程 sleep()是让当前线程暂停执行，不涉及对象类，无需对象锁 能直接调用Thread类的 run 方法么 可以，但是直接调用无法多线程。直接执行 run() 方法的话不会以多线程的方式执行。 new 一个 Thread，线程进入了新建状态。调用 start()方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。 start() 会执行线程的相应准备工作，然后自动执行 run() 方法的内容，这是真正的多线程工作。 但是，直接执行 run() 方法，会把 run() 方法当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。 JMM（Java内存模型） JMM(Java 内存模型)主要定义了对于一个共享变量，当另一个线程对这个共享变量执行写操作后，这个线程对这个共享变量的可见性。 线程 1 要与线程 2 通信的话： 线程 1 把本地内存中修改过的共享变量副本的值同步到主内存中去。 线程 2 到主存中读取对应的共享变量的值。 JMM为共享变量提供了可见性的保障。 volatile 关键字 保证数据的可见性，但是不能保证数据的原子性 防止 JVM 的指令重排序 一个使用 volatile 和 synchronized 关键字实现的对象单例（线程安全）： 1234567891011121314151617181920public class Singleton &#123; private volatile static Singleton uniqueInstance; private Singleton() &#123; &#125; public static Singleton getUniqueInstance() &#123; //先判断对象是否已经实例过，没有实例化过才进入加锁代码 if (uniqueInstance == null) &#123; //类对象加锁 synchronized (Singleton.class) &#123; if (uniqueInstance == null) &#123; uniqueInstance = new Singleton(); &#125; &#125; &#125; return uniqueInstance; &#125;&#125; uniqueInstance 采用 volatile 关键字修饰也是很有必要的， uniqueInstance = new Singleton(); 这段代码其实是分为**==三步*==*执行： 为 uniqueInstance 分配内存空间 初始化 uniqueInstance 将 uniqueInstance 指向分配的内存地址 但是由于 JVM 具有指令重排的特性，执行顺序有可能变成==1-&gt;3-&gt;2==。指令重排在单线程环境下不会出现问题，但是在多线程环境下会导致一个线程获得还没有初始化的实例。例如，线程 T1 执行了 1 和 3，此时 T2 调用 getUniqueInstance() 后发现 uniqueInstance 不为空，因此返回 uniqueInstance，但此时 uniqueInstance 还未被初始化 乐观锁和悲观锁 悲观锁 概念 共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程。 **synchronized **和 ReentrantLock等独占锁就是悲观锁思想的实现 高并发的场景下，激烈的锁竞争会造成线程阻塞还可能会存在死锁问题，影响代码的正常运行。 乐观锁 概念 共享资源每次被访问的时候不会出现问题，线程可以不停地执行，==无需加锁==也无需等待，只是在提交修改的时候去==验证对应的资源==（也就是数据）是否被其它线程修改了（具体方法可以使用**==版本号机制==或 ==CAS 算法==**）。 如果冲突频繁发生（写占比非常多的情况），会频繁失败和重试，这样同样会非常影响性能，导致 CPU 飙升。 比较 悲观锁通常多用于**==写比较多==**的情况（多写场景，竞争激烈），这样可以避免频繁失败和重试影响性能，悲观锁的开销是固定的。 乐观锁通常多用于**==写比较少==的情况（多读场景，竞争较少），这样可以避免频繁加锁影响性能。不过，乐观锁主要针对的对象是单个共享变量**（参考java.util.concurrent.atomic包下面的原子变量类）。 版本号机制 CAS算法 比较与交换算法 (Compare And Swap) 一个**==预期值==和要==更新的变量值==**进行比较，两值相等才会进行更新。 CAS 涉及到三个操作数： V：要更新的变量值(Var) E：预期值(Expected) N：拟写入的新值(New) 举一个简单的例子：线程 A 要修改变量 i 的值为 6，i 原值为 1（V = 1，E=1，N=6，假设不存在 ABA 问题）。 i 与 1 进行比较，如果相等， 则说明没被其他线程修改，可以被设置为 6 。 i 与 1 进行比较，如果不相等，则说明被其他线程修改，当前线程放弃更新，CAS 操作失败。 存在的问题 ABA 问题 读取的时候是 A ，赋值的时候也准备是 A ，不能说它没被其他线程修改过 可以通过在变量前面追加 版本号和时间戳 循环**==时间开销大==** CAS 经常会用到自旋操作来进行重试，也就是不成功就一直循环执行直到成功。 如果长时间不成功，会给 CPU 带来非常大的执行开销。 只能保证**==一个共享变量==的==原子==操作** 涉及跨多个共享变量时 CAS 无效 但是可以使用锁或者利用AtomicReference类把多个共享变量合并成一个共享变量来操作 synchronized 关键字 synchronized 关键字加到 static 静态方法和 synchronized(class) 代码块上都是是给 Class 类上锁； synchronized 关键字加到实例方法上是给对象实例上锁； 尽量不要使用 synchronized(String a) 因为 JVM 中，字符串常量池具有缓存功能 底层 同步 代码块 的情况 当执行 monitorenter 指令时，线程试图获取锁也就是获取 对象监视器 monitor 的持有权。 synchronized 同步语句块的实现使用的是 monitorenter 和 monitorexit 指令，其中 monitorenter 指令指向同步代码块的开始位置，monitorexit 指令则指明同步代码块的结束位置。 在 Java 虚拟机(HotSpot)中，Monitor 是基于 C++实现的，由ObjectMonitoropen in new window实现的。每个对象中都内置了一个 ObjectMonitor对象。 另外，wait/notify等方法也依赖于monitor对象，这就是为什么只有在同步的块或者方法中才能调用wait/notify等方法，否则会抛出java.lang.IllegalMonitorStateException的异常的原因。 同步 方法 的情况 ACC_SYNCHRONIZED 标识，该标识指明了该方法是一个同步方法。JVM 通过该 ACC_SYNCHRONIZED 访问标志来辨别一个方法是否声明为同步方法，从而执行相应的同步调用。 如果是实例方法，JVM 会尝试获取实例对象的锁。如果是静态方法，JVM 会尝试获取当前 class 的锁。 总结 synchronized 同步语句块的实现使用的是 monitorenter 和 monitorexit 指令，其中 monitorenter 指令指向同步代码块的开始位置，monitorexit 指令则指明同步代码块的结束位置。 synchronized 修饰的方法并没有 monitorenter 指令和 monitorexit 指令，取得代之的确实是 ACC_SYNCHRONIZED 标识，该标识指明了该方法是一个同步方法。 不过两者的本质都是对==对象监视器== monitor 的获取 synchronized 和 volatile 有什么区别 volatile 关键字是线程同步的轻量级实现，所以 volatile性能肯定比synchronized关键字要好 。 volatile 关键字只能用于变量而 synchronized 关键字可以修饰方法以及代码块 。 volatile 关键字能保证数据的可见性，但不能保证数据的原子性。synchronized 关键字两者都能保证。 volatile关键字主要用于解决变量在多个线程之间的可见性，而 synchronized 关键字解决的是多个线程之间访问资源的同步性。 ReentrantLock ReentrantLock 的底层就是由 AQS 来实现的。 公平锁和非公平锁 公平锁 : 锁被释放之后，先申请的线程先得到锁。性能较差一些，因为公平锁为了保证时间上的绝对顺序，上下文切换更频繁。 非公平锁：锁被释放之后，后申请的线程可能会先获取到锁，是随机或者按照其他优先级排序的。性能更好，但可能会导致某些线程永远无法获取到锁。 synchronized 和 ReentrantLock 有什么区别 两者都是可重入锁 ​ 可重入锁 也叫递归锁，指的是线程**==可以再次获取==**自己的内部锁。 12345678910public class SynchronizedDemo &#123; public synchronized void method1() &#123; System.out.println(&quot;方法1&quot;); method2(); &#125; public synchronized void method2() &#123; System.out.println(&quot;方法2&quot;); &#125;&#125; synchronized 依赖于 JVM 而 ReentrantLock 依赖于 API 增加了一些高级功能 等待可中断 可实现公平锁 可实现选择性通知 Condition是 JDK1.5 之后才有的，它具有很好的灵活性，比如可以实现多路通知功能也就是在一个Lock对象中可以创建多个Condition实例（即对象监视器），线程对象可以注册在指定的Condition中，从而可以有选择性的进行线程通知，在调度线程上更加灵活。 在使用notify()/notifyAll()方法进行通知时，被通知的线程是由 JVM 选择的，用ReentrantLock类结合Condition实例可以实现“选择性通知” ，这个功能非常重要，而且是 Condition 接口默认提供的。而synchronized关键字就相当于整个 Lock 对象中只有一个Condition实例，所有的线程都注册在它一个身上。如果执行notifyAll()方法的话就会通知所有处于等待状态的线程，这样会造成很大的效率问题。而Condition实例的signalAll()方法，只会唤醒注册在该Condition实例中的所有等待线程。 可中断锁和不可中断锁有什么区别？ 可中断锁：获取锁的过程中可以被中断，不需要一直等到获取锁之后 才能进行其他逻辑处理。ReentrantLock 就属于是可中断锁。 不可中断锁：一旦线程申请了锁，就只能等到拿到锁以后才能进行其他的逻辑处理。 synchronized 就属于是不可中断锁。 ReentrantReadWriteLock 是什么？ ReentrantReadWriteLock 实现了 ReadWriteLock ，是一个可重入的读写锁，既可以保证多个线程同时读的效率，同时又可以保证有写入操作时的线程安全。 一般锁进行并发控制的规则：读读互斥、读写互斥、写写互斥。 读写锁进行并发控制的规则：读读==不互斥==、读写互斥、写写互斥（只有读读不互斥）。 ReentrantReadWriteLock 适合什么场景？ 由于 ReentrantReadWriteLock 既可以保证多个线程同时读的效率，同时又可以保证有写入操作时的线程安全。因此，在**==读多写少==**的情况下，使用 ReentrantReadWriteLock 能够明显提升系统性能。 共享锁和独占锁有什么区别？ 共享锁：一把锁可以被多个线程同时获得。 独占锁：一把锁只能被一个线程获得。 线程持有读锁还能获取写锁吗？ 在线程**==持有读锁==的情况下，该线程不能取得写锁**(因为获取写锁的时候，如果发现当前的读锁被占用，就马上获取失败，不管读锁是不是被当前线程持有)。 在线程持有写锁的情况下，该线程可以继续获取读锁（获取读锁时如果发现写锁被占用，只有写锁没有被==当前线程==占用的情况才会获取失败）。 读写锁的源码分析，推荐阅读 聊聊 Java 的几把 JVM 级锁 - 阿里巴巴中间件 open in new window 这篇文章，写的很不错。 读锁为什么不能升级为写锁？ 写锁可以降级为读锁，但是读锁却不能升级为写锁。这是因为读锁升级为写锁会引起线程的争夺，毕竟写锁属于是独占锁，这样的话，会影响性能。 另外，还可能会有死锁问题发生。举个例子：假设两个线程的读锁都想升级写锁，则需要对方都释放自己锁，而双方都不释放，就会产生死锁。 ThreadLocal 通常情况下，我们创建的变量是可以被任何一个线程访问并修改的 ThreadLocal类主要解决的就是让==每个线程绑定自己的值==，可以将ThreadLocal类形象的比喻成存放数据的盒子，盒子中可以存储每个线程的==私有数据==。 原理 最终的变量是放在了==当前线程==的 ThreadLocalMap 中，并不是存在 ThreadLocal 上，ThreadLocal 可以理解为只是ThreadLocalMap的封装，传递了变量值。 ThrealLocal 类中可以通过**Thread.currentThread()获取到当前线程对象后，直接通过getMap(Thread t)可以访问到该线程的ThreadLocalMap**对象。 ==每个==Thread中都具备一个ThreadLocalMap，而ThreadLocalMap可以存储以ThreadLocal为 ==key== ，==Object== 对象为 value 的键值对。 比如我们在同一个线程中声明了两个 ThreadLocal 对象的话， Thread内部都是使用仅有的那个ThreadLocalMap 存放数据的，ThreadLocalMap的 key 就是 ThreadLocal对象，value 就是 ThreadLocal 对象调用set方法设置的值 ThreadLocalMap是ThreadLocal的静态内部类。 TheadLocal 的 内存泄漏问题 ThreadLocalMap 中使用的 key 为 ThreadLocal 的==弱引用==，而 value 是==强引用==。 弱引用： 如果一个对象只具有弱引用，那就类似于可有可无的生活用品。 弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。 在垃圾回收器线程扫描它 所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。不过，由于垃圾回收器是一个优先级很低的线程， 因此不一定会很快发现那些只具有弱引用的对象。 弱引用可以和一个引用队列（ReferenceQueue）联合使用，如果弱引用所引用的对象被垃圾回收，Java 虚拟机就会把这个弱引用加入到与之关联的引用队列中。 💠线程池 降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。 提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行。 提高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。 线程池创建方法 通过ThreadPoolExecutor构造函数来创建。 方式二：通过 Executor 框架的工具类 Executors 来创建。 （不推荐）无界的 LinkedBlockingQueue，同步队列 SynchronousQueue，无界的延迟阻塞队列DelayedWorkQueue任务队列最大长度为 Integer.MAX_VALUE,可能堆积大量的请求，从而导致 OOM。 线程池的多种类型（四种） FixedThreadPool 固定数量 SingleThreadExecutor 单一 CachedThreadPool 新创建 ScheduledThreadPool 定时任务 核心参数 corePoolSize : 任务队列未达到队列容量时，最大可以同时运行的线程数量。 maximumPoolSize : 任务队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数。 workQueue: 新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中。 ThreadPoolExecutor其他常见参数 : keepAliveTime:线程池中的线程数量大于 corePoolSize 的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了 keepAliveTime才会被回收销毁； unit : keepAliveTime 参数的时间单位。 threadFactory :executor 创建新线程的时候会用到。 handler :饱和策略。关于饱和策略下面单独介绍一下。 线程池的饱和策略 （==四种==） 当前同时运行的线程数量达到==最大线程数量==并且==队列也已经被放满==了任务时 ThreadPoolExecutor.AbortPolicy： 抛出 RejectedExecutionException来拒绝新任务的处理。 ThreadPoolExecutor.CallerRunsPolicy： 将 run 的任务返回给 调用者 调用执行自己的线程运行任务，也就是直接在调用execute方法的线程中运行(run)被拒绝的任务，如果执行程序已关闭，则会丢弃该任务。 因此这种策略会降低对于新任务提交速度，影响程序的整体性能。如果您的应用程序可以承受此延迟并且你要求任何一个任务请求都要被执行的话，你可以选择这个策略。 ThreadPoolExecutor.DiscardPolicy： 不处理新任务，直接丢弃掉。 ThreadPoolExecutor.DiscardOldestPolicy： 此策略将丢弃**==最早的未处理==**的任务请求。 线程池常用阻塞队列 （三种） workQueue LinkedBlockingQueue（无界队列 ----- 队列无限） 容量 Integer.MAX_VALUE 应用类型 FixedThreadPool 和 SingleThreadExector 问题 由于**==队列==永远不会被放满**，因此FixedThreadPool最多只能创建核心线程数的线程。 SynchronousQueue（同步队列 ------ 线程无限） ==没有容量== 目的是保证对于提交的任务，如果有空闲线程，则==使用空闲线程==来处理；否则新建一个线程来处理任务 应用类型 CachedThreadPool 问题 CachedThreadPool 的最大线程数是 Integer.MAX_VALUE ，可以理解为**==线程数==是可以==无限扩展==的**，可能会创建大量线程，从而导致 OOM。 DelayedWorkQueue（延迟阻塞队列） 容量 Integer.MAX_VALUE 应用类型 ScheduledThreadPool 和 SingleThreadScheduledExecutor 问题 内部元素并不是==按照放入的时间排序==，而是会**按照==延迟的时间长短==**对任务进行排序 内部采用的是 堆 的数据结构，可以保证每次出队的任务都是当前队列中==执行时间最靠前的==。 由于**==队列==永远不会被放满**，因此最多只能创建核心线程数的线程。 线程池处理任务流程 （ 3 个判断） 线程池命名 ( 两种 ) 利用 guava包 的 ThreadFactoryBuilder 自己实现 ThreadFactory。 如何设定线程池的大小 当前任务在执行完 CPU 时间片切换到另一个任务之前会先保存自己的状态，以便下次再切换回这个任务时，可以再加载这个任务的状态。任务从保存到再加载的过程就是一次==上下文切换==。 一个简单的公式: CPU 密集型任务(N+1) I/O 密集型任务(2N) 动态修改线程池参数: 美团 开源设置 AQS同步器 抽象队列同步器 AQS 就是一个抽象类，主要用来构建锁和同步器。 AQS 为构建锁和同步器提供了一些通用功能的实现。 使用 AQS 能简单且高效地构造出应用广泛的大量的同步器，比如我们提到的 ReentrantLock，Semaphore，其他的诸如 ReentrantReadWriteLock，SynchronousQueue等等皆是基于 AQS 的 原理 核心思想 如果被请求的共享资源空闲， 将当前请求资源的线程设置为有效的工作线程， 将共享资源设置为锁定状态。 如果被请求的共享资源被占用， 那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制， 用==CLH 队列锁==实现的，即将暂时获取不到锁的线程加入到队列中。 CLH 队列锁 一个虚拟的双向队列（虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系） AQS 使用 int 成员变量 state 表示同步状态，通过内置的 FIFO 线程等待/等待队列 来完成获取资源线程的排队工作 Semaphore synchronized 和 ReentrantLock 都是一次只允许一个线程访问某个资源， 而Semaphore(信号量)可以用来控制**==同时==访问特定资源的线程数量**。 123456// 初始共享资源数量final Semaphore semaphore = new Semaphore(5);// 获取1个许可semaphore.acquire();// 释放1个许可semaphore.release(); Semaphore 有两种模式：。 公平模式： 调用 acquire() 方法的顺序就是获取许可证的顺序，遵循 FIFO； 非公平模式： 抢占式的。 有两个构造方法，都必须提供许可的数量，第二个构造方法可以指定是公平模式还是非公平模式，默认非公平模式。 信号量的原理 Semaphore 是共享锁的一种实现， 默认构造 AQS 的 state 值为 permits，你可以将 permits 的值理解为许可证的数量，只有拿到许可证的线程才能执行。","categories":[{"name":"知识点梳理","slug":"知识点梳理","permalink":"http://kaillliu.github.io/categories/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://kaillliu.github.io/tags/Java/"},{"name":"知识点梳理","slug":"知识点梳理","permalink":"http://kaillliu.github.io/tags/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86/"}]},{"title":"Java IO 知识总结","slug":"JavaIO","date":"2023-08-03T07:00:00.000Z","updated":"2023-09-08T03:54:11.590Z","comments":true,"path":"2023/08/03/JavaIO/","link":"","permalink":"http://kaillliu.github.io/2023/08/03/JavaIO/","excerpt":"","text":"Java IO InputStream/Reader: 所有的输入流的基类，前者是字节输入流，后者是字符输入流。 OutputStream/Writer: 所有输出流的基类，前者是字节输出流，后者是字符输出流 IO 中的设计模式 装饰器模式 装饰器（Decorator）模式 可以在不改变原有对象的情况下拓展其功能。 举例： 1. 对于字节流来说， `FilterInputStream` （对应输入流）和`FilterOutputStream`（对应输出流）是装饰器模式的核心，分别用于增强 `InputStream` 和`OutputStream`子类对象的功能。 可以对原始类嵌套使用多个装饰器 适配器模式 适配器（Adapter Pattern）模式 主要用于接口互不兼容的类的协调工作 举例： 1. **`InputStreamReader`** 和 **`OutputStreamWriter`** 就是两个适配器(Adapter)， 同时，它们两个也是**字节流**和**字符流**之间的桥梁。 1. `InputStreamReader` 和 `OutputStreamWriter` 就是两个适配器(Adapter)， 同时，它们两个也是字节流和字符流之间的桥梁。 1. `OutputStreamWriter` 使用`StreamEncoder`（流编码器）对字符进行编码，实现字符流到字节流的转换 区别 装饰器模式 更侧重于动态地增强原始类的功能，装饰器类需要跟原始类继承相同的抽象类或者实现相同的接口。并且，装饰器模式支持对原始类嵌套使用多个装饰器。 适配器模式 更侧重于让接口不兼容而不能交互的类可以一起工作，当我们调用适配器对应的方法时，适配器内部会调用适配者类或者和适配类相关的类的方法，这个过程透明的。 工厂模式 工厂模式用于创建对象，NIO 中大量用到了工厂模式 举例： 1. `Files` 类的 `newInputStream` 方法用于创建 `InputStream` 对象（静态工厂） 1. `Paths` 类的 `get` 方法创建 `Path` 对象（静态工厂） 1. `ZipFileSystem` 类（`sun.nio`包下的类，属于 `java.nio` 相关的一些内部实现）的 `getPath` 的方法创建 `Path` 对象（简单工厂） 观察者模式 NIO 中的文件目录监听服务使用到了观察者模式。 举例： NIO 中的文件目录监听服务基于 WatchService 接口和 Watchable 接口。WatchService 属于观察者，Watchable 属于被观察者。 BIO 、 NIO 、 AIO BIO：同步阻塞 IO 模型 NIO：同步非阻塞 IO 模型 AIO：NIO 的改版，异步 IO 模型 IO 多路复用模型 通过减少无效的系统调用，减少了对 CPU 资源的消耗 NIO ，有一个非常重要的选择器 ( Selector ) 的概念，也可以被称为 ==多路复用器==。通过它，只需要一个线程便可以管理多个客户端连接。当客户端数据到了之后，才会为其服务。 NIO 核心组件 Buffer（缓冲区）：NIO 读写数据都是通过缓冲区进行操作的。读操作的时候将 Channel 中的数据填充到 Buffer中，而写操作时将 Buffer中的数据写入到 Channel 中。 Channel（通道）：Channel 是一个==双向==的、可读可写的数据传输通道，NIO 通过Channel来实现数据的输入输出。通道是一个抽象的概念，它可以代表文件、套接字或者其他数据源之间的连接。 Selector（选择器）：允许一个线程处理多个 Channel，基于事件驱动的 I/O 多路复用模型。所有的 Channel 都可以注册到Selector上，由Selector来分配线程来处理事件。 NIO 零拷贝 零拷贝是提升 IO 操作性能的一个常用手段，像 ActiveMQ、Kafka 、RocketMQ、QMQ、Netty 等顶级开源项目都用到了零拷贝。 零拷贝是指计算机执行 IO 操作时，CPU 不需要将数据从一个存储区域==复制==到另一个存储区域，从而可以减少上下文切换以及 CPU 的拷贝时间。也就是说，零拷贝主主要解决操作系统在处理 I/O 操作时频繁复制数据的问题。零拷贝的常见实现技术有： mmap+write、sendfile和 sendfile + DMA gather copy 。","categories":[{"name":"知识点梳理","slug":"知识点梳理","permalink":"http://kaillliu.github.io/categories/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://kaillliu.github.io/tags/Java/"},{"name":"知识点梳理","slug":"知识点梳理","permalink":"http://kaillliu.github.io/tags/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86/"}]},{"title":"Java集合知识总结","slug":"Java集合","date":"2023-08-02T07:00:00.000Z","updated":"2023-09-08T03:53:26.248Z","comments":true,"path":"2023/08/02/Java集合/","link":"","permalink":"http://kaillliu.github.io/2023/08/02/Java%E9%9B%86%E5%90%88/","excerpt":"","text":"概述 Map HashMap：==JDK1.8==之前 HashMap 由==数 组+链表==组成的，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的（“拉链法”解决冲突）。JDK1.8 ==以后==在解决哈希冲突时有了较大的变化，当链表==长度大于阈值==（默认为 8）（将链表转换成红黑树前会判断，如果当前数组的长度==小于 64==，那么会选择**==先进行数组扩容==，而不是转换为红黑树）时，将链表转化为==红黑树==**，以减少搜索时间 LinkedHashMap：LinkedHashMap 继承自 HashMap，所以它的底层仍然是基于拉链式散列结构即由**==数组和链表或红黑树==组成。另外，LinkedHashMap 在上面结构的基础上，增加了一条==双向链表==，使得上面的结构可以保持键值对的插入顺序**。同时通过对链表进行相应的操作，实现了访问顺序相关逻辑。详细可以查看：《LinkedHashMap 源码详细分析（JDK1.8）》open in new window Hashtable：数组+链表组成的，数组是 Hashtable 的主体，链表则是主要为了解决哈希冲突而存在 TreeMap：红黑树（自平衡的排序二叉树） List ArrayList：Object[] 数组 Vector：Object[] 数组 LinkedList：双向链表(JDK1.6 之前为循环链表，JDK1.7 取消了循环) Set HashSet(无序，唯一): 基于 HashMap 实现的，底层采用 HashMap 来保存元素 LinkedHashSet: LinkedHashSet 是 HashSet 的子类，并且其内部是通过 LinkedHashMap 来实现的。有点类似于我们之前说的 LinkedHashMap 其内部是基于 HashMap 实现一样，不过还是有一点点区别的 TreeSet(有序，唯一): 红黑树(自平衡的排序二叉树) Queue PriorityQueue: Object[] 数组来实现二叉堆 ArrayQueue: Object[] 数组 + 双指针 集合的优势 相较于数组，Java 集合的优势在于它们的**==大小可变==、==支持泛型==、==具有内建算法==等。Java 集合==提高==了数据的==存储==和==处理灵活性==，可以更好地适应现代软件开发中==多样化的数据需求==**，并支持高质量的代码编写。 List详细 rrayList 和 Array（数组）的区别 ArrayList 插入和删除元素的时间复杂度 对于插入 头部：O(n) 尾部： 大小足够 -----&gt;&gt; O(1) 扩容 -----&gt;&gt; O(n) + O(1) 指定位置插入**O(n)** 对于删除 头部：O(n) 尾部：O(1) 指定位置：O(n) 💠ArrayList 与 LinkedList 区别? 线程安全 都不同步，线程不安全 底层数据结构 ArrayList使用Object数组，LinkedList底层是双向链表 插入和删除是否受元素位置的影响 ArrayList插入和删除元素受位置影响，LinkedList在头尾插入和删除不受影响 快速随机访问的支持 ArrayList支持 LinkedList不支持 内存空间的占用 ArrayList 主要是在预留存储空间这里消耗 LinkedList 在 链表节点的头尾会多消耗空间 💠ArrayList 扩容机制 ArrayList 的底层是数组队列，相当于动态数组。在添加大量元素前，应用程序可以使用**ensureCapacity**操作来增加 ArrayList 实例的容量。这可以减少递增式再分配的数量。 初始容量 10 以无参数构造方法创建 ArrayList 时，实际上初始化赋值的是一个空数组。当真正对数组进行添加元素操作时，才真正分配容量。即向数组中添加第一个元素时，数组容量==扩为 10==。 源码中的 ArrayList 扩容 初始化 minCapacity ：==最小==需要的容量 elementData ：==当前的容量==,保存ArrayList数据的==数组== size ：ArrayList所包含的==元素个数== 构造方法 空，以初始容量 10 构造的空列表（无参数） 带初始容量 的构造 构造包含**==指定collection元素==**的列表 **add()**方法 12345678910/** * 将指定的元素追加到此列表的末尾。 */ public boolean add(E e) &#123; //添加元素之前，先调用ensureCapacityInternal方法 ensureCapacityInternal(size + 1); // Increments modCount!! //这里看到ArrayList添加元素的实质就相当于为数组赋值 elementData[size++] = e; return true; &#125; **ensureCapacityInternal()**方法 当 要 add 进第 1 个元素时，minCapacity 为 1，在 Math.max()方法比较后，==minCapacity 为 10==。 //得到最小扩容量 private void ensureCapacityInternal(int minCapacity) &#123; if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; // 获取默认的容量和传入参数的较大值 minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); &#125; ensureExplicitCapacity(minCapacity); &#125; 12345678910111213145. **`ensureExplicitCapacity()`** 方法 - 判断==**是否需要扩容**== - ```java private void ensureExplicitCapacity(int minCapacity) &#123; modCount++; // overflow-conscious code if (minCapacity - elementData.length &gt; 0) //调用grow方法进行扩容，调用此方法代表已经开始扩容了 grow(minCapacity); &#125; grow() 方法 /** * 要分配的最大数组大小 */ private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; /** * ArrayList扩容的核心方法。 */ private void grow(int minCapacity) &#123; // oldCapacity为旧容量，newCapacity为新容量 int oldCapacity = elementData.length; //将oldCapacity 右移一位，其效果相当于oldCapacity /2， //我们知道位运算的速度远远快于整除运算，整句运算式的结果就是将新容量更新为旧容量的1.5倍， int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); //然后检查新容量是否大于最小需要容量，若还是小于最小需要容量，那么就把最小需要容量当作数组的新容量， if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; // 如果新容量大于 MAX_ARRAY_SIZE,进入(执行) `hugeCapacity()` 方法来比较 minCapacity 和 MAX_ARRAY_SIZE， //如果minCapacity大于最大容量，则新容量则为`Integer.MAX_VALUE`，否则，新容量大小则为 MAX_ARRAY_SIZE 即为 `Integer.MAX_VALUE - 8`。 if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity); &#125; 1234567891011121314157. **`hugeCapacity()`** 方法 ```java private static int hugeCapacity(int minCapacity) &#123; if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); //对minCapacity和MAX_ARRAY_SIZE进行比较 //若minCapacity大，将Integer.MAX_VALUE作为新数组的大小 //若MAX_ARRAY_SIZE大，将MAX_ARRAY_SIZE作为新数组的大小 //MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE; &#125; System.arraycopy() 和**Arrays.copyOf()** 方法 arraycopy其中一个应用场景是**==在指定位置插入==**的方法add(index)中使用 12345678910111213141516/** * 在此列表中的指定位置插入指定的元素。 *先调用 rangeCheckForAdd 对index进行界限检查；然后调用 ensureCapacityInternal 方法保证capacity足够大； *再将从index开始之后的所有成员后移一个位置；将element插入index位置；最后size加1。 */public void add(int index, E element) &#123; rangeCheckForAdd(index); ensureCapacityInternal(size + 1); // Increments modCount!! //arraycopy()方法实现数组自己复制自己 //elementData:源数组;index:源数组中的起始位置;elementData：目标数组；index + 1：目标数组中的起始位置； size - index：要复制的数组元素的数量； System.arraycopy(elementData, index, elementData, index + 1, size - index); elementData[index] = element; size++;&#125; arrayOf()主要是对原有数组的扩容上 12345678 public static int[] copyOf(int[] original, int newLength) &#123; // 申请一个新的数组 int[] copy = new int[newLength];// 调用System.arraycopy,将源数组中的数据进行拷贝,并返回新的数组 System.arraycopy(original, 0, copy, 0, Math.min(original.length, newLength)); return copy; &#125; ensureCapacity() 方法 手动 调整 List 的容量 1234567891011121314151617/**如有必要，增加此 ArrayList 实例的容量，以确保它至少可以容纳由minimum capacity参数指定的元素数。 * * @param minCapacity 所需的最小容量 */public void ensureCapacity(int minCapacity) &#123; int minExpand = (elementData != DEFAULTCAPACITY_EMPTY_ELEMENTDATA) // any size if not default element table ? 0 // larger than default for default empty table. It&#x27;s already // supposed to be at default size. : DEFAULT_CAPACITY; if (minCapacity &gt; minExpand) &#123; ensureExplicitCapacity(minCapacity); &#125;&#125; Set 详 Comparable 和 Comparator 的区别 Comparable 接口 实际上是出自java.lang包 它有一个 compareTo(Object obj)方法用来排序 可以==直接==在需要进行排序的**==类中实现==**，重写compateTo(To) 方法 Comparator 接口 被称为外部比较器，通过**==实现==Comparator类来新建一个比较器，然后通过该==比较器==**对类进行排序。 ​ 无序性和不可重复性 Queue 详 Queue 和 Deque 的区别 ==单端==队列 和 ==双端==队列 Queue 接口 抛出异常 返回特殊值(true/false) 插入队尾 add(E e) offer(E e) 删除队首 remove() poll() 查询队首元素 element() peek() Deque 接口 抛出异常 返回特殊值 插入队首 addFirst(E e) offerFirst(E e) 插入队尾 addLast(E e) offerLast(E e) 删除队首 removeFirst() pollFirst() 删除队尾 removeLast() pollLast() 查询队首元素 getFirst() peekFirst() 查询队尾元素 getLast() peekLast() 事实上，Deque 还提供有 push():addFirst() 和 pop():removeFirst() 等其他方法，可用于模拟栈 Map HashMap 和 HashTable 的区别 线程安全： HashMap线程不安全，要是需要线程安全，可以用 ConcurrentHashMap 效率 HashMap效率高点，因为线程不安全 Null key HashMap可以存储一个 Null Key 和多个 Null value 初始容量和扩充容量的区别 HashMap默认的初始大小为 16 ，每次扩容为原来的 2 倍 底层数据结构 JDK1.8 以后的 HashMap 在解决哈希冲突时有了较大的变化，当链表长度==大于==阈值（默认为 8）时，将**==链表==转化为==红黑树==（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行==数组扩容==**，而不是==转换为红黑树==），以减少搜索时间 HashMap 和 HashSet 的区别 HashSet 底层就是基于 HashMap 实现的。 HashSet 解决重复问题 计算 hashcode，判断加入的位置并与其他元素比较 若 有 hashcode 相同的元素，再调用 equals 判断是否相同 在 JDK1.8 中，实际上无论HashSet中是否已经存在了某元素，HashSet都会直接插入，只是会在add()方法的返回值处告诉我们插入前是否存在相同元素。 HashMap 底层实现 HashMap 通过 key 的 hashcode 经过**==扰动函数==处理过后得到 hash 值，然后通过 (n - 1) &amp; hash 判断当前元素存放的位置（这里的 n 指的是数组的长度），如果当前位置存在元素的话，就判断该元素与要存入的元素的 hash 值以及 key 是否相同，如果相同的话，直接覆盖，不相同就通过==拉链法==**解决冲突。 扰动函数 HashMap 的 hash 方法，使用hash方法减少碰撞 不同版本的实现 JDK - 1.8 之前，有冲突直接加到链表 JDK - 1.8之后，当链表长度==大于==阈值（默认为 8）（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行==数组扩容==，而不是转换为红黑树）时，将链表转化为红黑树，以减少搜索时间。 链表到红黑树的判断逻辑 putVal方法 执行链表转红黑树，链表长度 大于 8 ，转换为 红黑树 // 遍历链表 for (int binCount = 0; ; ++binCount) &#123; // 遍历到链表最后一个节点 if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); // 如果链表元素个数大于等于TREEIFY_THRESHOLD（8） if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st // 红黑树转换（并不会直接转换成红黑树） treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; 123456789101112131415161718192021222324252627282. `treeifyBin` 判断 是 进行 **==数组扩容==** 还是 **==红黑树==** 转换 - ```java final void treeifyBin(Node&lt;K,V&gt;[] tab, int hash) &#123; int n, index; Node&lt;K,V&gt; e; // 判断当前数组的长度是否小于 64 if (tab == null || (n = tab.length) &lt; MIN_TREEIFY_CAPACITY) // 如果当前数组的长度小于 64，那么会选择先进行数组扩容 resize(); else if ((e = tab[index = (n - 1) &amp; hash]) != null) &#123; // 否则才将列表转换为红黑树 TreeNode&lt;K,V&gt; hd = null, tl = null; do &#123; TreeNode&lt;K,V&gt; p = replacementTreeNode(e, null); if (tl == null) hd = p; else &#123; p.prev = tl; tl.next = p; &#125; tl = p; &#125; while ((e = e.next) != null); if ((tab[index] = hd) != null) hd.treeify(tab); &#125; &#125; HashMap 长度为什么是 2 的幂次方 采用二进制位操作 &amp;，相对于 % 能够提高运算效率 在 n 为 2 的幂次方的时候，hash % length == hash &amp; (length-1) Map 遍历方法 主要两种 1. `KeySet` 方法 2. `EntrySet`方法 然后在这两种的基础上，有 通过 流 stream ，迭代器， foreach， Lambda表达式，这几种方法 尽量使用 EntrySet 派生的方法，他性能比较高。 因为 KeySet 相当于循环了两遍 Map 集合，而 EntrySet 只循环了一遍。 KeySet 在循环时使用了 map.get(key)，而 map.get(key) 相当于又遍历了一遍 Map 集合去查询 key 所对应的值 对集合的安全删除来说： 不能在遍历中使用集合 map.remove() 来删除数据，这是非安全的操作方式 可以使用迭代器的 iterator.remove() 的方法来删除数据，这是安全的删除集合的方式。 可以使用 Lambda 中的 removeIf 来提前删除数据， 使用 Stream 中的 filter 过滤掉要删除的数据进行循环，这样都是安全的，当然我们也可以在 for 循环前删除数据在遍历也是线程安全的。 ConcurrentHashMap 为什么线程安全 ConcurrentHashMap 取消了 Segment 分段锁，采用 Node + CAS + synchronized 来保证并发安全。","categories":[{"name":"知识点梳理","slug":"知识点梳理","permalink":"http://kaillliu.github.io/categories/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://kaillliu.github.io/tags/Java/"},{"name":"知识点梳理","slug":"知识点梳理","permalink":"http://kaillliu.github.io/tags/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86/"}]},{"title":"Java基础知识总结","slug":"Java基础","date":"2023-08-01T07:00:00.000Z","updated":"2023-09-08T03:51:15.824Z","comments":true,"path":"2023/08/01/Java基础/","link":"","permalink":"http://kaillliu.github.io/2023/08/01/Java%E5%9F%BA%E7%A1%80/","excerpt":"","text":"Java基础 背景 JVM JDK JRE 的关系 Java 虚拟机（JVM） 是运行 Java 字节码的虚拟机。JVM 有针对不同系统的特定实现（Windows，Linux，macOS），目的是使用相同的字节码，它们都会给出相同的结果。 JDK Java Development Kit 是功能齐全的 Java SDK，是提供给开发者使用的，能够**==创建和编译==** Java 程序。 ==包含==JRE JRE Java Runtime Environment 是 Java运行环境，运行已编译 Java 程序所需的所有内容的集合，主要包括 Java 虚拟机（JVM）、Java 基础类库（Class Library） ==仅==包含 Java 应用程序的运行时环境和必要的类库 为什么说 Java 语言“编译与解释并存”？ Java 程序要经过先编译，后解释两个步骤 先经过编译步骤，生成字节码（.class 文件） 由 Java 解释器来解释执行 基本数据类型 Java 中的几种基本数据类型 Java 中有 8 种基本数据类型，分别为： 6 种数字类型： 4 种整数型：byte、short、int、long 2 种浮点型：float、double 1 种字符类型：char 1 种布尔型：boolean。 对于的包装类型： 这八种基本类型都有对应的包装类分别为：Byte、Short、Integer、Long、Float、Double、Character、Boolean 包装类型大部分使用了==缓存==机制，除了浮点型都实现了。 自动拆装箱 装箱：将基本类型用它们对应的引用类型包装起来； Integer i = 10 等价于 Integer i = Integer.valueOf(10) 拆箱：将包装类型转换为基本数据类型； int n = i 等价于 int n = i.intValue(); 浮点数运算精度丢失 BigDecimal 可以实现对浮点数的运算，不会造成精度丢失。 变量 成员变量与局部变量 语法形式： 成员变量是属于类的，而局部变量是在代码块或方法中定义的变量或是方法的参数； 成员变量可以被 public,private,static 等修饰符所修饰，而局部变量不能被访问控制修饰符及 static 所修饰； 成员变量和局部变量都能被 final 所修饰。 存储方式： 成员变量是使用 static 修饰的，那么这个成员变量是属于类的， 如果没有使用 static 修饰，这个成员变量是属于实例的。 而对象存在于堆内存，局部变量则存在于栈内存。 生存时间： 成员变量是对象的一部分，它随着对象的创建而存在 局部变量随着方法的调用而自动生成，随着方法的调用结束而消亡。 默认值： 成员变量如果没有被赋初始值，则会自动以类型的默认值而赋值（一种情况例外:被 final 修饰的成员变量也必须显式地赋值） 局部变量则不会自动赋值 静态变量 被 static 关键字修饰的变量。它可以被类的==所有实例共享== 无论一个类创建了多少个对象，它们都共享==同一份==静态变量 方法 实例方法和静态方法 静态方法不能调用非静态成员 静态方法属于类了，在==类加载==的时候就会分配内存，可以通过类名直接访问。而非静态成员属于实例对象，只有在对象实例化之后才存在，需要通过类的实例对象去访问。 外部调用静态方法时，调用静态方法可以无需创建对象 。建议使用 ==类名.方法名== 的方式调用 重载和重写 重载就是同样的一个方法能够根据输入数据的不同，做出不同的处理 重写就是当子类继承自父类的相同方法，输入数据一样，但要做出有别于父类的响应时，你就要覆盖父类方法。子类对父类方法的重新改造，外部样子不能改变，内部逻辑可以改变。 面向对象 三大特征 封装 继承 多态 接口和抽象类的区别 共同点 不能被实例化 可以包含抽象方法 可以有默认实现的方法 区别 接口主要用于对==类的行为进行约束==，你实现了某个接口就具有了对应的行为。 抽象类主要用于==代码复用==，强调的是==所属关系==。 一个类只能继承一个类，但是可以实现多个接口 接口中的成员变量只能是 public static final 类型的，不能被修改且必须有初始值，而抽象类的成员变量默认 default，可在子类中被==重新定义==，也可被==重新赋值== 深拷贝和浅拷贝 深拷贝 深拷贝会**==完全复制==整个对象**，包括这个对象所包含的内部对象。 浅拷贝 浅拷贝会在堆上创建一个新的对象（区别于引用拷贝的一点），不过，如果原对象内部的属性是引用类型的话，浅拷贝会直接复制内部对象的引用地址，也就是说**==拷贝对象和原对象共用同一个内部对象==**。 == 和 equals() 的区别 对于基本数据类型来说，== 比较的是值。 对于引用数据类型来说，== 比较的是对象的内存地址。 equals()有两种使用情况 类没有重写 equals()方法： 通过equals()比较该类的两个对象时，等价于通过==比较这两个对象，使用的默认是 Object类equals()方法。 类重写了 equals()方法： 一般我们都重写 **equals()**方法来比较两个对象中的属性是否相等；若它们的属性相等，则返回 true(即，认为这两个对象相等)。 hashCode() hashCode() 的作用是获取哈希码（int 整数），也称为散列码。这个哈希码的作用是确定该对象在哈希表中的索引位置 如果两个对象的**hashCode** 值相等，那这两个对象不一定相等（==哈希碰撞==）。 如果两个对象的**hashCode** 值相等==并且==**equals()**方法也返回 true，我们才认为这两个对象相等。 如果两个对象的**hashCode** 值不相等，我们就可以直接认为这两个对象不相等。 String 可变性 String是不可变的。 StringBuilder 与 StringBuffer 都继承自 AbstractStringBuilder 类，同样使用==字符数组保存字符串== 没有使用 final 和 private 关键字修饰 提供了很多修改字符串的方法比如 append 方法 线程安全性 String 中的对象是不可变的，可以理解为==常量==，线程安全。 StringBuffer 对方法加了==同步锁==或者对调用的方法加了同步锁，所以是==线程安全==的。 StringBuilder 并没有对方法进行加同步锁，所以是==非线程安全==的。 性能 操作==少量==的数据: 适用 String ==单线程==操作字符串缓冲区下操作大量数据: 适用 StringBuilder 操作快 10 ~ 15 %，但不安全 ==多线程==操作字符串缓冲区下操作大量数据: 适用 StringBuffer 字符串常量池 JVM 为了提升性能和减少内存消耗针对字符串（String 类）专门开辟的一块区域，主要目的是为了**==避免==字符串的==重复创建==**。 异常 Throwable 类常用方法 String getMessage(): 返回异常发生时的简要描述 String toString(): 返回异常发生时的详细信息 String getLocalizedMessage(): 返回异常对象的本地化信息。使用 Throwable 的子类覆盖这个方法，可以生成本地化信息。如果子类没有覆盖该方法，则该方法返回的信息与 getMessage()返回的结果相同 void printStackTrace(): 在控制台上打印 Throwable 对象封装的异常信息 泛型 使用泛型参数，可以增强代码的可读性以及稳定性。 编译器可以对泛型参数进行检测，并且通过泛型参数可以指定传入的对象类型。 泛型的使用方法 泛型类 泛型接口 泛型方法 反射 大部分框架都用到了 动态代理 ，动态代理的实现依赖 反射 优缺点 优点：代码更灵活 缺点：增加了安全问题。比如可以**==无视==泛型参数的安全检查**（泛型参数的安全检查发生在编译时）。 Java 反射机制详解 注解 主要用于**==修饰==类、方法或者变量**，提供某些信息供程序在编译或者运行时使用。 注解的解析方法： 编译期直接扫描，例如@Override 运行期通过反射处理 SPI 序列化和反序列化 概述 序列化：将数据结构或对象**转换成==二进制字节流==**的过程 反序列化：将在序列化过程中所生成的**二进制字节流转换成==数据结构或者对象==**的过程 I / O 流 简介： InputStream/Reader: 所有的输入流的基类，前者是**==字节==输入流**，后者是**==字符==输入流**。 OutputStream/Writer: 所有输出流的基类，前者是**==字节==输出流**，后者是**==字符==输出流** 为什么要分两个 字符流是由 Java 虚拟机将字节转换得到的，过程比较==耗时==。 字节流容易出现**==乱码==问题**。 用到的设计模式 装饰器模式 在==不改变==原有对象的情况下**==拓展==其功能** 可以对原始类**==嵌套==**使用==多个==装饰器 BufferedWriter bw = new BufferedWriter(new OutputStreamWriter(new FileOutputStream(fileName), &quot;UTF-8&quot;)); 123456789101112131415161718192021222324252627282930313233343536373839 - **适配器模式** - 接口互不兼容的类的协调工作 - **字符流**和**字节流**的**==接口==不同**，它们之间可以**==协调工作==**就是**基于适配器模式**来做的，更准确点来说是**==对象适配器==** - 可以将字节流对象适配成一个字符流对象，这样我们可以**直接==通过字节流==**对象来**==读取==或者==写入==字符数据**。 - 例子：`InputStreamReader `和 `OutputStreamWriter`，使用 **`StreamDecoder`** 和 **`StreamEncoder`** **实现字节流和字符流的互相转换** - **工厂模式** - **观察者模式** - `NIO` 中的文件目录监听服务使用到了观察者模式。4. `BIO` 、`NIO` 、`AIO` 三大 IO 模型 - ![BIO、NIO 和 AIO 对比](https://fastly.jsdelivr.net/gh/Kaillliu/blog-img/202309081148966.png) - `BIO` **同步阻塞 IO 模型** 。 ![图源：《深入拆解Tomcat &amp; Jetty》](https://fastly.jsdelivr.net/gh/Kaillliu/blog-img/202309081148967.png) - `NIO`模型，**同步==非阻塞== IO 模型**，Java 中的 `NIO` 可以看作是 **==I/O 多路复用==模型**。 ![image-20230814195538907](https://fastly.jsdelivr.net/gh/Kaillliu/blog-img/202309081148968.png) - Java 中的 NIO ，有一个非常重要的**==选择器 ( Selector )==** 的概念，也可以被称为 **==多路复用器==**。通过它，只需要**一个线程**便可以**管理多个客户端**连接。当客户端数据到了之后，才会为其服务。## 语法糖- 特殊结构例子 ```java String[] strs = &#123;&quot;123&quot;, &quot;456&quot;, &quot;789&quot;&#125;; for (String s : strs) &#123; System.out.println(s); &#125; 常用的语法糖 主要有泛型、自动拆装箱、变长参数、枚举、内部类、增强 for 循环、try-with-resources 语法、lambda 表达式 Java 8 新特性 Java8 新特性 主要有以下几点： Interface &amp; functional Interface Interface 新增default，和static修饰的方法，为了解决接口的修改与现有的实现不兼容的问题 functional Interface 有且只有一个抽象方法，但可以有多个非抽象方法的接口 Lambda new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println(&quot;The runable now is using!&quot;); &#125; &#125;).start(); //用lambda new Thread(() -&gt; System.out.println(&quot;It's a lambda function!&quot;)).start(); 12345678910111213141516171819 - 只要方法的参数是**==函数式接口==**都可以用 Lambda 表达式 - 方法的引用 - 使用 `::` 关键字来传递方法或者构造函数引用3. Stream（流） - 新增了 `java.util.stream` 包 - 延迟执行 - 在执行返回 `Stream` 的方法时，并不立刻执行，而是等返回一个非 `Stream` 的方法后才执行。 - 。。。4. Optional - 使用 `Optional` 解决 NPE（`java.lang.NumberFormatException`）问题，它就是为 NPE 而生的，其中可以包含空值或非空值。 - ```jAVA Optional.ofNullable(zoo).map(o -&gt; o.getDog()).map(d -&gt; d.getAge()).filter(v-&gt;v==1).orElse(3); - &gt;这段代码使用了`Optional`的链式调用和操作，以下是对代码的解释： &gt; &gt;1. `Optional.ofNullable(zoo)`：将`zoo`对象包装为一个`Optional`对象。当`zoo`为`null`时，返回一个空的`Optional`对象。 &gt;2. `.map(o -&gt; o.getDog())`：对`Optional`对象进行映射操作，提取`zoo`中的`dog`属性。如果`zoo`为空或`dog`为空，返回一个空的`Optional`对象。 &gt;3. `.map(d -&gt; d.getAge())`：继续对`Optional`对象进行映射操作，提取`dog`的`age`属性。如果`dog`为空或`age`为空，返回一个空的`Optional`对象。 &gt;4. `.filter(v-&gt;v==1)`：对`Optional`对象进行过滤操作，仅保留`age`为1的元素。如果`age`不等于1，返回一个空的`Optional`对象。 &gt;5. `.orElse(3)`：在最后，如果`Optional`对象为空，使用默认值3。 &gt; &gt;综上所述，该行代码的作用是，从`zoo`对象中获取`dog`的`age`属性，并筛选出值为1的结果，如果最终结果为空，则返回默认值3。 &gt; &gt;请注意，由于只能通过上下文判断`zoo`、`dog`和`age`对象的类型和定义，我无法给出更具体的解释和运行结果。如果`zoo`或其他相关对象为空、`dog`或`age`属性不存在或为null，或者`age`的值不为1，最终返回的将是默认值3。 &gt; &gt; Date time-api 对java.util.Date 的补充 java.time","categories":[{"name":"知识点梳理","slug":"知识点梳理","permalink":"http://kaillliu.github.io/categories/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://kaillliu.github.io/tags/Java/"},{"name":"知识点梳理","slug":"知识点梳理","permalink":"http://kaillliu.github.io/tags/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86/"}]},{"title":"WDCNN预测CWRU数据集","slug":"wcnn处理cwru数据集","date":"2022-10-14T09:25:23.000Z","updated":"2022-10-30T06:10:24.788Z","comments":true,"path":"2022/10/14/wcnn处理cwru数据集/","link":"","permalink":"http://kaillliu.github.io/2022/10/14/wcnn%E5%A4%84%E7%90%86cwru%E6%95%B0%E6%8D%AE%E9%9B%86/","excerpt":"","text":"故障诊断 轴承故障诊断算法步骤分解 CWRU数据 ​ 在测试中，使用电火花加工(EDM)，在电机的驱动端和风扇端轴承(SKF深沟球轴承:6205-2RS JEM和6203-2RS JEM)上植入直径为0.007 - 0.028英寸(0.18 - 0.71 mm)的故障，故障分别被设置在滚动体、内圈和外圈上。每种故障轴承均被以同样的状态安装在试验台上，然后在0到3马力的电机负载下(大约电机转速为1797到1720 rpm)以恒速运行。 在每次测试中，测量驱动端轴承壳体(DE)垂直方向上的加速度，在一些测试中也测量风扇端轴承壳体(FE)和电机支撑底板(BA)垂直方向上的加速度。某些测试使用的采样率为12 kHz，其他测试使用的采样率为48 kHz。 ​ 本次主要使用 48k Drive End Bearing Fault Data 使用48kHz采样频率，SKF6205深沟球轴承，驱动端数据，驱动端轴承壳体(DE)的采样数据 使用三种不同的损伤直径 0.007inch，0.014inch，0.021inch；三种不同的故障，外圈6点钟方向、内圈、滚动体，9总不同的状态 每个样本使用 2048个数据点，并做归一化处理 4个数据集，1hp负载，2hp负载，3hp负载 ，以及前三个的并集 WDCNN 概述 本文章主要基于 Pytorch 复现WDCNN在CWRU数据集上的故障分类，未复现基于AdaBN的WDCNN和基于训练干扰的WDCNN的TiCNN模型 参考论文 [1]张伟. 基于卷积神经网络的轴承故障诊断算法研究[D]. 哈尔滨工业大学, 2017. A New Deep Learning Model for Fault Diagnosis with Good Anti-Noise and Domain Adaptation Ability on Raw Vibration Signals 模型结构 WDCNN的核心思想是通过使用1DCNN第一层的大卷积核，提取时序信号的特征；第一层为大卷积核，之后卷积层全部为 3×1 的小卷积核。 数据集设置 使用 采样频率为48kHz 1hp 工况的驱动端时序数据做数据集，数据包含十类数据 正常数据 ：98.mat 故障宽度（单位：mm） 内圈（IR） 滚动体（Ball） 外圈（OR)(center方向) 0.18 110 123 136 0.36 175 190 202 0.53 214 227 239 原始的时域信号 136号数据的原始数据展示 ​ 数据集参数设置 为了模拟旋转机械的正常工况，将正常样本的数量设置为问题样本的10倍，并使用滑动窗口，对数据进行增强。 设置项 参数 训练集比例 0.7 验证集比例 0.2 测试集比例 0.1 单个样本的数据长度 2048 滑动窗口的步长 28 正常类别的样本量 3000 故障类别的样本量 300 总样本量 5700 超参数的选择 超参数 数据 学习率 0.001 权重衰退 0.005 循环次数 100 优化器和损失函数 优化器 选用Adam优化器 1optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay=weight_dacay) 损失函数 选用交叉熵损失函数 1criterion = nn.CrossEntropyLoss() 训练结果可视化 精度和loss的训练过程 测试集精度 测试集混淆矩阵 标准化 T-sne 分类效果可视化 原始数据分布 WDCNN倒数第二层的全连接层 WDCNN分类结果的可视化 图像处理模型 概述 基于 Pytorch ，将一维的时序振动信号通过短时傅里叶变换转化成灰度图，再通过OpenCv的伪彩色处理方法，将灰度图映射为彩色图，并将生成的图片送入图像分类的神经网络中 参考论文 [1]刘飞, 陈仁文, 邢凯玲, 等. 基于迁移学习与深度残差网络的滚动轴承快速故障诊断算法[J]. 振动与冲击, 2022, 41(3): 154-164. [2]赵小强, 罗维兰. 改进卷积Lenet-5神经网络的轴承故障诊断方法[J]. 电子测量与仪器学报, 2022, 36(06): 113-125. [3]汤亮, 凡焱峰, 徐适斐, 等. 基于贝叶斯优化与改进LeNet-5的滚动轴承故障诊断[J]. 计量学报, 2022, 43(07): 913-919. 模型结构 分别使用了 AlexNet 、ResNet - 18、ResNeXt -50 进行了测试，这里展示一下 参考论文1中的网络模型 数据集设置 使用 采样频率为48kHz 1hp 工况的驱动端时序数据做数据集，数据包含十类数据 正常数据 ：98.mat 故障宽度（单位：mm） 内圈（IR） 滚动体（Ball） 外圈（OR)(center方向) 0.18 110 123 136 0.36 175 190 202 0.53 214 227 239 数据集参数设置 为了模拟旋转机械的正常工况，将正常样本的数量设置为问题样本的10倍，并使用滑动窗口，对数据进行增强。 设置项 参数 训练集比例 0.7 验证集比例 0.2 测试集比例 0.1 单个样本的数据长度 1024 滑动窗口的步长 28 正常类别的样本量 3000 故障类别的样本量 300 总样本量 5700 短时傅里叶变换(STFT) 使用STFT将一维时域数据转化成频谱图，并通过OpenCV的伪彩色处理成彩色图片，以适应网络中的三通道输入 超参数的选择 超参数 数据 学习率 0.001 权重衰退 0.00001 循环次数 10 优化器和损失函数 优化器 选用Adam优化器，同时，过滤模型中不需要训练的层 1optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr = learning_rate, weight_decay=weight_decay) 损失函数 选用交叉熵损失函数 1criterion = nn.CrossEntropyLoss() 训练结果可视化 精度和loss的训练过程 测试集精度 测试集混淆矩阵 标准化 T-sne 分类效果可视化 ResNet18倒数第二层的全连接层 ResNet18分类结果的可视化 总结 WDCNN模型复现部分 ​ 由于是 17 年的论文，WDCNN在近几年的文章中经常被拿来做性能对比，故尝试复现论文中的模型。 ​ 论文中，先是提出了WDCNN这个第一层宽卷积核算法，并在CWRU 12kHz不同负载的数据集上验证了WDCNN的准确率。然后，提出了将所有 BN 层的均值方差用测试集的均值方差替换，其他网络参数保持不变的基于AdaBN-WDCNN算法，通过对原始信号添加不同噪声的方式，验证算法的抗噪性能；并改变第一层卷积核大小，做实验展示了第一层卷积核在不同大小下模型的性能变化；还在变工况的情况下，展示了模型的迁移能力。 ​ 最后，更改了WDCNN中的部分结构，提出了Ti-CNN模型，并验证了其有效性。 ResNet模型复现部分 ​ 主要是通过将时序数据转化为二维灰度图，再通过OpenCV伪色彩处理，分为十类； ​ 论文中，主要是提出了TL-ResNet；将通过ImageNet预训练的ResNet18的layer1，layer2，layer3的参数冻结，只使用自己的数据去训练layer4和分类器。 ​ 在模型的性能验证方面，主要使用了CWRU和PU 的轴承数据集，在不同的迭代次数（2，10）和输入通道（灰度图和彩色图），不同的模型之中做对比实验，验证TL-ResNet的有效性。最后，使用了**小样本** 工况迁移的方法，得出小样本的大小为目标域数据集的 １０％ 及以上时，应用小样本迁移才能取得明显的和稳定的准确率提升。 ​ 最后和经典的故障诊断方法做比较，展示算法的有效性。 结论 ​ 在复现的过程中， 与论文中相比，选用了48kHz采样频率的数据，跑出来的模型精度与论文中选用的12kHz的数据对比相对较低，但是也取得了不错的效果。当把故障类别的样本和正常类别的样本比例设置为等比的时候，模型的精度能上升 1%，说明故障的样本比例和样本量对故障诊断的效果有一定影响。 ​ 目前还未做抗噪性实验，打算通过随机增加高斯白噪声的方式，对原始数据集进行处理，再进行训练和测试。 ​ 总的来看，故障样本量对模型的分类精度有较大影响，并且，在实际生产中，故障的样本量也是较少的；如何对模型进行优化，使其在高噪声，工况复杂的工况下保持良好的分类精度是目前故障诊断的研究方向。 ​ 农机备件的故障诊断的话，实验台的设计和备件的选择，以及备件的故障分类都至关重要；并且，基于振动信号的故障诊断对传感器的采样频率有较高要求，高采样频率能更好的反应旋转部件的运行情况，所以需要使用高采样频率的加速度传感器。还需要模拟不同负载，不同转速下的工况，采集数据并放入模型中实验。 程序完整代码","categories":[{"name":"故障诊断","slug":"故障诊断","permalink":"http://kaillliu.github.io/categories/%E6%95%85%E9%9A%9C%E8%AF%8A%E6%96%AD/"}],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://kaillliu.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"CNN","slug":"CNN","permalink":"http://kaillliu.github.io/tags/CNN/"},{"name":"故障诊断","slug":"故障诊断","permalink":"http://kaillliu.github.io/tags/%E6%95%85%E9%9A%9C%E8%AF%8A%E6%96%AD/"}]},{"title":"GitHub命令","slug":"github推送","date":"2022-06-19T14:46:23.000Z","updated":"2022-06-19T14:53:44.670Z","comments":true,"path":"2022/06/19/github推送/","link":"","permalink":"http://kaillliu.github.io/2022/06/19/github%E6%8E%A8%E9%80%81/","excerpt":"","text":"1.先在github上面创建一个项目地址 https://blog.csdn.net/qq_34645412/article/details/80517184 2.其次进入到本地项目的目录文件下面 执行 git init：初始化本地仓库 git add . 添加全部已经修改的文件，准备commit 提交 该命令效果等同于 git add -A git commit -m ‘提交说明’ 将修改后的文件提交到本地仓库，如：git commit -m ‘项目创建’ 连接到远程仓库，并将代码同步到远程仓库 ​ git remote add origin 远程仓库地址 git pull origin master // 把本地仓库的变化连接到远程仓库主分支 git push -u origin master 创建一个 upStream （上传流），并将本地代码通过这个 upStream 推送到 别名为 origin 的仓库中的 master 分支上， ​ -u ，就是创建 upStream 上传流，如果没有这个上传流就无法将代码推送到 github；同时，这个 upStream 只需要在初次推送代码的时候创建，以后就不用创建了 ​ 到此执行完毕，查看分支提交状态确认是否提交完整 git status 如果遇到：Updates were rejected because the remote contains work that you do的问题 执行git push -u origin master 前 执行git pull origin master 如果遇到Updates were rejected because the tip of your current branch is behind即:自己当前版本低于远程仓库版本 执行 git push -u origin master -f","categories":[{"name":"GitHub","slug":"GitHub","permalink":"http://kaillliu.github.io/categories/GitHub/"}],"tags":[{"name":"GitHub","slug":"GitHub","permalink":"http://kaillliu.github.io/tags/GitHub/"}]},{"title":"CentOS 7 配置docket","slug":"CentOS 7配置docket","date":"2022-05-09T07:32:13.000Z","updated":"2022-05-09T07:48:38.011Z","comments":true,"path":"2022/05/09/CentOS 7配置docket/","link":"","permalink":"http://kaillliu.github.io/2022/05/09/CentOS%207%E9%85%8D%E7%BD%AEdocket/","excerpt":"","text":"Docker 是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的容器中,然后发布到任何流行的Linux机器或Windows 机器上,也可以实现虚拟化,容器是完全使用沙箱机制,相互之间不会有任何接口。 Docker简介 一、Docker 安装 1、Docker 要求 CentOS 系统的内核版本高于 3.10 ，查看本页面的前提条件来验证你的CentOS 版本是否支持 Docker 。通过 uname -r 命令查看你当前的内核版本 1uname -r 2、(使用 root 权限登录 Centos)确保 yum 包更新到最新。 1sudo yum update 3、卸载旧版本(如果安装过旧版本的话) 1sudo yum remove docker docker-common docker-selinux docker-engine 4、安装需要的软件包， yum-util 提供yum-config-manager功能，另外两个是devicemapper驱动依赖的 1sudo yum install -y yum-utils device-mapper-persistent-data lvm2 5、设置yum源 1sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo 6、可以查看所有仓库中所有docker版本，并选择特定版本安装 1yum list docker-ce --showduplicates | sort -r 7、安装docker 1sudo yum install docker-ce 8、启动并加入开机启动 123456789sudo systemctl start dockersudo systemctl restart docker # 重启 sudo systemctl status docker # 查看状态 sudo systemctl stop docker # 停止 sudo systemctl enable docker 9、将用户移动到docker组里 123sudo usermod -G docker $USER //将当前用户添加到docker组中．docker version # 查看版本 二、docker 基本命令详解 1.查找镜像 1docker search nginx 2.拉取镜像 1docker pull nginx 3.运行镜像并进入镜像 12docker run - 运行一个容器 -t - 分配一个（伪）tty (link is external) -i - 交互模式 (so we can interact with it) nginx- 使用 nginx 基础镜像 /bin/bash - 运行命令 bash shelldocker run -i -t nginx /bin/bash 4.docker 命令帮助 123456789101112131415161718192021222324252627282930313233343536373839docker # docker 命令帮助Commands: attach # 当前 shell 下 attach 连接指定运行镜像 build # 通过 Dockerfile 定制镜像 commit # 提交当前容器为新的镜像 cp # 从容器中拷贝指定文件或者目录到宿主机中 create # 创建一个新的容器，同 run，但不启动容器 diff # 查看 docker 容器变化，检查容器文件系统上文件或目录的更改 A 添加了文件或目录，D 文件或目录已删除，C 文件或目录已更改 events # 从 docker 服务获取容器实时事件 exec # 在已存在的容器上运行命令 export # 导出容器的内容流作为一个 tar 归档文件[对应 import ] history # 展示一个镜像形成历史 images # 列出系统当前镜像 import # 从tar包中的内容创建一个新的文件系统映像[对应 export] info # 显示系统相关信息 inspect # 查看容器详细信息 kill # kill 指定 docker 容器 load # 从一个 tar 包中加载一个镜像[对应 save] login # 注册或者登陆一个 docker 源服务器 logout # 从当前 Docker registry 退出 logs # 输出当前容器日志信息 -f 动态查看 port # 查看映射端口对应的容器内部源端口 pause # 暂停容器 ps # 列出容器列表 pull # 从docker镜像源服务器拉取指定镜像或者库镜像 push # 推送指定镜像或者库镜像至docker源服务器 restart # 重启运行的容器 rm # 移除一个或者多个容器 rmi # 移除一个或多个镜像[无容器使用该镜像才可删除，否则需删除相关容器才可继续或 -f 强制删除] run # 创建一个新的容器并运行一个命令 save # 保存一个镜像为一个 tar 包[对应 load] search # 在 docker hub 中搜索镜像 start # 启动容器 stop # 停止容器 tag # 给源中镜像打标签 top # 查看容器中运行的进程信息 unpause # 取消暂停容器 version # 查看 docker 版本号 wait # 截取容器停止时的退出状态值 5. docker option 1234567891011121314151617181920212223242526272829303132333435Usage of docker: --api-enable-cors=false # 远程 API 中开启 CORS 头 -b, --bridge=&quot;&quot; # 桥接网络use &#x27;none&#x27; to disable container networking --bip=&quot;&quot; # 和 -b 选项不兼容，具体没有测试过 -d, --daemon=false # daemon 模式 -D, --debug=false # debug 模式 --dns=[] # 强制 docker 使用指定 dns 服务器 --dns-search=[] # 强制 docker 使用指定 dns 搜索域 -e, --exec-driver=&quot;native&quot; # 强制 docker 运行时使用指定执行驱动器 --fixed-cidr=&quot;&quot; IPv4 subnet for fixed IPs (ex: 10.20.0.0/16)this subnet must be nested in the bridge subnet (which is defined by -b or --bip) -G, --group=&quot;docker&quot; Group to assign the unix socket specified by -H when running in daemon mode use &#x27;&#x27; (the empty string) to disable setting of a group -g, --graph=&quot;/var/lib/docker&quot; # 容器运行的根目录路径 -H, --host=[] # daemon 模式下 docker 指定绑定方式[tcp or 本地 socket] specified using one or more tcp://host:port, unix:///path/to/socket, fd://* or fd://socketfd. --icc=true # 跨容器通信 --insecure-registry=[] Enable insecure communication with specified registries (no certificate verification for HTTPS and enable HTTP fallback) (e.g., localhost:5000 or 10.20.0.0/16) --ip=&quot;0.0.0.0&quot; # 指定监听地址，默认所有 ip --ip-forward=true # 开启转发 --ip-masq=true Enable IP masquerading for bridge&#x27;s IP range --iptables=true # 添加对应 iptables 规则 --mtu=0 # 设置网络 mtu if no value is provided: default to the default route MTU or 1500 if no default route is available -p, --pidfile=&quot;/var/run/docker.pid&quot; # 指定 pid 文件位置 --registry-mirror=[] Specify a preferred Docker registry mirror -s, --storage-driver=&quot;&quot; # 强制 docker 运行时使用指定存储驱动 --selinux-enabled=false # 开启 selinux 支持 --storage-opt=[] # 设置存储驱动选项 --tls=false # 开启 tls --tlscacert=&quot;/root/.docker/ca.pem&quot; Trust only remotes providing a certificate signed by the CA given here --tlscert=&quot;/root/.docker/cert.pem&quot; # tls 证书文件位置 --tlskey=&quot;/root/.docker/key.pem&quot; # tls key 文件位置 --tlsverify=false # 使用 tls 并确认远程控制主机 -v, --version=false # 输出 docker 版本信息 6.docker run 123456789101112131415161718192021222324252627282930313233docker run --helpUsage: docker run [OPTIONS] IMAGE [COMMAND] [ARG...] Run a command in a new container -a, --attach=[] Attach to stdin, stdout or stderr. -c, --cpu-shares=0 # 设置 cpu 使用权重 --cap-add=[] Add Linux capabilities --cap-drop=[] Drop Linux capabilities --cidfile=&quot;&quot; # 把容器 id 写入到指定文件 --cpuset=&quot;&quot; # cpu 绑定 -d, --detach=false Detached mode: Run container in the background, print new container id # 后台运行容器 --device=[] Add a host device to the container (e.g. --device=/dev/sdc:/dev/xvdc) --dns=[] # 设置 dns --dns-search=[] # 设置 dns 域搜索 -e, --env=[] # 定义环境变量 --entrypoint=&quot;&quot; Overwrite the default entrypoint of the image # ？ --env-file=[] # 从指定文件读取变量值 --expose=[] # 指定对外提供服务端口 -h, --hostname=&quot;&quot; # 设置容器主机名 -i, --interactive=false # 保持标准输出开启即使没有 attached --link=[] # 添加链接到另外一个容器 --lxc-conf=[] (lxc exec-driver only) Add custom lxc options --lxc-conf=&quot;lxc.cgroup.cpuset.cpus = 0,1&quot; -m, --memory=&quot;&quot; # 内存限制 --name=&quot;&quot; # 设置容器名 --net=&quot;bridge&quot; # 设置容器网络模式 &#x27;bridge&#x27;: creates a new network stack for the container on the docker bridge &#x27;none&#x27;: no networking for this container &#x27;container:&lt;name|id&gt;&#x27;: reuses another container network stack &#x27;host&#x27;: use the host network stack inside the container. Note: the host mode gives the container full access to local system services such as D-bus and is therefore considered insecure. -P, --publish-all=false # 自动映射容器对外提供服务的端口 -p, --publish=[] # 指定端口映射 format: ip:hostPort:containerPort | ip::containerPort | hostPort:containerPort (use &#x27;docker port&#x27; to see the actual mapping) --privileged=false # 提供更多的权限给容器 --restart=&quot;&quot; Restart policy to apply when a container exits (no, on-failure[:max-retry], always) --rm=false # 如果容器退出自动移除和 -d 选项冲突 --security-opt=[] Security Options --sig-proxy=true Proxify received signals to the process (even in non-tty mode). SIGCHLD is not proxied. -t, --tty=false # 分配伪终端 -u, --user=&quot;&quot; # 指定运行容器的用户 uid 或者用户名 -v, --volume=[] # 挂载卷 --volumes-from=[] # 从指定容器挂载卷 -w, --workdir=&quot;&quot; # 指定容器工作目录 7.命令举例 123456789101112docker ps：列出运行中的容器docker ps -a ：列出所有的容器docker stop 容器id：停止容器docker kill 容器id：强制停止容器docker start 容器id：启动已停止的容器docker inspect 容器id：查看容器的所有信息docker container logs 容器id：查看容器日志docker top 容器id：查看容器里的进程docker exec -it 容器id /bin/bash：进入容器exit：退出容器docker rm 容器id：删除已停止的容器docker rm -f 容器id：删除正在运行的容器 三、docker安装镜像并挂载目录文件 1以nginx为例： 1.在Docker下载Nginx镜像 12docker pull nginx ##拉取镜像docker images ##查看镜像 2.创建挂载目录 123mkdir nginxcd nginxmkdir conf.d logs html 3.挂载并启动nginx 12命令说明： –privileged=true 配置了nginx.conf的外部挂载 之后可能导致nginx不能启动，使用该命令； -v /home/dabing/conf.d/default.conf:/etc/nginx/conf.d/default.conf 挂载默认配置文件 -v /home/dabing/conf/nginx.conf:/etc/nginx/nginx.conf 挂载nginx.conf文件 -v /home/dabing/logs:/var/log/nginx 挂载日志目录 -v /home/dabing/html:/usr/share/nginx/html 挂载html目录docker run -p 80:80 --name nginx1 --privileged=true -v /home/dabing/nginx/html:/usr/share/nginx/html -v /home/dabing/nginx/conf/nginx.conf:/etc/nginx/nginx.conf -v /home/dabing/nginx/conf.d/default.conf:/etc/nginx/conf.d/default.conf -v /home/dabing/nginx/logs:/var/log/nginx -d nginx 4.docker进入容器 1docker exec -it 775c7c9ee1e1 /bin/bash 四、Dockerfile Dockerfile是一个包含用于组合映像的命令的文本文档。可以使用在命令行中调用任何命令。 Docker通过读取Dockerfile中的指令自动生成映像。 1.docker build命令用于从Dockerfile构建映像。可以在docker build命令中使用-f标志指向文件系统中任何位置的Dockerfile。 1docker build -f /path/to/a/Dockerfile 2.Dockerfile的基本结构 Dockerfile 一般分为四部分：基础镜像信息、维护者信息、镜像操作指令和容器启动时执行指令，’#’ 为 Dockerfile 中的注释。 3.Dockerfile文件说明 Docker以从上到下的顺序运行Dockerfile的指令。为了指定基本映像，第一条指令必须是FROM。一个声明以＃字符开头则被视为注释。可以在Docker文件中使用RUN，CMD，FROM，EXPOSE，ENV等指令。 1.FROM：指定基础镜像，必须为第一个命令 12345678格式： FROM &lt;image&gt; FROM &lt;image&gt;:&lt;tag&gt; FROM &lt;image&gt;@&lt;digest&gt;示例： FROM mysql:5.7注： tag或digest是可选的，如果不使用这两个值时，会使用latest版本的基础镜像 2.MAINTAINER: 维护者信息 123456格式： MAINTAINER &lt;name&gt;示例： MAINTAINER Jasper Xu MAINTAINER sorex@163.com MAINTAINER Jasper Xu &lt;sorex@163.com&gt; 3.RUN：构建镜像时执行的命令 12345678910111213RUN用于在镜像容器中执行命令，其有以下两种命令执行方式：shell执行格式： RUN &lt;command&gt;exec执行格式： RUN [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;]示例： RUN [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;] RUN apk update RUN [&quot;/etc/execfile&quot;, &quot;arg1&quot;, &quot;arg1&quot;]注： RUN指令创建的中间镜像会被缓存，并会在下次构建中使用。如果不想使用这些缓存镜像，可以在构建时指定--no-cache参数，如：docker build --no-cache 4.ADD：将本地文件添加到容器中，tar类型文件会自动解压(网络压缩资源不会被解压)，可以访问网络资源，类似wget 12345678格式： ADD &lt;src&gt;... &lt;dest&gt; ADD [&quot;&lt;src&gt;&quot;,... &quot;&lt;dest&gt;&quot;] 用于支持包含空格的路径示例： ADD hom* /mydir/ # 添加所有以&quot;hom&quot;开头的文件 ADD hom?.txt /mydir/ # ? 替代一个单字符,例如：&quot;home.txt&quot; ADD test relativeDir/ # 添加 &quot;test&quot; 到 `WORKDIR`/relativeDir/ ADD test /absoluteDir/ # 添加 &quot;test&quot; 到 /absoluteDir/ 5.COPY：功能类似ADD，但是是不会自动解压文件，也不能访问网络资源 6.CMD：构建容器后调用，也就是在容器启动时才进行调用。 123456789格式： CMD [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;] (执行可执行文件，优先) CMD [&quot;param1&quot;,&quot;param2&quot;] (设置了ENTRYPOINT，则直接调用ENTRYPOINT添加参数) CMD command param1 param2 (执行shell内部命令)示例： CMD echo &quot;This is a test.&quot; | wc - CMD [&quot;/usr/bin/wc&quot;,&quot;--help&quot;]注： CMD不同于RUN，CMD用于指定在容器启动时所要执行的命令，而RUN用于指定镜像构建时所要执行的命令。 7.ENTRYPOINT：配置容器，使其可执行化。配合CMD可省去&quot;application&quot;，只使用参数。 123456789格式： ENTRYPOINT [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;] (可执行文件, 优先) ENTRYPOINT command param1 param2 (shell内部命令)示例： FROM ubuntu ENTRYPOINT [&quot;top&quot;, &quot;-b&quot;] CMD [&quot;-c&quot;]注： ENTRYPOINT与CMD非常类似，不同的是通过docker run执行的命令不会覆盖ENTRYPOINT，而docker run命令中指定的任何参数，都会被当做参数再次传递给ENTRYPOINT。Dockerfile中只允许有一个ENTRYPOINT命令，多指定时会覆盖前面的设置，而只执行最后的ENTRYPOINT指令。 8.LABEL：用于为镜像添加元数据 123456格式： LABEL &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; ...示例： LABEL version=&quot;1.0&quot; description=&quot;这是一个Web服务器&quot; by=&quot;IT笔录&quot;注： 使用LABEL指定元数据时，一条LABEL指定可以指定一或多条元数据，指定多条元数据时不同元数据之间通过空格分隔。推荐将所有的元数据通过一条LABEL指令指定，以免生成过多的中间镜像。 9.ENV：设置环境变量 1234567格式： ENV &lt;key&gt; &lt;value&gt; #&lt;key&gt;之后的所有内容均会被视为其&lt;value&gt;的组成部分，因此，一次只能设置一个变量 ENV &lt;key&gt;=&lt;value&gt; ... #可以设置多个变量，每个变量为一个&quot;&lt;key&gt;=&lt;value&gt;&quot;的键值对，如果&lt;key&gt;中包含空格，可以使用来进行转义，也可以通过&quot;&quot;来进行标示；另外，反斜线也可以用于续行示例： ENV myName John Doe ENV myDog Rex The Dog ENV myCat=fluffy 10.EXPOSE：指定于外界交互的端口 12345678格式： EXPOSE &lt;port&gt; [&lt;port&gt;...]示例： EXPOSE 80 443 EXPOSE 8080 EXPOSE 11211/tcp 11211/udp注： EXPOSE并不会让容器的端口访问到主机。要使其可访问，需要在docker run运行容器时通过-p来发布这些端口，或通过-P参数来发布EXPOSE导出的所有端口 11.VOLUME：用于指定持久化目录 123456789101112格式： VOLUME [&quot;/path/to/dir&quot;]示例： VOLUME [&quot;/data&quot;] VOLUME [&quot;/var/www&quot;, &quot;/var/log/apache2&quot;, &quot;/etc/apache2&quot;注： 一个卷可以存在于一个或多个容器的指定目录，该目录可以绕过联合文件系统，并具有以下功能：1 卷可以容器间共享和重用2 容器并不一定要和其它容器共享卷3 修改卷后会立即生效4 对卷的修改不会对镜像产生影响5 卷会一直存在，直到没有任何容器在使用它 12.WORKDIR：工作目录，类似于cd命令 12345678格式： WORKDIR /path/to/workdir示例： WORKDIR /a (这时工作目录为/a) WORKDIR b (这时工作目录为/a/b) WORKDIR c (这时工作目录为/a/b/c)注： 通过WORKDIR设置工作目录后，Dockerfile中其后的命令RUN、CMD、ENTRYPOINT、ADD、COPY等命令都会在该目录下执行。在使用docker run运行容器时，可以通过-w参数覆盖构建时所设置的工作目录。 13.USER:指定运行容器时的用户名或 UID，后续的 RUN 也会使用指定用户。使用USER指定用户时，可以使用用户名、UID或GID，或是两者的组合。当服务不需要管理员权限时，可以通过该命令指定运行用户。并且可以在之前创建所需要的用户 1234567891011格式: USER user USER user:group USER uid USER uid:gid USER user:gid USER uid:group 示例： USER www 注： 使用USER指定用户后，Dockerfile中其后的命令RUN、CMD、ENTRYPOINT都将使用该用户。镜像构建完成后，通过docker run运行容器时，可以通过-u参数来覆盖所指定的用户。 14.ARG：用于指定传递给构建运行时的变量 12345格式： ARG &lt;name&gt;[=&lt;default value&gt;]示例： ARG site ARG build_user=www 15.ONBUILD：用于设置镜像触发器 1234567格式： ONBUILD [INSTRUCTION]示例： ONBUILD ADD . /app/src ONBUILD RUN /usr/local/bin/python-build --dir /app/src注： 当所构建的镜像被用做其它镜像的基础镜像，该镜像中的触发器将会被钥触发 例： 1234567891011121314151617181920212223# This my first nginx Dockerfile# Version 1.0# Base images 基础镜像FROM centos#MAINTAINER 维护者信息MAINTAINER tianfeiyu #ENV 设置环境变量ENV PATH /usr/local/nginx/sbin:$PATH#ADD 文件放在当前目录下，拷过去会自动解压ADD nginx-1.8.0.tar.gz /usr/local/ ADD epel-release-latest-7.noarch.rpm /usr/local/ #RUN 执行以下命令 RUN rpm -ivh /usr/local/epel-release-latest-7.noarch.rpmRUN yum install -y wget lftp gcc gcc-c++ make openssl-devel pcre-devel pcre &amp;&amp; yum clean allRUN useradd -s /sbin/nologin -M www#WORKDIR 相当于cdWORKDIR /usr/local/nginx-1.8.0 RUN ./configure --prefix=/usr/local/nginx --user=www --group=www --with-http_ssl_module --with-pcre &amp;&amp; make &amp;&amp; make installRUN echo &quot;daemon off;&quot; &gt;&gt; /etc/nginx.conf#EXPOSE 映射端口EXPOSE 80#CMD 运行以下命令CMD [&quot;nginx&quot;] dockerfile图解释义 五、docker-compose Compose是一个用于定义和运行多容器Docker应用程序的工具。使用组合，可以使用组合文件配置应用程序的服务。然后，使用单个命令从配置中创建和启动所有服务。 123456yum -y install epel-release ##安装pipyum -y install python-pippip --version ##确认版本pip install --upgrade pip ##更新pippip install docker-compose ##安装docker-composedocker-compose version 1.docker-compose.yml 详解 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281291301311321331341351361371381391401411421431441451461471481491501511521531541551561571581591601611621631641651661671681691701711721731741751761771781791801811821831841851861871881891901911921931941951961971981992002012022032042052062072082092102112122132142152162172182192202212222232242252262272282292302312322332342352362372382392402412422432442452462472482492502512522532542552562572582592602612622632642652662672682692702712722732742752762772782792802812822832842852862872882892902912922932942952962972982993003013023033043053063073083093103113123133143153163173183193203213223233243253263273283293303313323333343353363373383393403413423433443453463473483493503513523533543553563573583593603613623633643653663673683693703713723733743753763773783793803813823833843853863873883893903913923933943953963973983994004014024034044054064074084094104114124134144154164174184194204214224234244254264274284294304314324334344354364374384394404414424434444454464474484494504514524534544554564574584594604614624634644654664674684694704714724734744754764774784794804814824834844854864874884894904914924934944954964974984995005015025035045055065075085095105115125135145155165175185195205215225235245255265275285295305315325335345355365375385395405415425435445455465475485495505515525535545555565575585595605615625635645655665675685695705715725735745755765775785795805815825835845855865875885895905915925935945955965975985996006016026036046056066076086096106116126136146156166176186196206216226236246256266276286296306316326336346356366376386396406416426436446456466476486496506516526536546556566576586596606616626636646656666676686696706716726736746756766776786796806816826836846856866876886896906916926936946956966976986997007017027037047057067077087097107117127137147157167177187197207217227237247257267277287297307317327337347357367377387397407417427437447457467477487497507517527537547557567577587597607617627637647657667677687697707717727737747757767777787797807817827837847857867877887897907917927937947957967977987998008018028038048058068078088098108118128138148158168178188198208218228238248258268278288298308318328338348358368378388398408418428438448458468478488498508518528538548558568578588598608618628638648658668678688698708718728738748758768778788798808818828838848858868878888898908918928938948958968978988999009019029039049059069079089099109119129139149159169179189199209219229239249259269279289299309319329339349359369379389399409419429439449459469479489499509519529539549559569579589599609619629639649659669679689699709719729739749759769779789799809819829839849859869879889899909919929939949959969979989991000100110021003100410051006100710081009101010111012101310141015101610171018101910201021102210231024102510261027102810291030103110321033103410351036103710381039104010411042104310441045104610471048104910501051105210531054105510561057105810591060106110621063106410651066106710681069107010711072107310741075107610771078107910801081108210831084108510861087108810891090109110921093109410951096109710981099110011011102110311041105110611071108110911101111111211131114111511161117111811191120112111221123112411251126112711281129113011311132113311341135113611371138113911401141114211431144114511461147114811491150#系统变量$PWD ： 当前目录 #注意：YAML布尔值（true，false，yes，no，on，off）必须用引号括起来，以便解析器将它们解释为字符串。#字典时environment: SHOW: &#x27;true&#x27; 数组时 environment: - SHOW=true#版本号version: &quot;2.1&quot;# 指定创建的虚拟网络数量 # 作用：通过不同的虚拟网络实现了容器网络之间的隔离，从而在最大程度上去保护后端网络的安全。#networks:# mynet:# driver: bridge# mynet1: # 重用的代码模板# 模板的定义必须以 x- 开头x-logging: # 以 &amp; 开头的字符串为模板命名 # 以 * 加上模板的名称引用模板 &amp;default-logging driver: json-file options: max-size: &quot;200k&quot; max-file: &quot;10&quot; # 定义全局挂载卷 volumes: test_1.thinking.com: test_2.thinking.com: # 服务services: #服务名称 todo: # 构建镜像 build: # 指定dockerfile的上下文路径（相对当前docker-compose.yml的位置） # 包含Dockerfile文件的目录路径，或者是git仓库的URL。 # 当提供的值是相对路径时，它被解释为相对于当前compose文件的位置。 # 该目录也是发送到Docker守护程序构建镜像的上下文。 context: . # Dockerfile的文件名称 dockerfile: Dockerfile-todo args: # 变量 buildno: 1 password: secret # Dockerfile里面可使用的参数变量 # Dockerfile： # ARG buildno # ARG password # RUN echo &quot;Build number: $buildno&quot; # RUN script-requiring-password.sh &quot;$password&quot; # 镜像名 ： 仓库/标签:版本 image: zhanyang/todo-demo:1.0.0 # 依赖(以指定顺序启动) depends_on: mysql: condition: service_healthy # 指定一个自定义容器名称，而不是生成的默认名称。 # 由于Docker容器名称必须是唯一的，因此如果指定了自定义名称，则无法将服务扩展到多个容器。 container_name: todo # 卷挂载路径设置。 # 可以设置宿主机路径 （HOST:CONTAINER） 或加上访问模式 （HOST:CONTAINER:ro） # 挂载数据卷的默认权限是读写（rw），可以通过ro指定为只读。 volumes: # 只需指定一个路径，让引擎创建一个卷 - /var/lib/mysql # 指定绝对路径映射 - /opt/data:/var/lib/mysql # 相对于当前compose文件的相对路径 - ./cache:/tmp/cache # 用户家目录相对路径 - ~/configs:/etc/configs/:ro # 命名卷 - datavolume:/var/lib/mysql # 使用全局挂载卷 - test_1.thinking.com:/test:rw # 指定日志驱动为 json-file，存储日志的最大文件 size 为 200k，最多存储 10 这样大的文件。 # logging支持很多driver，而每一个driver对应的options都不一样 # docker inspect -f &#123;&#123;.HostConfig.LogConfig&#125;&#125; lnmp-nginx # result：&#123;json-file map[max-file:10 max-size:2000k]&#125; # docker info |grep &#x27;Logging Driver&#x27; # result：Logging Driver: json-file # 其他：https://docs.docker.com/engine/admin/logging/overview/ logging: driver: &quot;json-file&quot; options: max-size: &quot;200k&quot; max-file: &quot;10&quot; # 指定使用的虚拟网络 networks: # - mynet # 覆盖容器启动后默认执行的命令。 # 该命令也可以是一个类似于dockerfile的列表：command: [&quot;bundle&quot;, &quot;exec&quot;, &quot;thin&quot;, &quot;-p&quot;, &quot;3000&quot;] command: bundle exec thin -p 3000 # may command: [&quot;/usr/local/nginx/sbin/nginx&quot;] # 链接到另一个服务中的容器。 请指定服务名称和链接别名（SERVICE：ALIAS），或者仅指定服务名称。 # 实际是通过设置/etc/hosts的域名解析，从而实现容器间的通信。 # 故可以像在应用中使用localhost一样使用服务的别名链接其他容器的服务，前提是多个服务容器在一个网络中可路由联通 # links也可以起到和depends_on相似的功能，即定义服务之间的依赖关系，从而确定服务启动的顺序 links: - db - db:database - redis # 链接到docker-compose.yml 外部的容器，甚至并非 Compose 管理的容器。参数格式跟 links 类似。 external - redis_1 - project_db_1:mysql - project_db_1:postgresql # 暴露端口，但不映射到宿主机，只被连接的服务访问。 仅可以指定内部端口为参数 expose: - &quot;3000&quot; - &quot;8000&quot; # 暴露端口信息。使用宿主：容器 （HOST:CONTAINER）格式或者仅仅指定容器的端口（宿主将会随机选择端口）都可以。 ports: - &quot;3000&quot; - &quot;3000-3005&quot; - &quot;8000:8000&quot; - &quot;9090-9091:8080-8081&quot; - &quot;49100:22&quot; - &quot;127.0.0.1:8001:8001&quot; - &quot;127.0.0.1:5000-5010:5000-5010&quot; - &quot;6060:6060/udp&quot; # v3.2中ports的长格式的语法允许配置不能用短格式表示的附加字段。 ports: - target: 80 #容器内的端口 published: 8080 #物理主机的端口 protocol: tcp #端口协议（tcp或udp） mode: host #host 和ingress 两总模式，host用于在每个节点上发布主机端口，ingress 用于被负载平衡的swarm模式端口。 # no是默认的重启策略，在任何情况下都不会重启容器。 restart: &quot;no&quot; # 指定为always时，容器总是重新启动。 restart: always # 如果退出代码指示出现故障错误，则on-failure将重新启动容器。 restart: on-failure restart: unless-stopped # pid 将PID模式设置为主机PID模式。 # 这就打开了容器与主机操作系统之间的共享PID地址空间。 # 使用此标志启动的容器将能够访问和操作裸机的命名空间中的其他容器，反之亦然。 # 即打开该选项的容器可以相互通过进程 ID 来访问和操作。 pid: &quot;host&quot; # 配置 DNS 服务器。可以是一个值，也可以是一个列表。 dns: 8.8.8.8 dns: - 8.8.8.8 - 9.9.9.9 # 自定义搜索域 dns_search: example.com dns_search: - dc1.example.com - dc2.example.com # 覆盖Dockerfile中的entrypoint，用法同Dockerfile中的用法 entrypoint: [&quot;/usr/local/nginx/sbin/nginx&quot;,&quot;-g&quot;,&quot;daemon off;&quot;] # 添加环境变量。 你可以使用数组或字典两种形式。 # 任何布尔值; true，false，yes，no需要用引号括起来，以确保它们不被YML解析器转换为True或False。 environment: RACK_ENV: development SHOW: &#x27;true&#x27; SESSION_SECRET: # 【注意】：如果你的服务指定了build选项，那么在构建过程中通过environment定义的环境变量将不会起作用。 # 将使用build的args子选项来定义构建时的环境变量。 environment: - RACK_ENV=development - SHOW=true - SESSION_SECRE # 1&gt;将定义的变量编写在文件中，然后在yml文件中进行添加 env_file: .env env_file: - ./common.env - ./apps/web.env - /opt/secrets.env # 2&gt;例如： # old： db: image: mysql ports: - &quot;3306:3306&quot; environment: MYSQL_ROOT_PASSWORD: redhat MYSQL_DATABASE: wordpress MYSQL_USER: wordpress MYSQL_PASSWORD: wordpress # new： db: image: mysql ports: - &quot;3306:3306&quot; env_file: ./mysql_env # 创建env_file文件在当前目录mysql_env MYSQL_ROOT_PASSWORD=redhat MYSQL_DATABASE=wordpress MYSQL_USER=wordpress MYSQL_PASSWORD=wordpress3 # 添加hostname映射，类似于docker cli下面的--add-host extra_hosts: - &quot;www.hcstart.com:192.168.101.14&quot; # 配置一个检查去测试服务中的容器是否运行正常 # 具体： https://docs.docker.com/engine/reference/builder/#healthcheck # 查看healthcheck的状态输出 ： docker inspect lnmp-nginx healthcheck: test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;-f&quot;, &quot;http://localhost&quot;] interval: 1m30s timeout: 10s retries: 3 # labels:添加元数据到container中，查看现有容器的labels： # docker inspect -f &#123;&#123;.Config.Labels&#125;&#125; lnmp-nginx # lnmp-nginx ：容器名 labels: com.example.description: &quot;Accounting webapp&quot; com.example.department: &quot;Finance&quot; com.example.label-with-empty-value: &quot;&quot; labels: - &quot;com.example.description=Accounting webapp&quot; - &quot;com.example.department=Finance&quot; - &quot;com.example.label-with-empty-value&quot; # 在容器中设置内核参数 sysctls: net.core.somaxconn: 1024 net.ipv4.tcp_syncookies: 0 sysctls: - net.core.somaxconn=1024 - net.ipv4.tcp_syncookies=0 mysql: environment: MYSQL_ROOT_PASSWORD: password MYSQL_DATABASE: tododb MYSQL_USER: user MYSQL_PASSWORD: pass build: context: . dockerfile: Dockerfile-mysql image: zhanyang/mysql:5.6 container_name: mysql # 以 * 加上模板的名称引用模板 使用全局自定义模板 logging: *default-logging # 指定使用的虚拟网络 networks: # - mynet1Compose和Docker兼容性： Compose 文件格式有3个版本,分别为1, 2.x 和 3.x 目前主流的为 3.x 其支持 docker 1.13.0 及其以上的版本 常用参数： version # 指定 compose 文件的版本 services # 定义所有的 service 信息, services 下面的第一级别的 key 既是一个 service 的名称 build # 指定包含构建上下文的路径, 或作为一个对象，该对象具有 context 和指定的 dockerfile 文件以及 args 参数值 context # context: 指定 Dockerfile 文件所在的路径 dockerfile # dockerfile: 指定 context 指定的目录下面的 Dockerfile 的名称(默认为 Dockerfile) args # args: Dockerfile 在 build 过程中需要的参数 (等同于 docker container build --build-arg 的作用) cache_from # v3.2中新增的参数, 指定缓存的镜像列表 (等同于 docker container build --cache_from 的作用) labels # v3.3中新增的参数, 设置镜像的元数据 (等同于 docker container build --labels 的作用) shm_size # v3.5中新增的参数, 设置容器 /dev/shm 分区的大小 (等同于 docker container build --shm-size 的作用) command # 覆盖容器启动后默认执行的命令, 支持 shell 格式和 [] 格式 configs # 不知道怎么用 cgroup_parent # 不知道怎么用 container_name # 指定容器的名称 (等同于 docker run --name 的作用) credential_spec # 不知道怎么用 deploy # v3 版本以上, 指定与部署和运行服务相关的配置, deploy 部分是 docker stack 使用的, docker stack 依赖 docker swarm endpoint_mode # v3.3 版本中新增的功能, 指定服务暴露的方式 vip # Docker 为该服务分配了一个虚拟 IP(VIP), 作为客户端的访问服务的地址 dnsrr # DNS轮询, Docker 为该服务设置 DNS 条目, 使得服务名称的 DNS 查询返回一个 IP 地址列表, 客户端直接访问其中的一个地址 labels # 指定服务的标签，这些标签仅在服务上设置 mode # 指定 deploy 的模式 global # 每个集群节点都只有一个容器 replicated # 用户可以指定集群中容器的数量(默认) placement # 不知道怎么用 replicas # deploy 的 mode 为 replicated 时, 指定容器副本的数量 resources # 资源限制 limits # 设置容器的资源限制 cpus: &quot;0.5&quot; # 设置该容器最多只能使用 50% 的 CPU memory: 50M # 设置该容器最多只能使用 50M 的内存空间 reservations # 设置为容器预留的系统资源(随时可用) cpus: &quot;0.2&quot; # 为该容器保留 20% 的 CPU memory: 20M # 为该容器保留 20M 的内存空间 restart_policy # 定义容器重启策略, 用于代替 restart 参数 condition # 定义容器重启策略(接受三个参数) none # 不尝试重启 on-failure # 只有当容器内部应用程序出现问题才会重启 any # 无论如何都会尝试重启(默认) delay # 尝试重启的间隔时间(默认为 0s) max_attempts # 尝试重启次数(默认一直尝试重启) window # 检查重启是否成功之前的等待时间(即如果容器启动了, 隔多少秒之后去检测容器是否正常, 默认 0s) update_config # 用于配置滚动更新配置 parallelism # 一次性更新的容器数量 delay # 更新一组容器之间的间隔时间 failure_action # 定义更新失败的策略 continue # 继续更新 rollback # 回滚更新 pause # 暂停更新(默认) monitor # 每次更新后的持续时间以监视更新是否失败(单位: ns|us|ms|s|m|h) (默认为0) max_failure_ratio # 回滚期间容忍的失败率(默认值为0) order # v3.4 版本中新增的参数, 回滚期间的操作顺序 stop-first #旧任务在启动新任务之前停止(默认) start-first #首先启动新任务, 并且正在运行的任务暂时重叠 rollback_config # v3.7 版本中新增的参数, 用于定义在 update_config 更新失败的回滚策略 parallelism # 一次回滚的容器数, 如果设置为0, 则所有容器同时回滚 delay # 每个组回滚之间的时间间隔(默认为0) failure_action # 定义回滚失败的策略 continue # 继续回滚 pause # 暂停回滚 monitor # 每次回滚任务后的持续时间以监视失败(单位: ns|us|ms|s|m|h) (默认为0) max_failure_ratio # 回滚期间容忍的失败率(默认值0) order # 回滚期间的操作顺序 stop-first # 旧任务在启动新任务之前停止(默认) start-first # 首先启动新任务, 并且正在运行的任务暂时重叠 注意： 支持 docker-compose up 和 docker-compose run 但不支持 docker stack deploy 的子选项 security_opt container_name devices tmpfs stop_signal links cgroup_parent network_mode external_links restart build userns_mode sysctls devices # 指定设备映射列表 (等同于 docker run --device 的作用) depends_on # 定义容器启动顺序 (此选项解决了容器之间的依赖关系， 此选项在 v3 版本中 使用 swarm 部署时将忽略该选项) 示例： docker-compose up 以依赖顺序启动服务，下面例子中 redis 和 db 服务在 web 启动前启动 默认情况下使用 docker-compose up web 这样的方式启动 web 服务时，也会启动 redis 和 db 两个服务，因为在配置文件中定义了依赖关系 version: &#x27;3&#x27; services: web: build: . depends_on: - db - redis redis: image: redis db: image: postgres dns # 设置 DNS 地址(等同于 docker run --dns 的作用) dns_search # 设置 DNS 搜索域(等同于 docker run --dns-search 的作用) tmpfs # v2 版本以上, 挂载目录到容器中, 作为容器的临时文件系统(等同于 docker run --tmpfs 的作用, 在使用 swarm 部署时将忽略该选项) entrypoint # 覆盖容器的默认 entrypoint 指令 (等同于 docker run --entrypoint 的作用) env_file # 从指定文件中读取变量设置为容器中的环境变量, 可以是单个值或者一个文件列表, 如果多个文件中的变量重名则后面的变量覆盖前面的变量, environment 的值覆盖 env_file 的值 文件格式： RACK_ENV=development environment # 设置环境变量， environment 的值可以覆盖 env_file 的值 (等同于 docker run --env 的作用) expose # 暴露端口, 但是不能和宿主机建立映射关系, 类似于 Dockerfile 的 EXPOSE 指令 external_links # 连接不在 docker-compose.yml 中定义的容器或者不在 compose 管理的容器(docker run 启动的容器, 在 v3 版本中使用 swarm 部署时将忽略该选项) extra_hosts # 添加 host 记录到容器中的 /etc/hosts 中 (等同于 docker run --add-host 的作用) healthcheck # v2.1 以上版本, 定义容器健康状态检查, 类似于 Dockerfile 的 HEALTHCHECK 指令 test # 检查容器检查状态的命令, 该选项必须是一个字符串或者列表, 第一项必须是 NONE, CMD 或 CMD-SHELL, 如果其是一个字符串则相当于 CMD-SHELL 加该字符串 NONE # 禁用容器的健康状态检测 CMD # test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;-f&quot;, &quot;http://localhost&quot;] CMD-SHELL # test: [&quot;CMD-SHELL&quot;, &quot;curl -f http://localhost || exit 1&quot;] 或者 test: curl -f https://localhost || exit 1 interval: 1m30s # 每次检查之间的间隔时间 timeout: 10s # 运行命令的超时时间 retries: 3 # 重试次数 start_period: 40s # v3.4 以上新增的选项, 定义容器启动时间间隔 disable: true # true 或 false, 表示是否禁用健康状态检测和 test: NONE 相同 image # 指定 docker 镜像, 可以是远程仓库镜像、本地镜像 init # v3.7 中新增的参数, true 或 false 表示是否在容器中运行一个 init, 它接收信号并传递给进程 isolation # 隔离容器技术, 在 Linux 中仅支持 default 值 labels # 使用 Docker 标签将元数据添加到容器, 与 Dockerfile 中的 LABELS 类似 links # 链接到其它服务中的容器, 该选项是 docker 历史遗留的选项, 目前已被用户自定义网络名称空间取代, 最终有可能被废弃 (在使用 swarm 部署时将忽略该选项) logging # 设置容器日志服务 driver # 指定日志记录驱动程序, 默认 json-file (等同于 docker run --log-driver 的作用) options # 指定日志的相关参数 (等同于 docker run --log-opt 的作用) max-size # 设置单个日志文件的大小, 当到达这个值后会进行日志滚动操作 max-file # 日志文件保留的数量 network_mode # 指定网络模式 (等同于 docker run --net 的作用, 在使用 swarm 部署时将忽略该选项) networks # 将容器加入指定网络 (等同于 docker network connect 的作用), networks 可以位于 compose 文件顶级键和 services 键的二级键 aliases # 同一网络上的容器可以使用服务名称或别名连接到其中一个服务的容器 ipv4_address # IP V4 格式 ipv6_address # IP V6 格式 示例: version: &#x27;3.7&#x27; services: test: image: nginx:1.14-alpine container_name: mynginx command: ifconfig networks: app_net: # 调用下面 networks 定义的 app_net 网络 ipv4_address: 172.16.238.10 networks: app_net: driver: bridge ipam: driver: default config: - subnet: 172.16.238.0/24 pid: &#x27;host&#x27; # 共享宿主机的 进程空间(PID) ports # 建立宿主机和容器之间的端口映射关系, ports 支持两种语法格式 SHORT 语法格式示例: - &quot;3000&quot; # 暴露容器的 3000 端口, 宿主机的端口由 docker 随机映射一个没有被占用的端口 - &quot;3000-3005&quot; # 暴露容器的 3000 到 3005 端口, 宿主机的端口由 docker 随机映射没有被占用的端口 - &quot;8000:8000&quot; # 容器的 8000 端口和宿主机的 8000 端口建立映射关系 - &quot;9090-9091:8080-8081&quot; - &quot;127.0.0.1:8001:8001&quot; # 指定映射宿主机的指定地址的 - &quot;127.0.0.1:5000-5010:5000-5010&quot; - &quot;6060:6060/udp&quot; # 指定协议 LONG 语法格式示例:(v3.2 新增的语法格式) ports: - target: 80 # 容器端口 published: 8080 # 宿主机端口 protocol: tcp # 协议类型 mode: host # host 在每个节点上发布主机端口, ingress 对于群模式端口进行负载均衡 secrets # 不知道怎么用 security_opt # 为每个容器覆盖默认的标签 (在使用 swarm 部署时将忽略该选项) stop_grace_period # 指定在发送了 SIGTERM 信号之后, 容器等待多少秒之后退出(默认 10s) stop_signal # 指定停止容器发送的信号 (默认为 SIGTERM 相当于 kill PID; SIGKILL 相当于 kill -9 PID; 在使用 swarm 部署时将忽略该选项) sysctls # 设置容器中的内核参数 (在使用 swarm 部署时将忽略该选项) ulimits # 设置容器的 limit userns_mode # 如果Docker守护程序配置了用户名称空间, 则禁用此服务的用户名称空间 (在使用 swarm 部署时将忽略该选项) volumes # 定义容器和宿主机的卷映射关系, 其和 networks 一样可以位于 services 键的二级键和 compose 顶级键, 如果需要跨服务间使用则在顶级键定义, 在 services 中引用 SHORT 语法格式示例: volumes: - /var/lib/mysql # 映射容器内的 /var/lib/mysql 到宿主机的一个随机目录中 - /opt/data:/var/lib/mysql # 映射容器内的 /var/lib/mysql 到宿主机的 /opt/data - ./cache:/tmp/cache # 映射容器内的 /var/lib/mysql 到宿主机 compose 文件所在的位置 - ~/configs:/etc/configs/:ro # 映射容器宿主机的目录到容器中去, 权限只读 - datavolume:/var/lib/mysql # datavolume 为 volumes 顶级键定义的目录, 在此处直接调用 LONG 语法格式示例:(v3.2 新增的语法格式) version: &quot;3.2&quot; services: web: image: nginx:alpine ports: - &quot;80:80&quot; volumes: - type: volume # mount 的类型, 必须是 bind、volume 或 tmpfs source: mydata # 宿主机目录 target: /data # 容器目录 volume: # 配置额外的选项, 其 key 必须和 type 的值相同 nocopy: true # volume 额外的选项, 在创建卷时禁用从容器复制数据 - type: bind # volume 模式只指定容器路径即可, 宿主机路径随机生成; bind 需要指定容器和数据机的映射路径 source: ./static target: /opt/app/static read_only: true # 设置文件系统为只读文件系统 volumes: mydata: # 定义在 volume, 可在所有服务中调用 restart # 定义容器重启策略(在使用 swarm 部署时将忽略该选项, 在 swarm 使用 restart_policy 代替 restart) no # 禁止自动重启容器(默认) always # 无论如何容器都会重启 on-failure # 当出现 on-failure 报错时, 容器重新启动 其他选项： domainname, hostname, ipc, mac_address, privileged, read_only, shm_size, stdin_open, tty, user, working_dir 上面这些选项都只接受单个值和 docker run 的对应参数类似 对于值为时间的可接受的值： 2.5s 10s 1m30s 2h32m 5h34m56s 时间单位: us, ms, s, m， h 对于值为大小的可接受的值： 2b 1024kb 2048k 300m 1gb 单位: b, k, m, g 或者 kb, mb, gb networks # 定义 networks 信息 driver # 指定网络模式, 大多数情况下, 它 bridge 于单个主机和 overlay Swarm 上 bridge # Docker 默认使用 bridge 连接单个主机上的网络 overlay # overlay 驱动程序创建一个跨多个节点命名的网络 host # 共享主机网络名称空间(等同于 docker run --net=host) none # 等同于 docker run --net=none driver_opts # v3.2以上版本, 传递给驱动程序的参数, 这些参数取决于驱动程序 attachable # driver 为 overlay 时使用, 如果设置为 true 则除了服务之外，独立容器也可以附加到该网络; 如果独立容器连接到该网络，则它可以与其他 Docker 守护进程连接到的该网络的服务和独立容器进行通信 ipam # 自定义 IPAM 配置. 这是一个具有多个属性的对象, 每个属性都是可选的 driver # IPAM 驱动程序, bridge 或者 default config # 配置项 subnet # CIDR格式的子网，表示该网络的网段 external # 外部网络, 如果设置为 true 则 docker-compose up 不会尝试创建它, 如果它不存在则引发错误 name # v3.5 以上版本, 为此网络设置名称文件格式示例： version: &quot;3&quot; services: redis: image: redis:alpine ports: - &quot;6379&quot; networks: - frontend deploy: replicas: 2 update_config: parallelism: 2 delay: 10s restart_policy: condition: on-failure db: image: postgres:9.4 volumes: - db-data:/var/lib/postgresql/data networks: - backend deploy: placement: constraints: [node.role == manager] 2.docker-compose 常用命令 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859# 1.查看docker-compose的版本docker-compose --version# 2.验证（docker-compose.yml）文件配置，当配置正确时，不输出任何内容，当文件配置错误，输出错误信息。docker-compose config -q# 3.启动compose(后台运行，即守护进程)docker-compose up -d# 4.指定文件后台启动docker-compose -f docker-compose.yml up -d# 5.查看日志docker-compose logs tomcat# 6.监听日志docker-compose logs -f tomcat# 7.停止容器docker-compose stop tomcat# 8.启动容器docker-compose start tomcat# 9.重启容器docker-compose restart tomcat# 10.删除容器（推荐先执行停止容器）docker-compose rm tomcat# 11.进入tomcat服务下容器docker-compose exec tomcat bash# 12.查看当前有哪些容器（docker-compose.yml 所在文件夹下执行）docker-compose ps# 13.显示运行的进程：docker-compose top tomcat# 14.下载服务镜像docker-compose pull 镜像名称# 15.列出镜像docker-compose images 例：测试所用 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657version: &#x27;3.1&#x27; # 版本号services: ## 服务 tomcat: #tomcat 服务 restart: always image: tomcat:8 #镜像 container_name: tomcat8 #容器名 ports: #端口 - 8080:8080 volumes: #数据卷 - /home/dabing/lzz/webapps/:/usr/local/tomcat/webapps/ mysql: #mysql服务 build: . #通过MySQL的Dockerfile文件构建MySQL restart: always image: mysql:5.7 container_name: mysql5.7 ports: - 3306:3306 environment: MYSQL_ROOT_PASSWORD: 123456 command: --character-set-server=utf8mb4 --collation-server=utf8mb4_general_ci --explicit_defaults_for_timestamp=true --lower_case_table_names=1 --max_allowed_packet=128M --sql-mode=&quot;STRICT_TRANS_TABLES,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION,NO_ZERO_DATE,NO_ZERO_IN_DATE,ERROR_FOR_DIVISION_BY_ZERO&quot; volumes: - /home/dabing/mysql:/var/lib/mysql DOCKERFile 12345678910111213141516171819# 这个是构建MySQL的dockerfileFROM registry.saas.hand-china.com/tools/mysql:5.7.17# mysql的工作位置ENV WORK_PATH /usr/local/# 定义会被容器自动执行的目录ENV AUTO_RUN_DIR /docker-entrypoint-initdb.d#复制gropshop.sql到/usr/local COPY grogshop.sql /usr/local/#把要执行的shell文件放到/docker-entrypoint-initdb.d/目录下，容器会自动执行这个shellCOPY docker-entrypoint.sh $AUTO_RUN_DIR/#给执行文件增加可执行权限RUN chmod a+x $AUTO_RUN_DIR/docker-entrypoint.sh# 设置容器启动时执行的命令#CMD [&quot;sh&quot;, &quot;/docker-entrypoint-initdb.d/import.sh&quot;] 相关资源：Docker容器的创建、启动、和停止的方法_docker启动已创建的容器…","categories":[{"name":"Web开发","slug":"Web开发","permalink":"http://kaillliu.github.io/categories/Web%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://kaillliu.github.io/tags/Java/"},{"name":"Centos","slug":"Centos","permalink":"http://kaillliu.github.io/tags/Centos/"},{"name":"docket","slug":"docket","permalink":"http://kaillliu.github.io/tags/docket/"}]},{"title":"Nginx学习（五）--- 与Tomcat结合","slug":"Nginx学习其五","date":"2022-04-21T09:00:00.000Z","updated":"2022-05-23T05:41:23.080Z","comments":true,"path":"2022/04/21/Nginx学习其五/","link":"","permalink":"http://kaillliu.github.io/2022/04/21/Nginx%E5%AD%A6%E4%B9%A0%E5%85%B6%E4%BA%94/","excerpt":"","text":"Nginx实现服务器端集群搭建 Nginx与Tomcat部署 前面课程已经将Nginx的大部分内容进行了讲解，我们都知道了Nginx在高并发场景和处理静态资源是非常高性能的，但是在实际项目中除了静态资源还有就是后台业务代码模块，一般后台业务都会被部署在Tomcat，weblogic或者是websphere等web服务器上。那么如何使用Nginx接收用户的请求并把请求转发到后台web服务器？ 步骤分析: 121.准备Tomcat环境，并在Tomcat上部署一个web项目2.准备Nginx环境，使用Nginx接收请求，并把请求分发到Tomat上 环境准备(Tomcat) 浏览器访问: 1http://192.168.200.146:8080/demo/index.html 获取动态资源的链接地址: 1http://192.168.200.146:8080/demo/getAddress 本次课程将采用Tomcat作为后台web服务器 （1）在Centos上准备一个Tomcat 123451.Tomcat官网地址:https://tomcat.apache.org/2.下载tomcat,本次课程使用的是apache-tomcat-8.5.59.tar.gz3.将tomcat进行解压缩mkdir web_tomcattar -zxf apache-tomcat-8.5.59.tar.gz -C /web_tomcat （2）准备一个web项目，将其打包为war 1231.将资料中的demo.war上传到tomcat8目录下的webapps包下2.将tomcat进行启动，进入tomcat8的bin目录下./startup.sh （3）启动tomcat进行访问测试。 12静态资源: http://192.168.200.146:8080/demo/index.html动态资源: http://192.168.200.146:8080/demo/getAddress 环境准备(Nginx) （1）使用Nginx的反向代理，将请求转给Tomcat进行处理。 12345678910upstream webservice &#123; server 192.168.200.146:8080;&#125;server&#123; listen 80; server_name localhost; location /demo &#123; proxy_pass http://webservice; &#125;&#125; （2）启动访问测试 学习到这，可能大家会有一个困惑，明明直接通过tomcat就能访问，为什么还需要多加一个nginx，这样不是反而是系统的复杂度变高了么? 那接下来我们从两个方便给大家分析下这个问题， 第一个使用Nginx实现动静分离 第二个使用Nginx搭建Tomcat的集群 Nginx实现动静分离 什么是动静分离? 动:后台应用程序的业务处理 静:网站的静态资源(html,javaScript,css,images等文件) 分离:将两者进行分开部署访问，提供用户进行访问。举例说明就是以后所有和静态资源相关的内容都交给Nginx来部署访问，非静态内容则交个类似于Tomcat的服务器来部署访问。 为什么要动静分离? ​ 前面我们介绍过Nginx在处理静态资源的时候，效率是非常高的，而且Nginx的并发访问量也是名列前茅，而Tomcat则相对比较弱一些，所以把静态资源交个Nginx后，可以减轻Tomcat服务器的访问压力并提高静态资源的访问速度。 ​ 动静分离以后，降低了动态资源和静态资源的耦合度。如动态资源宕机了也不影响静态资源的展示。 如何实现动静分离? 实现动静分离的方式很多，比如静态资源可以部署到fastly、Nginx等服务器上，动态资源可以部署到Tomcat,weblogic或者websphere上。本次课程只要使用Nginx+Tomcat来实现动静分离。 需求分析 动静分离实现步骤 1.将demo.war项目中的静态资源都删除掉，重新打包生成一个war包，在资料中有提供。 2.将war包部署到tomcat中，把之前部署的内容删除掉 123进入到tomcat的webapps目录下，将之前的内容删除掉将新的war包复制到webapps下将tomcat启动 3.在Nginx所在服务器创建如下目录，并将对应的静态资源放入指定的位置 其中index.html页面的内容如下: 12345678910111213141516171819202122&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;Title&lt;/title&gt; &lt;script src=&quot;js/jquery.min.js&quot;&gt;&lt;/script&gt; &lt;script&gt; $(function()&#123; $.get(&#x27;http://192.168.200.133/demo/getAddress&#x27;,function(data)&#123; $(&quot;#msg&quot;).html(data); &#125;); &#125;); &lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;img src=&quot;images/logo.png&quot;/&gt; &lt;h1&gt;Nginx如何将请求转发到后端服务器&lt;/h1&gt; &lt;h3 id=&quot;msg&quot;&gt;&lt;/h3&gt; &lt;img src=&quot;images/mv.png&quot;/&gt;&lt;/body&gt;&lt;/html&gt; 4.配置Nginx的静态资源与动态资源的访问 12345678910111213141516171819202122upstream webservice&#123; server 192.168.200.146:8080;&#125;server &#123; listen 80; server_name localhost; #动态资源 location /demo &#123; proxy_pass http://webservice; &#125; #静态资源 location ~/.*\\.(png|jpg|gif|js)&#123; root html/web; gzip on; &#125; location / &#123; root html/web; index index.html index.htm; &#125;&#125; 5.启动测试，访问http://192.168.200.133/index.html 假如某个时间点，由于某个原因导致Tomcat后的服务器宕机了，我们再次访问Nginx,会得到如下效果，用户还是能看到页面，只是缺失了访问次数的统计，这就是前后端耦合度降低的效果，并且整个请求只和后的服务器交互了一次，js和images都直接从Nginx返回，提供了效率，降低了后的服务器的压力。 Nginx实现Tomcat集群搭建 在使用Nginx和Tomcat部署项目的时候，我们使用的是一台Nginx服务器和一台Tomcat服务器，效果图如下: 那么问题来了，如果Tomcat的真的宕机了，整个系统就会不完整，所以如何解决上述问题，一台服务器容易宕机，那就多搭建几台Tomcat服务器，这样的话就提升了后的服务器的可用性。这也就是我们常说的集群，搭建Tomcat的集群需要用到了Nginx的反向代理和赋值均衡的知识，具体如何来实现?我们先来分析下原理 环境准备： (1)准备3台tomcat,使用端口进行区分[实际环境应该是三台服务器]，修改server.ml，将端口修改分别修改为8080,8180,8280 (2)启动tomcat并访问测试， 1http://192.168.200.146:8080/demo/getAddress 1http://192.168.200.146:8180/demo/getAddress 1http://192.168.200.146:8280/demo/getAddress (3)在Nginx对应的配置文件中添加如下内容: 123456upstream webservice&#123; server 192.168.200.146:8080; server 192.168.200.146:8180; server 192.168.200.146:8280; &#125; 好了，完成了上述环境的部署，我们已经解决了Tomcat的高可用性，一台服务器宕机，还有其他两条对外提供服务，同时也可以实现后台服务器的不间断更新。但是新问题出现了，上述环境中，如果是Nginx宕机了呢，那么整套系统都将服务对外提供服务了，这个如何解决？ Nginx高可用解决方案 针对于上面提到的问题，我们来分析下要想解决上述问题，需要面临哪些问题? 1需要两台以上的Nginx服务器对外提供服务，这样的话就可以解决其中一台宕机了，另外一台还能对外提供服务，但是如果是两台Nginx服务器的话，会有两个IP地址，用户该访问哪台服务器，用户怎么知道哪台是好的，哪台是宕机了的? Keepalived 使用Keepalived来解决，Keepalived 软件由 C 编写的，最初是专为 LVS 负载均衡软件设计的，Keepalived 软件主要是通过 VRRP 协议实现高可用功能。 VRRP介绍 VRRP（Virtual Route Redundancy Protocol）协议，翻译过来为虚拟路由冗余协议。VRRP协议将两台或多台路由器设备虚拟成一个设备，对外提供虚拟路由器IP,而在路由器组内部，如果实际拥有这个对外IP的路由器如果工作正常的话就是MASTER,MASTER实现针对虚拟路由器IP的各种网络功能。其他设备不拥有该虚拟IP，状态为BACKUP,处了接收MASTER的VRRP状态通告信息以外，不执行对外的网络功能。当主机失效时，BACKUP将接管原先MASTER的网络功能。 从上面的介绍信息获取到的内容就是VRRP是一种协议，那这个协议是用来干什么的？ 1.选择协议 1VRRP可以把一个虚拟路由器的责任动态分配到局域网上的 VRRP 路由器中的一台。其中的虚拟路由即Virtual路由是由VRRP路由群组创建的一个不真实存在的路由，这个虚拟路由也是有对应的IP地址。而且VRRP路由1和VRRP路由2之间会有竞争选择，通过选择会产生一个Master路由和一个Backup路由。 2.路由容错协议 1Master路由和Backup路由之间会有一个心跳检测，Master会定时告知Backup自己的状态，如果在指定的时间内，Backup没有接收到这个通知内容，Backup就会替代Master成为新的Master。Master路由有一个特权就是虚拟路由和后端服务器都是通过Master进行数据传递交互的，而备份节点则会直接丢弃这些请求和数据，不做处理，只是去监听Master的状态 用了Keepalived后，解决方案如下: 环境搭建 环境准备 VIP IP 主机名 主/从 192.168.200.133 keepalived1 Master 192.168.200.222 192.168.200.122 keepalived2 Backup keepalived的安装 1234567891011步骤1:从官方网站下载keepalived,官网地址https://keepalived.org/步骤2:将下载的资源上传到服务器 keepalived-2.0.20.tar.gz步骤3:创建keepalived目录，方便管理资源 mkdir keepalived步骤4:将压缩文件进行解压缩，解压缩到指定的目录 tar -zxf keepalived-2.0.20.tar.gz -C keepalived/步骤5:对keepalived进行配置，编译和安装 cd keepalived/keepalived-2.0.20 ./configure --sysconf=/etc --prefix=/usr/local make &amp;&amp; make install 安装完成后，有两个文件需要我们认识下，一个是 /etc/keepalived/keepalived.conf(keepalived的系统配置文件，我们主要操作的就是该文件)，一个是/usr/local/sbin目录下的keepalived,是系统配置脚本，用来启动和关闭keepalived Keepalived配置文件介绍 打开keepalived.conf配置文件 这里面会分三部，第一部分是global全局配置、第二部分是vrrp相关配置、第三部分是LVS相关配置。 本次课程主要是使用keepalived实现高可用部署，没有用到LVS，所以我们重点关注的是前两部分 12345678910111213141516171819202122232425global全局部分：global_defs &#123; #通知邮件，当keepalived发送切换时需要发email给具体的邮箱地址 notification_email &#123; tom@itcast.cn jerry@itcast.cn &#125; #设置发件人的邮箱信息 notification_email_from zhaomin@itcast.cn #指定smpt服务地址 smtp_server 192.168.200.1 #指定smpt服务连接超时时间 smtp_connect_timeout 30 #运行keepalived服务器的一个标识，可以用作发送邮件的主题信息 router_id LVS_DEVEL #默认是不跳过检查。检查收到的VRRP通告中的所有地址可能会比较耗时，设置此命令的意思是，如果通告与接收的上一个通告来自相同的master路由器，则不执行检查(跳过检查) vrrp_skip_check_adv_addr #严格遵守VRRP协议。 vrrp_strict #在一个接口发送的两个免费ARP之间的延迟。可以精确到毫秒级。默认是0 vrrp_garp_interval 0 #在一个网卡上每组na消息之间的延迟时间，默认为0 vrrp_gna_interval 0&#125; 123456789101112131415161718192021VRRP部分，该部分可以包含以下四个子模块1. vrrp_script2. vrrp_sync_group3. garp_group4. vrrp_instance我们会用到第一个和第四个，#设置keepalived实例的相关信息，VI_1为VRRP实例名称vrrp_instance VI_1 &#123; state MASTER #有两个值可选MASTER主 BACKUP备 interface ens33 #vrrp实例绑定的接口，用于发送VRRP包[当前服务器使用的网卡名称] virtual_router_id 51#指定VRRP实例ID，范围是0-255 priority 100 #指定优先级，优先级高的将成为MASTER advert_int 1 #指定发送VRRP通告的间隔，单位是秒 authentication &#123; #vrrp之间通信的认证信息 auth_type PASS #指定认证方式。PASS简单密码认证(推荐) auth_pass 1111 #指定认证使用的密码，最多8位 &#125; virtual_ipaddress &#123; #虚拟IP地址设置虚拟IP地址，供用户访问使用，可设置多个，一行一个 192.168.200.222 &#125;&#125; 配置内容如下: 服务器1 1234567891011121314151617181920212223242526272829global_defs &#123; notification_email &#123; tom@itcast.cn jerry@itcast.cn &#125; notification_email_from zhaomin@itcast.cn smtp_server 192.168.200.1 smtp_connect_timeout 30 router_id keepalived1 vrrp_skip_check_adv_addr vrrp_strict vrrp_garp_interval 0 vrrp_gna_interval 0&#125;vrrp_instance VI_1 &#123; state MASTER interface ens33 virtual_router_id 51 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 192.168.200.222 &#125;&#125; 服务器2 12345678910111213141516171819202122232425262728293031! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; tom@itcast.cn jerry@itcast.cn &#125; notification_email_from zhaomin@itcast.cn smtp_server 192.168.200.1 smtp_connect_timeout 30 router_id keepalived2 vrrp_skip_check_adv_addr vrrp_strict vrrp_garp_interval 0 vrrp_gna_interval 0&#125;vrrp_instance VI_1 &#123; state BACKUP interface ens33 virtual_router_id 51 priority 90 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 192.168.200.222 &#125;&#125; 访问测试 启动keepalived之前，咱们先使用命令 ip a,查看192.168.200.133和192.168.200.122这两台服务器的IP情况。 分别启动两台服务器的keepalived 12cd /usr/local/sbin./keepalived 再次通过 ip a查看ip 当把192.168.200.133服务器上的keepalived关闭后，再次查看ip 通过上述的测试，我们会发现，虚拟IP(VIP)会在MASTER节点上，当MASTER节点上的keepalived出问题以后，因为BACKUP无法收到MASTER发出的VRRP状态通过信息，就会直接升为MASTER。VIP也会&quot;漂移&quot;到新的MASTER。 上面测试和Nginx有什么关系? 我们把192.168.200.133服务器的keepalived再次启动下，由于它的优先级高于服务器192.168.200.122的，所有它会再次成为MASTER，VIP也会&quot;漂移&quot;过去，然后我们再次通过浏览器访问: 1http://192.168.200.222/ 如果把192.168.200.133服务器的keepalived关闭掉，再次访问相同的地址 效果实现了以后， 我们会发现要想让vip进行切换，就必须要把服务器上的keepalived进行关闭，而什么时候关闭keepalived呢?应该是在keepalived所在服务器的nginx出现问题后，把keepalived关闭掉，就可以让VIP执行另外一台服务器，但是现在这所有的操作都是通过手动来完成的，我们如何能让系统自动判断当前服务器的nginx是否正确启动，如果没有，要能让VIP自动进行&quot;漂移&quot;，这个问题该如何解决? keepalived之vrrp_script keepalived只能做到对网络故障和keepalived本身的监控，即当出现网络故障或者keepalived本身出现问题时，进行切换。但是这些还不够，我们还需要监控keepalived所在服务器上的其他业务，比如Nginx,如果Nginx出现异常了，仅仅keepalived保持正常，是无法完成系统的正常工作的，因此需要根据业务进程的运行状态决定是否需要进行主备切换，这个时候，我们可以通过编写脚本对业务进程进行检测监控。 实现步骤: 在keepalived配置文件中添加对应的配置像 123456vrrp_script 脚本名称&#123; script &quot;脚本位置&quot; interval 3 #执行时间间隔 weight -20 #动态调整vrrp_instance的优先级&#125; 编写脚本 ck_nginx.sh 123456789#!/bin/bashnum=`ps -C nginx --no-header | wc -l`if [ $num -eq 0 ];then /usr/local/nginx/sbin/nginx sleep 2 if [ `ps -C nginx --no-header | wc -l` -eq 0 ]; then killall keepalived fifi Linux ps命令用于显示当前进程 (process) 的状态。 -C(command) :指定命令的所有进程 –no-header 排除标题 为脚本文件设置权限 1chmod 755 ck_nginx.sh 将脚本添加到 12345678910111213141516171819202122vrrp_script ck_nginx &#123; script &quot;/etc/keepalived/ck_nginx.sh&quot; #执行脚本的位置 interval 2 #执行脚本的周期，秒为单位 weight -20 #权重的计算方式&#125;vrrp_instance VI_1 &#123; state MASTER interface ens33 virtual_router_id 10 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 1111 &#125; virtual_ipaddress &#123; 192.168.200.111 &#125; track_script &#123; ck_nginx &#125;&#125; 如果效果没有出来，可以使用 tail -f /var/log/messages查看日志信息，找对应的错误信息。 测试 问题思考: 通常如果master服务死掉后backup会变成master，但是当master服务又好了的时候 master此时会抢占VIP，这样就会发生两次切换对业务繁忙的网站来说是不好的。所以我们要在配置文件加入 nopreempt 非抢占，但是这个参数只能用于state 为backup，故我们在用HA的时候最好master 和backup的state都设置成backup 让其通过priority来竞争。 Nginx制作下载站点 首先我们先要清楚什么是下载站点? 我们先来看一个网站http://nginx.org/download/这个我们刚开始学习Nginx的时候给大家看过这样的网站，该网站主要就是用来提供用户来下载相关资源的网站，就叫做下载网站。 如何制作一个下载站点: nginx使用的是模块ngx_http_autoindex_module来实现的，该模块处理以斜杠(“/”)结尾的请求，并生成目录列表。 nginx编译的时候会自动加载该模块，但是该模块默认是关闭的，我们需要使用下来指令来完成对应的配置 （1）autoindex:启用或禁用目录列表输出 语法 autoindex on|off; 默认值 autoindex off; 位置 http、server、location （2）autoindex_exact_size:对应HTLM格式，指定是否在目录列表展示文件的详细大小 默认为on，显示出文件的确切大小，单位是bytes。 改为off后，显示出文件的大概大小，单位是kB或者MB或者GB 语法 autoindex_exact_size on|off; 默认值 autoindex_exact_size on; 位置 http、server、location （3）autoindex_format：设置目录列表的格式 语法 autoindex_format html|xml|json|jsonp; 默认值 autoindex_format html; 位置 http、server、location 注意:该指令在1.7.9及以后版本中出现 （4）autoindex_localtime:对应HTML格式，是否在目录列表上显示时间。 默认为off，显示的文件时间为GMT时间。 改为on后，显示的文件时间为文件的服务器时间 语法 autoindex_localtime on | off; 默认值 autoindex_localtime off; 位置 http、server、location 配置方式如下: 12345678location /download&#123; root /usr/local; autoindex on; autoindex_exact_size on; autoindex_format html; autoindex_localtime on;&#125; XML/JSON格式[一般不用这两种方式] Nginx的用户认证模块 对应系统资源的访问，我们往往需要限制谁能访问，谁不能访问。这块就是我们通常所说的认证部分，认证需要做的就是根据用户输入的用户名和密码来判定用户是否为合法用户，如果是则放行访问，如果不是则拒绝访问。 Nginx对应用户认证这块是通过ngx_http_auth_basic_module模块来实现的，它允许通过使用&quot;HTTP基本身份验证&quot;协议验证用户名和密码来限制对资源的访问。默认情况下nginx是已经安装了该模块，如果不需要则使用–without-http_auth_basic_module。 该模块的指令比较简单， （1）auth_basic:使用“ HTTP基本认证”协议启用用户名和密码的验证 语法 auth_basic string|off; 默认值 auth_basic off; 位置 http,server,location,limit_except 开启后，服务端会返回401，指定的字符串会返回到客户端，给用户以提示信息，但是不同的浏览器对内容的展示不一致。 （2）auth_basic_user_file:指定用户名和密码所在文件 语法 auth_basic_user_file file; 默认值 — 位置 http,server,location,limit_except 指定文件路径，该文件中的用户名和密码的设置，密码需要进行加密。可以采用工具自动生成 实现步骤: 1.nginx.conf添加如下内容 123456789location /download&#123; root /usr/local; autoindex on; autoindex_exact_size on; autoindex_format html; autoindex_localtime on; auth_basic &#x27;please input your auth&#x27;; auth_basic_user_file htpasswd;&#125; 2.我们需要使用htpasswd工具生成 1yum install -y httpd-tools 1234htpasswd -c /usr/local/nginx/conf/htpasswd username //创建一个新文件记录用户名和密码htpasswd -b /usr/local/nginx/conf/htpasswd username password //在指定文件新增一个用户名和密码htpasswd -D /usr/local/nginx/conf/htpasswd username //从指定文件删除一个用户信息htpasswd -v /usr/local/nginx/conf/htpasswd username //验证用户名和密码是否正确 上述方式虽然能实现用户名和密码的验证，但是大家也看到了，所有的用户名和密码信息都记录在文件里面，如果用户量过大的话，这种方式就显得有点麻烦了，这时候我们就得通过后台业务代码来进行用户权限的校验了。 Nginx的扩展模块 Nginx是可扩展的，可用于处理各种使用场景。本节中，我们将探讨使用Lua扩展Nginx的功能。 Lua 概念 Lua是一种轻量、小巧的脚本语言，用标准C语言编写并以源代码形式开发。设计的目的是为了嵌入到其他应用程序中，从而为应用程序提供灵活的扩展和定制功能。 特性 跟其他语言进行比较，Lua有其自身的特点： （1）轻量级 1Lua用标准C语言编写并以源代码形式开发，编译后仅仅一百余千字节，可以很方便的嵌入到其他程序中。 （2）可扩展 1Lua提供非常丰富易于使用的扩展接口和机制，由宿主语言(通常是C或C++)提供功能，Lua可以使用它们，就像内置的功能一样。 （3）支持面向过程编程和函数式编程 应用场景 Lua在不同的系统中得到大量应用，场景的应用场景如下: 游戏开发、独立应用脚本、web应用脚本、扩展和数据库插件、系统安全上。 Lua的安装 在linux上安装Lua非常简单，只需要下载源码包并在终端解压、编译即可使用。 Lua的官网地址为:https://www.lua.org 点击download可以找到对应版本的下载地址，我们本次课程采用的是lua-5.3.5,其对应的资源链接地址为https://www.lua.org/ftp/lua-5.4.1.tar.gz,也可以使用wget命令直接下载: 1wget https://www.lua.org/ftp/lua-5.4.1.tar.gz 编译安装 123cd lua-5.4.1make linux testmake install 如果在执行make linux test失败，报如下错误: 说明当前系统缺少libreadline-dev依赖包，需要通过命令来进行安装 1yum install -y readline-devel 验证是否安装成功 1lua -v Lua的语法 Lua和C/C++语法非常相似，整体上比较清晰，简洁。条件语句、循环语句、函数调用都与C/C++基本一致。如果对C/C++不太熟悉的同学来说，也没关系，因为天下语言是一家，基本上理解起来都不会太困难。我们一点点来讲。 第一个Lua程序 大家需要知道的是，Lua有两种交互方式，分别是:交互式和脚本式，这两者的区别，下面我们分别来讲解下： 交互式之HELLOWORLD 1交互式是指可以在命令行输入程序，然后回车就可以看到运行的效果。 Lua交互式编程模式可以通过命令lua -i 或lua来启用: 在命令行中key输入如下命令，并按回车,会有输出在控制台： 脚本式之HELLOWORLD 脚本式是将代码保存到一个以lua为扩展名的文件中并执行的方式。 方式一: 我们需要一个文件名为 hello.lua,在文件中添加要执行的代码，然后通过命令 lua hello.lua来执行，会在控制台输出对应的结果。 hello.lua 1print(&quot;Hello World!!&quot;) 方式二: 将hello.lua做如下修改 12#!/usr/local/bin/luaprint(&quot;Hello World!!!&quot;) 第一行用来指定Lua解释器所在位置为 /usr/local/bin/lua，加上#号标记解释器会忽略它。一般情况下#!就是用来指定用哪个程序来运行本文件。但是hello.lua并不是一个可执行文件，需要通过chmod来设置可执行权限，最简单的方式为: 1chmod 755 hello.lua 然后执行该文件 1./hello.lua 补充一点，如果想在交互式中运行脚本式的hello.lua中的内容，我们可以使用一个dofile函数，如： 1dofile(&quot;lua_demo/hello.lua&quot;) 注意:在Lua语言中，连续语句之间的分隔符并不是必须的，也就是说后面不需要加分号，当然加上也不会报错， 在Lua语言中，表达式之间的换行也起不到任何作用。如以下四个写法，其实都是等效的 12345678910写法一a=1b=a+2写法二a=1;b=a+2;写法三a=1; b=a+2;写法四a=1 b=a+2 不建议使用第四种方式，可读性太差。 Lua的注释 关于Lua的注释要分两种，第一种是单行注释，第二种是多行注释。 单行注释的语法为： 1--注释内容 多行注释的语法为: 1234--[[ 注释内容 注释内容--]] 如果想取消多行注释，只需要在第一个–之前在加一个-即可，如： 1234---[[ 注释内容 注释内容--]] 标识符 换句话说标识符就是我们的变量名，Lua定义变量名以一个字母 A 到 Z 或 a 到 z 或下划线 _ 开头后加上0个或多个字母，下划线，数字（0到9）。这块建议大家最好不要使用下划线加大写字母的标识符，因为Lua的保留字也是这样定义的，容易发生冲突。注意Lua是区分大小写字母的。 A0 关键字 下列是Lua的关键字，大家在定义常量、变量或其他用户自定义标识符都要避免使用以下这些关键字： and break do else elseif end false for function if in local nil not or repeat return then true until while goto 一般约定，以下划线开头连接一串大写字母的名字（比如 _VERSION）被保留用于 Lua 内部全局变量。这个也是上面我们不建议这么定义标识符的原因。 运算符 Lua中支持的运算符有算术运算符、关系运算符、逻辑运算符、其他运算符。 算术运算符: 1234567+ 加法- 减法* 乘法/ 除法% 取余^ 乘幂- 负号 例如: 123456710+20 --&gt;3020-10 --&gt;1010*20 --&gt;20020/10 --&gt;23%2 --&gt;110^2 --&gt;100-10 --&gt;-10 关系运算符 123456== 等于~= 不等于&gt; 大于&lt; 小于&gt;= 大于等于&lt;= 小于等于 例如: 12345610==10 --&gt;true10~=10 --&gt;false20&gt;10 --&gt;true20&lt;10 --&gt;false20&gt;=10 --&gt;true20&lt;=10 --&gt;false 逻辑运算符 123and 逻辑与 A and B &amp;&amp; or 逻辑或 A or B ||not 逻辑非 取反，如果为true,则返回false ! 逻辑运算符可以作为if的判断条件，返回的结果如下: 123456789101112131415161718192021A = trueB = trueA and B --&gt;trueA or B --&gt;truenot A --&gt;falseA = trueB = falseA and B --&gt;falseA or B --&gt;truenot A --&gt;falseA = falseB = trueA and B --&gt;falseA or B --&gt;truenot A --&gt;true 其他运算符 12.. 连接两个字符串# 一元预算法，返回字符串或表的长度 例如: 12&gt; &quot;HELLO &quot;..&quot;WORLD&quot; --&gt;HELLO WORLD&gt; #&quot;HELLO&quot; --&gt;5 全局变量&amp;局部变量 在Lua语言中，全局变量无须声明即可使用。在默认情况下，变量总是认为是全局的，如果未提前赋值，默认为nil: 要想声明一个局部变量，需要使用local来声明 Lua数据类型 Lua有8个数据类型 12345678nil(空，无效值)boolean(布尔，true/false)number(数值)string(字符串)function(函数)table（表）thread(线程)userdata（用户数据） 可以使用type函数测试给定变量或者的类型： 123456789print(type(nil)) --&gt;nilprint(type(true)) --&gt; booleanprint(type(1.1*1.1)) --&gt; numberprint(type(&quot;Hello world&quot;)) --&gt; stringprint(type(io.stdin)) --&gt;userdataprint(type(print)) --&gt; functionprint(type(type)) --&gt;functionprint(type&#123;&#125;) --&gt;tableprint(type(type(X))) --&gt; string nil nil是一种只有一个nil值的类型，它的作用可以用来与其他所有值进行区分，也可以当想要移除一个变量时，只需要将该变量名赋值为nil,垃圾回收就会会释放该变量所占用的内存。 boolean boolean类型具有两个值，true和false。boolean类型一般被用来做条件判断的真与假。在Lua语言中，只会将false和nil视为假，其他的都视为真，特别是在条件检测中0和空字符串都会认为是真，这个和我们熟悉的大多数语言不太一样。 number 在Lua5.3版本开始，Lua语言为数值格式提供了两种选择:integer(整型)和float(双精度浮点型)[和其他语言不太一样，float不代表单精度类型]。 数值常量的表示方式: 1234&gt;4 --&gt;4&gt;0.4 --&gt;0.4&gt;4.75e-3 --&gt;0.00475&gt;4.75e3 --&gt;4750 不管是整型还是双精度浮点型，使用type()函数来取其类型，都会返回的是number 12&gt;type(3) --&gt;number&gt;type(3.3) --&gt;number 所以它们之间是可以相互转换的，同时，具有相同算术值的整型值和浮点型值在Lua语言中是相等的 string Lua语言中的字符串即可以表示单个字符，也可以表示一整本书籍。在Lua语言中，操作100K或者1M个字母组成的字符串的程序很常见。 可以使用单引号或双引号来声明字符串 1234&gt;a = &quot;hello&quot;&gt;b = &#x27;world&#x27;&gt;print(a) --&gt;hello&gt;print(b) --&gt;world 如果声明的字符串比较长或者有多行，则可以使用如下方式进行声明 12345678910html = [[&lt;html&gt;&lt;head&gt;&lt;title&gt;Lua-string&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;a href=&quot;http://www.lua.org&quot;&gt;Lua&lt;/a&gt;&lt;/body&gt;&lt;/html&gt;]] table ​ table是Lua语言中最主要和强大的数据结构。使用表， Lua 语言可以以一种简单、统一且高效的方式表示数组、集合、记录和其他很多数据结构。 Lua语言中的表本质上是一种辅助数组。这种数组比Java中的数组更加灵活，可以使用数值做索引，也可以使用字符串或其他任意类型的值作索引(除nil外)。 创建表的最简单方式: 1&gt; a = &#123;&#125; 创建数组: ​ 我们都知道数组就是相同数据类型的元素按照一定顺序排列的集合，那么使用table如何创建一个数组呢? 1&gt;arr = &#123;&quot;TOM&quot;,&quot;JERRY&quot;,&quot;ROSE&quot;&#125; ​ 要想获取数组中的值，我们可以通过如下内容来获取: 1234print(arr[0]) nilprint(arr[1]) TOMprint(arr[2]) JERRYprint(arr[3]) ROSE ​ 从上面的结果可以看出来，数组的下标默认是从1开始的。所以上述创建数组，也可以通过如下方式来创建 1234&gt;arr = &#123;&#125;&gt;arr[1] = &quot;TOM&quot;&gt;arr[2] = &quot;JERRY&quot;&gt;arr[3] = &quot;ROSE&quot; 上面我们说过了，表的索引即可以是数字，也可以是字符串等其他的内容，所以我们也可以将索引更改为字符串来创建 1234&gt;arr = &#123;&#125;&gt;arr[&quot;X&quot;] = 10&gt;arr[&quot;Y&quot;] = 20&gt;arr[&quot;Z&quot;] = 30 当然，如果想要获取这些数组中的值，可以使用下面的方式 12345678方式一&gt;print(arr[&quot;X&quot;])&gt;print(arr[&quot;Y&quot;])&gt;print(arr[&quot;Z&quot;])方式二&gt;print(arr.X)&gt;print(arr.Y)&gt;print(arr.Z) 当前table的灵活不进于此，还有更灵活的声明方式 1&gt;arr = &#123;&quot;TOM&quot;,X=10,&quot;JERRY&quot;,Y=20,&quot;ROSE&quot;,Z=30&#125; 如何获取上面的值? 12345TOM : arr[1]10 : arr[&quot;X&quot;] | arr.XJERRY: arr[2]20 : arr[&quot;Y&quot;] | arr.YROESE? function 在 Lua语言中，函数（ Function ）是对语句和表达式进行抽象的主要方式。 定义函数的语法为: 123function functionName(params)end 函数被调用的时候，传入的参数个数与定义函数时使用的参数个数不一致的时候，Lua 语言会通过 抛弃多余参数和将不足的参数设为 nil 的方式来调整参数的个数。 12345678function f(a,b)print(a,b)endf() --&gt; nil nilf(2) --&gt; 2 nilf(2,6) --&gt; 2 6f(2.6.8) --&gt; 2 6 (8被丢弃) 可变长参数函数 12345678function add(...)a,b,c=...print(a)print(b)print(c)endadd(1,2,3) --&gt; 1 2 3 函数返回值可以有多个，这点和Java不太一样 12345function f(a,b)return a,bendx,y=f(11,22) --&gt; x=11,y=22 thread thread翻译过来是线程的意思，在Lua中，thread用来表示执行的独立线路，用来执行协同程序。 userdata userdata是一种用户自定义数据，用于表示一种由应用程序或C/C++语言库所创建的类型。 Lua控制结构 Lua 语言提供了一组精简且常用的控制结构，包括用于条件执行的证 以及用于循环的 while、 repeat 和 for。 所有的控制结构语法上都有一个显式的终结符： end 用于终结 if、 for 及 while 结构， until 用于终结 repeat 结构。 if then elseif else if语句先测试其条件，并根据条件是否满足执行相应的 then 部分或 else 部分。 else 部分 是可选的。 12345678910111213function testif(a) if a&gt;0 then print(&quot;a是正数&quot;) endendfunction testif(a) if a&gt;0 then print(&quot;a是正数&quot;) else print(&quot;a是负数&quot;) endend 如果要编写嵌套的 if 语句，可以使用 elseif。 它类似于在 else 后面紧跟一个if。根据传入的年龄返回不同的结果，如 12345678910111213141516age&lt;=18 青少年，age&gt;18 , age &lt;=45 青年age&gt;45 , age&lt;=60 中年人age&gt;60 老年人function show(age)if age&lt;=18 then return &quot;青少年&quot;elseif age&gt;18 and age&lt;=45 then return &quot;青年&quot;elseif age&gt;45 and age&lt;=60 then return &quot;中年人&quot;elseif age&gt;60 then return &quot;老年人&quot;endend while循环 顾名思义，当条件为真时 while 循环会重复执行其循环体。 Lua 语言先测试 while 语句 的条件，若条件为假则循环结束；否则， Lua 会执行循环体并不断地重复这个过程。 语法： 123while 条件 do 循环体end 例子:实现数组的循环 1234567function testWhile() local i = 1 while i&lt;=10 do print(i) i=i+1 endend repeat循环 顾名思义， repeat-until语句会重复执行其循环体直到条件为真时结束。 由于条件测试在循环体之后执行，所以循环体至少会执行一次。 语法 123repeat 循环体 until 条件 1234567function testRepeat() local i = 10 repeat print(i) i=i-1 until i &lt; 1end for循环 数值型for循环 语法 123for param=exp1,exp2,exp3 do 循环体end param的值从exp1变化到exp2之前的每次循环会执行 循环体，并在每次循环结束后将步长(step)exp3增加到param上。exp3可选，如果不设置默认为1 123for i = 1,100,10 doprint(i)end 泛型for循环 泛型for循环通过一个迭代器函数来遍历所有值，类似于java中的foreach语句。 语法 123for i,v in ipairs(x) do 循环体end i是数组索引值，v是对应索引的数组元素值，ipairs是Lua提供的一个迭代器函数，用来迭代数组，x是要遍历的数组。 例如: 1234arr = &#123;&quot;TOME&quot;,&quot;JERRY&quot;,&quot;ROWS&quot;,&quot;LUCY&quot;&#125;for i,v in ipairs(arr) do print(i,v)end 上述实例输出的结果为 12341 TOM2 JERRY3 ROWS4 LUCY 但是如果将arr的值进行修改为 1arr = &#123;&quot;TOME&quot;,&quot;JERRY&quot;,&quot;ROWS&quot;,x=&quot;JACK&quot;,&quot;LUCY&quot;&#125; 同样的代码在执行的时候，就只能看到和之前一样的结果，而其中的x为JACK就无法遍历出来，缺失了数据，如果解决呢? 我们可以将迭代器函数变成pairs,如 123for i,v in pairs(arr) do print(i,v)end 上述实例就输出的结果为 123451 TOM2 JERRY3 ROWS4 LUCYx JACK ngx_lua模块概念 淘宝开发的ngx_lua模块通过将lua解释器集成进Nginx，可以采用lua脚本实现业务逻辑，由于lua的紧凑、快速以及内建协程，所以在保证高并发服务能力的同时极大地降低了业务逻辑实现成本。 ngx_lua模块环境准备 方式一:lua-nginx-module LuaJIT是采用C语言编写的Lua代表的解释器。 官网地址为:http://luajit.org/ 在官网上找到对应的下载地址:http://luajit.org/download/LuaJIT-2.0.5.tar.gz 在centos上使用wget来下载: wget http://luajit.org/download/LuaJIT-2.0.5.tar.gz 将下载的资源进行解压: tar -zxf LuaJIT-2.0.5.tar.gz 进入解压的目录: cd LuaJIT-2.0.5 执行编译和安装: make &amp;&amp; make install 下载lua-nginx-module 下载地址:https://github.com/openresty/lua-nginx-module/archive/v0.10.16rc4.tar.gz 在centos上使用wget来下载: wget https://github.com/openresty/lua-nginx-module/archive/v0.10.16rc4.tar.gz 将下载的资源进行解压: tar -zxf lua-nginx-module-0.10.16rc4.tar.gz 更改目录名:mv lua-nginx-module-0.10.16rc4 lua-nginx-module 导入环境变量，告诉Nginx去哪里找luajit 12export LUAJIT_LIB=/usr/local/libexport LUAJIT_INC=/usr/local/include/luajit-2.0 进入Nginx的目录执行如下命令: 12./configure --prefix=/usr/local/nginx --add-module=../lua-nginx-modulemake &amp;&amp; make install 注意事项: （1）如果启动Nginx出现如下错误: 解决方案: 设置软链接，使用如下命令 1ln -s /usr/local/lib/libluajit-5.1.so.2 /lib64/libluajit-5.1.so.2 （2）如果启动Nginx出现以下错误信息 分析原因:因为lua-nginx-module是来自openrestry,错误中提示的resty.core是openrestry的核心模块，对其下的很多函数进行了优化等工作。以前的版本默认不会把该模块编译进去，所以需要使用的话，我们得手动安装，或者禁用就可以。但是最新的lua-nginx-module模块已经强制性安装了该模块，所以此处因为缺少resty模块导致的报错信息。 解决方案有两个:一种是下载对应的模块，另一种则是禁用掉restry模块，禁用的方式为: 123http&#123; lua_load_resty_core off;&#125; 测试 在nginx.conf下配置如下内容: 1234location /lua&#123; default_type &#x27;text/html&#x27;; content_by_lua &#x27;ngx.say(&quot;&lt;h1&gt;HELLO,LUA&lt;/h1&gt;&quot;)&#x27;;&#125; 配置成功后，启动nginx,通过浏览器进行访问，如果获取到如下结果，则证明安装成功。 方式二:OpenRestry 概述 ​ 前面我们提到过，OpenResty是由淘宝工程师开发的，所以其官方网站(http://openresty.org/)我们读起来是非常的方便。OpenResty是一个基于Nginx与 Lua 的高性能 Web 平台，其内部集成了大量精良的 Lua 库、第三方模块以及大多数的依赖项。用于方便地搭建能够处理超高并发、扩展性极高的动态 Web 应用、Web 服务和动态网关。所以本身OpenResty内部就已经集成了Nginx和Lua，所以我们使用起来会更加方便。 安装 1234567891011121314(1) 下载OpenResty：https://openresty.org/download/openresty-1.15.8.2.tar.gz(2)使用wget下载: wget https://openresty.org/download/openresty-1.15.8.2.tar.gz(3)解压缩: tar -zxf openresty-1.15.8.2.tar.gz(4)进入OpenResty目录: cd openresty-1.15.8.2(5) 执行命令:./configure(6) 执行命令:make &amp;&amp; make install(7)进入OpenResty的目录，找到nginx：cd /usr/local/openresty/nginx/(8)在conf目录下的nginx.conf添加如下内容location /lua&#123; default_type &#x27;text/html&#x27;; content_by_lua &#x27;ngx.say(&quot;&lt;h1&gt;HELLO,OpenRestry&lt;/h1&gt;&quot;)&#x27;;&#125;(9)在sbin目录下启动nginx(10)通过浏览器访问测试 ngx_lua的使用 使用Lua编写Nginx脚本的基本构建块是指令。指令用于指定何时运行用户Lua代码以及如何使用结果。下图显示了执行指令的顺序。 先来解释下*的作用 123*：无 ， 即 xxx_by_lua ,指令后面跟的是 lua指令*:_file，即 xxx_by_lua_file 指令后面跟的是 lua文件*:_block,即 xxx_by_lua_block 在0.9.17版后替换init_by_lua_file init_by_lua* 1该指令在每次Nginx重新加载配置时执行，可以用来完成一些耗时模块的加载，或者初始化一些全局配置。 init_worker_by_lua* 1该指令用于启动一些定时任务，如心跳检查、定时拉取服务器配置等。 set_by_lua* 1该指令只要用来做变量赋值，这个指令一次只能返回一个值，并将结果赋值给Nginx中指定的变量。 rewrite_by_lua* 1该指令用于执行内部URL重写或者外部重定向，典型的如伪静态化URL重写，本阶段在rewrite处理阶段的最后默认执行。 access_by_lua* 1该指令用于访问控制。例如，如果只允许内网IP访问。 content_by_lua* 1该指令是应用最多的指令，大部分任务是在这个阶段完成的，其他的过程往往为这个阶段准备数据，正式处理基本都在本阶段。 header_filter_by_lua* 1该指令用于设置应答消息的头部信息。 body_filter_by_lua* 1该指令是对响应数据进行过滤，如截断、替换。 log_by_lua* 1该指令用于在log请求处理阶段，用Lua代码处理日志，但并不替换原有log处理。 balancer_by_lua* 1该指令主要的作用是用来实现上游服务器的负载均衡器算法 ssl_certificate_by_* 1该指令作用在Nginx和下游服务开始一个SSL握手操作时将允许本配置项的Lua代码。 需求: 123http://192.168.200.133?name=张三&amp;gender=1Nginx接收到请求后，根据gender传入的值，如果gender传入的是1，则在页面上展示张三先生,如果gender传入的是0，则在页面上展示张三女士,如果未传或者传入的不是1和2则在页面上展示张三。 实现代码 12345678910111213141516171819location /getByGender &#123; default_type &#x27;text/html&#x27;; set_by_lua $name &quot; local uri_args = ngx.req.get_uri_args() gender = uri_args[&#x27;gender&#x27;] name = uri_args[&#x27;name&#x27;] if gender==&#x27;1&#x27; then return name..&#x27;先生&#x27; elseif gender==&#x27;0&#x27; then return name..&#x27;女士&#x27; else return name end &quot;; header_filter_by_lua &quot; ngx.header.aaa=&#x27;bbb&#x27; &quot;; return 200 $name;&#125; ngx_lua操作Redis Redis在系统中经常作为数据缓存、内存数据库使用，在大型系统中扮演着非常重要的作用。在Nginx核心系统中，Redis是常备组件。Nginx支持3种方法访问Redis,分别是HttpRedis模块、HttpRedis2Module、lua-resty-redis库。这三种方式中HttpRedis模块提供的指令少，功能单一，适合做简单缓存，HttpRedis2Module模块比HttpRedis模块操作更灵活，功能更强大。而Lua-resty-redis库是OpenResty提供的一个操作Redis的接口库，可根据自己的业务情况做一些逻辑处理，适合做复杂的业务逻辑。所以本次课程将主要以Lua-resty-redis来进行讲解。 lua-resty-redis环境准备 步骤一:准备一个Redis环境 123连接地址host= 192.168.200.111port=6379 步骤二:准备对应的API 123456789101112131415lua-resty-redis提供了访问Redis的详细API，包括创建对接、连接、操作、数据处理等。这些API基本上与Redis的操作一一对应。（1）redis = require &quot;resty.redis&quot;（2）new 语法: redis,err = redis:new(),创建一个Redis对象。（3）connect 语法:ok,err=redis:connect(host,port[,options_table]),设置连接Redis的连接信息。 ok:连接成功返回 1，连接失败返回nil err:返回对应的错误信息（4）set_timeout 语法: redis:set_timeout(time) ，设置请求操作Redis的超时时间。（5）close 语法: ok,err = redis:close(),关闭当前连接，成功返回1，失败返回nil和错误信息（6）redis命令对应的方法 在lua-resty-redis中，所有的Redis命令都有自己的方法，方法名字和命令名字相同，只是全部为小写。 步骤三:效果实现 123456789101112131415161718192021location / &#123; default_type &quot;text/html&quot;; content_by_lua_block&#123; local redis = require &quot;resty.redis&quot; -- 引入Redis local redisObj = redis:new() --创建Redis对象 redisObj:set_timeout(1000) --设置超时数据为1s local ok,err = redisObj:connect(&quot;192.168.200.1&quot;,6379) --设置redis连接信息 if not ok then --判断是否连接成功 ngx.say(&quot;failed to connection redis&quot;,err) return end ok,err = redisObj:set(&quot;username&quot;,&quot;TOM&quot;)--存入数据 if not ok then --判断是否存入成功 ngx.say(&quot;failed to set username&quot;,err) return end local res,err = redisObj:get(&quot;username&quot;) --从redis中获取数据 ngx.say(res) --将数据写会消息体中 redisObj:close() &#125;&#125; 步骤四:运行测试效果 ngx_lua操作Mysql MySQL是一个使用广泛的关系型数据库。在ngx_lua中，MySQL有两种访问模式,分别是使 （1）用ngx_lua模块和lua-resty-mysql模块：这两个模块是安装OpenResty时默认安装的。 （2）使用drizzle_nginx_module(HttpDrizzleModule)模块：需要单独安装，这个库现不在OpenResty中。 lua-resty-mysql lua-resty-mysql是OpenResty开发的模块，使用灵活、功能强大，适合复杂的业务场景，同时支持存储过程的访问。 使用lua-resty-mysql实现数据库的查询 步骤一: 准备MYSQL 1234host: 192.168.200.111port: 3306username:rootpassword:123456 创建一个数据库表及表中的数据。 12345678910111213141516create database nginx_db;use nginx_db;create table users( id int primary key auto_increment, username varchar(30), birthday date, salary double);insert into users(id,username,birthday,salary) values(null,&quot;TOM&quot;,&quot;1988-11-11&quot;,10000.0);insert into users(id,username,birthday,salary) values(null,&quot;JERRY&quot;,&quot;1989-11-11&quot;,20000.0);insert into users(id,username,birthday,salary) values(null,&quot;ROWS&quot;,&quot;1990-11-11&quot;,30000.0);insert into users(id,username,birthday,salary) values(null,&quot;LUCY&quot;,&quot;1991-11-11&quot;,40000.0);insert into users(id,username,birthday,salary) values(null,&quot;JACK&quot;,&quot;1992-11-11&quot;,50000.0); 数据库连接四要素: 1234driverClass=com.mysql.jdbc.Driverurl=jdbc:mysql://192.168.200.111:3306/nginx_dbusername=rootpassword=123456 步骤二:API学习 12345678910111213141516171819202122232425262728293031323334353637383940414243444546（1）引入&quot;resty.mysql&quot;模块 local mysql = require &quot;resty.mysql&quot;（2）new 创建一个MySQL连接对象，遇到错误时，db为nil，err为错误描述信息 语法: db,err = mysql:new()（3）connect 尝试连接到一个MySQL服务器 语法:ok,err=db:connect(options),options是一个参数的Lua表结构，里面包含数据库连接的相关信息 host:服务器主机名或IP地址 port:服务器监听端口，默认为3306 user:登录的用户名 password:登录密码 database:使用的数据库名（4）set_timeout 设置子请求的超时时间(ms)，包括connect方法 语法:db:set_timeout(time)（5）close 关闭当前MySQL连接并返回状态。如果成功，则返回1；如果出现任何错误，则将返回nil和错误描述。 语法:db:close()（6）send_query 异步向远程MySQL发送一个查询。如果成功则返回成功发送的字节数；如果错误，则返回nil和错误描述 语法:bytes,err=db:send_query(sql)（7）read_result 从MySQL服务器返回结果中读取一行数据。res返回一个描述OK包或结果集包的Lua表,语法: res, err, errcode, sqlstate = db:read_result() res, err, errcode, sqlstate = db:read_result(rows) :rows指定返回结果集的最大值，默认为4 如果是查询，则返回一个容纳多行的数组。每行是一个数据列的key-value对，如 &#123; &#123;id=1,username=&quot;TOM&quot;,birthday=&quot;1988-11-11&quot;,salary=10000.0&#125;, &#123;id=2,username=&quot;JERRY&quot;,birthday=&quot;1989-11-11&quot;,salary=20000.0&#125; &#125; 如果是增删改，则返回类上如下数据 &#123; insert_id = 0, server_status=2, warning_count=1, affected_rows=2, message=nil &#125; 返回值: res:操作的结果集 err:错误信息 errcode:MySQL的错误码，比如1064 sqlstate:返回由5个字符组成的标准SQL错误码，比如42000 步骤三:效果实现 1234567891011121314151617181920location /&#123; content_by_lua_block&#123; local mysql = require &quot;resty.mysql&quot; local db = mysql:new() local ok,err = db:connect&#123; host=&quot;192.168.200.111&quot;, port=3306, user=&quot;root&quot;, password=&quot;123456&quot;, database=&quot;nginx_db&quot; &#125; db:set_timeout(1000) db:send_query(&quot;select * from users where id =1&quot;) local res,err,errcode,sqlstate = db:read_result() ngx.say(res[1].id..&quot;,&quot;..res[1].username..&quot;,&quot;..res[1].birthday..&quot;,&quot;..res[1].salary) db:close() &#125;&#125; 问题: 1231.如何获取返回数据的内容2.如何实现查询多条数据3.如何实现数据库的增删改操作 使用lua-cjson处理查询结果 通过上述的案例学习，read_result()得到的结果res都是table类型，要想在页面上展示，就必须知道table的具体数据结构才能进行遍历获取。处理起来比较麻烦，接下来我们介绍一种简单方式cjson，使用它就可以将table类型的数据转换成json字符串，把json字符串展示在页面上即可。具体如何使用? 步骤一：引入cjson 1local cjson = require &quot;cjson&quot; 步骤二：调用cjson的encode方法进行类型转换 1cjson.encode(res) 步骤三:使用 12345678910111213141516171819202122232425262728location /&#123; content_by_lua_block&#123; local mysql = require &quot;resty.mysql&quot; local cjson = require &quot;cjson&quot; local db = mysql:new() local ok,err = db:connect&#123; host=&quot;192.168.200.111&quot;, port=3306, user=&quot;root&quot;, password=&quot;123456&quot;, database=&quot;nginx_db&quot; &#125; db:set_timeout(1000) --db:send_query(&quot;select * from users where id = 2&quot;) db:send_query(&quot;select * from users&quot;) local res,err,errcode,sqlstate = db:read_result() ngx.say(cjson.encode(res)) for i,v in ipairs(res) do ngx.say(v.id..&quot;,&quot;..v.username..&quot;,&quot;..v.birthday..&quot;,&quot;..v.salary) end db:close() &#125;&#125; lua-resty-mysql实现数据库的增删改 优化send_query和read_result 本方法是send_query和read_result组合的快捷方法。 语法: 1res, err, errcode, sqlstate = db:query(sql[,rows]) 有了该API，上面的代码我们就可以进行对应的优化，如下: 12345678910111213141516171819202122232425location /&#123; content_by_lua_block&#123; local mysql = require &quot;resty.mysql&quot; local db = mysql:new() local ok,err = db:connect&#123; host=&quot;192.168.200.1&quot;, port=3306, user=&quot;root&quot;, password=&quot;123456&quot;, database=&quot;nginx_db&quot;, max_packet_size=1024, compact_arrays=false &#125; db:set_timeout(1000) local res,err,errcode,sqlstate = db:query(&quot;select * from users&quot;) --local res,err,errcode,sqlstate = db:query(&quot;insert into users(id,username,birthday,salary) values(null,&#x27;zhangsan&#x27;,&#x27;2020-11-11&#x27;,32222.0)&quot;) --local res,err,errcode,sqlstate = db:query(&quot;update users set username=&#x27;lisi&#x27; where id = 6&quot;) --local res,err,errcode,sqlstate = db:query(&quot;delete from users where id = 6&quot;) db:close() &#125;&#125; 综合小案例 使用ngx_lua模块完成Redis缓存预热。 分析: （1）先得有一张表(users) （2）浏览器输入如下地址 1http://191.168.200.133?username=TOM （3）从表中查询出符合条件的记录，此时获取的结果为table类型 （4）使用cjson将table数据转换成json字符串 （5）将查询的结果数据存入Redis中 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657init_by_lua_block&#123; redis = require &quot;resty.redis&quot; mysql = require &quot;resty.mysql&quot; cjson = require &quot;cjson&quot;&#125;location /&#123; default_type &quot;text/html&quot;; content_by_lua_block&#123; --获取请求的参数username local param = ngx.req.get_uri_args()[&quot;username&quot;] --建立mysql数据库的连接 local db = mysql:new() local ok,err = db:connect&#123; host=&quot;192.168.200.111&quot;, port=3306, user=&quot;root&quot;, password=&quot;123456&quot;, database=&quot;nginx_db&quot; &#125; if not ok then ngx.say(&quot;failed connect to mysql:&quot;,err) return end --设置连接超时时间 db:set_timeout(1000) --查询数据 local sql = &quot;&quot;; if not param then sql=&quot;select * from users&quot; else sql=&quot;select * from users where username=&quot;..&quot;&#x27;&quot;..param..&quot;&#x27;&quot; end local res,err,errcode,sqlstate=db:query(sql) if not res then ngx.say(&quot;failed to query from mysql:&quot;,err) return end --连接redis local rd = redis:new() ok,err = rd:connect(&quot;192.168.200.111&quot;,6379) if not ok then ngx.say(&quot;failed to connect to redis:&quot;,err) return end rd:set_timeout(1000) --循环遍历数据 for i,v in ipairs(res) do rd:set(&quot;user_&quot;..v.username,cjson.encode(v)) end ngx.say(&quot;success&quot;) rd:close() db:close() &#125; &#125;","categories":[{"name":"Web开发","slug":"Web开发","permalink":"http://kaillliu.github.io/categories/Web%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://kaillliu.github.io/tags/Java/"},{"name":"Centos","slug":"Centos","permalink":"http://kaillliu.github.io/tags/Centos/"},{"name":"Linux","slug":"Linux","permalink":"http://kaillliu.github.io/tags/Linux/"}]},{"title":"Nginx学习（三）--- 反向代理","slug":"Nginx学习其三","date":"2022-04-21T08:53:00.000Z","updated":"2022-05-23T05:41:23.080Z","comments":true,"path":"2022/04/21/Nginx学习其三/","link":"","permalink":"http://kaillliu.github.io/2022/04/21/Nginx%E5%AD%A6%E4%B9%A0%E5%85%B6%E4%B8%89/","excerpt":"","text":"Rewrite功能配置 Rewrite是Nginx服务器提供的一个重要基本功能，是Web服务器产品中几乎必备的功能。主要的作用是用来实现URL的重写。www.jd.com 注意:Nginx服务器的Rewrite功能的实现依赖于PCRE的支持，因此在编译安装Nginx服务器之前，需要安装PCRE库。Nginx使用的是ngx_http_rewrite_module模块来解析和处理Rewrite功能的相关配置。 Rewrite的相关命令 123456set指令if指令break指令return指令rewrite指令rewrite_log指令 Rewrite的应用场景 123456域名跳转域名镜像独立域名目录自动添加&quot;/&quot;合并目录防盗链的实现 Rewrite的相关指令 set指令 该指令用来设置一个新的变量。 语法 set $variable value; 默认值 — 位置 server、location、if variable:变量的名称，该变量名称要用&quot;$&quot;作为变量的第一个字符，且不要与Nginx服务器预设的全局变量同名。 value:变量的值，可以是字符串、其他变量或者变量的组合等。 Rewrite常用全局变量 变量 说明 $args 变量中存放了请求URL中的请求参数。比如http://192.168.200.133/server?arg1=value1&amp;args2=value2中的&quot;arg1=value1&amp;arg2=value2&quot;，功能和$query_string一样 $http_user_agent 变量存储的是用户访问服务的代理信息(如果通过浏览器访问，记录的是浏览器的相关版本信息) $host 变量存储的是访问服务器的server_name值 $document_uri 变量存储的是当前访问地址的URI。比如http://192.168.200.133/server?id=10&amp;name=zhangsan中的&quot;/server&quot;，功能和$uri一样 $document_root 变量存储的是当前请求对应location的root值，如果未设置，默认指向Nginx自带html目录所在位置 $content_length 变量存储的是请求头中的Content-Length的值 $content_type 变量存储的是请求头中的Content-Type的值 $http_cookie 变量存储的是客户端的cookie信息，可以通过add_header Set-Cookie 'cookieName=cookieValue’来添加cookie数据 $limit_rate 变量中存储的是Nginx服务器对网络连接速率的限制，也就是Nginx配置中对limit_rate指令设置的值，默认是0，不限制。 $remote_addr 变量中存储的是客户端的IP地址 $remote_port 变量中存储了客户端与服务端建立连接的端口号 $remote_user 变量中存储了客户端的用户名，需要有认证模块才能获取 $scheme 变量中存储了访问协议 $server_addr 变量中存储了服务端的地址 $server_name 变量中存储了客户端请求到达的服务器的名称 $server_port 变量中存储了客户端请求到达服务器的端口号 $server_protocol 变量中存储了客户端请求协议的版本，比如&quot;HTTP/1.1&quot; $request_body_file 变量中存储了发给后端服务器的本地文件资源的名称 $request_method 变量中存储了客户端的请求方式，比如&quot;GET&quot;,&quot;POST&quot;等 $request_filename 变量中存储了当前请求的资源文件的路径名 $request_uri 变量中存储了当前请求的URI，并且携带请求参数，比如http://192.168.200.133/server?id=10&amp;name=zhangsan中的&quot;/server?id=10&amp;name=zhangsan&quot; 上述参数还可以在日志文件中使用，这个就要用到前面我们介绍的log_format指令 123log_format main &#x27;$remote_addr - $request - $status-$request_uri $http_user_agent&#x27;;access_log logs/access.log main; if指令 该指令用来支持条件判断，并根据条件判断结果选择不同的Nginx配置。 语法 if (condition){…} 默认值 — 位置 server、location condition为判定条件，可以支持以下写法： 变量名。如果变量名对应的值为空字符串或&quot;0&quot;，if都判断为false,其他条件为true。 123if ($param)&#123; &#125; 使用&quot;=“和”!=&quot;比较变量和字符串是否相等，满足条件为true，不满足为false 123if ($request_method = POST)&#123; return 405;&#125; 注意：此处和Java不太一样的地方是字符串不需要添加引号,并且等号和不等号前后到需要加空格。 使用正则表达式对变量进行匹配，匹配成功返回true，否则返回false。变量与正则表达式之间使用&quot;~“,”~*“,”!~“,”!~*&quot;来连接。 &quot;~&quot;代表匹配正则表达式过程中区分大小写， &quot;~*&quot;代表匹配正则表达式过程中不区分大小写 &quot;!~“和”!~*&quot;刚好和上面取相反值，如果匹配上返回false,匹配不上返回true 123if ($http_user_agent ~ MSIE)&#123; #$http_user_agent的值中是否包含MSIE字符串，如果包含返回true&#125; 注意：正则表达式字符串一般不需要加引号，但是如果字符串中包含&quot;}“或者是”;&quot;等字符时，就需要把引号加上。 判断请求的文件是否存在使用&quot;-f&quot;和&quot;!-f&quot;, 123456if (-f $request_filename)&#123; #判断请求的文件是否存在&#125;if (!-f $request_filename)&#123; #判断请求的文件是否不存在&#125; 判断请求的目录是否存在使用&quot;-d&quot;和&quot;!-d&quot; 判断请求的目录或者文件是否存在使用&quot;-e&quot;和&quot;!-e&quot; 判断请求的文件是否可执行使用&quot;-x&quot;和&quot;!-x&quot; break指令 该指令用于中断当前相同作用域中的其他Nginx配置。与该指令处于同一作用域的Nginx配置中，位于它前面的指令配置生效，位于后面的指令配置无效。并且break还有另外一个功能就是终止当前的匹配并把当前的URI在本location进行重定向访问处理。 语法 break; 默认值 — 位置 server、location、if 例子: 1234567891011location /testbreak&#123; default_type text/plain; set $username TOM; if ($args)&#123; Set $username JERRY; break; set $username ROSE; &#125; add_header username $username; return 200 $username;&#125; return指令 该指令用于完成对请求的处理，直接向客户端返回。在return后的所有Nginx配置都是无效的。 语法 return code [text];return code URL;return URL; 默认值 — 位置 server、location、if code:为返回给客户端的HTTP状态代理。可以返回的状态代码为0~999的任意HTTP状态代理 text:为返回给客户端的响应体内容，支持变量的使用 URL:为返回给客户端的URL地址 1234567891011121314151617location /testreturn &#123; return 200 success;&#125;location /testreturn &#123; return https://www.baidu.com; // 302重定向到百度&#125;location /testreturn &#123; return 302 https://www.baidu.com;&#125;location /testreturn &#123; return 302 www.baidu.com;//不允许这么写&#125; rewrite指令 该指令通过正则表达式的使用来改变URI。可以同时存在一个或者多个指令，按照顺序依次对URL进行匹配和处理。 语法 rewrite regex replacement [flag]; 默认值 — 位置 server、location、if regex:用来匹配URI的正则表达式 replacement:匹配成功后，用于替换URI中被截取内容的字符串。如果该字符串是以&quot;http://&quot;或者&quot;https://&quot;开头的，则不会继续向下对URI进行其他处理，而是直接返回重写后的URI给客户端。 12345678910111213location rewrite &#123; rewrite ^/rewrite/url\\w*$ https://www.baidu.com; rewrite ^/rewrite/(test)\\w*$ /$1; rewrite ^/rewrite/(demo)\\w*$ /$1;&#125;location /test&#123; default_type text/plain; return 200 test_success;&#125;location /demo&#123; default_type text/plain; return 200 demo_success;&#125; flag:用来设置rewrite对URI的处理行为，可选值有如下： last:终止继续在本location块中处理接收到的URI，并将此处重写的URI作为一个新的URI，使用各location块进行处理。该标志将重写后的URI重写在server块中执行，为重写后的URI提供了转入到其他location块的机会。 123456789101112location rewrite &#123; rewrite ^/rewrite/(test)\\w*$ /$1 last; rewrite ^/rewrite/(demo)\\w*$ /$1 last;&#125;location /test&#123; default_type text/plain; return 200 test_success;&#125;location /demo&#123; default_type text/plain; return 200 demo_success;&#125; 访问 http://192.168.200.133:8081/rewrite/testabc,能正确访问 break：将此处重写的URI作为一个新的URI,在本块中继续进行处理。该标志将重写后的地址在当前的location块中执行，不会将新的URI转向其他的location块。 12345678910111213location rewrite &#123; #/test /usr/local/nginx/html/test/index.html rewrite ^/rewrite/(test)\\w*$ /$1 break; rewrite ^/rewrite/(demo)\\w*$ /$1 break;&#125;location /test&#123; default_type text/plain; return 200 test_success;&#125;location /demo&#123; default_type text/plain; return 200 demo_success;&#125; 访问 http://192.168.200.133:8081/rewrite/demoabc,页面报404错误 redirect：将重写后的URI返回给客户端，状态码为302，指明是临时重定向URI,主要用在replacement变量不是以&quot;http://&quot;或者&quot;https://&quot;开头的情况。 123456789101112location rewrite &#123; rewrite ^/rewrite/(test)\\w*$ /$1 redirect; rewrite ^/rewrite/(demo)\\w*$ /$1 redirect;&#125;location /test&#123; default_type text/plain; return 200 test_success;&#125;location /demo&#123; default_type text/plain; return 200 demo_success;&#125; 访问http://192.168.200.133:8081/rewrite/testabc请求会被临时重定向，浏览器地址也会发生改变 permanent：将重写后的URI返回给客户端，状态码为301，指明是永久重定向URI,主要用在replacement变量不是以&quot;http://&quot;或者&quot;https://&quot;开头的情况。 123456789101112location rewrite &#123; rewrite ^/rewrite/(test)\\w*$ /$1 permanent; rewrite ^/rewrite/(demo)\\w*$ /$1 permanent;&#125;location /test&#123; default_type text/plain; return 200 test_success;&#125;location /demo&#123; default_type text/plain; return 200 demo_success;&#125; 访问http://192.168.200.133:8081/rewrite/testabc请求会被永久重定向，浏览器地址也会发生改变 rewrite_log指令 该指令配置是否开启URL重写日志的输出功能。 语法 rewrite_log on|off; 默认值 rewrite_log off; 位置 http、server、location、if 开启后，URL重写的相关日志将以notice级别输出到error_log指令配置的日志文件汇总。 12rewrite_log on;error_log logs/error.log notice; Rewrite的案例 域名跳转 》问题分析 先来看一个效果，如果我们想访问京东网站，大家都知道我们可以输入www.jd.com,但是同样的我们也可以输入www.360buy.com同样也都能访问到京东网站。这个其实是因为京东刚开始的时候域名就是www.360buy.com，后面由于各种原因把自己的域名换成了www.jd.com, 虽然说域名变量，但是对于以前只记住了www.360buy.com的用户来说，我们如何把这部分用户也迁移到我们新域名的访问上来，针对于这个问题，我们就可以使用Nginx中Rewrite的域名跳转来解决。 》环境准备 准备三个域名： 1vim /etc/hosts 123127.0.0.1 www.itcast.cn127.0.0.1 www.itheima.cn127.0.0.1 www.itheima.com 通过Nginx实现访问www.itcast.cn 12345678server &#123; listen 80; server_name www.itcast.cn; location /&#123; default_type text/html; return 200 &#x27;&lt;h1&gt;welcome to itcast&lt;/h1&gt;&#x27;; &#125;&#125; 》通过Rewrite完成将www.ithema.com和www.itheima.cn的请求跳转到www.itcast.com 12345server &#123; listen 80; server_name www.itheima.com www.itheima.cn; rewrite ^/ http://www.itcast.cn;&#125; 问题描述:如何在域名跳转的过程中携带请求的URI？ 修改配置信息 12345server &#123; listen 80; server_name www.itheima.com www.itheima.cn; rewrite ^(.*) http://www.itcast.cn$1；&#125; 域名镜像 镜像网站指定是将一个完全相同的网站分别放置到几台服务器上，并分别使用独立的URL进行访问。其中一台服务器上的网站叫主站，其他的为镜像网站。镜像网站和主站没有太大的区别，可以把镜像网站理解为主站的一个备份节点。可以通过镜像网站提供网站在不同地区的响应速度。镜像网站可以平衡网站的流量负载、可以解决网络宽带限制、封锁等。 而我们所说的域名镜像和网站镜像比较类似，上述案例中，将www.itheima.com和 www.itheima.cn都能跳转到www.itcast.cn，那么www.itcast.cn我们就可以把它起名叫主域名，其他两个就是我们所说的镜像域名，当然如果我们不想把整个网站做镜像，只想为其中某一个子目录下的资源做镜像，我们可以在location块中配置rewrite功能，比如: 123456789101112server &#123; listen 80; server_name www.itheima.cn www.itheima.com; location /user &#123; rewrite ^/user(.*)$ http://www.itcast.cn$1; &#125; location /emp&#123; default_type text/html; return 200 &#x27;&lt;h1&gt;emp_success&lt;/h1&gt;&#x27;; &#125;&#125; 独立域名 一个完整的项目包含多个模块，比如购物网站有商品搜索模块、商品详情模块和购物车模块等，那么我们如何为每一个模块设置独立的域名。 需求： 123http://search.itcast.com:81 访问商品搜索模块http://item.itcast.com:82 访问商品详情模块http://cart.itcast.com:83 访问商品购物车模块 123456789101112131415server&#123; listen 81; server_name search.itcast.com; rewrite ^(.*) http://www.itcast.cn/search$1;&#125;server&#123; listen 82; server_name item.itcast.com; rewrite ^(.*) http://www.itcast.cn/item$1;&#125;server&#123; listen 83; server_name cart.itcast.com; rewrite ^(.*) http://www.itcast.cn/cart$1;&#125; 目录自动添加&quot;/&quot; 问题描述 通过一个例子来演示下问题: 123456789server &#123; listen 8082; server_name localhost; location /heima &#123; root html; index index.html; &#125;&#125; 通过http://192.168.200.133:8082/heima和通过http://192.168.200.133:8082/heima/访问的区别？ 如果不加斜杠，Nginx服务器内部会自动做一个301的重定向，重定向的地址会有一个指令叫server_name_in_redirect on|off;来决定重定向的地址： 123456如果该指令为on 重定向的地址为: http://server_name:8082/目录名/; http://localhost:8082/heima/如果该指令为off 重定向的地址为: http://原URL中的域名:8082/目录名/; http://192.168.200.133:8082/heima/ 所以就拿刚才的地址来说，http://192.168.200.133:8082/heima如果不加斜杠，那么按照上述规则，如果指令server_name_in_redirect为on，则301重定向地址变为 http://localhost:8082/heima/,如果为off，则301重定向地址变为http://192.168.200.133:8082/heima/。后面这个是正常的，前面地址就有问题。 注意server_name_in_redirect指令在Nginx的0.8.48版本之前默认都是on，之后改成了off,所以现在我们这个版本不需要考虑这个问题，但是如果是0.8.48以前的版本并且server_name_in_redirect设置为on，我们如何通过rewrite来解决这个问题？ 解决方案 我们可以使用rewrite功能为末尾没有斜杠的URL自动添加一个斜杠 12345678910server &#123; listen 80; server_name localhost; server_name_in_redirect on; location /heima &#123; if (-d $request_filename)&#123; rewrite ^/(.*)([^/])$ http://$host/$1$2/ permanent; &#125; &#125;&#125; 合并目录 搜索引擎优化(SEO)是一种利用搜索引擎的搜索规则来提高目的网站在有关搜索引擎内排名的方式。我们在创建自己的站点时，可以通过很多中方式来有效的提供搜索引擎优化的程度。其中有一项就包含URL的目录层级一般不要超过三层，否则的话不利于搜索引擎的搜索也给客户端的输入带来了负担，但是将所有的文件放在一个目录下又会导致文件资源管理混乱并且访问文件的速度也会随着文件增多而慢下来，这两个问题是相互矛盾的，那么使用rewrite如何解决上述问题? 举例，网站中有一个资源文件的访问路径时 /server/11/22/33/44/20.html,也就是说20.html存在于第5级目录下，如果想要访问该资源文件，客户端的URL地址就要写成 http://192.168.200.133/server/11/22/33/44/20.html, 1234567server &#123; listen 8083; server_name localhost; location /server&#123; root html; &#125;&#125; 但是这个是非常不利于SEO搜索引擎优化的，同时客户端也不好记.使用rewrite我们可以进行如下配置: 1234567server &#123; listen 8083; server_name localhost; location /server&#123; rewrite ^/server-([0-9]+)-([0-9]+)-([0-9]+)-([0-9]+)\\.html$ /server/$1/$2/$3/$4/$5.html last; &#125;&#125; 这样的花，客户端只需要输入http://www.web.name/server-11-22-33-44-20.html就可以访问到20.html页面了。这里也充分利用了rewrite指令支持正则表达式的特性。 防盗链 防盗链之前我们已经介绍过了相关的知识，在rewrite中的防盗链和之前将的原理其实都是一样的，只不过通过rewrite可以将防盗链的功能进行完善下，当出现防盗链的情况，我们可以使用rewrite将请求转发到自定义的一张图片和页面，给用户比较好的提示信息。下面我们就通过根据文件类型实现防盗链的一个配置实例: 123456789location /images &#123; root html; valid_referers none blocked www.baidu.com; if ($invalid_referer)&#123; #return 403; rewrite ^/ /images/forbidden.png break; &#125;&#125; Nginx反向代理 Nginx反向代理概述 关于正向代理和反向代理，我们在前面的章节已经通过一张图给大家详细的介绍过了，简而言之就是正向代理代理的对象是客户端，反向代理代理的是服务端，这是两者之间最大的区别。 Nginx即可以实现正向代理，也可以实现反向代理。 我们先来通过一个小案例演示下Nginx正向代理的简单应用。 先提需求： (1)服务端的设置： 123456789101112http &#123; log_format main &#x27;client send request=&gt;clientIp=$remote_addr serverIp=&gt;$host&#x27;; server&#123; listen 80; server_name localhost; access_log logs/access.log main; location &#123; root html; index index.html index.htm; &#125; &#125;&#125; (2)使用客户端访问服务端，打开日志查看结果 (3)代理服务器设置： 123456789server &#123; listen 82; resolver 8.8.8.8; location /&#123; proxy_pass http://$host$request_uri; &#125; &#125; (4)查看代理服务器的IP(192.168.200.146)和Nginx配置监听的端口(82) (5)在客户端配置代理服务器 (6)设置完成后，再次通过浏览器访问服务端 通过对比，上下两次的日志记录，会发现虽然我们是客户端访问服务端，但是如何使用了代理，那么服务端能看到的只是代理发送过去的请求，这样的化，就使用Nginx实现了正向代理的设置。 但是Nginx正向代理，在实际的应用中不是特别多，所以我们简单了解下，接下来我们继续学习Nginx的反向代理，这是Nginx比较重要的一个功能。 Nginx反向代理的配置语法 Nginx反向代理模块的指令是由ngx_http_proxy_module模块进行解析，该模块在安装Nginx的时候已经自己加装到Nginx中了，接下来我们把反向代理中的常用指令一一介绍下： 123proxy_passproxy_set_headerproxy_redirect proxy_pass 该指令用来设置被代理服务器地址，可以是主机名称、IP地址加端口号形式。 语法 proxy_pass URL; 默认值 — 位置 location URL:为要设置的被代理服务器地址，包含传输协议(http,https://)、主机名称或IP地址加端口号、URI等要素。 举例： 123456proxy_pass http://www.baidu.com;location /server&#123;&#125;proxy_pass http://192.168.200.146; http://192.168.200.146/server/index.htmlproxy_pass http://192.168.200.146/; http://192.168.200.146/index.html 大家在编写proxy_pass的时候，后面的值要不要加&quot;/&quot;? 接下来通过例子来说明刚才我们提到的问题： 1234567891011121314151617181920server &#123; listen 80; server_name localhost; location /&#123; #proxy_pass http://192.168.200.146; proxy_pass http://192.168.200.146/; &#125;&#125;当客户端访问 http://localhost/index.html,效果是一样的server&#123; listen 80; server_name localhost; location /server&#123; #proxy_pass http://192.168.200.146; proxy_pass http://192.168.200.146/; &#125;&#125;当客户端访问 http://localhost/server/index.html这个时候，第一个proxy_pass就变成了http://localhost/server/index.html第二个proxy_pass就变成了http://localhost/index.html效果就不一样了。 proxy_set_header 该指令可以更改Nginx服务器接收到的客户端请求的请求头信息，然后将新的请求头发送给代理的服务器 语法 proxy_set_header field value; 默认值 proxy_set_header Host $proxy_host;proxy_set_header Connection close; 位置 http、server、location 需要注意的是，如果想要看到结果，必须在被代理的服务器上来获取添加的头信息。 被代理服务器： [192.168.200.146] 123456server &#123; listen 8080; server_name localhost; default_type text/plain; return 200 $http_username;&#125; 代理服务器: [192.168.200.133] 123456789server &#123; listen 8080; server_name localhost; location /server &#123; proxy_pass http://192.168.200.146:8080/; proxy_set_header username TOM; &#125; &#125; 访问测试 proxy_redirect 该指令是用来重置头信息中的&quot;Location&quot;和&quot;Refresh&quot;的值。 语法 proxy_redirect redirect replacement;proxy_redirect default;proxy_redirect off; 默认值 proxy_redirect default; 位置 http、server、location 》为什么要用该指令? 服务端[192.168.200.146] 12345678server &#123; listen 8081; server_name localhost; if (!-f $request_filename)&#123; return 302 http://192.168.200.146; &#125;&#125; 代理服务端[192.168.200.133] 12345678server &#123; listen 8081; server_name localhost; location / &#123; proxy_pass http://192.168.200.146:8081/; proxy_redirect http://192.168.200.146 http://192.168.200.133; &#125;&#125; 》该指令的几组选项 proxy_redirect redirect replacement; 12redirect:目标,Location的值replacement:要替换的值 proxy_redirect default; 123default;将location块的uri变量作为replacement,将proxy_pass变量作为redirect进行替换 proxy_redirect off; 1关闭proxy_redirect的功能 Nginx反向代理实战 服务器1,2,3存在两种情况 12第一种情况: 三台服务器的内容不一样。第二种情况: 三台服务器的内容是一样。 如果服务器1、服务器2和服务器3的内容不一样，那我们可以根据用户请求来分发到不同的服务器。 12345678910111213141516171819202122232425262728293031323334353637代理服务器server &#123; listen 8082; server_name localhost; location /server1 &#123; proxy_pass http://192.168.200.146:9001/; &#125; location /server2 &#123; proxy_pass http://192.168.200.146:9002/; &#125; location /server3 &#123; proxy_pass http://192.168.200.146:9003/; &#125;&#125;服务端server1server &#123; listen 9001; server_name localhost; default_type text/html; return 200 &#x27;&lt;h1&gt;192.168.200.146:9001&lt;/h1&gt;&#x27;&#125;server2server &#123; listen 9002; server_name localhost; default_type text/html; return 200 &#x27;&lt;h1&gt;192.168.200.146:9002&lt;/h1&gt;&#x27;&#125;server3server &#123; listen 9003; server_name localhost; default_type text/html; return 200 &#x27;&lt;h1&gt;192.168.200.146:9003&lt;/h1&gt;&#x27;&#125; 如果服务器1、服务器2和服务器3的内容是一样的，该如何处理? Nginx的安全控制 关于web服务器的安全是比较大的一个话题，里面所涉及的内容很多，Nginx反向代理是如何来提升web服务器的安全呢？ 1安全隔离 什么是安全隔离? 通过代理分开了客户端到应用程序服务器端的连接，实现了安全措施。在反向代理之前设置防火墙，仅留一个入口供代理服务器访问。 如何使用SSL对流量进行加密 翻译成大家能熟悉的说法就是将我们常用的http请求转变成https请求，那么这两个之间的区别简单的来说两个都是HTTP协议，只不过https是身披SSL外壳的http. HTTPS是一种通过计算机网络进行安全通信的传输协议。它经由HTTP进行通信，利用SSL/TLS建立全通信，加密数据包，确保数据的安全性。 SSL(Secure Sockets Layer)安全套接层 TLS(Transport Layer Security)传输层安全 上述这两个是为网络通信提供安全及数据完整性的一种安全协议，TLS和SSL在传输层和应用层对网络连接进行加密。 总结来说为什么要使用https: 1http协议是明文传输数据，存在安全问题，而https是加密传输，相当于http+ssl，并且可以防止流量劫持。 Nginx要想使用SSL，需要满足一个条件即需要添加一个模块--with-http_ssl_module,而该模块在编译的过程中又需要OpenSSL的支持，这个我们之前已经准备好了。 nginx添加SSL的支持 （1）完成 --with-http_ssl_module模块的增量添加 123456》将原有/usr/local/nginx/sbin/nginx进行备份》拷贝nginx之前的配置信息》在nginx的安装源码进行配置指定对应模块 ./configure --with-http_ssl_module》通过make模板进行编译》将objs下面的nginx移动到/usr/local/nginx/sbin下》在源码目录下执行 make upgrade进行升级，这个可以实现不停机添加新模块的功能 Nginx的SSL相关指令 因为刚才我们介绍过该模块的指令都是通过ngx_http_ssl_module模块来解析的。 》ssl:该指令用来在指定的服务器开启HTTPS,可以使用 listen 443 ssl,后面这种方式更通用些。 语法 ssl on | off; 默认值 ssl off; 位置 http、server 123server&#123; listen 443 ssl;&#125; 》ssl_certificate:为当前这个虚拟主机指定一个带有PEM格式证书的证书。 语法 ssl_certificate file; 默认值 — 位置 http、server 》ssl_certificate_key:该指令用来指定PEM secret key文件的路径 语法 ssl_ceritificate_key file; 默认值 — 位置 http、server 》ssl_session_cache:该指令用来配置用于SSL会话的缓存 语法 ssl_sesion_cache off|none|[builtin[:size]] [shared:name:size] 默认值 ssl_session_cache none; 位置 http、server off:禁用会话缓存，客户端不得重复使用会话 none:禁止使用会话缓存，客户端可以重复使用，但是并没有在缓存中存储会话参数 builtin:内置OpenSSL缓存，仅在一个工作进程中使用。 shared:所有工作进程之间共享缓存，缓存的相关信息用name和size来指定 》ssl_session_timeout：开启SSL会话功能后，设置客户端能够反复使用储存在缓存中的会话参数时间。 语法 ssl_session_timeout time; 默认值 ssl_session_timeout 5m; 位置 http、server 》ssl_ciphers:指出允许的密码，密码指定为OpenSSL支持的格式 语法 ssl_ciphers ciphers; 默认值 ssl_ciphers HIGH:!aNULL:!MD5; 位置 http、server 可以使用openssl ciphers查看openssl支持的格式。 》ssl_prefer_server_ciphers：该指令指定是否服务器密码优先客户端密码 语法 ssl_perfer_server_ciphers on|off; 默认值 ssl_perfer_server_ciphers off; 位置 http、server 生成证书 方式一：使用阿里云/腾讯云等第三方服务进行购买。 方式二:使用openssl生成证书 先要确认当前系统是否有安装openssl 1openssl version 安装下面的命令进行生成 1234567mkdir /root/certcd /root/certopenssl genrsa -des3 -out server.key 1024openssl req -new -key server.key -out server.csrcp server.key server.key.orgopenssl rsa -in server.key.org -out server.keyopenssl x509 -req -days 365 -in server.csr -signkey server.key -out server.crt 开启SSL实例 123456789101112131415161718server &#123; listen 443 ssl; server_name localhost; ssl_certificate server.cert; ssl_certificate_key server.key; ssl_session_cache shared:SSL:1m; ssl_session_timeout 5m; ssl_ciphers HIGH:!aNULL:!MD5; ssl_prefer_server_ciphers on; location / &#123; root html; index index.html index.htm; &#125;&#125; （4）验证 反向代理系统调优 反向代理值Buffer和Cache Buffer翻译过来是&quot;缓冲&quot;，Cache翻译过来是&quot;缓存&quot;。 总结下： 12345相同点:两种方式都是用来提供IO吞吐效率，都是用来提升Nginx代理的性能。不同点:缓冲主要用来解决不同设备之间数据传递速度不一致导致的性能低的问题，缓冲中的数据一旦此次操作完成后，就可以删除。缓存主要是备份，将被代理服务器的数据缓存一份到代理服务器，这样的话，客户端再次获取相同数据的时候，就只需要从代理服务器上获取，效率较高，缓存中的数据可以重复使用，只有满足特定条件才会删除. （1）Proxy Buffer相关指令 》proxy_buffering :该指令用来开启或者关闭代理服务器的缓冲区； 语法 proxy_buffering on|off; 默认值 proxy_buffering on; 位置 http、server、location 》proxy_buffers:该指令用来指定单个连接从代理服务器读取响应的缓存区的个数和大小。 语法 proxy_buffers number size; 默认值 proxy_buffers 8 4k | 8K;(与系统平台有关) 位置 http、server、location number:缓冲区的个数 size:每个缓冲区的大小，缓冲区的总大小就是number*size 》proxy_buffer_size:该指令用来设置从被代理服务器获取的第一部分响应数据的大小。保持与proxy_buffers中的size一致即可，当然也可以更小。 语法 proxy_buffer_size size; 默认值 proxy_buffer_size 4k | 8k;(与系统平台有关) 位置 http、server、location 》proxy_busy_buffers_size：该指令用来限制同时处于BUSY状态的缓冲总大小。 语法 proxy_busy_buffers_size size; 默认值 proxy_busy_buffers_size 8k|16K; 位置 http、server、location 》proxy_temp_path:当缓冲区存满后，仍未被Nginx服务器完全接受，响应数据就会被临时存放在磁盘文件上，该指令设置文件路径 语法 proxy_temp_path path; 默认值 proxy_temp_path proxy_temp; 位置 http、server、location 注意path最多设置三层。 》proxy_temp_file_write_size：该指令用来设置磁盘上缓冲文件的大小。 语法 proxy_temp_file_write_size size; 默认值 proxy_temp_file_write_size 8K|16K; 位置 http、server、location 通用网站的配置 1234proxy_buffering on;proxy_buffer_size 4 32k;proxy_busy_buffers_size 64k;proxy_temp_file_write_size 64k; 根据项目的具体内容进行相应的调节。","categories":[{"name":"Web开发","slug":"Web开发","permalink":"http://kaillliu.github.io/categories/Web%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://kaillliu.github.io/tags/Java/"},{"name":"Centos","slug":"Centos","permalink":"http://kaillliu.github.io/tags/Centos/"},{"name":"Linux","slug":"Linux","permalink":"http://kaillliu.github.io/tags/Linux/"}]},{"title":"Nginx学习（四）--- 负载均衡","slug":"Nginx学习其四","date":"2022-04-21T08:53:00.000Z","updated":"2022-05-23T05:41:23.080Z","comments":true,"path":"2022/04/21/Nginx学习其四/","link":"","permalink":"http://kaillliu.github.io/2022/04/21/Nginx%E5%AD%A6%E4%B9%A0%E5%85%B6%E5%9B%9B/","excerpt":"","text":"Nginx负载均衡 负载均衡概述 早期的网站流量和业务功能都比较简单，单台服务器足以满足基本的需求，但是随着互联网的发展，业务流量越来越大并且业务逻辑也跟着越来越复杂，单台服务器的性能及单点故障问题就凸显出来了，因此需要多台服务器进行性能的水平扩展及避免单点故障出现。那么如何将不同用户的请求流量分发到不同的服务器上呢？ 负载均衡的原理及处理流程 系统的扩展可以分为纵向扩展和横向扩展。 纵向扩展是从单机的角度出发，通过增加系统的硬件处理能力来提升服务器的处理能力 横向扩展是通过添加机器来满足大型网站服务的处理能力。 这里面涉及到两个重要的角色分别是&quot;应用集群&quot;和&quot;负载均衡器&quot;。 应用集群：将同一应用部署到多台机器上，组成处理集群，接收负载均衡设备分发的请求，进行处理并返回响应的数据。 负载均衡器:将用户访问的请求根据对应的负载均衡算法，分发到集群中的一台服务器进行处理。 负载均衡的作用 1、解决服务器的高并发压力，提高应用程序的处理性能。 2、提供故障转移，实现高可用。 3、通过添加或减少服务器数量，增强网站的可扩展性。 4、在负载均衡器上进行过滤，可以提高系统的安全性。 负载均衡常用的处理方式 方式一:用户手动选择 这种方式比较原始，只要实现的方式就是在网站主页上面提供不同线路、不同服务器链接方式，让用户来选择自己访问的具体服务器，来实现负载均衡。 方式二:DNS轮询方式 DNS 1域名系统（服务）协议（DNS）是一种分布式网络目录服务，主要用于域名与 IP 地址的相互转换。 大多域名注册商都支持对同一个主机名添加多条A记录，这就是DNS轮询，DNS服务器将解析请求按照A记录的顺序，随机分配到不同的IP上，这样就能完成简单的负载均衡。DNS轮询的成本非常低，在一些不重要的服务器，被经常使用。 如下是我们为某一个域名添加的IP地址，用2台服务器来做负载均衡。 验证: 1ping www.nginx521.cn 清空本地的dns缓存 1ipconfig/flushdns 我们发现使用DNS来实现轮询，不需要投入过多的成本，虽然DNS轮询成本低廉，但是DNS负载均衡存在明显的缺点。 1.可靠性低 假设一个域名DNS轮询多台服务器，如果其中的一台服务器发生故障，那么所有的访问该服务器的请求将不会有所回应，即使你将该服务器的IP从DNS中去掉，但是由于各大宽带接入商将众多的DNS存放在缓存中，以节省访问时间，导致DNS不会实时更新。所以DNS轮流上一定程度上解决了负载均衡问题，但是却存在可靠性不高的缺点。 2.负载均衡不均衡 DNS负载均衡采用的是简单的轮询负载算法，不能区分服务器的差异，不能反映服务器的当前运行状态，不能做到为性能好的服务器多分配请求，另外本地计算机也会缓存已经解析的域名到IP地址的映射，这也会导致使用该DNS服务器的用户在一定时间内访问的是同一台Web服务器，从而引发Web服务器减的负载不均衡。 负载不均衡则会导致某几台服务器负荷很低，而另外几台服务器负荷确很高，处理请求的速度慢，配置高的服务器分配到的请求少，而配置低的服务器分配到的请求多。 方式三:四/七层负载均衡 介绍四/七层负载均衡之前，我们先了解一个概念，OSI(open system interconnection),叫开放式系统互联模型，这个是由国际标准化组织ISO指定的一个不基于具体机型、操作系统或公司的网络体系结构。该模型将网络通信的工作分为七层。 应用层：为应用程序提供网络服务。 表示层：对数据进行格式化、编码、加密、压缩等操作。 会话层：建立、维护、管理会话连接。 传输层：建立、维护、管理端到端的连接，常见的有TCP/UDP。 网络层：IP寻址和路由选择 数据链路层：控制网络层与物理层之间的通信。 物理层：比特流传输。 所谓四层负载均衡指的是OSI七层模型中的传输层，主要是基于IP+PORT的负载均衡 123实现四层负载均衡的方式：硬件：F5 BIG-IP、Radware等软件：LVS、Nginx、Hayproxy等 所谓的七层负载均衡指的是在应用层，主要是基于虚拟的URL或主机IP的负载均衡 12实现七层负载均衡的方式：软件：Nginx、Hayproxy等 四层和七层负载均衡的区别 12四层负载均衡数据包是在底层就进行了分发，而七层负载均衡数据包则在最顶端进行分发，所以四层负载均衡的效率比七层负载均衡的要高。四层负载均衡不识别域名，而七层负载均衡识别域名。 处理四层和七层负载以为其实还有二层、三层负载均衡，二层是在数据链路层基于mac地址来实现负载均衡，三层是在网络层一般采用虚拟IP地址的方式实现负载均衡。 实际环境采用的模式 1四层负载(LVS)+七层负载(Nginx) Nginx七层负载均衡 Nginx要实现七层负载均衡需要用到proxy_pass代理模块配置。Nginx默认安装支持这个模块，我们不需要再做任何处理。Nginx的负载均衡是在Nginx的反向代理基础上把用户的请求根据指定的算法分发到一组【upstream虚拟服务池】。 Nginx七层负载均衡的指令 upstream指令 该指令是用来定义一组服务器，它们可以是监听不同端口的服务器，并且也可以是同时监听TCP和Unix socket的服务器。服务器可以指定不同的权重，默认为1。 语法 upstream name {…} 默认值 — 位置 http server指令 该指令用来指定后端服务器的名称和一些参数，可以使用域名、IP、端口或者unix socket 语法 server name [paramerters] 默认值 — 位置 upstream Nginx七层负载均衡的实现流程 服务端设置 123456789101112131415161718192021222324server &#123; listen 9001; server_name localhost; default_type text/html; location /&#123; return 200 &#x27;&lt;h1&gt;192.168.200.146:9001&lt;/h1&gt;&#x27;; &#125;&#125;server &#123; listen 9002; server_name localhost; default_type text/html; location /&#123; return 200 &#x27;&lt;h1&gt;192.168.200.146:9002&lt;/h1&gt;&#x27;; &#125;&#125;server &#123; listen 9003; server_name localhost; default_type text/html; location /&#123; return 200 &#x27;&lt;h1&gt;192.168.200.146:9003&lt;/h1&gt;&#x27;; &#125;&#125; 负载均衡器设置 123456789101112upstream backend&#123; server 192.168.200.146:9091; server 192.168.200.146:9092; server 192.168.200.146:9093;&#125;server &#123; listen 8083; server_name localhost; location /&#123; proxy_pass http://backend; &#125;&#125; 负载均衡状态 代理服务器在负责均衡调度中的状态有以下几个： 状态 概述 down 当前的server暂时不参与负载均衡 backup 预留的备份服务器 max_fails 允许请求失败的次数 fail_timeout 经过max_fails失败后, 服务暂停时间 max_conns 限制最大的接收连接数 down down:将该服务器标记为永久不可用，那么该代理服务器将不参与负载均衡。 123456789101112upstream backend&#123; server 192.168.200.146:9001 down; server 192.168.200.146:9002 server 192.168.200.146:9003;&#125;server &#123; listen 8083; server_name localhost; location /&#123; proxy_pass http://backend; &#125;&#125; 该状态一般会对需要停机维护的服务器进行设置。 backup backup:将该服务器标记为备份服务器，当主服务器不可用时，将用来传递请求。 123456789101112upstream backend&#123; server 192.168.200.146:9001 down; server 192.168.200.146:9002 backup; server 192.168.200.146:9003;&#125;server &#123; listen 8083; server_name localhost; location /&#123; proxy_pass http://backend; &#125;&#125; 此时需要将9094端口的访问禁止掉来模拟下唯一能对外提供访问的服务宕机以后，backup的备份服务器就要开始对外提供服务，此时为了测试验证，我们需要使用防火墙来进行拦截。 介绍一个工具firewall-cmd,该工具是Linux提供的专门用来操作firewall的。 查询防火墙中指定的端口是否开放 1firewall-cmd --query-port=9001/tcp 如何开放一个指定的端口 1firewall-cmd --permanent --add-port=9002/tcp 批量添加开发端口 1firewall-cmd --permanent --add-port=9001-9003/tcp 如何移除一个指定的端口 1firewall-cmd --permanent --remove-port=9003/tcp 重新加载 1firewall-cmd --reload 其中 ​ --permanent表示设置为持久 ​ --add-port表示添加指定端口 ​ --remove-port表示移除指定端口 max_conns max_conns=number:用来设置代理服务器同时活动链接的最大数量，默认为0，表示不限制，使用该配置可以根据后端服务器处理请求的并发量来进行设置，防止后端服务器被压垮。 max_fails和fail_timeout max_fails=number:设置允许请求代理服务器失败的次数，默认为1。 fail_timeout=time:设置经过max_fails失败后，服务暂停的时间，默认是10秒。 123456789101112upstream backend&#123; server 192.168.200.133:9001 down; server 192.168.200.133:9002 backup; server 192.168.200.133:9003 max_fails=3 fail_timeout=15;&#125;server &#123; listen 8083; server_name localhost; location /&#123; proxy_pass http://backend; &#125;&#125; 负载均衡策略 介绍完Nginx负载均衡的相关指令后，我们已经能实现将用户的请求分发到不同的服务器上，那么除了采用默认的分配方式以外，我们还能采用什么样的负载算法? Nginx的upstream支持如下六种方式的分配算法，分别是: 算法名称 说明 轮询 默认方式 weight 权重方式 ip_hash 依据ip分配方式 least_conn 依据最少连接方式 url_hash 依据URL分配方式 fair 依据响应时间方式 轮询 是upstream模块负载均衡默认的策略。每个请求会按时间顺序逐个分配到不同的后端服务器。轮询不需要额外的配置。 123456789101112upstream backend&#123; server 192.168.200.146:9001 weight=1; server 192.168.200.146:9002; server 192.168.200.146:9003;&#125;server &#123; listen 8083; server_name localhost; location /&#123; proxy_pass http://backend; &#125;&#125; weight加权[加权轮询] weight=number:用来设置服务器的权重，默认为1，权重数据越大，被分配到请求的几率越大；该权重值，主要是针对实际工作环境中不同的后端服务器硬件配置进行调整的，所有此策略比较适合服务器的硬件配置差别比较大的情况。 123456789101112upstream backend&#123; server 192.168.200.146:9001 weight=10; server 192.168.200.146:9002 weight=5; server 192.168.200.146:9003 weight=3;&#125;server &#123; listen 8083; server_name localhost; location /&#123; proxy_pass http://backend; &#125;&#125; ip_hash 当对后端的多台动态应用服务器做负载均衡时，ip_hash指令能够将某个客户端IP的请求通过哈希算法定位到同一台后端服务器上。这样，当来自某一个IP的用户在后端Web服务器A上登录后，在访问该站点的其他URL，能保证其访问的还是后端web服务器A。 语法 ip_hash; 默认值 — 位置 upstream 12345678910111213upstream backend&#123; ip_hash; server 192.168.200.146:9001; server 192.168.200.146:9002; server 192.168.200.146:9003;&#125;server &#123; listen 8083; server_name localhost; location /&#123; proxy_pass http://backend; &#125;&#125; 需要额外多说一点的是使用ip_hash指令无法保证后端服务器的负载均衡，可能导致有些后端服务器接收到的请求多，有些后端服务器接收的请求少，而且设置后端服务器权重等方法将不起作用。 least_conn 最少连接，把请求转发给连接数较少的后端服务器。轮询算法是把请求平均的转发给各个后端，使它们的负载大致相同；但是，有些请求占用的时间很长，会导致其所在的后端负载较高。这种情况下，least_conn这种方式就可以达到更好的负载均衡效果。 12345678910111213upstream backend&#123; least_conn; server 192.168.200.146:9001; server 192.168.200.146:9002; server 192.168.200.146:9003;&#125;server &#123; listen 8083; server_name localhost; location /&#123; proxy_pass http://backend; &#125;&#125; 此负载均衡策略适合请求处理时间长短不一造成服务器过载的情况。 url_hash 按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，要配合缓存命中来使用。同一个资源多次请求，可能会到达不同的服务器上，导致不必要的多次下载，缓存命中率不高，以及一些资源时间的浪费。而使用url_hash，可以使得同一个url（也就是同一个资源请求）会到达同一台服务器，一旦缓存住了资源，再此收到请求，就可以从缓存中读取。 12345678910111213upstream backend&#123; hash &amp;request_uri; server 192.168.200.146:9001; server 192.168.200.146:9002; server 192.168.200.146:9003;&#125;server &#123; listen 8083; server_name localhost; location /&#123; proxy_pass http://backend; &#125;&#125; 访问如下地址： 123http://192.168.200.133:8083/ahttp://192.168.200.133:8083/bhttp://192.168.200.133:8083/c fair fair采用的不是内建负载均衡使用的轮换的均衡算法，而是可以根据页面大小、加载时间长短智能的进行负载均衡。那么如何使用第三方模块的fair负载均衡策略。 12345678910111213upstream backend&#123; fair; server 192.168.200.146:9001; server 192.168.200.146:9002; server 192.168.200.146:9003;&#125;server &#123; listen 8083; server_name localhost; location /&#123; proxy_pass http://backend; &#125;&#125; 但是如何直接使用会报错，因为fair属于第三方模块实现的负载均衡。需要添加nginx-upstream-fair,如何添加对应的模块: 下载nginx-upstream-fair模块 12下载地址为: https://github.com/gnosek/nginx-upstream-fair 将下载的文件上传到服务器并进行解压缩 1unzip nginx-upstream-fair-master.zip 重命名资源 1mv nginx-upstream-fair-master fair 使用./configure命令将资源添加到Nginx模块中 1./configure --add-module=/root/fair 编译 1make 编译可能会出现如下错误，ngx_http_upstream_srv_conf_t结构中缺少default_port 解决方案: 在Nginx的源码中 src/http/ngx_http_upstream.h,找到ngx_http_upstream_srv_conf_s，在模块中添加添加default_port属性 1in_port_t default_port 然后再进行make. 更新Nginx ​ 6.1 将sbin目录下的nginx进行备份 1mv /usr/local/nginx/sbin/nginx /usr/local/nginx/sbin/nginxold ​ 6.2 将安装目录下的objs中的nginx拷贝到sbin目录 12cd objscp nginx /usr/local/nginx/sbin ​ 6.3 更新Nginx 12cd ../make upgrade 编译测试使用Nginx 上面介绍了Nginx常用的负载均衡的策略，有人说是5种，是把轮询和加权轮询归为一种，也有人说是6种。那么在咱们以后的开发中到底使用哪种，这个需要根据实际项目的应用场景来决定的。 负载均衡案例 案例一：对所有请求实现一般轮询规则的负载均衡 123456789101112upstream backend&#123; server 192.168.200.146:9001; server 192.168.200.146:9002; server 192.168.200.146:9003;&#125;server &#123; listen 8083; server_name localhost; location /&#123; proxy_pass http://backend; &#125;&#125; 案例二：对所有请求实现加权轮询规则的负载均衡 123456789101112upstream backend&#123; server 192.168.200.146:9001 weight=7; server 192.168.200.146:9002 weight=5; server 192.168.200.146:9003 weight=3;&#125;server &#123; listen 8083; server_name localhost; location /&#123; proxy_pass http://backend; &#125;&#125; 案例三：对特定资源实现负载均衡 123456789101112131415161718upstream videobackend&#123; server 192.168.200.146:9001; server 192.168.200.146:9002;&#125;upstream filebackend&#123; server 192.168.200.146:9003; server 192.168.200.146:9004;&#125;server &#123; listen 8084; server_name localhost; location /video/ &#123; proxy_pass http://videobackend; &#125; location /file/ &#123; proxy_pass http://filebackend; &#125;&#125; 案例四：对不同域名实现负载均衡 12345678910111213141516171819202122upstream itcastbackend&#123; server 192.168.200.146:9001; server 192.168.200.146:9002;&#125;upstream itheimabackend&#123; server 192.168.200.146:9003; server 192.168.200.146:9004;&#125;server &#123; listen 8085; server_name www.itcast.cn; location / &#123; proxy_pass http://itcastbackend; &#125;&#125;server &#123; listen 8086; server_name www.itheima.cn; location / &#123; proxy_pass http://itheimabackend; &#125;&#125; 案例五：实现带有URL重写的负载均衡 123456789101112131415upstream backend&#123; server 192.168.200.146:9001; server 192.168.200.146:9002; server 192.168.200.146:9003;&#125;server &#123; listen 80; server_name localhost; location /file/ &#123; rewrite ^(/file/.*) /server/$1 last; &#125; location / &#123; proxy_pass http://backend; &#125;&#125; Nginx四层负载均衡 Nginx在1.9之后，增加了一个stream模块，用来实现四层协议的转发、代理、负载均衡等。stream模块的用法跟http的用法类似，允许我们配置一组TCP或者UDP等协议的监听，然后通过proxy_pass来转发我们的请求，通过upstream添加多个后端服务，实现负载均衡。 四层协议负载均衡的实现，一般都会用到LVS、HAProxy、F5等，要么很贵要么配置很麻烦，而Nginx的配置相对来说更简单，更能快速完成工作。 添加stream模块的支持 Nginx默认是没有编译这个模块的，需要使用到stream模块，那么需要在编译的时候加上--with-stream。 完成添加--with-stream的实现步骤: 123456》将原有/usr/local/nginx/sbin/nginx进行备份》拷贝nginx之前的配置信息》在nginx的安装源码进行配置指定对应模块 ./configure --with-stream》通过make模板进行编译》将objs下面的nginx移动到/usr/local/nginx/sbin下》在源码目录下执行 make upgrade进行升级，这个可以实现不停机添加新模块的功能 Nginx四层负载均衡的指令 stream指令 该指令提供在其中指定流服务器指令的配置文件上下文。和http指令同级。 语法 stream { … } 默认值 — 位置 main upstream指令 该指令和http的upstream指令是类似的。 四层负载均衡的案例 需求分析 实现步骤 (1)准备Redis服务器,在一条服务器上准备三个Redis，端口分别是6379,6378 1.上传redis的安装包，redis-4.0.14.tar.gz 2.将安装包进行解压缩 1tar -zxf redis-4.0.14.tar.gz 3.进入redis的安装包 1cd redis-4.0.14 4.使用make和install进行编译和安装 1make PREFIX=/usr/local/redis/redis01 install 5.拷贝redis配置文件redis.conf到/usr/local/redis/redis01/bin目录中 1cp redis.conf /usr/local/redis/redis01/bin 6.修改redis.conf配置文件 12port 6379 #redis的端口daemonize yes #后台启动redis 7.将redis01复制一份为redis02 12cd /usr/local/rediscp -r redis01 redis02 8.将redis02文件文件夹中的redis.conf进行修改 12port 6378 #redis的端口daemonize yes #后台启动redis 9.分别启动，即可获取两个Redis.并查看 1ps -ef | grep redis 使用Nginx将请求分发到不同的Redis服务器上。 (2)准备Tomcat服务器. 1.上传tomcat的安装包，apache-tomcat-8.5.56.tar.gz 2.将安装包进行解压缩 1tar -zxf apache-tomcat-8.5.56.tar.gz 3.进入tomcat的bin目录 12cd apache-tomcat-8.5.56/bin./startup nginx.conf配置 1234567891011121314151617stream &#123; upstream redisbackend &#123; server 192.168.200.146:6379; server 192.168.200.146:6378; &#125; upstream tomcatbackend &#123; server 192.168.200.146:8080; &#125; server &#123; listen 81; proxy_pass redisbackend; &#125; server &#123; listen 82; proxy_pass tomcatbackend; &#125;&#125; 访问测试。 Nginx缓存集成 缓存的概念 缓存就是数据交换的缓冲区(称作:Cache),当用户要获取数据的时候，会先从缓存中去查询获取数据，如果缓存中有就会直接返回给用户，如果缓存中没有，则会发请求从服务器重新查询数据，将数据返回给用户的同时将数据放入缓存，下次用户就会直接从缓存中获取数据。 缓存其实在很多场景中都有用到，比如： 场景 作用 操作系统磁盘缓存 减少磁盘机械操作 数据库缓存 减少文件系统的IO操作 应用程序缓存 减少对数据库的查询 Web服务器缓存 减少对应用服务器请求次数 浏览器缓存 减少与后台的交互次数 缓存的优点 ​ 1.减少数据传输，节省网络流量，加快响应速度，提升用户体验； ​ 2.减轻服务器压力； ​ 3.提供服务端的高可用性； 缓存的缺点 ​ 1.数据的不一致 ​ 2.增加成本 本次课程注解讲解的是Nginx,Nginx作为web服务器，Nginx作为Web缓存服务器，它介于客户端和应用服务器之间，当用户通过浏览器访问一个URL时，web缓存服务器会去应用服务器获取要展示给用户的内容，将内容缓存到自己的服务器上，当下一次请求到来时，如果访问的是同一个URL，web缓存服务器就会直接将之前缓存的内容返回给客户端，而不是向应用服务器再次发送请求。web缓存降低了应用服务器、数据库的负载，减少了网络延迟，提高了用户访问的响应速度，增强了用户的体验。 Nginx的web缓存服务 Nginx是从0.7.48版开始提供缓存功能。Nginx是基于Proxy Store来实现的，其原理是把URL及相关组合当做Key,在使用MD5算法对Key进行哈希，得到硬盘上对应的哈希目录路径，从而将缓存内容保存在该目录中。它可以支持任意URL连接，同时也支持404/301/302这样的非200状态码。Nginx即可以支持对指定URL或者状态码设置过期时间，也可以使用purge命令来手动清除指定URL的缓存。 Nginx缓存设置的相关指令 Nginx的web缓存服务主要是使用ngx_http_proxy_module模块相关指令集来完成，接下来我们把常用的指令来进行介绍下。 proxy_cache_path 该指定用于设置缓存文件的存放路径 语法 proxy_cache_path path [levels=number] keys_zone=zone_name:zone_size [inactive=time][max_size=size]; 默认值 — 位置 http path:缓存路径地址,如： 1/usr/local/proxy_cache levels: 指定该缓存空间对应的目录，最多可以设置3层，每层取值为1|2如 : 123456levels=1:2 缓存空间有两层目录，第一次是1个字母，第二次是2个字母举例说明:itheima[key]通过MD5加密以后的值为 43c8233266edce38c2c9af0694e2107dlevels=1:2 最终的存储路径为/usr/local/proxy_cache/d/07levels=2:1:2 最终的存储路径为/usr/local/proxy_cache/7d/0/21levels=2:2:2 最终的存储路径为??/usr/local/proxy_cache/7d/10/e2 keys_zone:用来为这个缓存区设置名称和指定大小，如： 1keys_zone=itcast:200m 缓存区的名称是itcast,大小为200M,1M大概能存储8000个keys inactive:指定缓存的数据多次时间未被访问就将被删除，如： 1inactive=1d 缓存数据在1天内没有被访问就会被删除 max_size:设置最大缓存空间，如果缓存空间存满，默认会覆盖缓存时间最长的资源，如: 1max_size=20g 配置实例: 123http&#123; proxy_cache_path /usr/local/proxy_cache keys_zone=itcast:200m levels=1:2:1 inactive=1d max_size=20g;&#125; proxy_cache 该指令用来开启或关闭代理缓存，如果是开启则自定使用哪个缓存区来进行缓存。 语法 proxy_cache zone_name|off; 默认值 proxy_cache off; 位置 http、server、location zone_name：指定使用缓存区的名称 proxy_cache_key 该指令用来设置web缓存的key值，Nginx会根据key值MD5哈希存缓存。 语法 proxy_cache_key key; 默认值 proxy_cache_key $scheme$proxy_host$request_uri; 位置 http、server、location proxy_cache_valid 该指令用来对不同返回状态码的URL设置不同的缓存时间 语法 proxy_cache_valid [code …] time; 默认值 — 位置 http、server、location 如： 12345proxy_cache_valid 200 302 10m;proxy_cache_valid 404 1m;为200和302的响应URL设置10分钟缓存，为404的响应URL设置1分钟缓存proxy_cache_valid any 1m;对所有响应状态码的URL都设置1分钟缓存 proxy_cache_min_uses 该指令用来设置资源被访问多少次后被缓存 语法 proxy_cache_min_uses number; 默认值 proxy_cache_min_uses 1; 位置 http、server、location proxy_cache_methods 该指令用户设置缓存哪些HTTP方法 语法 proxy_cache_methods GET|HEAD|POST; 默认值 proxy_cache_methods GET HEAD; 位置 http、server、location 默认缓存HTTP的GET和HEAD方法，不缓存POST方法。 Nginx缓存设置案例 需求分析 步骤实现 1.环境准备 应用服务器的环境准备 （1）在192.168.200.146服务器上的tomcat的webapps下面添加一个js目录，并在js目录中添加一个jquery.js文件 （2）启动tomcat （3）访问测试 1http://192.168.200.146:8080/js/jquery.js Nginx的环境准备 （1）完成Nginx反向代理配置 123456789101112http&#123; upstream backend&#123; server 192.168.200.146:8080; &#125; server &#123; listen 8080; server_name localhost; location / &#123; proxy_pass http://backend/js/; &#125; &#125;&#125; （2）完成Nginx缓存配置 4.添加缓存配置 1234567891011121314151617181920http&#123; proxy_cache_path /usr/local/proxy_cache levels=2:1 keys_zone=itcast:200m inactive=1d max_size=20g; upstream backend&#123; server 192.168.200.146:8080; &#125; server &#123; listen 8080; server_name localhost; location / &#123; proxy_cache itcast; proxy_cache_key itheima; proxy_cache_min_uses 5; proxy_cache_valid 200 5d; proxy_cache_valid 404 30s; proxy_cache_valid any 1m; add_header nginx-cache &quot;$upstream_cache_status&quot;; proxy_pass http://backend/js/; &#125; &#125;&#125; Nginx缓存的清除 方式一:删除对应的缓存目录 1rm -rf /usr/local/proxy_cache/...... 方式二:使用第三方扩展模块 ngx_cache_purge （1）下载ngx_cache_purge模块对应的资源包，并上传到服务器上。 1ngx_cache_purge-2.3.tar.gz （2）对资源文件进行解压缩 1tar -zxf ngx_cache_purge-2.3.tar.gz （3）修改文件夹名称，方便后期配置 1mv ngx_cache_purge-2.3 purge （4）查询Nginx的配置参数 1nginx -V （5）进入Nginx的安装目录，使用./configure进行参数配置 1./configure --add-module=/root/nginx/module/purge （6）使用make进行编译 1make （7）将nginx安装目录的nginx二级制可执行文件备份 1mv /usr/local/nginx/sbin/nginx /usr/local/nginx/sbin/nginxold （8）将编译后的objs中的nginx拷贝到nginx的sbin目录下 1cp objs/nginx /usr/local/nginx/sbin （9）使用make进行升级 1make upgrade （10）在nginx配置文件中进行如下配置 12345server&#123; location ~/purge(/.*) &#123; proxy_cache_purge itcast itheima; &#125;&#125; Nginx设置资源不缓存 前面咱们已经完成了Nginx作为web缓存服务器的使用。但是我们得思考一个问题就是不是所有的数据都适合进行缓存。比如说对于一些经常发生变化的数据。如果进行缓存的话，就很容易出现用户访问到的数据不是服务器真实的数据。所以对于这些资源我们在缓存的过程中就需要进行过滤，不进行缓存。 Nginx也提供了这块的功能设置，需要使用到如下两个指令 proxy_no_cache 该指令是用来定义不将数据进行缓存的条件。 语法 proxy_no_cache string …; 默认值 — 位置 http、server、location 配置实例 1proxy_no_cache $cookie_nocache $arg_nocache $arg_comment; proxy_cache_bypass 该指令是用来设置不从缓存中获取数据的条件。 语法 proxy_cache_bypass string …; 默认值 — 位置 http、server、location 配置实例 1proxy_cache_bypass $cookie_nocache $arg_nocache $arg_comment; 上述两个指令都有一个指定的条件，这个条件可以是多个，并且多个条件中至少有一个不为空且不等于&quot;0&quot;,则条件满足成立。上面给的配置实例是从官方网站获取的，里面使用到了三个变量，分别是$cookie_nocache、$arg_nocache、$arg_comment $cookie_nocache、$arg_nocache、$arg_comment 这三个参数分别代表的含义是: 1234$cookie_nocache指的是当前请求的cookie中键的名称为nocache对应的值$arg_nocache和$arg_comment指的是当前请求的参数中属性名为nocache和comment对应的属性值 案例演示下: 1234567891011log_format params $cookie_nocache | $arg_nocache | $arg_comment；server&#123; listen 8081; server_name localhost; location /&#123; access_log logs/access_params.log params; add_header Set-Cookie &#x27;nocache=999&#x27;; root html; index index.html; &#125;&#125; 案例实现 设置不缓存资源的配置方案 1234567891011server&#123; listen 8080; server_name localhost; location / &#123; if ($request_uri ~ /.*\\.js$)&#123; set $nocache 1; &#125; proxy_no_cache $nocache $cookie_nocache $arg_nocache $arg_comment; proxy_cache_bypass $nocache $cookie_nocache $arg_nocache $arg_comment; &#125;&#125;","categories":[{"name":"Web开发","slug":"Web开发","permalink":"http://kaillliu.github.io/categories/Web%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://kaillliu.github.io/tags/Java/"},{"name":"Centos","slug":"Centos","permalink":"http://kaillliu.github.io/tags/Centos/"},{"name":"Linux","slug":"Linux","permalink":"http://kaillliu.github.io/tags/Linux/"}]},{"title":"Nginx学习（二）","slug":"Nginx学习其二","date":"2022-04-21T08:27:00.000Z","updated":"2022-05-23T05:41:23.080Z","comments":true,"path":"2022/04/21/Nginx学习其二/","link":"","permalink":"http://kaillliu.github.io/2022/04/21/Nginx%E5%AD%A6%E4%B9%A0%E5%85%B6%E4%BA%8C/","excerpt":"","text":"Nginx进阶篇 Nginx服务器基础配置实例 前面我们已经对Nginx服务器默认配置文件的结构和涉及的基本指令做了详细的阐述。通过这些指令的合理配置，我们就可以让一台Nginx服务器正常工作，并且提供基本的web服务器功能。 接下来我们将通过一个比较完整和最简单的基础配置实例，来巩固下前面所学习的指令及其配置。 需求如下: 1234567891011121314（1）有如下访问： http://192.168.200.133:8081/server1/location1 访问的是：index_sr1_location1.html http://192.168.200.133:8081/server1/location2 访问的是：index_sr1_location2.html http://192.168.200.133:8082/server2/location1 访问的是：index_sr2_location1.html http://192.168.200.133:8082/server2/location2 访问的是：index_sr2_location2.html（2）如果访问的资源不存在， 返回自定义的404页面（3）将/server1和/server2的配置使用不同的配置文件分割 将文件放到/home/www/conf.d目录下，然后使用include进行合并（4）为/server1和/server2各自创建一个访问日志文件 准备相关文件，目录如下： 配置的内容如下: 12345678910111213141516171819202122232425262728293031323334353637383940414243##全局块 begin###配置允许运行Nginx工作进程的用户和用户组user www;#配置运行Nginx进程生成的worker进程数worker_processes 2;#配置Nginx服务器运行对错误日志存放的路径error_log logs/error.log;#配置Nginx服务器允许时记录Nginx的master进程的PID文件路径和名称pid logs/nginx.pid;#配置Nginx服务是否以守护进程方法启动#daemon on;##全局块 end####events块 begin##events&#123; #设置Nginx网络连接序列化 accept_mutex on; #设置Nginx的worker进程是否可以同时接收多个请求 multi_accept on; #设置Nginx的worker进程最大的连接数 worker_connections 1024; #设置Nginx使用的事件驱动模型 use epoll;&#125;##events块 end####http块 start##http&#123; #定义MIME-Type include mime.types; default_type application/octet-stream; #配置允许使用sendfile方式运输 sendfile on; #配置连接超时时间 keepalive_timeout 65; #配置请求处理日志格式 log_format server1 &#x27;===&gt;server1 access log&#x27;; log_format server2 &#x27;===&gt;server2 access log&#x27;; ##server块 开始## include /home/www/conf.d/*.conf; ##server块 结束##&#125;##http块 end## server1.conf 123456789101112131415161718192021222324server&#123; #配置监听端口和主机名称 listen 8081; server_name localhost; #配置请求处理日志存放路径 access_log /home/www/myweb/server1/logs/access.log server1; #配置错误页面 error_page 404 /404.html; #配置处理/server1/location1请求的location location /server1/location1&#123; root /home/www/myweb; index index_sr1_location1.html; &#125; #配置处理/server1/location2请求的location location /server1/location2&#123; root /home/www/myweb; index index_sr1_location2.html; &#125; #配置错误页面转向 location = /404.html &#123; root /home/www/myweb; index 404.html; &#125;&#125; server2.conf 123456789101112131415161718192021222324server&#123; #配置监听端口和主机名称 listen 8082; server_name localhost; #配置请求处理日志存放路径 access_log /home/www/myweb/server2/logs/access.log server2; #配置错误页面,对404.html做了定向配置 error_page 404 /404.html; #配置处理/server1/location1请求的location location /server2/location1&#123; root /home/www/myweb; index index_sr2_location1.html; &#125; #配置处理/server2/location2请求的location location /server2/location2&#123; root /home/www/myweb; index index_sr2_location2.html; &#125; #配置错误页面转向 location = /404.html &#123; root /home/www/myweb; index 404.html; &#125; &#125; 访问测试： Nginx服务操作的问题 经过前面的操作，我们会发现，如果想要启动、关闭或重新加载nginx配置文件，都需要先进入到nginx的安装目录的sbin目录，然后使用nginx的二级制可执行文件来操作，相对来说操作比较繁琐，这块该如何优化？另外如果我们想把Nginx设置成随着服务器启动就自动完成启动操作，又该如何来实现?这就需要用到接下来我们要讲解的两个知识点： 12Nginx配置成系统服务Nginx命令配置到系统环境 Nginx配置成系统服务 把Nginx应用服务设置成为系统服务，方便对Nginx服务的启动和停止等相关操作，具体实现步骤: (1) 在/usr/lib/systemd/system目录下添加nginx.service,内容如下: 1vim /usr/lib/systemd/system/nginx.service 12345678910111213141516[Unit]Description=nginx web serviceDocumentation=http://nginx.org/en/docs/After=network.target[Service]Type=forkingPIDFile=/usr/local/nginx/logs/nginx.pidExecStartPre=/usr/local/nginx/sbin/nginx -t -c /usr/local/nginx/conf/nginx.confExecStart=/usr/local/nginx/sbin/nginxExecReload=/usr/local/nginx/sbin/nginx -s reloadExecStop=/usr/local/nginx/sbin/nginx -s stopPrivateTmp=true[Install]WantedBy=default.target (2)添加完成后如果权限有问题需要进行权限设置 1chmod 755 /usr/lib/systemd/system/nginx.service (3)使用系统命令来操作Nginx服务 启动: systemctl start nginx 停止: systemctl stop nginx 重启: systemctl restart nginx 重新加载配置文件: systemctl reload nginx 查看nginx状态: systemctl status nginx 开机启动: systemctl enable nginx Nginx命令配置到系统环境 前面我们介绍过Nginx安装目录下的二级制可执行文件nginx的很多命令，要想使用这些命令前提是需要进入sbin目录下才能使用，很不方便，如何去优化，我们可以将该二进制可执行文件加入到系统的环境变量，这样的话在任何目录都可以使用nginx对应的相关命令。具体实现步骤如下: 演示可删除 123/usr/local/nginx/sbin/nginx -Vcd /usr/local/nginx/sbin nginx -V#如何优化？？？ (1)修改/etc/profile文件 123vim /etc/profile#在最后一行添加export PATH=$PATH:/usr/local/nginx/sbin (2)使之立即生效 1source /etc/profile (3)执行nginx命令 1nginx -V Nginx静态资源部署 Nginx静态资源概述 上网去搜索访问资源对于我们来说并不陌生，通过浏览器发送一个HTTP请求实现从客户端发送请求到服务器端获取所需要内容后并把内容回显展示在页面的一个过程。这个时候，我们所请 求的内容就分为两种类型，一类是静态资源、一类是动态资源。 静态资源即指在服务器端真实存在并且能直接拿来展示的一些文件，比如常见的html页面、css文件、js文件、图 片、视频等资源； 动态资源即指在服务器端真实存在但是要想获取需要经过一定的业务逻辑处理，根据不同的条件展示在页面不同这 一部分内容，比如说报表数据展示、根据当前登录用户展示相关具体数据等资源； Nginx处理静态资源的内容，我们需要考虑下面这几个问题： （1）静态资源的配置指令 （2）静态资源的配置优化 （3）静态资源的压缩配置指令 （4）静态资源的缓存处理 （5）静态资源的访问控制，包括跨域问题和防盗链问题 Nginx静态资源的配置指令 listen指令 listen:用来配置监听端口。 语法 listen address[:port] [default_server]…;listen port [default_server]…; 默认值 listen *:80 | *:8000 位置 server listen的设置比较灵活，我们通过几个例子来把常用的设置方式熟悉下： 1234listen 127.0.0.1:8000; // listen localhost:8000 监听指定的IP和端口listen 127.0.0.1; 监听指定IP的所有端口listen 8000; 监听指定端口上的连接listen *:8000; 监听指定端口上的连接 default_server属性是标识符，用来将此虚拟主机设置成默认主机。所谓的默认主机指的是如果没有匹配到对应的address:port，则会默认执行的。如果不指定默认使用的是第一个server。 1234567891011121314server&#123; listen 8080; server_name 127.0.0.1; location /&#123; root html; index index.html; &#125;&#125;server&#123; listen 8080 default_server; server_name localhost; default_type text/plain; return 444 &#x27;This is a error request&#x27;;&#125; server_name指令 server_name：用来设置虚拟主机服务名称。 127.0.0.1 、 localhost 、域名[www.baidu.com | www.jd.com] 语法 server_name name …;name可以提供多个中间用空格分隔 默认值 server_name “”; 位置 server 关于server_name的配置方式有三种，分别是： 123精确匹配通配符匹配正则表达式匹配 配置方式一：精确匹配 如： 12345server &#123; listen 80; server_name www.itcast.cn www.itheima.cn; ...&#125; 补充小知识点: 1hosts是一个没有扩展名的系统文件，可以用记事本等工具打开，其作用就是将一些常用的网址域名与其对应的IP地址建立一个关联“数据库”，当用户在浏览器中输入一个需要登录的网址时，系统会首先自动从hosts文件中寻找对应的IP地址，一旦找到，系统会立即打开对应网页，如果没有找到，则系统会再将网址提交DNS域名解析服务器进行IP地址的解析。 windows:C:\\Windows\\System32\\drivers\\etc centos：/etc/hosts 因为域名是要收取一定的费用，所以我们可以使用修改hosts文件来制作一些虚拟域名来使用。需要修改 /etc/hosts文件来添加 123vim /etc/hosts127.0.0.1 www.itcast.cn127.0.0.1 www.itheima.cn 配置方式二:使用通配符配置 server_name中支持通配符&quot;*&quot;,但需要注意的是通配符不能出现在域名的中间，只能出现在首段或尾段，如： 123456server &#123; listen 80; server_name *.itcast.cn www.itheima.*; # www.itcast.cn abc.itcast.cn www.itheima.cn www.itheima.com ...&#125; 下面的配置就会报错 12345server &#123; listen 80; server_name www.*.cn www.itheima.c* ...&#125; 配置三:使用正则表达式配置 server_name中可以使用正则表达式，并且使用~作为正则表达式字符串的开始标记。 常见的正则表达式 代码 说明 ^ 匹配搜索字符串开始位置 $ 匹配搜索字符串结束位置 . 匹配除换行符\\n之外的任何单个字符 \\ 转义字符，将下一个字符标记为特殊字符 [xyz] 字符集，与任意一个指定字符匹配 [a-z] 字符范围，匹配指定范围内的任何字符 \\w 与以下任意字符匹配 A-Z a-z 0-9 和下划线,等效于[A-Za-z0-9_] \\d 数字字符匹配，等效于[0-9] {n} 正好匹配n次 {n,} 至少匹配n次 {n,m} 匹配至少n次至多m次 * 零次或多次，等效于{0,} + 一次或多次，等效于{1,} ? 零次或一次，等效于{0,1} 配置如下： 1234567server&#123; listen 80; server_name ~^www\\.(\\w+)\\.com$; default_type text/plain; return 200 $1 $2 ..;&#125;注意 ~后面不能加空格，括号可以取值 匹配执行顺序 由于server_name指令支持通配符和正则表达式，因此在包含多个虚拟主机的配置文件中，可能会出现一个名称被多个虚拟主机的server_name匹配成功，当遇到这种情况，当前的请求交给谁来处理呢？ 12345678910111213141516171819202122232425262728293031323334server&#123; listen 80; server_name ~^www\\.\\w+\\.com$; default_type text/plain; return 200 &#x27;regex_success&#x27;;&#125;server&#123; listen 80; server_name www.itheima.*; default_type text/plain; return 200 &#x27;wildcard_after_success&#x27;;&#125;server&#123; listen 80; server_name *.itheima.com; default_type text/plain; return 200 &#x27;wildcard_before_success&#x27;;&#125;server&#123; listen 80; server_name www.itheima.com; default_type text/plain; return 200 &#x27;exact_success&#x27;;&#125;server&#123; listen 80 default_server; server_name _; default_type text/plain; return 444 &#x27;default_server not found server&#x27;;&#125; 结论： 12345exact_successwildcard_before_successwildcard_after_successregex_successdefault_server not found server!! 123456789No1:准确匹配server_nameNo2:通配符在开始时匹配server_name成功No3:通配符在结束时匹配server_name成功No4:正则表达式匹配server_name成功No5:被默认的default_server处理，如果没有指定默认找第一个server location指令 1234567891011server&#123; listen 80; server_name localhost; location / &#123; &#125; location /abc&#123; &#125; ...&#125; location:用来设置请求的URI 语法 location [ = | ~ | ~* | ^~ |@ ] uri{…} 默认值 — 位置 server,location uri变量是待匹配的请求字符串，可以不包含正则表达式，也可以包含正则表达式，那么nginx服务器在搜索匹配location的时候，是先使用不包含正则表达式进行匹配，找到一个匹配度最高的一个，然后在通过包含正则表达式的进行匹配，如果能匹配到直接访问，匹配不到，就使用刚才匹配度最高的那个location来处理请求。 属性介绍: 不带符号，要求必须以指定模式开始 12345678910111213server &#123; listen 80; server_name 127.0.0.1; location /abc&#123; default_type text/plain; return 200 &quot;access success&quot;; &#125;&#125;以下访问都是正确的http://192.168.200.133/abchttp://192.168.200.133/abc?p1=TOMhttp://192.168.200.133/abc/http://192.168.200.133/abcdef = : 用于不包含正则表达式的uri前，必须与指定的模式精确匹配 1234567891011121314server &#123; listen 80; server_name 127.0.0.1; location =/abc&#123; default_type text/plain; return 200 &quot;access success&quot;; &#125;&#125;可以匹配到http://192.168.200.133/abchttp://192.168.200.133/abc?p1=TOM匹配不到http://192.168.200.133/abc/http://192.168.200.133/abcdef ~ ： 用于表示当前uri中包含了正则表达式，并且区分大小写 ~*: 用于表示当前uri中包含了正则表达式，并且不区分大小写 换句话说，如果uri包含了正则表达式，需要用上述两个符合来标识 12345678910111213141516server &#123; listen 80; server_name 127.0.0.1; location ~^/abc\\w$&#123; default_type text/plain; return 200 &quot;access success&quot;; &#125;&#125;server &#123; listen 80; server_name 127.0.0.1; location ~*^/abc\\w$&#123; default_type text/plain; return 200 &quot;access success&quot;; &#125;&#125; ^~: 用于不包含正则表达式的uri前，功能和不加符号的一致，唯一不同的是，如果模式匹配，那么就停止搜索其他模式了。 12345678server &#123; listen 80; server_name 127.0.0.1; location ^~/abc&#123; default_type text/plain; return 200 &quot;access success&quot;; &#125;&#125; 设置请求资源的目录root / alias root：设置请求的根目录 语法 root path; 默认值 root html; 位置 http、server、location path为Nginx服务器接收到请求以后查找资源的根目录路径。 alias：用来更改location的URI 语法 alias path; 默认值 — 位置 location path为修改后的根路径。 以上两个指令都可以来指定访问资源的路径，那么这两者之间的区别是什么? 举例说明： （1）在/usr/local/nginx/html目录下创建一个 images目录,并在目录下放入一张图片mv.png图片 123location /images &#123; root /usr/local/nginx/html;&#125; 访问图片的路径为: 1http://192.168.200.133/images/mv.png （2）如果把root改为alias 123location /images &#123; alias /usr/local/nginx/html;&#125; 再次访问上述地址，页面会出现404的错误，查看错误日志会发现是因为地址不对，所以验证了： 1234root的处理结果是: root路径+location路径/usr/local/nginx/html/images/mv.pngalias的处理结果是:使用alias路径替换location路径/usr/local/nginx/html/images 需要在alias后面路径改为 123location /images &#123; alias /usr/local/nginx/html/images;&#125; （3）如果location路径是以/结尾,则alias也必须是以/结尾，root没有要求 将上述配置修改为 123location /images/ &#123; alias /usr/local/nginx/html/images;&#125; 访问就会出问题，查看错误日志还是路径不对，所以需要把alias后面加上 / 小结： 1234root的处理结果是: root路径+location路径alias的处理结果是:使用alias路径替换location路径alias是一个目录别名的定义，root则是最上层目录的含义。如果location路径是以/结尾,则alias也必须是以/结尾，root没有要求 index指令 index:设置网站的默认首页 语法 index file …; 默认值 index index.html; 位置 http、server、location index后面可以跟多个设置，如果访问的时候没有指定具体访问的资源，则会依次进行查找，找到第一个为止。 举例说明： 12345location / &#123; root /usr/local/nginx/html; index index.html index.htm;&#125;访问该location的时候，可以通过 http://ip:port/，地址后面如果不添加任何内容，则默认依次访问index.html和index.htm，找到第一个来进行返回 error_page指令 error_page:设置网站的错误页面 语法 error_page code … [=[response]] uri; 默认值 — 位置 http、server、location… 当出现对应的响应code后，如何来处理。 举例说明： （1）可以指定具体跳转的地址 123server &#123; error_page 404 http://www.itcast.cn;&#125; （2）可以指定重定向地址 1234567server&#123; error_page 404 /50x.html; error_page 500 502 503 504 /50x.html; location =/50x.html&#123; root html; &#125;&#125; （3）使用location的@符合完成错误信息展示 1234567server&#123; error_page 404 @jump_to_error; location @jump_to_error &#123; default_type text/plain; return 404 &#x27;Not Found Page...&#x27;; &#125;&#125; 可选项=[response]的作用是用来将相应代码更改为另外一个 1234567server&#123; error_page 404 =200 /50x.html; location =/50x.html&#123; root html; &#125;&#125;这样的话，当返回404找不到对应的资源的时候，在浏览器上可以看到，最终返回的状态码是200，这块需要注意下，编写error_page后面的内容，404后面需要加空格，200前面不能加空格 静态资源优化配置语法 Nginx对静态资源如何进行优化配置。这里从三个属性配置进行优化： 123sendfile on;tcp_nopush on;tcp_nodeplay on; （1）sendﬁle，用来开启高效的文件传输模式。 语法 sendﬁle on |oﬀ; 默认值 sendﬁle oﬀ; 位置 http、server、location… 请求静态资源的过程：客户端通过网络接口向服务端发送请求，操作系统将这些客户端的请求传递给服务器端应用程序，服务器端应用程序会处理这些请求，请求处理完成以后，操作系统还需要将处理得到的结果通过网络适配器传递回去。 如： 12345678910server &#123; listen 80; server_name localhost； location / &#123; root html; index index.html; &#125;&#125;在html目录下有一个welcome.html页面，访问地址http://192.168.200.133/welcome.html （2）tcp_nopush：该指令必须在sendfile打开的状态下才会生效，主要是用来提升网络包的传输’效率’ 语法 tcp_nopush on|off; 默认值 tcp_nopush oﬀ; 位置 http、server、location （3）tcp_nodelay：该指令必须在keep-alive连接开启的情况下才生效，来提高网络包传输的’实时性’ 语法 tcp_nodelay on|off; 默认值 tcp_nodelay on; 位置 http、server、location 经过刚才的分析，“tcp_nopush&quot;和”tcp_nodelay“看起来是&quot;互斥的”，那么为什么要将这两个值都打开，这个大家需要知道的是在linux2.5.9以后的版本中两者是可以兼容的，三个指令都开启的好处是，sendfile可以开启高效的文件传输模式，tcp_nopush开启可以确保在发送到客户端之前数据包已经充分“填满”， 这大大减少了网络开销，并加快了文件发送的速度。 然后，当它到达最后一个可能因为没有“填满”而暂停的数据包时，Nginx会忽略tcp_nopush参数， 然后，tcp_nodelay强制套接字发送数据。由此可知，TCP_NOPUSH可以与TCP_NODELAY一起设置，它比单独配置TCP_NODELAY具有更强的性能。所以我们可以使用如下配置来优化Nginx静态资源的处理 123sendfile on;tcp_nopush on;tcp_nodelay on; Nginx静态资源压缩实战 经过上述内容的优化，我们再次思考一个问题，假如在满足上述优化的前提下，我们传送一个1M的数据和一个10M的数据那个效率高?，答案显而易见，传输内容小，速度就会快。那么问题又来了，同样的内容，如果把大小降下来，我们脑袋里面要蹦出一个词就是&quot;压缩&quot;，接下来，我们来学习Nginx的静态资源压缩模块。 在Nginx的配置文件中可以通过配置gzip来对静态资源进行压缩，相关的指令可以配置在http块、server块和location块中，Nginx可以通过 123ngx_http_gzip_module模块ngx_http_gzip_static_module模块ngx_http_gunzip_module模块 对这些指令进行解析和处理。 接下来我们从以下内容进行学习 1234（1）Gzip各模块支持的配置指令（2）Gzip压缩功能的配置（3）Gzip和sendfile的冲突解决（4）浏览器不支持Gzip的解决方案 Gzip模块配置指令 接下来所学习的指令都来自ngx_http_gzip_module模块，该模块会在nginx安装的时候内置到nginx的安装环境中，也就是说我们可以直接使用这些指令。 gzip指令：该指令用于开启或者关闭gzip功能 语法 gzip on|off; 默认值 gzip off; 位置 http、server、location… 注意只有该指令为打开状态，下面的指令才有效果 123http&#123; gzip on;&#125; gzip_types指令：该指令可以根据响应页的MIME类型选择性地开启Gzip压缩功能 语法 gzip_types mime-type …; 默认值 gzip_types text/html; 位置 http、server、location 所选择的值可以从mime.types文件中进行查找，也可以使用&quot;*&quot;代表所有。 123http&#123; gzip_types application/javascript;&#125; gzip_comp_level指令：该指令用于设置Gzip压缩程度，级别从1-9,1表示要是程度最低，要是效率最高，9刚好相反，压缩程度最高，但是效率最低最费时间。 语法 gzip_comp_level level; 默认值 gzip_comp_level 1; 位置 http、server、location 123http&#123; gzip_comp_level 6;&#125; gzip_vary指令：该指令用于设置使用Gzip进行压缩发送是否携带“Vary:Accept-Encoding”头域的响应头部。主要是告诉接收方，所发送的数据经过了Gzip压缩处理 语法 gzip_vary on|off; 默认值 gzip_vary off; 位置 http、server、location gzip_buffers指令：该指令用于处理请求压缩的缓冲区数量和大小。 语法 gzip_buffers number size; 默认值 gzip_buffers 32 4k|16 8k; 位置 http、server、location 其中number:指定Nginx服务器向系统申请缓存空间个数，size指的是每个缓存空间的大小。主要实现的是申请number个每个大小为size的内存空间。这个值的设定一般会和服务器的操作系统有关，所以建议此项不设置，使用默认值即可。 1gzip_buffers 4 16K; #缓存空间大小 gzip_disable指令：针对不同种类客户端发起的请求，可以选择性地开启和关闭Gzip功能。 语法 gzip_disable regex …; 默认值 — 位置 http、server、location regex:根据客户端的浏览器标志(user-agent)来设置，支持使用正则表达式。指定的浏览器标志不使用Gzip.该指令一般是用来排除一些明显不支持Gzip的浏览器。 1gzip_disable &quot;MSIE [1-6]\\.&quot;; gzip_http_version指令：针对不同的HTTP协议版本，可以选择性地开启和关闭Gzip功能。 语法 gzip_http_version 1.0|1.1; 默认值 gzip_http_version 1.1; 位置 http、server、location 该指令是指定使用Gzip的HTTP最低版本，该指令一般采用默认值即可。 gzip_min_length指令：该指令针对传输数据的大小，可以选择性地开启和关闭Gzip功能 语法 gzip_min_length length; 默认值 gzip_min_length 20; 位置 http、server、location 12nignx计量大小的单位：bytes[字节] / kb[千字节] / M[兆]例如: 1024 / 10k|K / 10m|M Gzip压缩功能对大数据的压缩效果明显，但是如果要压缩的数据比较小的化，可能出现越压缩数据量越大的情况，因此我们需要根据响应内容的大小来决定是否使用Gzip功能，响应页面的大小可以通过头信息中的Content-Length来获取。但是如何使用了Chunk编码动态压缩，该指令将被忽略。建议设置为1K或以上。 gzip_proxied指令：该指令设置是否对服务端返回的结果进行Gzip压缩。 语法 gzip_proxied off|expired|no-cache|no-store|private|no_last_modified|no_etag|auth|any; 默认值 gzip_proxied off; 位置 http、server、location off - 关闭Nginx服务器对后台服务器返回结果的Gzip压缩 expired - 启用压缩，如果header头中包含 “Expires” 头信息 no-cache - 启用压缩，如果header头中包含 “Cache-Control:no-cache” 头信息 no-store - 启用压缩，如果header头中包含 “Cache-Control:no-store” 头信息 private - 启用压缩，如果header头中包含 “Cache-Control:private” 头信息 no_last_modified - 启用压缩,如果header头中不包含 “Last-Modified” 头信息 no_etag - 启用压缩 ,如果header头中不包含 “ETag” 头信息 auth - 启用压缩 , 如果header头中包含 “Authorization” 头信息 any - 无条件启用压缩 Gzip压缩功能的实例配置 123456789gzip on; #开启gzip功能gzip_types *; #压缩源文件类型,根据具体的访问资源类型设定gzip_comp_level 6; #gzip压缩级别gzip_min_length 1024; #进行压缩响应页面的最小长度,content-lengthgzip_buffers 4 16K; #缓存空间大小gzip_http_version 1.1; #指定压缩响应所需要的最低HTTP请求版本gzip_vary on; #往头信息中添加压缩标识gzip_disable &quot;MSIE [1-6]\\.&quot;; #对IE6以下的版本都不进行压缩gzip_proxied off； #nginx作为反向代理压缩服务端返回数据的条件 这些配置在很多地方可能都会用到，所以我们可以将这些内容抽取到一个配置文件中，然后通过include指令把配置文件再次加载到nginx.conf配置文件中，方法使用。 nginx_gzip.conf 123456789gzip on;gzip_types *;gzip_comp_level 6;gzip_min_length 1024;gzip_buffers 4 16K;gzip_http_version 1.1;gzip_vary on;gzip_disable &quot;MSIE [1-6]\\.&quot;;gzip_proxied off; nginx.conf 1include nginx_gzip.conf Gzip和sendfile共存问题 前面在讲解sendfile的时候，提到过，开启sendfile以后，在读取磁盘上的静态资源文件的时候，可以减少拷贝的次数，可以不经过用户进程将静态文件通过网络设备发送出去，但是Gzip要想对资源压缩，是需要经过用户进程进行操作的。所以如何解决两个设置的共存问题。 可以使用ngx_http_gzip_static_module模块的gzip_static指令来解决。 gzip_static指令 gzip_static: 检查与访问资源同名的.gz文件时，response中以gzip相关的header返回.gz文件的内容。 语法 gzip_static on | off | always; 默认值 gzip_static off; 位置 http、server、location 添加上述命令后，会报一个错误，unknown directive &quot;gzip_static&quot;主要的原因是Nginx默认是没有添加ngx_http_gzip_static_module模块。如何来添加? 添加模块到Nginx的实现步骤 (1)查询当前Nginx的配置参数 1nginx -V (2)将nginx安装目录下sbin目录中的nginx二进制文件进行更名 12cd /usr/local/nginx/sbinmv nginx nginxold (3) 进入Nginx的安装目录 1cd /root/nginx/core/nginx-1.16.1 (4)执行make clean清空之前编译的内容 1make clean (5)使用configure来配置参数 1./configure --with-http_gzip_static_module (6)使用make命令进行编译 1make (7) 将objs目录下的nginx二进制执行文件移动到nginx安装目录下的sbin目录中 1mv objs/nginx /usr/local/nginx/sbin (8)执行更新命令 1make upgrade gzip_static测试使用 (1)直接访问http://192.168.200.133/jquery.js (2)使用gzip命令进行压缩 12cd /usr/local/nginx/htmlgzip jquery.js (3)再次访问http://192.168.200.133/jquery.js 静态资源的缓存处理 什么是缓存 1缓存（cache），原始意义是指访问速度比一般随机存取存储器（RAM）快的一种高速存储器，通常它不像系统主存那样使用DRAM技术，而使用昂贵但较快速的SRAM技术。缓存的设置是所有现代计算机系统发挥高性能的重要因素之一。 什么是web缓存 1Web缓存是指一个Web资源（如html页面，图片，js，数据等）存在于Web服务器和客户端（浏览器）之间的副本。缓存会根据进来的请求保存输出内容的副本；当下一个请求来到的时候，如果是相同的URL，缓存会根据缓存机制决定是直接使用副本响应访问请求，还是向源服务器再次发送请求。比较常见的就是浏览器会缓存访问过网站的网页，当再次访问这个URL地址的时候，如果网页没有更新，就不会再次下载网页，而是直接使用本地缓存的网页。只有当网站明确标识资源已经更新，浏览器才会再次下载网页 web缓存的种类 1234客户端缓存 浏览器缓存服务端缓存 Nginx / Redis / Memcached等 浏览器缓存 1是为了节约网络的资源加速浏览，浏览器在用户磁盘上对最近请求过的文档进行存储，当访问者再次请求这个页面时，浏览器就可以从本地磁盘显示文档，这样就可以加速页面的阅览. 为什么要用浏览器缓存 1234成本最低的一种缓存实现减少网络带宽消耗降低服务器压力减少网络延迟，加快页面打开速度 浏览器缓存的执行流程 HTTP协议中和页面缓存相关的字段，我们先来认识下： header 说明 Expires 缓存过期的日期和时间 Cache-Control 设置和缓存相关的配置信息 Last-Modified 请求资源最后修改时间 ETag 请求变量的实体标签的当前值，比如文件的MD5值 （1）用户首次通过浏览器发送请求到服务端获取数据，客户端是没有对应的缓存，所以需要发送request请求来获取数据； （2）服务端接收到请求后，获取服务端的数据及服务端缓存的允许后，返回200的成功状态码并且在响应头上附上对应资源以及缓存信息； （3）当用户再次访问相同资源的时候，客户端会在浏览器的缓存目录中查找是否存在响应的缓存文件 （4）如果没有找到对应的缓存文件，则走(2)步 （5）如果有缓存文件，接下来对缓存文件是否过期进行判断，过期的判断标准是(Expires), （6）如果没有过期，则直接从本地缓存中返回数据进行展示 （7）如果Expires过期，接下来需要判断缓存文件是否发生过变化 （8）判断的标准有两个，一个是ETag(Entity Tag),一个是Last-Modified （9）判断结果是未发生变化，则服务端返回304，直接从缓存文件中获取数据 （10）如果判断是发生了变化，重新从服务端获取数据，并根据缓存协商(服务端所设置的是否需要进行缓存数据的设置)来进行数据缓存。 浏览器缓存相关指令 Nginx需要进行缓存相关设置，就需要用到如下的指令 expires指令 expires:该指令用来控制页面缓存的作用。可以通过该指令控制HTTP应答中的“Expires&quot;和”Cache-Control&quot; 语法 expires [modified] timeexpires epoch|max|off; 默认值 expires off; 位置 http、server、location time:可以整数也可以是负数，指定过期时间，如果是负数，Cache-Control则为no-cache,如果为整数或0，则Cache-Control的值为max-age=time; epoch: 指定Expires的值为’1 January,1970,00:00:01 GMT’(1970-01-01 00:00:00)，Cache-Control的值no-cache max:指定Expires的值为’31 December2037 23:59:59GMT’ (2037-12-31 23:59:59) ，Cache-Control的值为10年 off:默认不缓存。 add_header指令 add_header指令是用来添加指定的响应头和响应值。 语法 add_header name value [always]; 默认值 — 位置 http、server、location… Cache-Control作为响应头信息，可以设置如下值： 缓存响应指令： 123456789Cache-control: must-revalidateCache-control: no-cacheCache-control: no-storeCache-control: no-transformCache-control: publicCache-control: privateCache-control: proxy-revalidateCache-Control: max-age=&lt;seconds&gt;Cache-control: s-maxage=&lt;seconds&gt; 指令 说明 must-revalidate 可缓存但必须再向源服务器进行确认 no-cache 缓存前必须确认其有效性 no-store 不缓存请求或响应的任何内容 no-transform 代理不可更改媒体类型 public 可向任意方提供响应的缓存 private 仅向特定用户返回响应 proxy-revalidate 要求中间缓存服务器对缓存的响应有效性再进行确认 max-age=&lt;秒&gt; 响应最大Age值 s-maxage=&lt;秒&gt; 公共缓存服务器响应的最大Age值 max-age=[秒]： Nginx的跨域问题解决 这块内容，我们主要从以下方面进行解决： 123什么情况下会出现跨域问题?实例演示跨域问题具体的解决方案是什么? 同源策略 浏览器的同源策略：是一种约定，是浏览器最核心也是最基本的安全功能，如果浏览器少了同源策略，则浏览器的正常功能可能都会受到影响。 同源: 协议、域名(IP)、端口相同即为同源 1234567891011121314151617181920212223http://192.168.200.131/user/1https://192.168.200.131/user/1不http://192.168.200.131/user/1http://192.168.200.132/user/1不http://192.168.200.131/user/1http://192.168.200.131:8080/user/1不http://www.nginx.com/user/1http://www.nginx.org/user/1不http://192.168.200.131/user/1http://192.168.200.131:8080/user/1不http://www.nginx.org:80/user/1http://www.nginx.org/user/1满足 跨域问题 简单描述下: 1有两台服务器分别为A,B,如果从服务器A的页面发送异步请求到服务器B获取数据，如果服务器A和服务器B不满足同源策略，则就会出现跨域问题。 跨域问题的案例演示 出现跨域问题会有什么效果?,接下来通过一个需求来给大家演示下： （1）nginx的html目录下新建一个a.html 1234567891011121314151617181920&lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;title&gt;跨域问题演示&lt;/title&gt; &lt;script src=&quot;jquery.js&quot;&gt;&lt;/script&gt; &lt;script&gt; $(function()&#123; $(&quot;#btn&quot;).click(function()&#123; $.get(&#x27;http://192.168.200.133:8080/getUser&#x27;,function(data)&#123; alert(JSON.stringify(data)); &#125;); &#125;); &#125;); &lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;input type=&quot;button&quot; value=&quot;获取数据&quot; id=&quot;btn&quot;/&gt; &lt;/body&gt;&lt;/html&gt; （2）在nginx.conf配置如下内容 12345678910111213141516server&#123; listen 8080; server_name localhost; location /getUser&#123; default_type application/json; return 200 &#x27;&#123;&quot;id&quot;:1,&quot;name&quot;:&quot;TOM&quot;,&quot;age&quot;:18&#125;&#x27;; &#125;&#125;server&#123; listen 80; server_name localhost; location /&#123; root html; index index.html; &#125;&#125; (3)通过浏览器访问测试 解决方案 使用add_header指令，该指令可以用来添加一些头信息 语法 add_header name value… 默认值 — 位置 http、server、location 此处用来解决跨域问题，需要添加两个头信息，一个是Access-Control-Allow-Origin,Access-Control-Allow-Methods Access-Control-Allow-Origin: 直译过来是允许跨域访问的源地址信息，可以配置多个(多个用逗号分隔)，也可以使用*代表所有源 Access-Control-Allow-Methods:直译过来是允许跨域访问的请求方式，值可以为 GET POST PUT DELETE…,可以全部设置，也可以根据需要设置，多个用逗号分隔 具体配置方式 123456location /getUser&#123; add_header Access-Control-Allow-Origin *; add_header Access-Control-Allow-Methods GET,POST,PUT,DELETE; default_type application/json; return 200 &#x27;&#123;&quot;id&quot;:1,&quot;name&quot;:&quot;TOM&quot;,&quot;age&quot;:18&#125;&#x27;;&#125; 静态资源防盗链 什么是资源盗链 资源盗链指的是此内容不在自己服务器上，而是通过技术手段，绕过别人的限制将别人的内容放到自己页面上最终展示给用户。以此来盗取大网站的空间和流量。简而言之就是用别人的东西成就自己的网站。 效果演示 京东:https://img14.360buyimg.com/n7/jfs/t1/101062/37/2153/254169/5dcbd410E6d10ba22/4ddbd212be225fcd.jpg 百度:https://pics7.baidu.com/feed/cf1b9d16fdfaaf516f7e2011a7cda1e8f11f7a1a.jpeg?token=551979a23a0995e5e5279b8fa1a48b34&amp;s=BD385394D2E963072FD48543030030BB 我们自己准备一个页面，在页面上引入这两个图片查看效果 从上面的效果，可以看出来，下面的图片地址添加了防止盗链的功能，京东这边我们可以直接使用其图片。 Nginx防盗链的实现原理： 了解防盗链的原理之前，我们得先学习一个HTTP的头信息Referer,当浏览器向web服务器发送请求的时候，一般都会带上Referer,来告诉浏览器该网页是从哪个页面链接过来的。 后台服务器可以根据获取到的这个Referer信息来判断是否为自己信任的网站地址，如果是则放行继续访问，如果不是则可以返回403(服务端拒绝访问)的状态信息。 在本地模拟上述的服务器效果： Nginx防盗链的具体实现: valid_referers:nginx会通就过查看referer自动和valid_referers后面的内容进行匹配，如果匹配到了就将$invalid_referer变量置0，如果没有匹配到，则将$invalid_referer变量置为1，匹配的过程中不区分大小写。 语法 valid_referers none|blocked|server_names|string… 默认值 — 位置 server、location none: 如果Header中的Referer为空，允许访问 blocked:在Header中的Referer不为空，但是该值被防火墙或代理进行伪装过，如不带&quot;http://&quot; 、&quot;https://&quot;等协议头的资源允许访问。 server_names:指定具体的域名或者IP string: 可以支持正则表达式和*的字符串。如果是正则表达式，需要以~开头表示，例如 12345678location ~*\\.(png|jpg|gif)&#123; valid_referers none blocked www.baidu.com 192.168.200.222 *.example.com example.* www.example.org ~\\.google\\.; if ($invalid_referer)&#123; return 403; &#125; root /usr/local/nginx/html;&#125; 遇到的问题:图片有很多，该如何批量进行防盗链？ 针对目录进行防盗链 配置如下： 12345678location /images &#123; valid_referers none blocked www.baidu.com 192.168.200.222 *.example.com example.* www.example.org ~\\.google\\.; if ($invalid_referer)&#123; return 403; &#125; root /usr/local/nginx/html;&#125; 这样我们可以对一个目录下的所有资源进行翻到了操作。 遇到的问题：Referer的限制比较粗，比如随意加一个Referer，上面的方式是无法进行限制的。那么这个问题改如何解决？ 此处我们需要用到Nginx的第三方模块ngx_http_accesskey_module，第三方模块如何实现盗链，如果在Nginx中使用第三方模块的功能，这些我们在后面的Nginx的模块篇再进行详细的讲解。 Rewrite功能配置 Rewrite是Nginx服务器提供的一个重要基本功能，是Web服务器产品中几乎必备的功能。主要的作用是用来实现URL的重写。 注意:Nginx服务器的Rewrite功能的实现依赖于PCRE的支持，因此在编译安装Nginx服务器之前，需要安装PCRE库。Nginx使用的是ngx_http_rewrite_module模块来解析和处理Rewrite功能的相关配置。 “地址重写&quot;与&quot;地址转发” 重写和转发的区别: 12345地址重写浏览器地址会发生变化而地址转发则不变一次地址重写会产生两次请求而一次地址转发只会产生一次请求地址重写到的页面必须是一个完整的路径而地址转发则不需要地址重写因为是两次请求所以request范围内属性不能传递给新页面而地址转发因为是一次请求所以可以传递值地址转发速度快于地址重写 Rewrite规则 set指令 该指令用来设置一个新的变量。 语法 set $variable value; 默认值 — 位置 server、location、if variable:变量的名称，该变量名称要用&quot;$&quot;作为变量的第一个字符，且不能与Nginx服务器预设的全局变量同名。 value:变量的值，可以是字符串、其他变量或者变量的组合等。 Rewrite常用全局变量 变量 说明 $args 变量中存放了请求URL中的请求指令。比如http://192.168.200.133:8080?arg1=value1&amp;args2=value2中的&quot;arg1=value1&amp;arg2=value2&quot;，功能和$query_string一样 $http_user_agent 变量存储的是用户访问服务的代理信息(如果通过浏览器访问，记录的是浏览器的相关版本信息) $host 变量存储的是访问服务器的server_name值 $document_uri 变量存储的是当前访问地址的URI。比如http://192.168.200.133/server?id=10&amp;name=zhangsan中的&quot;/server&quot;，功能和$uri一样 $document_root 变量存储的是当前请求对应location的root值，如果未设置，默认指向Nginx自带html目录所在位置 $content_length 变量存储的是请求头中的Content-Length的值 $content_type 变量存储的是请求头中的Content-Type的值 $http_cookie 变量存储的是客户端的cookie信息，可以通过add_header Set-Cookie 'cookieName=cookieValue’来添加cookie数据 $limit_rate 变量中存储的是Nginx服务器对网络连接速率的限制，也就是Nginx配置中对limit_rate指令设置的值，默认是0，不限制。 $remote_addr 变量中存储的是客户端的IP地址 $remote_port 变量中存储了客户端与服务端建立连接的端口号 $remote_user 变量中存储了客户端的用户名，需要有认证模块才能获取 $scheme 变量中存储了访问协议 $server_addr 变量中存储了服务端的地址 $server_name 变量中存储了客户端请求到达的服务器的名称 $server_port 变量中存储了客户端请求到达服务器的端口号 $server_protocol 变量中存储了客户端请求协议的版本，比如&quot;HTTP/1.1&quot; $request_body_file 变量中存储了发给后端服务器的本地文件资源的名称 $request_method 变量中存储了客户端的请求方式，比如&quot;GET&quot;,&quot;POST&quot;等 $request_filename 变量中存储了当前请求的资源文件的路径名 $request_uri 变量中存储了当前请求的URI，并且携带请求参数，比如http://192.168.200.133/server?id=10&amp;name=zhangsan中的&quot;/server?id=10&amp;name=zhangsan&quot; if指令 该指令用来支持条件判断，并根据条件判断结果选择不同的Nginx配置。 语法 if (condition){…} 默认值 — 位置 server、location condition为判定条件，可以支持以下写法： 变量名。如果变量名对应的值为空或者是0，if都判断为false,其他条件为true。 123if ($param)&#123; &#125; 12. 使用&quot;=&quot;和&quot;!=&quot;比较变量和字符串是否相等，满足条件为true，不满足为false 123if ($request_method = POST)&#123; return 405;&#125; 注意：此处和Java不太一样的地方是字符串不需要添加引号。 使用正则表达式对变量进行匹配，匹配成功返回true，否则返回false。变量与正则表达式之间使用&quot;~“,”~*“,”!~“,”!~*&quot;来连接。 &quot;~&quot;代表匹配正则表达式过程中区分大小写， &quot;~*&quot;代表匹配正则表达式过程中不区分大小写 &quot;!~“和”!~*&quot;刚好和上面取相反值，如果匹配上返回false,匹配不上返回true 123if ($http_user_agent ~ MSIE)&#123; #$http_user_agent的值中是否包含MSIE字符串，如果包含返回true&#125; 注意：正则表达式字符串一般不需要加引号，但是如果字符串中包含&quot;}“或者是”;&quot;等字符时，就需要把引号加上。 判断请求的文件是否存在使用&quot;-f&quot;和&quot;!-f&quot;, 当使用&quot;-f&quot;时，如果请求的文件存在返回true，不存在返回false。 当使用&quot;!f&quot;时，如果请求文件不存在，但该文件所在目录存在返回true,文件和目录都不存在返回false,如果文件存在返回false 123456if (-f $request_filename)&#123; #判断请求的文件是否存在&#125;if (!-f $request_filename)&#123; #判断请求的文件是否不存在&#125; 判断请求的目录是否存在使用&quot;-d&quot;和&quot;!-d&quot;, 当使用&quot;-d&quot;时，如果请求的目录存在，if返回true，如果目录不存在则返回false 当使用&quot;!-d&quot;时，如果请求的目录不存在但该目录的上级目录存在则返回true，该目录和它上级目录都不存在则返回false,如果请求目录存在也返回false. 判断请求的目录或者文件是否存在使用&quot;-e&quot;和&quot;!-e&quot; 当使用&quot;-e&quot;,如果请求的目录或者文件存在时，if返回true,否则返回false. 当使用&quot;!-e&quot;,如果请求的文件和文件所在路径上的目录都不存在返回true,否则返回false 判断请求的文件是否可执行使用&quot;-x&quot;和&quot;!-x&quot; 当使用&quot;-x&quot;,如果请求的文件可执行，if返回true,否则返回false 当使用&quot;!-x&quot;,如果请求文件不可执行，返回true,否则返回false break指令 该指令用于中断当前相同作用域中的其他Nginx配置。与该指令处于同一作用域的Nginx配置中，位于它前面的指令配置生效，位于后面的指令配置无效。 语法 break; 默认值 — 位置 server、location、if 例子: 1234567location /&#123; if ($param)&#123; set $id $1; break; limit_rate 10k; &#125;&#125; return指令 该指令用于完成对请求的处理，直接向客户端返回响应状态代码。在return后的所有Nginx配置都是无效的。 语法 return code [text];return code URL;return URL; 默认值 — 位置 server、location、if code:为返回给客户端的HTTP状态代理。可以返回的状态代码为0~999的任意HTTP状态代理 text:为返回给客户端的响应体内容，支持变量的使用 URL:为返回给客户端的URL地址 rewrite指令 该指令通过正则表达式的使用来改变URI。可以同时存在一个或者多个指令，按照顺序依次对URL进行匹配和处理。 URL和URI的区别： 12URI:统一资源标识符URL:统一资源定位符 语法 rewrite regex replacement [flag]; 默认值 — 位置 server、location、if regex:用来匹配URI的正则表达式 replacement:匹配成功后，用于替换URI中被截取内容的字符串。如果该字符串是以&quot;http://&quot;或者&quot;https://&quot;开头的，则不会继续向下对URI进行其他处理，而是直接返回重写后的URI给客户端。 flag:用来设置rewrite对URI的处理行为，可选值有如下： last: break redirect permanent rewrite_log指令 该指令配置是否开启URL重写日志的输出功能。 语法 rewrite_log on|off; 默认值 rewrite_log off; 位置 http、server、location、if 开启后，URL重写的相关日志将以notice级别输出到error_log指令配置的日志文件汇总。 Rewrite的案例 域名跳转 》问题分析 先来看一个效果，如果我们想访问京东网站，大家都知道我们可以输入www.jd.com,但是同样的我们也可以输入www.360buy.com同样也都能访问到京东网站。这个其实是因为京东刚开始的时候域名就是www.360buy.com，后面由于各种原因把自己的域名换成了www.jd.com, 虽然说域名变量，但是对于以前只记住了www.360buy.com的用户来说，我们如何把这部分用户也迁移到我们新域名的访问上来，针对于这个问题，我们就可以使用Nginx中Rewrite的域名跳转来解决。 》环境准备 准备两个域名 www.360buy.com | www.jd.com 1vim /etc/hosts 12192.168.200.133 www.360buy.com192.168.200.133 www.jd.com 在/usr/local/nginx/html/hm目录下创建一个访问页面 123456&lt;html&gt; &lt;title&gt;&lt;/title&gt; &lt;body&gt; &lt;h1&gt;欢迎来到我们的网站&lt;/h1&gt; &lt;/body&gt;&lt;/html&gt; 通过Nginx实现当访问www.访问到系统的首页 12345678server &#123; listen 80; server_name www.hm.com; location /&#123; root /usr/local/nginx/html/hm; index index.html; &#125;&#125; 》通过Rewrite完成将www.360buy.com的请求跳转到www.jd.com 12345server &#123; listen 80; server_name www.360buy.com; rewrite ^/ http://www.jd.com permanent;&#125; 问题描述:如何在域名跳转的过程中携带请求的URI？ 修改配置信息 12345server &#123; listen 80; server_name www.itheima.com; rewrite ^(.*) http://www.hm.com$1 permanent;&#125; 问题描述:我们除了上述说的www.jd.com 、www.360buy.com其实还有我们也可以通过www.jingdong.com来访问，那么如何通过Rewrite来实现多个域名的跳转? 添加域名 12vim /etc/hosts192.168.200.133 www.jingdong.com 修改配置信息 12345server&#123; listen 80; server_name www.360buy.com www.jingdong.com; rewrite ^(.*) http://www.jd.com$1 permanent;&#125; 域名镜像 上述案例中，将www.360buy.com 和 www.jingdong.com都能跳转到www.jd.com，那么www.jd.com我们就可以把它起名叫主域名，其他两个就是我们所说的镜像域名，当然如果我们不想把整个网站做镜像，只想为其中某一个子目录下的资源做镜像，我们可以在location块中配置rewrite功能，比如: 12345678910server &#123; listen 80; server_name rewrite.myweb.com; location ^~ /source1&#123; rewrite ^/resource1(.*) http://rewrite.myweb.com/web$1 last; &#125; location ^~ /source2&#123; rewrite ^/resource2(.*) http://rewrite.myweb.com/web$1 last; &#125;&#125; 独立域名 一个完整的项目包含多个模块，比如购物网站有商品商品搜索模块、商品详情模块已经购物车模块等，那么我们如何为每一个模块设置独立的域名。 需求： 123http://search.hm.com 访问商品搜索模块http://item.hm.com 访问商品详情模块http://cart.hm.com 访问商品购物车模块 123456789101112131415server&#123; listen 80; server_name search.hm.com; rewrite ^(.*) http://www.hm.com/bbs$1 last;&#125;server&#123; listen 81; server_name item.hm.com; rewrite ^(.*) http://www.hm.com/item$1 last;&#125;server&#123; listen 82; server_name cart.hm.com; rewrite ^(.*) http://www.hm.com/cart$1 last;&#125; 目录自动添加&quot;/&quot; 问题描述 通过一个例子来演示下问题: 123456789server &#123; listen 80; server_name localhost; location / &#123; root html; index index.html; &#125;&#125; 要想访问上述资源，很简单，只需要通过http://192.168.200.133直接就能访问，地址后面不需要加/,但是如果将上述的配置修改为如下内容: 12345678server &#123; listen 80; server_name localhost; location /hm &#123; root html; index index.html; &#125;&#125; 这个时候，要想访问上述资源，按照上述的访问方式，我们可以通过http://192.168.200.133/hm/来访问,但是如果地址后面不加斜杠，页面就会出问题。如果不加斜杠，Nginx服务器内部会自动做一个301的重定向，重定向的地址会有一个指令叫server_name_in_redirect on|off;来决定重定向的地址： 1234如果该指令为on 重定向的地址为: http://server_name/目录名/;如果该指令为off 重定向的地址为: http://原URL中的域名/目录名/; 所以就拿刚才的地址来说，http://192.168.200.133/hm如果不加斜杠，那么按照上述规则，如果指令server_name_in_redirect为on，则301重定向地址变为 http://localhost/hm/,如果为off，则301重定向地址变为http://192.168.200.133/ht/。后面这个是正常的，前面地址就有问题。 注意server_name_in_redirect指令在Nginx的0.8.48版本之前默认都是on，之后改成了off,所以现在我们这个版本不需要考虑这个问题，但是如果是0.8.48以前的版本并且server_name_in_redirect设置为on，我们如何通过rewrite来解决这个问题？ 解决方案 我们可以使用rewrite功能为末尾没有斜杠的URL自动添加一个斜杠 12345678910server &#123; listen 80; server_name localhost; server_name_in_redirect on; location /hm &#123; if (-d $request_filename)&#123; rewrite ^/(.*)([^/])$ http://$host/$1$2/ permanent; &#125; &#125;&#125; 合并目录 搜索引擎优化(SEO)是一种利用搜索引擎的搜索规则来提供目的网站的有关搜索引擎内排名的方式。我们在创建自己的站点时，可以通过很多中方式来有效的提供搜索引擎优化的程度。其中有一项就包含URL的目录层级一般不要超过三层，否则的话不利于搜索引擎的搜索也给客户端的输入带来了负担，但是将所有的文件放在一个目录下又会导致文件资源管理混乱并且访问文件的速度也会随着文件增多而慢下来，这两个问题是相互矛盾的，那么使用rewrite如何解决上述问题? 举例，网站中有一个资源文件的访问路径时 /server/11/22/33/44/20.html,也就是说20.html存在于第5级目录下，如果想要访问该资源文件，客户端的URL地址就要写成 http://www.web.name/server/11/22/33/44/20.html, 1234567server &#123; listen 80; server_name www.web.name; location /server&#123; root html; &#125;&#125; 但是这个是非常不利于SEO搜索引擎优化的，同时客户端也不好记.使用rewrite我们可以进行如下配置: 1234567server &#123; listen 80; server_name www.web.name; location /server&#123; rewrite ^/server-([0-9]+)-([0-9]+)-([0-9]+)-([0-9]+)\\.html$ /server/$1/$2/$3/$4/$5.html last; &#125;&#125; 这样的花，客户端只需要输入http://www.web.name/server-11-22-33-44-20.html就可以访问到20.html页面了。这里也充分利用了rewrite指令支持正则表达式的特性。 防盗链 防盗链之前我们已经介绍过了相关的知识，在rewrite中的防盗链和之前将的原理其实都是一样的，只不过通过rewrite可以将防盗链的功能进行完善下，当出现防盗链的情况，我们可以使用rewrite将请求转发到自定义的一张图片和页面，给用户比较好的提示信息。下面我们就通过根据文件类型实现防盗链的一个配置实例: 12345678910server&#123; listen 80; server_name www.web.com; locatin ~* ^.+\\.(gif|jpg|png|swf|flv|rar|zip)$&#123; valid_referers none blocked server_names *.web.com; if ($invalid_referer)&#123; rewrite ^/ http://www.web.com/images/forbidden.png; &#125; &#125;&#125; 根据目录实现防盗链配置： 1234567891011server&#123; listen 80; server_name www.web.com; location /file/&#123; root /server/file/; valid_referers none blocked server_names *.web.com; if ($invalid_referer)&#123; rewrite ^/ http://www.web.com/images/forbidden.png; &#125; &#125;&#125;","categories":[{"name":"Web开发","slug":"Web开发","permalink":"http://kaillliu.github.io/categories/Web%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://kaillliu.github.io/tags/Java/"},{"name":"Centos","slug":"Centos","permalink":"http://kaillliu.github.io/tags/Centos/"},{"name":"Linux","slug":"Linux","permalink":"http://kaillliu.github.io/tags/Linux/"}]},{"title":"Nginx学习（一）","slug":"Nginx学习其一","date":"2022-04-21T08:17:00.000Z","updated":"2022-05-23T05:41:23.080Z","comments":true,"path":"2022/04/21/Nginx学习其一/","link":"","permalink":"http://kaillliu.github.io/2022/04/21/Nginx%E5%AD%A6%E4%B9%A0%E5%85%B6%E4%B8%80/","excerpt":"","text":"Nginx简介 背景介绍 Nginx（“engine x”）一个具有高性能的【HTTP】和【反向代理】的【WEB服务器】，同时也是一个【POP3/SMTP/IMAP代理服务器】，是由伊戈尔·赛索耶夫(俄罗斯人)使用C语言编写的，Nginx的第一个版本是2004年10月4号发布的0.1.0版本。另外值得一提的是伊戈尔·赛索耶夫将Nginx的源码进行了开源，这也为Nginx的发展提供了良好的保障。 名词解释 WEB服务器： WEB服务器也叫网页服务器，英文名叫Web Server，主要功能是为用户提供网上信息浏览服务。 HTTP: HTTP是超文本传输协议的缩写，是用于从WEB服务器传输超文本到本地浏览器的传输协议，也是互联网上应用最为广泛的一种网络协议。HTTP是一个客户端和服务器端请求和应答的标准，客户端是终端用户，服务端是网站，通过使用Web浏览器、网络爬虫或者其他工具，客户端发起一个到服务器上指定端口的HTTP请求。 POP3/SMTP/IMAP： POP3(Post Offic Protocol 3)邮局协议的第三个版本， SMTP(Simple Mail Transfer Protocol)简单邮件传输协议， IMAP(Internet Mail Access Protocol)交互式邮件存取协议， 通过上述名词的解释，我们可以了解到Nginx也可以作为电子邮件代理服务器。 反向代理 正向代理 反向代理 常见服务器对比 在介绍这一节内容之前，我们先来认识一家公司叫Netcraft。 1Netcraft公司于1994年底在英国成立，多年来一直致力于互联网市场以及在线安全方面的咨询服务，其中在国际上最具影响力的当属其针对网站服务器、SSL市场所做的客观严谨的分析研究，公司官网每月公布的调研数据（Web Server Survey）已成为当今人们了解全球网站数量以及服务器市场分额情况的主要参考依据，时常被诸如华尔街杂志，英国BBC，Slashdot等媒体报道或引用。 我们先来看一组数据，我们先打开Nginx的官方网站 http://nginx.org/,找到Netcraft公司公布的数据，对当前主流服务器产品进行介绍。 上面这张图展示了2019年全球主流Web服务器的市场情况，其中有Apache、Microsoft-IIS、google Servers、Nginx、Tomcat等，而我们在了解新事物的时候，往往习惯通过类比来帮助自己理解事物的概貌。所以下面我们把几种常见的服务器来给大家简单介绍下： IIS ​ 全称(Internet Information Services)即互联网信息服务，是由微软公司提供的基于windows系统的互联网基本服务。windows作为服务器在稳定性与其他一些性能上都不如类UNIX操作系统，因此在需要高性能Web服务器的场合下，IIS可能就会被&quot;冷落&quot;. Tomcat ​ Tomcat是一个运行Servlet和JSP的Web应用软件，Tomcat技术先进、性能稳定而且开放源代码，因此深受Java爱好者的喜爱并得到了部分软件开发商的认可，成为目前比较流行的Web应用服务器。但是Tomcat天生是一个重量级的Web服务器，对静态文件和高并发的处理比较弱。 Apache ​ Apache的发展时期很长，同时也有过一段辉煌的业绩。从上图可以看出大概在2014年以前都是市场份额第一的服务器。Apache有很多优点，如稳定、开源、跨平台等。但是它出现的时间太久了，在它兴起的年代，互联网的产业规模远远不如今天，所以它被设计成一个重量级的、不支持高并发的Web服务器。在Apache服务器上，如果有数以万计的并发HTTP请求同时访问，就会导致服务器上消耗大量能存，操作系统内核对成百上千的Apache进程做进程间切换也会消耗大量的CUP资源，并导致HTTP请求的平均响应速度降低，这些都决定了Apache不可能成为高性能的Web服务器。这也促使了Lighttpd和Nginx的出现。 Lighttpd ​ Lighttpd是德国的一个开源的Web服务器软件，它和Nginx一样，都是轻量级、高性能的Web服务器，欧美的业界开发者比较钟爱Lighttpd,而国内的公司更多的青睐Nginx，同时网上Nginx的资源要更丰富些。 其他的服务器 Google Servers，Weblogic, Webshpere(IBM)… 经过各个服务器的对比，种种迹象都表明，Nginx将以性能为王。这也是我们为什么选择Nginx的理由。 Nginx的优点 (1)速度更快、并发更高 单次请求或者高并发请求的环境下，Nginx都会比其他Web服务器响应的速度更快。一方面在正常情况下，单次请求会得到更快的响应，另一方面，在高峰期(如有数以万计的并发请求)，Nginx比其他Web服务器更快的响应请求。Nginx之所以有这么高的并发处理能力和这么好的性能原因在于Nginx采用了多进程和I/O多路复用(epoll)的底层实现。 (2)配置简单，扩展性强 Nginx的设计极具扩展性，它本身就是由很多模块组成，这些模块的使用可以通过配置文件的配置来添加。这些模块有官方提供的也有第三方提供的模块，如果需要完全可以开发服务自己业务特性的定制模块。 (3)高可靠性 Nginx采用的是多进程模式运行，其中有一个master主进程和N多个worker进程，worker进程的数量我们可以手动设置，每个worker进程之间都是相互独立提供服务，并且master主进程可以在某一个worker进程出错时，快速去&quot;拉起&quot;新的worker进程提供服务。 (4)热部署 现在互联网项目都要求以7*24小时进行服务的提供，针对于这一要求，Nginx也提供了热部署功能，即可以在Nginx不停止的情况下，对Nginx进行文件升级、更新配置和更换日志文件等功能。 (5)成本低、BSD许可证 BSD是一个开源的许可证，世界上的开源许可证有很多，现在比较流行的有六种分别是GPL、BSD、MIT、Mozilla、Apache、LGPL。这六种的区别是什么，我们可以通过下面一张图来解释下： Nginx本身是开源的，我们不仅可以免费的将Nginx应用在商业领域，而且还可以在项目中直接修改Nginx的源码来定制自己的特殊要求。这些点也都是Nginx为什么能吸引无数开发者继续为Nginx来贡献自己的智慧和青春。OpenRestry [Nginx+Lua] Tengine[淘宝] Nginx的功能特性及常用功能 Nginx提供的基本功能服务从大体上归纳为&quot;基本HTTP服务&quot;、“高级HTTP服务”和&quot;邮件服务&quot;等三大类。 基本HTTP服务 Nginx可以提供基本HTTP服务，可以作为HTTP代理服务器和反向代理服务器，支持通过缓存加速访问，可以完成简单的负载均衡和容错，支持包过滤功能，支持SSL等。 处理静态文件、处理索引文件以及支持自动索引； 提供反向代理服务器，并可以使用缓存加上反向代理，同时完成负载均衡和容错； 提供对FastCGI、memcached等服务的缓存机制，，同时完成负载均衡和容错； 使用Nginx的模块化特性提供过滤器功能。Nginx基本过滤器包括gzip压缩、ranges支持、chunked响应、XSLT、SSI以及图像缩放等。其中针对包含多个SSI的页面，经由FastCGI或反向代理，SSI过滤器可以并行处理。 支持HTTP下的安全套接层安全协议SSL. 支持基于加权和依赖的优先权的HTTP/2 高级HTTP服务 支持基于名字和IP的虚拟主机设置 支持HTTP/1.0中的KEEP-Alive模式和管线(PipeLined)模型连接 自定义访问日志格式、带缓存的日志写操作以及快速日志轮转。 提供3xx~5xx错误代码重定向功能 支持重写（Rewrite)模块扩展 支持重新加载配置以及在线升级时无需中断正在处理的请求 支持网络监控 支持FLV和MP4流媒体传输 邮件服务 Nginx提供邮件代理服务也是其基本开发需求之一，主要包含以下特性： 支持IMPA/POP3代理服务功能 支持内部SMTP代理服务功能 Nginx常用的功能模块 12345678910静态资源部署Rewrite地址重写 正则表达式反向代理负载均衡 轮询、加权轮询、ip_hash、url_hash、fairWeb缓存环境部署 高可用的环境用户认证模块... Nginx的核心组成 1234nginx二进制可执行文件nginx.conf配置文件error.log错误的日志记录access.log访问日志记录 Nginx环境准备 Nginx版本介绍 Nginx的官方网站为: http://nginx.org 打开源码可以看到如下的页面内容 Nginx的官方下载网站为http://nginx.org/en/download.html，当然你也可以之间在首页选中右边的download进入版本下载网页。在下载页面我们会看到如下内容： 获取Nginx源码 http://nginx.org/download/ 打开上述网站，就可以查看到Nginx的所有版本，选中自己需要的版本进行下载。下载我们可以直接在windows上下载然后上传到服务器，也可以直接从服务器上下载，这个时候就需要准备一台服务器。 准备服务器系统 环境准备 12345VMware WorkStationCentos7MobaXterm xsheel,SecureCRT网络 (1)确认centos的内核 准备一个内核为2.6及以上版本的操作系统，因为linux2.6及以上内核才支持epoll,而Nginx需要解决高并发压力问题是需要用到epoll，所以我们需要有这样的版本要求。 我们可以使用uname -a命令来查询linux的内核版本。 (2)确保centos能联网 1ping www.baidu.com (3)确认关闭防火墙 这一项的要求仅针对于那些对linux系统的防火墙设置规则不太清楚的，建议大家把防火墙都关闭掉，因为我们此次课程主要的内容是对Nginx的学习，把防火墙关闭掉，可以省掉后续Nginx学习过程中遇到的诸多问题。 关闭的方式有如下两种： 123systemctl stop firewalld 关闭运行的防火墙，系统重新启动后，防火墙将重新打开systemctl disable firewalld 永久关闭防火墙，，系统重新启动后，防火墙依然关闭systemctl status firewalld 查看防火墙状态 （4）确认停用selinux selinux(security-enhanced linux),美国安全局对于强制访问控制的实现，在linux2.6内核以后的版本中，selinux已经成功内核中的一部分。可以说selinux是linux史上最杰出的新安全子系统之一。虽然有了selinux，我们的系统会更安全，但是对于我们的学习Nginx的历程中，会多很多设置，所以这块建议大家将selinux进行关闭。 sestatus查看状态 如果查看不是disabled状态，我们可以通过修改配置文件来进行设置,修改SELINUX=disabled，然后重启下系统即可生效。 1vim /etc/selinux/config Nginx安装方式介绍 Nginx的安装方式有两种分别是: 1234通过Nginx源码 通过Nginx源码简单安装 (1) 通过Nginx源码复杂安装 (3)通过yum安装 (2) 如果通过Nginx源码安装需要提前准备的内容： GCC编译器 Nginx是使用C语言编写的程序，因此想要运行Nginx就需要安装一个编译工具。GCC就是一个开源的编译器集合，用于处理各种各样的语言，其中就包含了C语言。 使用命令yum install -y gcc来安装 安装成功后，可以通过gcc --version来查看gcc是否安装成功 PCRE Nginx在编译过程中需要使用到PCRE库（perl Compatible Regular Expressoin 兼容正则表达式库)，因为在Nginx的Rewrite模块和http核心模块都会使用到PCRE正则表达式语法。 可以使用命令yum install -y pcre pcre-devel来进行安装 安装成功后，可以通过rpm -qa pcre pcre-devel来查看是否安装成功 zlib zlib库提供了开发人员的压缩算法，在Nginx的各个模块中需要使用gzip压缩，所以我们也需要提前安装其库及源代码zlib和zlib-devel 可以使用命令yum install -y zlib zlib-devel来进行安装 安装成功后，可以通过rpm -qa zlib zlib-devel来查看是否安装成功 OpenSSL OpenSSL是一个开放源代码的软件库包，应用程序可以使用这个包进行安全通信，并且避免被窃听。 SSL:Secure Sockets Layer安全套接协议的缩写，可以在Internet上提供秘密性传输，其目标是保证两个应用间通信的保密性和可靠性。在Nginx中，如果服务器需要提供安全网页时就需要用到OpenSSL库，所以我们需要对OpenSSL的库文件及它的开发安装包进行一个安装。 可以使用命令yum install -y openssl openssl-devel来进行安装 安装成功后，可以通过rpm -qa openssl openssl-devel来查看是否安装成功 上述命令，一个个来的话比较麻烦，我们也可以通过一条命令来进行安装 yum install -y gcc pcre pcre-devel zlib zlib-devel openssl openssl-devel进行全部安装。 方案一：Nginx的源码简单安装 (1)进入官网查找需要下载版本的链接地址，然后使用wget命令进行下载 1wget http://nginx.org/download/nginx-1.16.1.tar.gz (2)建议大家将下载的资源进行包管理 12mkdir -p nginx/coremv nginx-1.16.1.tar.gz nginx/core (3)解压缩 1tar -xzf nginx-1.16.1.tar.gz (4)进入资源文件中，发现configure 1./configure (5)编译 1make (6)安装 1make install 方案二：yum安装 使用源码进行简单安装，我们会发现安装的过程比较繁琐，需要提前准备GCC编译器、PCRE兼容正则表达式库、zlib压缩库、OpenSSL安全通信的软件库包，然后才能进行Nginx的安装。 （1）安装yum-utils 1sudo yum install -y yum-utils （2）添加yum源文件 1vim /etc/yum.repos.d/nginx.repo 123456789101112131415[nginx-stable]name=nginx stable repobaseurl=http://nginx.org/packages/centos/$releasever/$basearch/gpgcheck=1enabled=1gpgkey=https://nginx.org/keys/nginx_signing.keymodule_hotfixes=true[nginx-mainline]name=nginx mainline repobaseurl=http://nginx.org/packages/mainline/centos/$releasever/$basearch/gpgcheck=1enabled=0gpgkey=https://nginx.org/keys/nginx_signing.keymodule_hotfixes=true （3）查看是否安装成功 1yum list | grep nginx （4）使用yum进行安装 1yun install -y nginx （5）查看nginx的安装位置 1whereis nginx （6）启动测试 123cd /usr/sbin./nginx#浏览器打开IPADDR，出现nginx即为启动成功 源码简单安装和yum安装的差异： 这里先介绍一个命令: ./nginx -V,通过该命令可以查看到所安装Nginx的版本及相关配置信息。 简单安装 yum安装 解压Nginx目录 执行tar -zxvf nginx-1.16.1.tar.gz对下载的资源进行解压缩，进入压缩后的目录，可以看到如下结构 内容解释： auto:存放的是编译相关的脚本 CHANGES:版本变更记录 CHANGES.ru:俄罗斯文的版本变更记录 conf:nginx默认的配置文件 configure:nginx软件的自动脚本程序,是一个比较重要的文件，作用如下： ​ （1）检测环境及根据环境检测结果生成C代码 ​ （2）生成编译代码需要的Makefile文件 contrib:存放的是几个特殊的脚本文件，其中README中对脚本有着详细的说明 html:存放的是Nginx自带的两个html页面，访问Nginx的首页和错误页面 LICENSE:许可证的相关描述文件 man:nginx的man手册 README:Nginx的阅读指南 src:Nginx的源代码 方案三:Nginx的源码复杂安装 这种方式和简单的安装配置不同的地方在第一步，通过./configure来对编译参数进行设置，需要我们手动来指定。那么都有哪些参数可以进行设置，接下来我们进行一个详细的说明。 PATH:是和路径相关的配置信息 with:是启动模块，默认是关闭的 without:是关闭模块，默认是开启的 我们先来认识一些简单的路径配置已经通过这些配置来完成一个简单的编译： –prefix=PATH 1指向Nginx的安装目录，默认值为/usr/local/nginx –sbin-path=PATH 1指向(执行)程序文件(nginx)的路径,默认值为&lt;prefix&gt;/sbin/nginx –modules-path=PATH 1指向Nginx动态模块安装目录，默认值为&lt;prefix&gt;/modules –conf-path=PATH 1指向配置文件(nginx.conf)的路径,默认值为&lt;prefix&gt;/conf/nginx.conf –error-log-path=PATH 1指向错误日志文件的路径,默认值为&lt;prefix&gt;/logs/error.log –http-log-path=PATH 1指向访问日志文件的路径,默认值为&lt;prefix&gt;/logs/access.log –pid-path=PATH 1指向Nginx启动后进行ID的文件路径，默认值为&lt;prefix&gt;/logs/nginx.pid –lock-path=PATH 1指向Nginx锁文件的存放路径,默认值为&lt;prefix&gt;/logs/nginx.lock 要想使用可以通过如下命令 12345678./configure --prefix=/usr/local/nginx \\--sbin-path=/usr/local/nginx/sbin/nginx \\--modules-path=/usr/local/nginx/modules \\--conf-path=/usr/local/nginx/conf/nginx.conf \\--error-log-path=/usr/local/nginx/logs/error.log \\--http-log-path=/usr/local/nginx/logs/access.log \\--pid-path=/usr/local/nginx/logs/nginx.pid \\--lock-path=/usr/local/nginx/logs/nginx.lock 在使用上述命令之前，需要将之前服务器已经安装的nginx进行卸载，卸载的步骤分为三步骤： 步骤一：需要将nginx的进程关闭 1./nginx -s stop 步骤二:将安装的nginx进行删除 1rm -rf /usr/local/nginx 步骤三:将安装包之前编译的环境清除掉 1make clean Nginx目录结构分析 在使用Nginx之前，我们先对安装好的Nginx目录文件进行一个分析，在这块给大家介绍一个工具tree，通过tree我们可以很方面的去查看centos系统上的文件目录结构，当然，如果想使用tree工具，就得先通过yum install -y tree来进行安装，安装成功后，可以通过执行tree /usr/local/nginx(tree后面跟的是Nginx的安装目录)，获取的结果如下： conf:nginx所有配置文件目录 ​ CGI(Common Gateway Interface)通用网关【接口】，主要解决的问题是从客户端发送一个请求和数据，服务端获取到请求和数据后可以调用调用CGI【程序】处理及相应结果给客户端的一种标准规范。 ​ fastcgi.conf:fastcgi相关配置文件 ​ fastcgi.conf.default:fastcgi.conf的备份文件 ​ fastcgi_params:fastcgi的参数文件 ​ fastcgi_params.default:fastcgi的参数备份文件 ​ scgi_params:scgi的参数文件 ​ scgi_params.default：scgi的参数备份文件 ​ uwsgi_params:uwsgi的参数文件 ​ uwsgi_params.default:uwsgi的参数备份文件 ​ mime.types:记录的是HTTP协议中的Content-Type的值和文件后缀名的对应关系 ​ mime.types.default:mime.types的备份文件 ​ nginx.conf:这个是Nginx的核心配置文件，这个文件非常重要，也是我们即将要学习的重点 ​ nginx.conf.default:nginx.conf的备份文件 ​ koi-utf、koi-win、win-utf这三个文件都是与编码转换映射相关的配置文件，用来将一种编码转换成另一种编码 html:存放nginx自带的两个静态的html页面 ​ 50x.html:访问失败后的失败页面 ​ index.html:成功访问的默认首页 logs:记录入门的文件，当nginx服务器启动后，这里面会有 access.log error.log 和nginx.pid三个文件出现。 sbin:是存放执行程序文件nginx ​ nginx是用来控制Nginx的启动和停止等相关的命令。 Nginx服务器启停命令 Nginx安装完成后，接下来我们要学习的是如何启动、重启和停止Nginx的服务。 对于Nginx的启停在linux系统中也有很多种方式，我们本次课程介绍两种方式： Nginx服务的信号控制 Nginx的命令行控制 方式一:Nginx服务的信号控制 12345Nginx中的master和worker进程?Nginx的工作方式?如何获取进程的PID?信号有哪些?如何通过信号控制Nginx的启停等相关操作? 前面在提到Nginx的高性能，其实也和它的架构模式有关。Nginx默认采用的是多进程的方式来工作的，当将Nginx启动后，我们通过ps -ef | grep nginx命令可以查看到如下内容： ps 命令 ：获取正在运行进程信息 grep：过滤nginx相关命令 从上图中可以看到,Nginx后台进程中包含一个master进程和多个worker进程，master进程主要用来管理worker进程，包含接收外界的信息，并将接收到的信号发送给各个worker进程，监控worker进程的状态，当worker进程出现异常退出后，会自动重新启动新的worker进程。而worker进程则是专门用来处理用户请求的，各个worker进程之间是平等的并且相互独立，处理请求的机会也是一样的。nginx的进程模型，我们可以通过下图来说明下： 我们现在作为管理员，只需要通过给master进程发送信号就可以来控制Nginx,这个时候我们需要有两个前提条件，一个是要操作的master进程，一个是信号。 （1）要想操作Nginx的master进程，就需要获取到master进程的进程号ID。获取方式简单介绍两个， 方式一：通过ps -ef | grep nginx； 方式二：在讲解nginx的./configure的配置参数的时候，有一个参数是--pid-path=PATH默认是/usr/local/nginx/logs/nginx.pid,所以可以通过查看该文件来获取nginx的master进程ID. （2）信号 信号 作用 TERM/INT 立即关闭整个服务 QUIT &quot;优雅&quot;地关闭整个服务 HUP 重读配置文件并使用服务对新配置项生效 USR1 重新打开日志文件，可以用来进行日志切割 USR2 平滑升级到最新版的nginx WINCH 所有子进程不在接收处理新连接，相当于给work进程发送QUIT指令 调用命令为kill -signal PID 例如 kill -TERM 20211 signal:即为信号；PID即为获取到的master线程ID 发送TERM/INT信号给master进程，会将Nginx服务立即关闭。 12kill -TERM PID / kill -TERM `cat /usr/local/nginx/logs/nginx.pid`kill -INT PID / kill -INT `cat /usr/local/nginx/logs/nginx.pid` 发送QUIT信号给master进程，master进程会控制所有的work进程不再接收新的请求，等所有请求处理完后，在把进程都关闭掉。 1kill -QUIT PID / kill -TERM `cat /usr/local/nginx/logs/nginx.pid` 发送HUP信号给master进程，master进程会把控制旧的work进程不再接收新的请求，等处理完请求后将旧的work进程关闭掉，然后根据nginx的配置文件重新启动新的work进程 1kill -HUP PID / kill -TERM `cat /usr/local/nginx/logs/nginx.pid` 发送USR1信号给master进程，告诉Nginx重新开启日志文件 1kill -USR1 PID / kill -TERM `cat /usr/local/nginx/logs/nginx.pid` 发送USR2信号给master进程，告诉master进程要平滑升级，这个时候，会重新开启对应的master进程和work进程，整个系统中将会有两个master进程，并且新的master进程的PID会被记录在/usr/local/nginx/logs/nginx.pid而之前的旧的master进程PID会被记录在/usr/local/nginx/logs/nginx.pid.oldbin文件中，接着再次发送QUIT信号给旧的master进程，让其处理完请求后再进行关闭 1kill -USR2 PID / kill -USR2 `cat /usr/local/nginx/logs/nginx.pid` 1kill -QUIT PID / kill -QUIT `cat /usr/local/nginx/logs/nginx.pid.oldbin` 发送WINCH信号给master进程,让master进程控制不让所有的work进程在接收新的请求了，请求处理完后关闭work进程。注意master进程不会被关闭掉 1kill -WINCH PID /kill -WINCH`cat /usr/local/nginx/logs/nginx.pid` 方式二:Nginx的命令行控制 此方式是通过Nginx安装目录下的sbin下的可执行文件nginx来进行Nginx状态的控制，我们可以通过nginx -h来查看都有哪些参数可以用： -?和-h:显示帮助信息 -v:打印版本号信息并退出 -V:打印版本号信息和配置信息并退出 -t:测试nginx的配置文件语法是否正确并退出 -T:测试nginx的配置文件语法是否正确并列出用到的配置文件信息然后退出 -q:在配置测试期间禁止显示非错误消息 -s:signal信号，后面可以跟 ： ​ stop[快速关闭，类似于TERM/INT信号的作用] ​ quit[优雅的关闭，类似于QUIT信号的作用] ​ reopen[重新打开日志文件类似于USR1信号的作用] ​ reload[类似于HUP信号的作用] -p:prefix，指定Nginx的prefix路径，(默认为: /usr/local/nginx/) -c:filename,指定Nginx的配置文件路径,(默认为: conf/nginx.conf) -g:用来补充Nginx配置文件，向Nginx服务指定启动时应用全局的配置 Nginx服务器版本升级和新增模块 如果想对Nginx的版本进行更新，或者要应用一些新的模块，最简单的做法就是停止当前的Nginx服务，然后开启新的Nginx服务。但是这样会导致在一段时间内，用户是无法访问服务器。为了解决这个问题，我们就需要用到Nginx服务器提供的平滑升级功能。这个也是Nginx的一大特点，使用这种方式，就可以使Nginx在7*24小时不间断的提供服务了。接下来我们分析下需求： 1需求：Nginx的版本最开始使用的是Nginx-1.14.2,由于服务升级，需要将Nginx的版本升级到Nginx-1.16.1,要求Nginx不能中断提供服务。 为了应对上述的需求，这里我们给大家提供两种解决方案: 方案一:使用Nginx服务信号完成Nginx的升级 方案二:使用Nginx安装目录的make命令完成升级 环境准备 （1）先准备两个版本的Nginx分别是 1.14.2和1.16.1 （2）使用Nginx源码安装的方式将1.14.2版本安装成功并正确访问 123进入安装目录./configuremake &amp;&amp; make install （3）将Nginx1.16.1进行参数配置和编译，不需要进行安装。 123进入安装目录./configuremake 方案一:使用Nginx服务信号进行升级 第一步:将1.14.2版本的sbin目录下的nginx进行备份 12cd /usr/local/nginx/sbinmv nginx nginxold 第二步:将Nginx1.16.1安装目录编译后的objs目录下的nginx文件，拷贝到原来/usr/local/nginx/sbin目录下 12cd ~/nginx/core/nginx-1.16.1/objscp nginx /usr/local/nginx/sbin 第三步:发送信号USR2给Nginx的1.14.2版本对应的master进程 第四步:发送信号QUIT给Nginx的1.14.2版本对应的master进程 1kill -QUIT `more /usr/local/logs/nginx.pid.oldbin` 方案二:使用Nginx安装目录的make命令完成升级 第一步:将1.14.2版本的sbin目录下的nginx进行备份 12cd /usr/local/nginx/sbinmv nginx nginxold 第二步:将Nginx1.16.1安装目录编译后的objs目录下的nginx文件，拷贝到原来/usr/local/nginx/sbin目录下 12cd ~/nginx/core/nginx-1.16.1/objscp nginx /usr/local/nginx/sbin 第三步:进入到安装目录，执行make upgrade 第四步:查看是否更新成功 1./nginx -v 在整个过程中，其实Nginx是一直对外提供服务的。并且当Nginx的服务器启动成功后，我们是可以通过浏览器进行直接访问的，同时我们可以通过更改html目录下的页面来修改我们在页面上所看到的内容，那么问题来了，为什么我们要修改html目录下的文件，能不能多添加一些页面是Nginx的功能更加丰富，还有前面聊到Nginx的前端功能又是如何来实现的，这就需要我们对Nginx的核心配置文件进行一个详细的学习。 Nginx核心配置文件结构 从前面的内容学习中，我们知道Nginx的核心配置文件默认是放在/usr/local/nginx/conf/nginx.conf，这一节，我们就来学习下nginx.conf的内容和基本配置方法。 读取Nginx自带的Nginx配置文件，我们将其中的注释部分【学习一个技术点就是在Nginx的配置文件中可以使用#来注释】删除掉后，就剩下下面内容: 1234567891011121314151617181920212223242526worker_processes 1;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; server &#123; listen 80; server_name localhost; location / &#123; root html; index index.html index.htm; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; &#125;&#125; 123456789101112131415161718指令名 指令值; #全局块，主要设置Nginx服务器整体运行的配置指令 #events块,主要设置,Nginx服务器与用户的网络连接,这一部分对Nginx服务器的性能影响较大events &#123; 指令名 指令值;&#125;#http块，是Nginx服务器配置中的重要部分，代理、缓存、日志记录、第三方模块配置... http &#123; 指令名 指令值; server &#123; #server块，是Nginx配置和虚拟主机相关的内容 指令名 指令值; location / &#123; #location块，基于Nginx服务器接收请求字符串与location后面的值进行匹配，对特定请求进行处理 指令名 指令值; &#125; &#125; ...&#125; 简单小结下: nginx.conf配置文件中默认有三大块：全局块、events块、http块 http块中可以配置多个server块，每个server块又可以配置多个location块。 全局块 user指令 （1）user:用于配置运行Nginx服务器的worker进程的用户和用户组。 语法 user user [group] 默认值 nobody 位置 全局块 该属性也可以在编译的时候指定，语法如下./configure --user=user --group=group,如果两个地方都进行了设置，最终生效的是配置文件中的配置。 该指令的使用步骤: (1)设置一个用户信息&quot;www&quot; 1user www; (2) 创建一个用户 1useradd www (3)修改user属性 1user www (4)创建/root/html/index.html页面，添加如下内容 123456789101112131415161718192021222324252627&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;Welcome to nginx!&lt;/title&gt;&lt;style&gt; body &#123; width: 35em; margin: 0 auto; font-family: Tahoma, Verdana, Arial, sans-serif; &#125;&lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;&lt;p&gt;If you see this page, the nginx web server is successfully installed andworking. Further configuration is required.&lt;/p&gt;&lt;p&gt;For online documentation and support please refer to&lt;a href=&quot;http://nginx.org/&quot;&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;Commercial support is available at&lt;a href=&quot;http://nginx.com/&quot;&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;I am WWW&lt;/em&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; (5)修改nginx.conf 1234location / &#123; root /root/html; index index.html index.htm;&#125; (5)测试启动访问 1页面会报403拒绝访问的错误 (6)分析原因 1因为当前用户没有访问/root/html目录的权限 (7)将文件创建到 /home/www/html/index.html,修改配置 1234location / &#123; root /home/www/html; index index.html index.htm;&#125; (8)再次测试启动访问 1能正常访问。 综上所述，使用user指令可以指定启动运行工作进程的用户及用户组，这样对于系统的权限访问控制的更加精细，也更加安全。 work process指令 master_process:用来指定是否开启工作进程。 语法 master_process on|off; 默认值 master_process on; 位置 全局块 worker_processes:用于配置Nginx生成工作进程的数量，这个是Nginx服务器实现并发处理服务的关键所在。理论上来说workder process的值越大，可以支持的并发处理量也越多，但事实上这个值的设定是需要受到来自服务器自身的限制，建议将该值和服务器CPU的内核数保存一致。 语法 worker_processes num/auto; 默认值 1 位置 全局块 如果将worker_processes设置成2，则会看到如下内容: 其他指令 daemon：设定Nginx是否以守护进程的方式启动。 守护式进程是linux后台执行的一种服务进程，特点是独立于控制终端，不会随着终端关闭而停止。 语法 daemon on|off; 默认值 daemon on; 位置 全局块 pid:用来配置Nginx当前master进程的进程号ID存储的文件路径。 语法 pid file; 默认值 默认为:/usr/local/nginx/logs/nginx.pid 位置 全局块 该属性可以通过./configure --pid-path=PATH来指定 error_log:用来配置Nginx的错误日志存放路径 语法 error_log file [日志级别]; 默认值 error_log logs/error.log error; 位置 全局块、http、server、location 该属性可以通过./configure --error-log-path=PATH来指定 其中日志级别的值有：debug|info|notice|warn|error|crit|alert|emerg，翻译过来为试|信息|通知|警告|错误|临界|警报|紧急，这块建议大家设置的时候不要设置成info以下的等级，因为会带来大量的磁盘I/O消耗，影响Nginx的性能。 （5）include:用来引入其他配置文件，使Nginx的配置更加灵活 语法 include file; 默认值 无 位置 any events块 （1）accept_mutex:用来设置Nginx网络连接序列化 语法 accept_mutex on|off; 默认值 accept_mutex on; 位置 events 这个配置主要可以用来解决常说的&quot;惊群&quot;问题。大致意思是在某一个时刻，客户端发来一个请求连接，Nginx后台是以多进程的工作模式，也就是说有多个worker进程会被同时唤醒，但是最终只会有一个进程可以获取到连接，如果每次唤醒的进程数目太多，就会影响Nginx的整体性能。如果将上述值设置为on(开启状态)，将会对多个Nginx进程接收连接进行序列号，一个个来唤醒接收，就防止了多个进程对连接的争抢。 （2）multi_accept:用来设置是否允许同时接收多个网络连接 语法 multi_accept on|off; 默认值 multi_accept off; 位置 events 如果multi_accept被禁止了，nginx一个工作进程只能同时接受一个新的连接。否则，一个工作进程可以同时接受所有的新连接 （3）worker_connections：用来配置单个worker进程最大的连接数 语法 worker_connections number; 默认值 worker_commections 512; 位置 events 这里的连接数不仅仅包括和前端用户建立的连接数，而是包括所有可能的连接数。另外，number值不能大于操作系统支持打开的最大文件句柄数量。 （4）use:用来设置Nginx服务器选择哪种事件驱动来处理网络消息。 语法 use method; 默认值 根据操作系统定 位置 events 注意：此处所选择事件处理模型是Nginx优化部分的一个重要内容，method的可选值有select/poll/epoll/kqueue等，之前在准备centos环境的时候，我们强调过要使用linux内核在2.6以上，就是为了能使用epoll函数来优化Nginx。 另外这些值的选择，我们也可以在编译的时候使用 --with-select_module、--without-select_module、 --with-poll_module、 --without-poll_module来设置是否需要将对应的事件驱动模块编译到Nginx的内核。 events指令配置实例 打开Nginx的配置文件 nginx.conf,添加如下配置 123456events&#123; accept_mutex on; multi_accept on; worker_commections 1024; use epoll;&#125; 启动测试 12./nginx -t./nginx -s reload http块 定义MIME-Type 我们都知道浏览器中可以显示的内容有HTML、XML、GIF等种类繁多的文件、媒体等资源，浏览器为了区分这些资源，就需要使用MIME Type。所以说MIME Type是网络资源的媒体类型。Nginx作为web服务器，也需要能够识别前端请求的资源类型。 在Nginx的配置文件中，默认有两行配置 12include mime.types;default_type application/octet-stream; （1）default_type:用来配置Nginx响应前端请求默认的MIME类型。 语法 default_type mime-type; 默认值 default_type text/plain； 位置 http、server、location 在default_type之前还有一句include mime.types,include之前我们已经介绍过，相当于把mime.types文件中MIMT类型与相关类型文件的文件后缀名的对应关系加入到当前的配置文件中。 举例来说明： 有些时候请求某些接口的时候需要返回指定的文本字符串或者json字符串，如果逻辑非常简单或者干脆是固定的字符串，那么可以使用nginx快速实现，这样就不用编写程序响应请求了，可以减少服务器资源占用并且响应性能非常快。 如何实现: 123456789location /get_text &#123; #这里也可以设置成text/plain default_type text/html; return 200 &quot;This is nginx&#x27;s text&quot;;&#125;location /get_json&#123; default_type application/json; return 200 &#x27;&#123;&quot;name&quot;:&quot;TOM&quot;,&quot;age&quot;:18&#125;&#x27;;&#125; 自定义服务日志 Nginx中日志的类型分access.log、error.log。 access.log:用来记录用户所有的访问请求。 error.log:记录nginx本身运行时的错误信息，不会记录用户的访问请求。 Nginx服务器支持对服务日志的格式、大小、输出等进行设置，需要使用到两个指令，分别是access_log和log_format指令。 （1）access_log:用来设置用户访问日志的相关属性。 语法 access_log path[format[buffer=size]] 默认值 access_log logs/access.log combined; 位置 http, server, location （2）log_format:用来指定日志的输出格式。 语法 log_format name [escape=default|json|none] string…; 默认值 log_format combined “…”; 位置 http 其他配置指令 （1）sendfile:用来设置Nginx服务器是否使用sendfile()传输文件，该属性可以大大提高Nginx处理静态资源的性能 语法 sendfile on|off； 默认值 sendfile off; 位置 http、server、location （2）keepalive_timeout:用来设置长连接的超时时间。 》为什么要使用keepalive？ 12我们都知道HTTP是一种无状态协议，客户端向服务端发送一个TCP请求，服务端响应完毕后断开连接。如何客户端向服务端发送多个请求，每个请求都需要重新创建一次连接，效率相对来说比较多，使用keepalive模式，可以告诉服务器端在处理完一个请求后保持这个TCP连接的打开状态，若接收到来自这个客户端的其他请求，服务端就会利用这个未被关闭的连接，而不需要重新创建一个新连接，提升效率，但是这个连接也不能一直保持，这样的话，连接如果过多，也会是服务端的性能下降，这个时候就需要我们进行设置其的超时时间。 语法 keepalive_timeout time; 默认值 keepalive_timeout 75s; 位置 http、server、location （3）keepalive_requests:用来设置一个keep-alive连接使用的次数。 语法 keepalive_requests number; 默认值 keepalive_requests 100; 位置 http、server、location server块和location块 server块和location块都是我们要重点讲解和学习的内容，因为我们后面会对Nginx的功能进行详细讲解，所以这块内容就放到静态资源部署的地方给大家详细说明。 本节我们主要来认识下Nginx默认给的nginx.conf中的相关内容，以及server块与location块在使用的时候需要注意的一些内容。 12345678910111213server &#123; listen 80; server_name localhost; location / &#123; root html; index index.html index.htm; &#125; error_page 500 502 503 504 404 /50x.html; location = /50x.html &#123; root html; &#125; &#125;","categories":[{"name":"Web开发","slug":"Web开发","permalink":"http://kaillliu.github.io/categories/Web%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://kaillliu.github.io/tags/Java/"},{"name":"Centos","slug":"Centos","permalink":"http://kaillliu.github.io/tags/Centos/"},{"name":"Linux","slug":"Linux","permalink":"http://kaillliu.github.io/tags/Linux/"}]},{"title":"CentOS 7 安装 JAVA环境（JDK 1.8）","slug":"CentOS 7安装JAVA环境（JDK 1.8）","date":"2022-04-21T06:29:13.000Z","updated":"2022-04-21T06:30:12.821Z","comments":true,"path":"2022/04/21/CentOS 7安装JAVA环境（JDK 1.8）/","link":"","permalink":"http://kaillliu.github.io/2022/04/21/CentOS%207%E5%AE%89%E8%A3%85JAVA%E7%8E%AF%E5%A2%83%EF%BC%88JDK%201.8%EF%BC%89/","excerpt":"","text":"卸载CentOS默认安装的OpenJDK 查看是否安装 OpenJDK 1234java -versionopenjdk version &quot;1.8.0_222&quot;OpenJDK Runtime Environment (build 1.8.0_222-b10)OpenJDK 64-Bit Server VM (build 25.222-b10, mixed mode) 复制 查看安装位置 123456789rpm -qa | grep javajavamail-1.4.6-8.el7.noarchpython-javapackages-3.4.1-11.el7.noarchtzdata-java-2019b-1.el7.noarchjavapackages-tools-3.4.1-11.el7.noarchjava-1.8.0-openjdk-headless-1.8.0.222.b10-0.el7_6.x86_64java-1.8.0-openjdk-1.8.0.222.b10-0.el7_6.x86_64javassist-3.16.1-10.el7.noarchjava-1.8.0-openjdk-devel-1.8.0.222.b10-0.el7_6.x86_64 复制 执行语句删除openjdk 123rpm -e --nodeps java-1.8.0-openjdk-headless-1.8.0.222.b10-0.el7_6.x86_64rpm -e --nodeps java-1.8.0-openjdk-1.8.0.222.b10-0.el7_6.x86_64rpm -e --nodeps java-1.8.0-openjdk-devel-1.8.0.222.b10-0.el7_6.x86_64 复制 检查是否删除 12java -version-bash: /usr/bin/java: No such file or directory 复制 安装Oracle Java JDK 8 从官网下载jdk-8u221-linux-x64.tar.gz。 下载后通过ftp上传到服务器。 创建目录，解压 12mkdir /usr/javatar zvxf jdk-8u221-linux-x64.tar.gz -C /usr/java 复制 环境配置，修改profile文件 1vi /etc/profile 添加 123export JAVA_HOME=/usr/java/jdk1.8.0_221export PATH=$JAVA_HOME/bin:$PATHexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar 复制 使环境变量生效 1source /etc/profile 检查是否配置成功 1234java -versionjava version &quot;1.8.0_221&quot;Java(TM) SE Runtime Environment (build 1.8.0_221-b11)Java HotSpot(TM) 64-Bit Server VM (build 25.221-b11, mixed mode) 复制","categories":[{"name":"Java","slug":"Java","permalink":"http://kaillliu.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://kaillliu.github.io/tags/Java/"},{"name":"Centos","slug":"Centos","permalink":"http://kaillliu.github.io/tags/Centos/"}]},{"title":"在VMware上安装Centos7系统","slug":"在VMware上安装Centos7系统在VMware上安装Centos7系统","date":"2022-04-19T09:18:13.000Z","updated":"2022-05-23T05:41:23.080Z","comments":true,"path":"2022/04/19/在VMware上安装Centos7系统在VMware上安装Centos7系统/","link":"","permalink":"http://kaillliu.github.io/2022/04/19/%E5%9C%A8VMware%E4%B8%8A%E5%AE%89%E8%A3%85Centos7%E7%B3%BB%E7%BB%9F%E5%9C%A8VMware%E4%B8%8A%E5%AE%89%E8%A3%85Centos7%E7%B3%BB%E7%BB%9F/","excerpt":"","text":"前言 本地虚拟机服务器，使用CentOs7，运维环境是宝塔面板。 工具 VMware Workstation Pro 15.5.5（虚拟机） CentOs7（iso镜像） 阿里云镜像：http://mirrors.aliyun.com/centos/7/isos/x86_64/ Xshell（用于连接虚拟机，方便使用Linux命令，是一个远程工具，右键就可以复制粘贴，还可以拉滚动条。） 虚拟机vmnet8 ip 虚拟机里面的虚拟网络需要设置一下，虚拟机里面的虚拟网络需要处理一下，虚拟机里面的虚拟网络需要编辑一下。 下图标记2的地方，勾勾要去掉，去掉之后点击NAT设置，查看虚拟机的vmnet8 ip，把红框里的子网IP、子网掩码、默认网关用文本记下来，然后点击确定。 记住子网IP、子网掩码、网关 创建虚拟机 点击创建新的虚拟机。 点击自定义，下一步。 选择虚拟机版本，我这里是15.5.5，下一步 点击稍后安装操作系统，下一步。 选择Linux操作系统，现在安装的是entOs7，所以版本选择CentOs7 64位，下一步。 虚拟机名称随意，可以中文，这里我写的是服务器ip名（可以重命名的），为了方便定位，不用我说都懂的啦，从左边栏就可以看出100、101、102没有102，哎？我跳过102了？我是把流程走一遍再码字的，码字的时候，服务器已经ok了，不过问题不大，下一步。。。。 默认（本站的核心是2个，但是我100、101都是1个核心，这里默认1个核心够用了），本地服务器，也就自己一个人访问，而且这里配置是跟本机电脑配置有关的，服务器一核心足矣（只要电脑带得动，给八核我也没意见），下一步。 默认（本站的内存是1GB，但是我100、101都是2GB，这里默认1GB够用了），同上（如果在阿里云买服务器，我建议是1核心2GB内存哦），下一步。 点击使用网络地址转换(NAT)，下一步。 默认，下一步。 默认，下一步。 默认，下一步。 默认（磁盘大小自己改，20GB实际上够了，下面选项默认），下一步。 默认，下一步。 点击自定义硬件。 点击打印机，然后点击移除。 跟着数字的步骤走（步骤3：选择下载好的CentOs7镜像，我个人是推荐放在服务器根目录下，看我图中的路径，这里不明白要留言哦）。 点击完成。 安装CentOs7系统 点击开启此虚拟机。 这里说一下，默认选中的是Test this this media &amp; install CentOS 7（白色字体是选中状态），按方向键↑然后回车（如果按键没效果，需要把鼠标点一下虚拟机显示屏）。 中文在最下面，滚下去或者拉到下面才看到（下面的搜索chinese），点击继续。 这里看一下自己的日期和时间是不是亚洲/上海 时区，不是的话自己进去调一下（百度）。 点击软件选择。 把红框里的两个勾勾点上，完成。 点击安装位置。 点击我要配置分区，完成。 点击点这里自动创建他们，完成。 默认，/boot（启动文件），swap（交换分区，类似windows虚拟内存。看内存总大小，如果内存足够大，这个空间就要设置很大，如果内存小于2G，那么这个空间设置成内存的2倍大小。），/（根分区），完成。 点击接受更改。 点击网络和主机名。 打开以太网，修改主机名（也可以使用默认），然后点击应用（点完应用后看看以太网是不是关闭了，如果关闭了再点开），完成。 点击开始安装。 点击ROOT密码。 设置密码，我这里设置123456（本机的，起个好记的就好），完成（点两次）。 等待安装（根据自己的需求去创建用户吧，但是创建后可能某些操作需要root权限，不折腾就不要创了，昨晚搞CentOs8服务器差点崩溃，CentOs8是规定要创建用户的，CentOs7和CentOs8就跟windows7和windows10一样）。 安装完毕，点击重启。 选择第一个。 我的用户名是root，密码123456。 输入用户名root，回车。 输入密码123456（不可见的，输入就行了），回车。 配置服务器静态ip（需要配置服务器动态ip的自己百度一下） 打开目录：cd /etc/sysconfig/network-scripts/（复制粘贴就好，这个复制粘贴有点麻烦，找不到的就手敲，正是这样才要用Xshell工具来远程，得先配置ip，忍一忍吧），回车。 我这里显示的是ifcfg-ens33，这里要说一下，我百度过，有些是32，也有1667777，先用cd /etc/sysconfig/network-scripts/进入目录，然后ll显示列表（ls也可以显示列表，只显示列表名）。 编辑ifcfg-ens33：vi ifcfg-ens33（vi：进入编辑模式，文件名别敲错。），回车。 按 i 字母键进入编辑模式（如果不显示下图的，肯定是vi ifcfg-ens33输入错了，自己检查一下，退出vi方法：按Esc（注意左下角），输入:q!（不保存退出））。 看图 1234#虚拟机IP相同，但是IPADDR后三位在3~240之间选择IPADDR=192.168.157.103NETMASK=255.255.255.0GATEWAY=192.168.157.2 保存并退出：按Esc键，然后输入:wq（必须小写），回车。 重启网络：systemctl restart network，回车。 查看ip：ip addr， 回车。 配置本地的网络（只需要配置一次） 这是本地访问虚拟机要配置的 12#选择使用下面的IP地址,最后一位为 1 ，子网掩码自动生成IP=192.168.157.1 使用Xshell连接虚拟机服务器 新建会话，这里隧道要取消转发X11连接到： 新建会话，输入IPADDR名称192.168.157.103（输入名称后，下面的主机也是同步的。），然后点击连接。 出现这个弹窗就说明99.99%成功了，如果没有就说明本地网络配置出错 输入用户名root。 输入用户名123456。 okay。 安装宝塔面板 宝塔官网：https://www.bt.cn/ 宝塔Linux面板命令大全：https://www.bt.cn/btcode.html（一定要多看） 这里标注几个常用的命令（本文章用到的）：cd、clear（清屏，也可以用Ctrl+L）、ll（当前列表，详细的展示列表），ls（当前列表，简洁的展示列表）、vi 文件名（编辑文件，按Esc：:wq保存并退出、:q（退出）、:q!强制不保存并退出）。 安装 安装脚本：yum install -y wget &amp;&amp; wget -O install.sh http://download.bt.cn/install/install_6.0.sh &amp;&amp; sh install.sh PS：此脚本从官方复制过来的时间为2020年6月19日，仅限CentOs系统，如果距离已久，请到官网复制。 右键随意复制粘贴，Xshell工具的好处（佛主：https://www.kancloud.cn/jiangguowu/kfjsdkfjskd/1076752）。 DO you want to install Bt Panel tothe /www directory now?(y/n):（现在是否要将Bt面板安装到/www目录？（是/否）：）。 按y，回车。 宝塔面板访问地址：http://192.168.157.103:8888/7a81976f，119.137.3.117换成192.168.157.103自己设置的服务器ip（别傻了，只有本地才能访问）。 username: yq0g4uxd password: c937d4a9 点击一键安装（也可以不选择，然后自己去左边的软件商店自己选择安装）。 建议设置一下安全入口、面板用户、面板密码（只能设置8位数，为了方便，我强行使用命令行将密码设置为123456，命令：cd /www/server/panel &amp;&amp; python tools.py panel 123456，更多的宝塔命令请到宝塔Linux面板命令大全查看：https://www.bt.cn/btcode.html） 参考链接： 配置步骤： https://www.cnblogs.com/langting/p/13167539.html https://blog.langting.top/archives/117.html 虚拟机网络相关问题的解决 https://blog.csdn.net/weixin_44080445/article/details/110714332","categories":[{"name":"Web开发","slug":"Web开发","permalink":"http://kaillliu.github.io/categories/Web%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://kaillliu.github.io/tags/Java/"},{"name":"Centos","slug":"Centos","permalink":"http://kaillliu.github.io/tags/Centos/"},{"name":"Linux","slug":"Linux","permalink":"http://kaillliu.github.io/tags/Linux/"},{"name":"虚拟机","slug":"虚拟机","permalink":"http://kaillliu.github.io/tags/%E8%99%9A%E6%8B%9F%E6%9C%BA/"}]},{"title":"设计模式总览","slug":"设计模式","date":"2022-04-12T09:27:23.000Z","updated":"2022-04-12T11:05:30.789Z","comments":true,"path":"2022/04/12/设计模式/","link":"","permalink":"http://kaillliu.github.io/2022/04/12/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"书本网盘链接😀 链接：https://pan.baidu.com/s/1KU0Ik8WTDn5fwBGvDd5dQw?pwd=rlye 提取码：rlye CSDN总结： https://blog.csdn.net/cooldragon/article/details/52164380 范围 创建型 结构型 行为型 类 Factory Method（工厂方法） Adapter(类)（适配器） Interpreter（解释器）Template Method（模版方法） 对象 Abstract Factory（抽象工厂）Builder（建造者）Prototype（原型）Singleton（单例） Adapter(对象)（适配器)Bridge（桥接）Composite（组合）Decorator（装饰者）Façade（外观）Flyweight（享元）Proxy（代理） Chain of Responsibility（职责链）CoMmand（命令）Iterator（迭代器）Mediator（中介者）Memento（备忘录）Observer（观察者）State（状体）Strategy（策略）Visitor（访问者）","categories":[{"name":"计算机基础","slug":"计算机基础","permalink":"http://kaillliu.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://kaillliu.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"计算机基础","slug":"计算机基础","permalink":"http://kaillliu.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"}]},{"title":"设计模式笔记之Factory Method（工厂方法）模式","slug":"设计模式笔记之Factory（工厂）模式","date":"2022-04-02T05:36:59.000Z","updated":"2022-05-23T05:41:22.939Z","comments":true,"path":"2022/04/02/设计模式笔记之Factory（工厂）模式/","link":"","permalink":"http://kaillliu.github.io/2022/04/02/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E7%AC%94%E8%AE%B0%E4%B9%8BFactory%EF%BC%88%E5%B7%A5%E5%8E%82%EF%BC%89%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"书本网盘链接😀 链接：https://pan.baidu.com/s/1KU0Ik8WTDn5fwBGvDd5dQw?pwd=rlye 提取码：rlye Factory Method（工厂方法）模式 意图 定义一个用于创建对象的接口，让子类决定实例化哪一个类。Factory Method 使一个类的实例化延迟到其子类。 适用性 • 当一个类不知道它所必须创建的对象的类的时候。 • 当一个类希望由它的子类来指定它所创建的对象的时候。 • 当类将创建对象的职责委托给多个帮助子类中的某一个，并且你希望将哪一个帮助子类是代理者这一信息局部化的时候。 结构 登场角色 Product 产品 定义工厂方法所创建的对象的接口。 Creator 创建者 声明工厂方法,该方法返回一个 Product类型的对象。 Creator也可以定义一个工厂方 法的缺省实现,它返回一个缺省的 ConcreteProduct对象。 ConcreteProduct 具体的产品 决定了具体的产品，实现Product接口。 ConcreteCreator 具体的创建者 负责生成具体的产品，重定义工厂方法以返回一个 ConcreteProduct实例。 优缺点 优点： 首先，良好的封装性，代码结构清晰。一个对象创建是有条件约束的，如一个调用者需要一个具体的产品对象，只要知道这个产品的类名（或约束字符串）就可以了，不用知道创建对象的艰辛过程，降低模块间的耦合。 工厂方法模式是典型的解耦框架。高层模块只需要知道产品的抽象类，其他的实现类都不用关心，符合迪米特法则，我不需要的就不要去交流；也符合依赖倒置原则，只依赖产品类的抽象；当然也符合里氏替换原则，可以使用产品子类替换产品父类。","categories":[{"name":"计算机基础","slug":"计算机基础","permalink":"http://kaillliu.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://kaillliu.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"计算机基础","slug":"计算机基础","permalink":"http://kaillliu.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"}]},{"title":"设计模式笔记之Adapter（适配器）模式","slug":"设计模式笔记之Adapter（适配器）模式","date":"2022-04-02T05:36:59.000Z","updated":"2022-05-23T05:41:22.999Z","comments":true,"path":"2022/04/02/设计模式笔记之Adapter（适配器）模式/","link":"","permalink":"http://kaillliu.github.io/2022/04/02/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E7%AC%94%E8%AE%B0%E4%B9%8BAdapter%EF%BC%88%E9%80%82%E9%85%8D%E5%99%A8%EF%BC%89%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"书本网盘链接😀 链接：https://pan.baidu.com/s/1KU0Ik8WTDn5fwBGvDd5dQw?pwd=rlye 提取码：rlye Adapter（适配器）模式 意图 将一个类的接口转换成另外一个客户希望的接口。Adapter 模式使得原本由于接口不兼容而不能一起工作的那些类可以一起工作。 注：适配器模式在详细设计阶段不需要考虑它，它是为了对现有系统或产品接口兼容时，也就是既成事实的情况下的补救措施。 适用性 你想使用一个已经存在的类，而它的接口不符合你的需求。 你想创建一个可以复用的类，该类可以与其他不相关的类或不可预见的类（即那些接口可能不一定兼容的类）协同工作。 （仅适用于对象Adapter）你想使用一些已经存在的子类，但是不可能对每一个都进行子类化以匹配它们的接口。对象适配器可以适配它的父类接口。 结构 类适配器模式 对象适配器模式 登场角色 **Target (目标角色 对象，要用的接口) ** 定义Client所需的方法。 **Client (使用场景 请求者) ** 与符合Target接口的对象协同，使用Target角色定义的方法进行具体处理。 **Adaptee (被适配) ** 定义一个已经存在的接角色，这个角色需要适配。 Adapter (适配器，把Adaptee接口转换为Target可用的接口) 对Adaptee的接口与Target接口进行适配 优点 可以让两个没有任何关系的类在一起运行，只要适配器这个角色能够搞定他们就成。 增加了类的透明性 提高了类的复用度 灵活性非常好","categories":[{"name":"计算机基础","slug":"计算机基础","permalink":"http://kaillliu.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://kaillliu.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"计算机基础","slug":"计算机基础","permalink":"http://kaillliu.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"}]},{"title":"设计模式笔记之Iterator（迭代器）模式","slug":"设计模式笔记之Iterator（迭代器）模式","date":"2022-04-02T05:36:59.000Z","updated":"2022-05-23T05:41:22.939Z","comments":true,"path":"2022/04/02/设计模式笔记之Iterator（迭代器）模式/","link":"","permalink":"http://kaillliu.github.io/2022/04/02/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E7%AC%94%E8%AE%B0%E4%B9%8BIterator%EF%BC%88%E8%BF%AD%E4%BB%A3%E5%99%A8%EF%BC%89%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"书本网盘链接😀 链接：https://pan.baidu.com/s/1KU0Ik8WTDn5fwBGvDd5dQw?pwd=rlye 提取码：rlye Iterator（迭代器）模式 意图 提供一种方法顺序访问一个聚合对象中各个元素, 而又不需暴露该对象的内部表示，即为遍历和实现可以分离开来。 适用性 访问一个聚合对象的内容而无需暴露它的内部表示。 支持对聚合对象的多种遍历。 为遍历不同的聚合结构提供一个统一的接口（即, 支持多态迭代）。 结构 登场角色 Iterator 迭代器 负责定义访问和遍历元素的接口（API）。 Concretelterator 具体的迭代器 负责实现Iterator角色所定义的接口（API）。 Aggregate 集合 集合定义创建Iterator角色的接口，在示例程序中，由Aggregate接口扮演此角色，里面定义了Iterator方法。 ConcreteAggregate 具体的集合 负责实现Aggregate角色所定义的接口。","categories":[{"name":"计算机基础","slug":"计算机基础","permalink":"http://kaillliu.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://kaillliu.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"计算机基础","slug":"计算机基础","permalink":"http://kaillliu.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"}]},{"title":"设计模式笔记之Template Method（模板方法）模式","slug":"设计模式笔记之Template（模板方法）模式","date":"2022-04-02T05:36:59.000Z","updated":"2022-05-23T05:41:22.939Z","comments":true,"path":"2022/04/02/设计模式笔记之Template（模板方法）模式/","link":"","permalink":"http://kaillliu.github.io/2022/04/02/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E7%AC%94%E8%AE%B0%E4%B9%8BTemplate%EF%BC%88%E6%A8%A1%E6%9D%BF%E6%96%B9%E6%B3%95%EF%BC%89%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"书本网盘链接😀 链接：https://pan.baidu.com/s/1KU0Ik8WTDn5fwBGvDd5dQw?pwd=rlye 提取码：rlye Template Method（模板方法）模式 意图 定义一个操作中的算法的骨架，而将一些步骤延迟到子类中。Template Method使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤。 适用性 一次性实现一个算法的不变的部分，并将可变的行为留给子类来实现。 各子类中公共的 行为应被提取出来并集中到一个公共父类中以避免代码重复。这是Opdyke和Johnson所描述过的“重分解以一般化”的一个很好的例子。首先识别现有 代码中的不同之处，并且将不同之处分离为新的操作。最后，用一个调用这些新的操作的模板方法来替换这些不同的代码。 控制子类扩展。模板方法只在特定点调用“hook”操作，这样就只允许在这些点进行扩展。 结构 登场角色 **AbstractClass(抽象类) ** 负责实现模板方法，声明在模板方法中所使用到的抽象方法。这些抽象方法由子类ConcreteClass角色负责实现。 **ConcreteClass(具体类) ** 负责具体实现AbstractClass角色中定义的抽象方法。 优点 封装不变部分，扩展可变部分 把认为是不变部分的算法封装到父类实现，而可变部分的则可以通过继承来继续扩展。在悍马模型例子中，是不是就非常容易扩展？例如增加一个H3型号的悍马模型，很容易呀，增加一个子类，实现父类的基本方法就可以了。 提取公共部分代码，便于维护 我们例子中刚刚走过的弯路就是最好的证明，如果我们不抽取到父类中，任由这种散乱的代码发生，想想后果是什么样子？维护人员为了修正一个缺陷，需要到处查找类似的代码！ 行为由父类控制，子类实现 基本方法是由子类实现的，因此子类可以通过扩展的方式增加相应的功能，符合开闭原则。 思考 习题3-2 123public final void diaplay()&#123; ...&#125; AbstractDisplay类中使用final 表示子类无法重写display方法。 不要重写模板方法 习题3-4 Java为什么不用接口代替抽象类？ 因为此模式下AbstractClass角色必须实现部分处理流程。接口无法实现","categories":[{"name":"计算机基础","slug":"计算机基础","permalink":"http://kaillliu.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://kaillliu.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"计算机基础","slug":"计算机基础","permalink":"http://kaillliu.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"}]},{"title":"Leetcode-084,085-单调栈-数组中的最大矩阵,最大矩阵","slug":"leetcode-42-数组中的最大矩形","date":"2022-03-29T13:28:00.000Z","updated":"2022-03-31T12:00:14.287Z","comments":true,"path":"2022/03/29/leetcode-42-数组中的最大矩形/","link":"","permalink":"http://kaillliu.github.io/2022/03/29/leetcode-42-%E6%95%B0%E7%BB%84%E4%B8%AD%E7%9A%84%E6%9C%80%E5%A4%A7%E7%9F%A9%E5%BD%A2/","excerpt":"","text":"题目链接：https://leetcode-cn.com/problems/largest-rectangle-in-histogram/ ​ ：https://leetcode-cn.com/problems/maximal-rectangle/ 84. 解法一：暴力求解 123456789101112131415161718192021222324252627//时间复杂度为o(N^2)，提交结果超时class Solution &#123; public int largestRectangleArea(int[] heights) &#123; //定义长度，返回值 int area = 0, n = heights.length; for(int i = 0; i &lt; n; i++)&#123; //确定宽 int left = i; int right = i; //确定左边 for(; left&gt;=0; left--)&#123; if(heights[left] &lt; heights[i])&#123; break; &#125; &#125; //确定右边 for(; right&lt;n; right++)&#123; if(heights[right] &lt; heights[i])&#123; break; &#125; &#125; //计算面积 area = Math.max(area,(heights[i] * (right - left -1))); &#125; return area; &#125;&#125; 解法二：单调栈，用Deque数据结构（来自评论区大佬，太妙了） 1234567891011121314151617181920212223public int largestRectangleArea(int[] heights) &#123; // 这里为了代码简便，在柱体数组的头和尾加了两个高度为 0 的柱体。 // arraycopy(源，起始，目标，目标起始，源长度) int[] tmp = new int[heights.length + 2]; System.arraycopy(heights, 0, tmp, 1, heights.length); Deque&lt;Integer&gt; stack = new ArrayDeque&lt;&gt;(); int area = 0; for (int i = 0; i &lt; tmp.length; i++) &#123; // 对栈中柱体来说，栈中的下一个柱体就是其「左边第一个小于自身的柱体」； // 若当前柱体 i 的高度小于栈顶柱体的高度，说明 i 是栈顶柱体的「右边第一个小于栈顶柱体的柱体」。 // i是右边界 // 因此以栈顶柱体为高的矩形的左右宽度边界就确定了，可以计算面积～ //stack.peek()获得栈顶元素，stack.pop()获取栈顶元素并删除 while (!stack.isEmpty() &amp;&amp; tmp[i] &lt; tmp[stack.peek()]) &#123; int h = tmp[stack.pop()]; area = Math.max(area, (i - stack.peek() - 1) * h); &#125; stack.push(i); &#125; return area; &#125; 85. 解法 给定一个仅包含 0 和 1 、大小为 rows x cols 的二维二进制矩阵，找出只包含 1 的最大矩形，并返回其面积。 思路：转化为84中的求矩阵中的最大矩形，遍历，对每一行求高 123456789101112131415161718192021222324252627282930313233343536373839404142class Solution &#123; //85-最大矩阵 public int maximalRectangle(char[][] matrix) &#123; if(matrix.length == 0 || matrix[0].length == 0)&#123; return 0; &#125; int col = matrix.length; int row = matrix[0].length; int[] heights = new int[row]; int result = 0; //遍历行 for(int i = 0; i &lt; col; i++)&#123; //遍历列，求高 for (int j = 0; j &lt; row; j++) &#123; if(matrix[i][j] == &#x27;1&#x27;) &#123; heights[j] += 1; &#125; else &#123; heights[j] = 0; &#125; &#125; result = Math.max(result,max(heights)); &#125; return result; &#125; //84 public int max(int[] heights)&#123; int[] temp = new int[heights.length + 2]; System.arraycopy(heights, 0, temp, 1, heights.length); Deque&lt;Integer&gt; stack = new ArrayDeque&lt;&gt;(); int area = 0; for(int i = 0; i &lt; temp.length; i++)&#123; while(!stack.isEmpty() &amp;&amp; temp[i] &lt; temp[stack.peek()] )&#123; int h = temp[stack.pop()]; area = Math.max(area,(i - stack.peek() - 1) * h); &#125; stack.push(i); &#125; return area; &#125;&#125;","categories":[{"name":"LeetCode","slug":"LeetCode","permalink":"http://kaillliu.github.io/categories/LeetCode/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://kaillliu.github.io/tags/Java/"},{"name":"LeetCode","slug":"LeetCode","permalink":"http://kaillliu.github.io/tags/LeetCode/"},{"name":"单调栈","slug":"单调栈","permalink":"http://kaillliu.github.io/tags/%E5%8D%95%E8%B0%83%E6%A0%88/"}]},{"title":"Hexo配合Github Pages搭建个人博客","slug":"HI","date":"2022-03-27T08:21:26.000Z","updated":"2023-09-08T03:02:13.930Z","comments":true,"path":"2022/03/27/HI/","link":"","permalink":"http://kaillliu.github.io/2022/03/27/HI/","excerpt":"","text":"前言 目前市面上有成熟的知识分享平台，例如CSDN、掘金等等，也可以被搜索引擎检索到。除此之外也可以自己搭建一个个人博客网站，主要使用的就是 Hexo + GitPage 的方式，本站主要使用 GitHub Page + Hexo搭建静态博客网站。 GitHub Pages 是什么？ What is GitHub Pages? - GitHub Help GitHub Pages 是由 GitHub 官方提供的一种免费的静态站点托管服务，让我们可以在 GitHub 仓库里托管和发布自己的静态网站页面。 Hexo是什么？ 官网：hexo.io Hexo 是一个快速、简洁且高效的静态博客框架，它基于 Node.js 运行，可以将我们撰写的 Markdown 文档解析渲染成静态的 HTML 网页。 为什么使用Hexo + GitHub Pages 优点： 主要是 Hexo 完全免费，静态，轻量快速，并且可以托管在GitHub，当然也可以托管在国内的Gitee里面，但是会麻烦一点。 缺点： 在国内GitHub访问速度一般，前期搭建和发布文章有点点麻烦。 搭建步骤 安装准备 在搭建博客之前，需要确认电脑上已经安装好了 Git 和 Node.js ，然后再安装Hexo。 ​ Node.js 官网 ​ Git 官网 ​ Git 安装教程 ​ Node.js 安装教程 12# 安装Node.js之后使用国内的淘宝镜像源加速，安装之后可以用 cnpm 代替 npmnpm install -g cnpm --registry=https://registry.npm.taobao.org 链接GitHub 需要一个GitHub账号，使用邮箱注册。 配置GitHub账号 123# 配置用户名和邮箱git config --global user.name &quot;github的用户名&quot;git config --global user.email &quot;github的注册邮箱&quot; 创建SSH密钥 12# 生成 ssh 密钥ssh-keygen -t rsa -C &quot;github的注册邮箱&quot; 添加密匙： 进入 C:\\Users\\用户名\\.ssh 目录（要勾选显示“隐藏的项目”），用记事本打开公钥 id_rsa.pub 文件并复制里面的内容。 登陆 GitHub ，进入 Settings 页面，选择左边栏的 SSH and GPG keys，点击 New SSH key。 Title 随便取个名字，粘贴复制的 id_rsa.pub 内容到 Key 中，点击 Add SSH key 完成添加。 验证连接： 打开 Git Bash，输入 ssh -T git@github.com 出现 “Are you sure……”，输入 yes 回车确认。 显示 “Hi xxx! You’ve successfully……” 即连接成功。 新建Github Pages 仓库 GitHub 主页右上角加号 -&gt; New repository： Repository name 中输入 用户名.github.io 勾选 “Initialize this repository with a README” Description 选填 填好后点击 Create repository 创建。 创建后默认自动启用 HTTPS，博客地址为：https://用户名.github.io 本地安装Hexo 新建一个文件夹用来存放 Hexo 的程序文件，如 Hexo-Blog。打开该文件夹，右键 -&gt; Git Bash Here。 安装 Hexo 使用 npm 一键安装 Hexo 博客程序： 1cnpm install -g hexo-cli Hexo 初始化和本地预览 初始化并安装所需组件： 12hexo init # 初始化cnpm install # 安装组件 完成后依次输入下面命令，启动本地服务器进行预览： 1234# hexo clean hexo g # 生成页面hexo s # 启动预览 访问 http://localhost:4000，出现 Hexo 默认页面，本地博客安装成功！ **Tips：**如果出现页面加载不出来，可能是端口被占用了。Ctrl+C 关闭服务器，运行 hexo server -p 5000 更改端口号后重试。 Hexo 博客文件夹目录结构如下： 部署Hexo到GitHub Pages 本地博客测试成功后，就是上传到 GitHub 进行部署，使其能够在网络上访问。 首先安装 hexo-deployer-git： 1cnpm install hexo-deployer-git --save 然后修改 _config.yml 文件末尾的 Deployment 部分，修改成如下： 12345# 仓库地址最好是ssh方式，也可以是http格式，可以在github仓库中查找到deploy: type: git repository: git@github.com:用户名/用户名.github.io.git branch: master 完成后运行 hexo d 将网站上传部署到 GitHub Pages。 完成！这时访问我们的 GitHub 域名 https://用户名.github.io 就可以看到 Hexo 网站了。 绑定域名（待更新） 开始使用 发布文章 进入博客所在目录，右键打开 Git Bash Here，创建博文： 1hexo new &quot;My New Post&quot; 然后 source 文件夹中会出现一个 My New Post.md 文件，就可以使用 Markdown 编辑器在该文件中撰写文章了。 写完后运行下面代码将文章渲染并部署到 GitHub Pages 上完成发布。以后每次发布文章都是这两条命令。 12hexo g # 生成页面hexo d # 部署发布 也可以不使用命令自己创建 .md 文件，只需在文件开头手动加入如下格式 Front-matter 即可，写完后运行 hexo g 和 hexo d 发布。 12345678910111213---title: Hello World # 标题date: 2019/3/26 hh:mm:ss # 时间categories: # 分类- Diarytags: # 标签- PS3- Games---摘要&lt;!--more--&gt;正文 网站设置 包括网站名称、描述、作者、链接样式等，全部在网站目录下的 _config.yml 文件中，参考官方文档按需要编辑。 注意：冒号后要加一个空格！ 更换主题 在 Themes | Hexo 选择一个喜欢的主题，比如 NexT，进入网站目录打开 Git Bash Here 下载主题： 1git clone https://github.com/iissnan/hexo-theme-next themes/next 然后修改 _config.yml 中的 theme 为新主题名称 next，发布。（有的主题需要将 _config.yml 替换为主题自带的，参考主题说明。） 常用命令 12345678hexo new &quot;name&quot; # 新建文章hexo new page &quot;name&quot; # 新建页面hexo g # 生成页面hexo d # 部署hexo g -d # 生成页面并部署hexo s # 本地预览hexo clean # 清除缓存和已生成的静态文件hexo help # 帮助 PicGo + Github + fastly 搭建博客图床 创建仓库 新键一个图片仓库 填好相关信息 获取token token token的意思是“令牌”，是服务端生成的一串字符串，作为客户端进行请求的一个标识。 当用户第一次登录后，服务器生成一个token并将此token返回给客户端，以后客户端只需带上这个token前来请求数据即可，无需再次带上用户名和密码。我们通过token来确定GitHub仓库的位置。 点击setting Settings -&gt; Developer settings -&gt; Personal access tokens，最后点击 generate new token； 点击生成token 保存好生成的token(仅显示一次)，因此最好存放到备忘录里面。 下载PicGo 进入picgo官网: https://picgo.github.io/PicGo-Doc/zh/ 点击免费下载，跳转到GitHub界面，选择对应系统的版本进行安装 设置PicGo 选择GitHub图床，根据提示填写，保存图片的库可以更换，只需要把PicGo里面的仓库名对应改掉就行 在picgo设置里面可以设置上传的快捷键，此外，最好打开时间戳重命名功能，防止图片名字重复 fastly加速 fastly的全称是Content Delivery Network，即内容分发网络。其目的是通过在现有的internet中增加一层新的网络架构，将网站的内容发布到最接近用户的网络边缘，使用户可以就近取得所需的内容，提高用户访问网站的响应速度。 在这里，我们选择了快速免费公有的fastly-jsdelivr 配置方法： 只需要在我们 PicGo 图床配置中添加如下自定义域名即可 https://fastly.jsdelivr.net/gh/用户名/仓库名 到这里，一个图床算是基本搭建好了。通过picgo上传图片，会在GitHub创建的仓库中保存。 Markdown编辑器Typora的设置（可选） Markdown 官网：https://markdown.com.cn/ Markdown是一种轻量级的「标记语言」，通常为程序员群体所用，目前它已是全球最大的技术分享网站 GitHub 和技术问答网站 StackOverFlow 的御用书写格式。 markdown的优点： 专注于文字内容； 纯文本，易读易写，可以方便地纳入版本控制； 语法简单，没有什么学习成本，能轻松在码字的同时做出美观大方的排版。 Typora ypora是一个专注于markdown语言的优秀编辑器。 官网：https://typora.io/ 打开Typora的偏好设置，设置好红色方框里面的内容，便可以在Typora里面编写文章的同时上传图片到图床了。 常见问题 设置网站图标 进入 themes/主题 文件夹，打开 _config.yml 配置文件，找到 favicon 修改，一般格式为：favicon: 图标地址。（不同主题可能略有差别） 修改并部署后没有效果 使用 hexo clean 清理后重新部署。 开启 HTTPS 后访问网站显示连接不安全？ 证书还未部署生效，等待一会儿，清除浏览器缓存再试。 Hexo部署出现错误err: Error: Spawn failed解决方式 https://blog.csdn.net/weixin_41256398/article/details/117994899 Github连接出现ssh: connect to host github.com port 22: Connection timed out 错误 ​ Github连接出现ssh: connect to host github.com port 22: Connection timed out 错误 ​ git commit、merge 如何退出git bash vim编辑器 更换电脑重新设置hexo 123npm installnpm install hexo-deployer-git --savenpm i hexo-generator-json-content --save 参考资料 Easy Hexo ：包括Hexo快速开始，推荐主题，插件使用等等 Butterfly：本站使用的主题 搭建教程： https://zhuanlan.zhihu.com/p/60578464 https://blog.csdn.net/github_39655029/article/details/116485386 使用ssh连接Git仓库（Github) https://www.jianshu.com/p/20089411571d PicGo+GitHub图床搭建部分的参考 https://zhuanlan.zhihu.com/p/350598351 https://zhuanlan.zhihu.com/p/138012354 Node.js 使用淘宝 NPM 镜像的相关说明 https://www.twle.cn/l/yufei/nodejs/nodejs-basic-cnpm.html","categories":[{"name":"Hexo","slug":"Hexo","permalink":"http://kaillliu.github.io/categories/Hexo/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://kaillliu.github.io/tags/Hexo/"}]}],"categories":[{"name":"题库","slug":"题库","permalink":"http://kaillliu.github.io/categories/%E9%A2%98%E5%BA%93/"},{"name":"知识点梳理","slug":"知识点梳理","permalink":"http://kaillliu.github.io/categories/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86/"},{"name":"故障诊断","slug":"故障诊断","permalink":"http://kaillliu.github.io/categories/%E6%95%85%E9%9A%9C%E8%AF%8A%E6%96%AD/"},{"name":"GitHub","slug":"GitHub","permalink":"http://kaillliu.github.io/categories/GitHub/"},{"name":"Web开发","slug":"Web开发","permalink":"http://kaillliu.github.io/categories/Web%E5%BC%80%E5%8F%91/"},{"name":"Java","slug":"Java","permalink":"http://kaillliu.github.io/categories/Java/"},{"name":"计算机基础","slug":"计算机基础","permalink":"http://kaillliu.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"},{"name":"LeetCode","slug":"LeetCode","permalink":"http://kaillliu.github.io/categories/LeetCode/"},{"name":"Hexo","slug":"Hexo","permalink":"http://kaillliu.github.io/categories/Hexo/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://kaillliu.github.io/tags/Java/"},{"name":"面试题","slug":"面试题","permalink":"http://kaillliu.github.io/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/"},{"name":"题库","slug":"题库","permalink":"http://kaillliu.github.io/tags/%E9%A2%98%E5%BA%93/"},{"name":"计算机网络","slug":"计算机网络","permalink":"http://kaillliu.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"操作系统","slug":"操作系统","permalink":"http://kaillliu.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"websocket","slug":"websocket","permalink":"http://kaillliu.github.io/tags/websocket/"},{"name":"多线程","slug":"多线程","permalink":"http://kaillliu.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"知识点梳理","slug":"知识点梳理","permalink":"http://kaillliu.github.io/tags/%E7%9F%A5%E8%AF%86%E7%82%B9%E6%A2%B3%E7%90%86/"},{"name":"Spring","slug":"Spring","permalink":"http://kaillliu.github.io/tags/Spring/"},{"name":"Redis","slug":"Redis","permalink":"http://kaillliu.github.io/tags/Redis/"},{"name":"MySQL","slug":"MySQL","permalink":"http://kaillliu.github.io/tags/MySQL/"},{"name":"深度学习","slug":"深度学习","permalink":"http://kaillliu.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"CNN","slug":"CNN","permalink":"http://kaillliu.github.io/tags/CNN/"},{"name":"故障诊断","slug":"故障诊断","permalink":"http://kaillliu.github.io/tags/%E6%95%85%E9%9A%9C%E8%AF%8A%E6%96%AD/"},{"name":"GitHub","slug":"GitHub","permalink":"http://kaillliu.github.io/tags/GitHub/"},{"name":"Centos","slug":"Centos","permalink":"http://kaillliu.github.io/tags/Centos/"},{"name":"docket","slug":"docket","permalink":"http://kaillliu.github.io/tags/docket/"},{"name":"Linux","slug":"Linux","permalink":"http://kaillliu.github.io/tags/Linux/"},{"name":"虚拟机","slug":"虚拟机","permalink":"http://kaillliu.github.io/tags/%E8%99%9A%E6%8B%9F%E6%9C%BA/"},{"name":"设计模式","slug":"设计模式","permalink":"http://kaillliu.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"计算机基础","slug":"计算机基础","permalink":"http://kaillliu.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"},{"name":"LeetCode","slug":"LeetCode","permalink":"http://kaillliu.github.io/tags/LeetCode/"},{"name":"单调栈","slug":"单调栈","permalink":"http://kaillliu.github.io/tags/%E5%8D%95%E8%B0%83%E6%A0%88/"},{"name":"Hexo","slug":"Hexo","permalink":"http://kaillliu.github.io/tags/Hexo/"}]}